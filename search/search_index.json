{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to hydroutils","text":"<p>A collection of commonly used utility functions for hydrological modeling and analysis</p> <p><code>hydroutils</code> is a comprehensive Python package that provides essential tools and utilities for hydrological data processing, statistical analysis, and modeling. It is designed to streamline common tasks in hydrology research and engineering applications.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#statistical-analysis","title":"\ud83d\udcca Statistical Analysis","text":"<ul> <li>Comprehensive hydrological statistics (NSE, KGE, RMSE, Bias, etc.)</li> <li>Flow duration curve analysis</li> <li>Peak flow analysis and timing metrics</li> <li>Flood event extraction and characterization</li> </ul>"},{"location":"#time-series-processing","title":"\ud83d\udd50 Time Series Processing","text":"<ul> <li>Time unit conversions and standardization</li> <li>Time interval detection and validation</li> <li>Temporal data manipulation utilities</li> </ul>"},{"location":"#data-visualization","title":"\ud83d\udcc8 Data Visualization","text":"<ul> <li>Specialized plotting functions for hydrological data</li> <li>Flow duration curves</li> <li>Time series plots with hydrological context</li> </ul>"},{"location":"#file-operations","title":"\ud83d\udcc1 File Operations","text":"<ul> <li>NetCDF file handling</li> <li>CSV and text file processing</li> <li>Data import/export utilities</li> </ul>"},{"location":"#cloud-integration","title":"\u2601\ufe0f Cloud Integration","text":"<ul> <li>AWS S3 integration for large dataset handling</li> <li>Cloud-based data storage and retrieval</li> </ul>"},{"location":"#mathematical-operations","title":"\ud83e\uddee Mathematical Operations","text":"<ul> <li>Hydrological unit conversions</li> <li>Mathematical utilities for water resources calculations</li> <li>Array operations optimized for hydrological data</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import hydroutils as hu\n\n# Calculate hydrological statistics\nnse = hu.stat_error(observed, simulated)['NSE']\n\n# Extract flood events\nevents = hu.extract_flood_events(dataframe)\n\n# Convert streamflow units\nconverted = hu.streamflow_unit_conv(data, from_unit='cms', to_unit='cfs')\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install hydroutils\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Installation Guide - Detailed installation instructions</li> <li>Usage Examples - Practical examples and tutorials  </li> <li>API Reference - Complete API documentation</li> <li>Contributing - How to contribute to the project</li> <li>FAQ - Frequently asked questions</li> </ul>"},{"location":"#license-credits","title":"License &amp; Credits","text":"<ul> <li>Free software: MIT license</li> <li>Documentation: https://zhuanglaihong.github.io/hydroutils</li> <li>Created with Cookiecutter and the giswqs/pypackage project template</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to the hydroutils project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#v0014-2025-08-19","title":"v0.0.14 - 2025-08-19","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>\u5b8c\u6574\u7684\u9879\u76ee\u6587\u6863\u7ed3\u6784\uff0c\u5305\u62ecAPI\u53c2\u8003\u3001\u4f7f\u7528\u6307\u5357\u548c\u793a\u4f8b</li> <li>\u65b0\u589e\u6c34\u6587\u7edf\u8ba1\u5206\u6790\u6a21\u5757 (<code>hydro_stat</code>)</li> <li>\u652f\u6301NSE\u3001KGE\u3001RMSE\u7b49\u591a\u79cd\u8bc4\u4ef7\u6307\u6807</li> <li>\u6d2a\u6c34\u4e8b\u4ef6\u63d0\u53d6\u548c\u5206\u6790\u529f\u80fd</li> <li>\u6d41\u91cf\u6301\u7eed\u66f2\u7ebf\u5206\u6790</li> <li>\u65f6\u95f4\u5e8f\u5217\u5904\u7406\u6a21\u5757 (<code>hydro_time</code>)</li> <li>\u65f6\u95f4\u95f4\u9694\u68c0\u6d4b\u548c\u9a8c\u8bc1</li> <li>\u5355\u4f4d\u8f6c\u6362\u529f\u80fd</li> <li>\u53ef\u89c6\u5316\u5de5\u5177\u6a21\u5757 (<code>hydro_plot</code>)</li> <li>\u6c34\u6587\u6570\u636e\u4e13\u7528\u7ed8\u56fe\u51fd\u6570</li> <li>\u6a21\u578b\u8bc4\u4ef7\u53ef\u89c6\u5316\u5de5\u5177</li> <li>\u53d1\u5e03\u7ea7\u522b\u56fe\u8868\u8f93\u51fa</li> <li>AWS S3\u96c6\u6210\u6a21\u5757 (<code>hydro_s3</code>)</li> <li>\u652f\u6301\u5927\u89c4\u6a21\u6c34\u6587\u6570\u636e\u4e91\u5b58\u50a8</li> <li>\u6279\u91cf\u6570\u636e\u4e0a\u4f20\u4e0b\u8f7d</li> <li>\u65e5\u5fd7\u5de5\u5177\u6a21\u5757 (<code>hydro_log</code>)</li> <li>\u4e13\u4e1a\u7684\u6c34\u6587\u5206\u6790\u65e5\u5fd7\u8bb0\u5f55</li> <li>\u6027\u80fd\u76d1\u63a7\u548c\u9519\u8bef\u8ffd\u8e2a</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>\u91cd\u6784\u4e86\u9879\u76ee\u7ed3\u6784\uff0c\u4f18\u5316\u6a21\u5757\u7ec4\u7ec7</li> <li>\u6539\u8fdb\u4e86\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387</li> <li>\u66f4\u65b0\u4e86\u6240\u6709\u4f9d\u8d56\u5305\u7684\u7248\u672c\u8981\u6c42</li> <li>\u7edf\u4e00\u4e86\u4ee3\u7801\u98ce\u683c\u548c\u6587\u6863\u683c\u5f0f</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>\u4fee\u590d\u4e86\u7edf\u8ba1\u8ba1\u7b97\u4e2d\u7684NaN\u503c\u5904\u7406\u95ee\u9898</li> <li>\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u5bf9\u9f50\u7684bug</li> <li>\u4fee\u6b63\u4e86\u5355\u4f4d\u8f6c\u6362\u7684\u7cbe\u5ea6\u95ee\u9898</li> <li>\u4f18\u5316\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u89e3\u51b3\u4e86\u5927\u6570\u636e\u5904\u7406\u65f6\u7684\u5185\u5b58\u6ea2\u51fa</li> </ul>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<ul> <li>\u79fb\u9664\u4e86\u8fc7\u65f6\u7684\u6570\u636e\u683c\u5f0f\u652f\u6301</li> <li>\u5e9f\u5f03\u4e86\u90e8\u5206\u4e0d\u63a8\u8350\u4f7f\u7528\u7684\u51fd\u6570\u63a5\u53e3</li> </ul>"},{"location":"changelog/#v0013-2025-07-15","title":"v0.0.13 - 2025-07-15","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>\u521d\u59cb\u7248\u672c\u53d1\u5e03</li> <li>\u57fa\u7840\u7684\u6c34\u6587\u7edf\u8ba1\u529f\u80fd</li> <li>\u7b80\u5355\u7684\u6570\u636e\u5904\u7406\u5de5\u5177</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>\u57fa\u7840\u529f\u80fd\u5b9e\u73b0\u548c\u6d4b\u8bd5</li> </ul>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#planned","title":"Planned","text":"<ul> <li>\u589e\u52a0\u673a\u5668\u5b66\u4e60\u6a21\u5757\u652f\u6301</li> <li>\u6dfb\u52a0\u66f4\u591a\u6c34\u6587\u6a21\u578b\u8bc4\u4ef7\u6307\u6807</li> <li>\u6539\u8fdb\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd</li> <li>\u4f18\u5316\u5927\u89c4\u6a21\u6570\u636e\u5904\u7406\u6027\u80fd</li> <li>\u6dfb\u52a0\u66f4\u591a\u5355\u5143\u6d4b\u8bd5\u548c\u96c6\u6210\u6d4b\u8bd5</li> </ul>"},{"location":"changelog/#version-number-guide","title":"Version Number Guide","text":"<ul> <li>MAJOR version (x.0.0) - \u4e0d\u517c\u5bb9\u7684API\u4fee\u6539</li> <li>MINOR version (0.x.0) - \u5411\u540e\u517c\u5bb9\u7684\u529f\u80fd\u6027\u65b0\u589e</li> <li>PATCH version (0.0.x) - \u5411\u540e\u517c\u5bb9\u7684\u95ee\u9898\u4fee\u590d</li> </ul>"},{"location":"changelog/#links","title":"Links","text":""},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/zhuanglaihong/hydroutils/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>hydroutils could always use more documentation, whether as part of the official hydroutils docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/zhuanglaihong/hydroutils/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up hydroutils for local development.</p> <ol> <li> <p>Fork the hydroutils repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/hydroutils.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv hydroutils\n$ cd hydroutils/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 hydroutils tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and     for PyPy. Check https://github.com/zhuanglaihong/hydroutils/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"faq/#q-how-do-i-install-hydroutils","title":"Q: How do I install hydroutils?","text":"<p>A: The easiest way is using pip: <pre><code>pip install hydroutils\n</code></pre></p> <p>For the latest development version: <pre><code>pip install git+https://github.com/zhuanglaihong/hydroutils.git\n</code></pre></p>"},{"location":"faq/#q-what-python-versions-are-supported","title":"Q: What Python versions are supported?","text":"<p>A: hydroutils supports Python 3.8 and higher. We recommend using Python 3.10 or later for the best performance and compatibility.</p>"},{"location":"faq/#q-im-getting-import-errors-what-should-i-do","title":"Q: I'm getting import errors. What should I do?","text":"<p>A: First, ensure all dependencies are installed: <pre><code>pip install --upgrade hydroutils\n</code></pre></p> <p>If you're still having issues, try installing in a fresh virtual environment: <pre><code>python -m venv hydroutils-env\nsource hydroutils-env/bin/activate  # On Windows: hydroutils-env\\Scripts\\activate\npip install hydroutils\n</code></pre></p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#q-how-do-i-calculate-basic-hydrological-statistics","title":"Q: How do I calculate basic hydrological statistics?","text":"<p>A: Use the <code>stat_error</code> function: <pre><code>import hydroutils as hu\nimport numpy as np\n\nobserved = np.array([10.5, 12.3, 8.7, 15.2, 11.8])\nsimulated = np.array([10.1, 12.8, 8.9, 14.7, 11.2])\n\nstats = hu.stat_error(observed, simulated)\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\nprint(f\"RMSE: {stats['RMSE'][0]:.3f}\")\n</code></pre></p>"},{"location":"faq/#q-can-i-handle-missing-data-nan-values","title":"Q: Can I handle missing data (NaN values)?","text":"<p>A: Yes, most functions automatically handle NaN values by excluding them from calculations: <pre><code>obs_with_nan = np.array([1.0, 2.0, np.nan, 4.0, 5.0])\nsim_with_nan = np.array([1.1, 2.2, 3.1, 4.2, np.nan])\n\n# This works fine - NaN values are automatically excluded\nstats = hu.stat_error(obs_with_nan, sim_with_nan)\n</code></pre></p>"},{"location":"faq/#q-how-do-i-convert-between-different-flow-units","title":"Q: How do I convert between different flow units?","text":"<p>A: Use the <code>streamflow_unit_conv</code> function: <pre><code># Convert from cubic meters per second to cubic feet per second\nflow_cms = np.array([10.5, 12.3, 8.7])\nflow_cfs = hu.streamflow_unit_conv(flow_cms, from_unit='cms', to_unit='cfs')\n</code></pre></p>"},{"location":"faq/#q-what-performance-metrics-are-available","title":"Q: What performance metrics are available?","text":"<p>A: hydroutils provides many standard hydrological metrics: - NSE: Nash-Sutcliffe Efficiency - KGE: Kling-Gupta Efficiency - RMSE: Root Mean Square Error - Bias: Mean Error - Corr: Pearson Correlation Coefficient - R2: Coefficient of Determination - FHV/FLV: High/Low Flow Volume metrics</p>"},{"location":"faq/#data-processing","title":"Data Processing","text":""},{"location":"faq/#q-how-do-i-process-multiple-time-series-at-once","title":"Q: How do I process multiple time series at once?","text":"<p>A: Use the <code>stat_errors</code> function for batch processing: <pre><code># Multiple stations data (5 stations, 100 time steps each)\nobserved_series = np.random.rand(5, 100)\nsimulated_series = observed_series + np.random.normal(0, 0.1, (5, 100))\n\n# Calculate statistics for all series\nall_stats = hu.stat_errors(observed_series, simulated_series)\n\n# Extract NSE values for all stations\nnse_values = [stats['NSE'][0] for stats in all_stats]\n</code></pre></p>"},{"location":"faq/#q-can-i-work-with-pandas-dataframes","title":"Q: Can I work with pandas DataFrames?","text":"<p>A: Yes, you can easily work with pandas DataFrames: <pre><code>import pandas as pd\n\n# Convert DataFrame columns to numpy arrays\ndf = pd.read_csv('streamflow_data.csv')\nobs = df['observed'].values\nsim = df['simulated'].values\n\nstats = hu.stat_error(obs, sim)\n</code></pre></p>"},{"location":"faq/#q-how-do-i-handle-different-time-intervals","title":"Q: How do I handle different time intervals?","text":"<p>A: Use the time processing functions: <pre><code># Detect time interval automatically\ntime_series = pd.date_range('2020-01-01', periods=100, freq='D')\ninterval = hu.detect_time_interval(time_series)\n\n# Validate unit compatibility\nis_compatible = hu.validate_unit_compatibility('cms', 'streamflow')\n</code></pre></p>"},{"location":"faq/#visualization","title":"Visualization","text":""},{"location":"faq/#q-how-do-i-create-basic-plots","title":"Q: How do I create basic plots?","text":"<p>A: Use the hydro_plot module: <pre><code>import matplotlib.pyplot as plt\n\n# Time series plot\nfig, ax = hu.plot_timeseries(\n    dates, observed, simulated,\n    labels=['Observed', 'Simulated'],\n    title='Streamflow Comparison'\n)\nplt.show()\n\n# Performance scatter plot\nfig, ax = hu.plot_scatter_performance(\n    observed, simulated,\n    add_stats=True,\n    add_1to1_line=True\n)\nplt.show()\n</code></pre></p>"},{"location":"faq/#q-can-i-customize-plot-appearance","title":"Q: Can I customize plot appearance?","text":"<p>A: Yes, hydroutils provides several styling options: <pre><code># Set hydrological plot style\nhu.set_hydro_plot_style()\n\n# Use hydrological color schemes\ncolors = hu.get_hydro_colors(data_type='streamflow')\n</code></pre></p>"},{"location":"faq/#advanced-features","title":"Advanced Features","text":""},{"location":"faq/#q-how-do-i-use-aws-s3-integration","title":"Q: How do I use AWS S3 integration?","text":"<p>A: First configure your AWS credentials, then use S3 functions: <pre><code># Upload data to S3\nhu.upload_to_s3(\n    local_file='data.csv',\n    bucket='my-hydro-data',\n    s3_key='station_001/data.csv'\n)\n\n# Download from S3\nhu.download_from_s3(\n    bucket='my-hydro-data',\n    s3_key='station_001/data.csv',\n    local_file='downloaded_data.csv'\n)\n</code></pre></p>"},{"location":"faq/#q-how-do-i-enable-logging-for-my-analysis","title":"Q: How do I enable logging for my analysis?","text":"<p>A: Use the logging utilities: <pre><code># Setup logger\nlogger = hu.setup_hydro_logger(\n    name='my_analysis',\n    log_file='analysis.log',\n    level='INFO'\n)\n\n# Log your analysis steps\nlogger.info(\"Starting streamflow analysis\")\nstats = hu.stat_error(observed, simulated)\nlogger.info(f\"NSE calculated: {stats['NSE'][0]:.3f}\")\n</code></pre></p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#q-im-getting-unexpected-nse-values-what-could-be-wrong","title":"Q: I'm getting unexpected NSE values. What could be wrong?","text":"<p>A: Check these common issues: 1. Data alignment: Ensure observed and simulated data have the same time periods 2. Missing values: Make sure missing data is properly handled 3. Data quality: Check for outliers or unrealistic values 4. Array dimensions: Verify that arrays have the same shape</p> <pre><code># Debug your data\nprint(f\"Observed shape: {observed.shape}\")\nprint(f\"Simulated shape: {simulated.shape}\")\nprint(f\"NaN count in observed: {np.isnan(observed).sum()}\")\nprint(f\"NaN count in simulated: {np.isnan(simulated).sum()}\")\n</code></pre>"},{"location":"faq/#q-why-am-i-getting-poor-performance-metrics","title":"Q: Why am I getting poor performance metrics?","text":"<p>A: Consider these factors: 1. Model quality: The underlying model may need improvement 2. Data period: Performance can vary by season or flow conditions 3. Metric selection: Different metrics emphasize different aspects of performance 4. Data preprocessing: Check if data normalization or transformation is needed</p>"},{"location":"faq/#q-functions-are-running-slowly-how-can-i-improve-performance","title":"Q: Functions are running slowly. How can I improve performance?","text":"<p>A: Try these optimization strategies: 1. Use appropriate data types: Convert to float32 if high precision isn't needed 2. Process in chunks: For very large datasets, process data in smaller chunks 3. Vectorize operations: Use NumPy operations instead of loops 4. Consider memory usage: Monitor memory consumption for large arrays</p> <pre><code># Example of chunked processing\ndef process_large_dataset(large_array, chunk_size=10000):\n    results = []\n    for i in range(0, len(large_array), chunk_size):\n        chunk = large_array[i:i+chunk_size]\n        result = hu.stat_error(chunk['obs'], chunk['sim'])\n        results.append(result)\n    return results\n</code></pre>"},{"location":"faq/#getting-help","title":"Getting Help","text":""},{"location":"faq/#q-where-can-i-find-more-examples","title":"Q: Where can I find more examples?","text":"<p>A: Check these resources: 1. Usage Guide: Detailed examples in the Usage section 2. API Documentation: Complete function reference in API Reference 3. GitHub Examples: Example notebooks in the repository 4. Community: Ask questions in GitHub Issues</p>"},{"location":"faq/#q-how-do-i-report-bugs-or-request-features","title":"Q: How do I report bugs or request features?","text":"<p>A: Please use the GitHub Issues: 1. Bug Reports: Create a bug report 2. Feature Requests: Request a new feature 3. Questions: Use the Discussions section</p>"},{"location":"faq/#q-can-i-contribute-to-the-project","title":"Q: Can I contribute to the project?","text":"<p>A: Yes! We welcome contributions. See the Contributing Guide for details on: - Setting up a development environment - Code style guidelines - Testing requirements - Submitting pull requests</p>"},{"location":"faq/#q-is-there-a-citation-for-academic-use","title":"Q: Is there a citation for academic use?","text":"<p>A: Yes, if you use hydroutils in academic research, please cite: <pre><code>@software{hydroutils,\n  author = {Your Name},\n  title = {hydroutils: A Python package for hydrological analysis},\n  url = {https://github.com/zhuanglaihong/hydroutils},\n  version = {X.X.X},\n  year = {2024}\n}\n</code></pre></p>"},{"location":"faq/#still-need-help","title":"Still Need Help?","text":"<p>If your question isn't answered here:</p> <ol> <li>Search existing issues: GitHub Issues</li> <li>Ask a question: GitHub Discussions</li> <li>Email support: [Contact Information]</li> </ol> <p>We're here to help you succeed with your hydrological analysis!</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<p><code>hydroutils</code> requires Python 3.8 or higher. The package has been tested on:</p> <ul> <li>Python 3.8, 3.9, 3.10, 3.11</li> <li>Windows, macOS, and Linux</li> </ul>"},{"location":"installation/#core-dependencies","title":"Core Dependencies","text":"<p>The following packages are automatically installed:</p> <ul> <li><code>numpy</code> - Array operations and mathematical functions</li> <li><code>pandas</code> - Data manipulation and analysis</li> <li><code>scipy</code> - Scientific computing</li> <li><code>matplotlib</code> - Plotting and visualization</li> <li><code>xarray</code> - Labeled multi-dimensional arrays</li> <li><code>netCDF4</code> - NetCDF file handling</li> <li><code>HydroErr</code> - Hydrological error metrics</li> </ul>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For extended functionality:</p> <ul> <li><code>boto3</code> - AWS S3 integration (for cloud features)</li> <li><code>jupyter</code> - For notebook examples</li> </ul>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#1-stable-release-recommended","title":"1. Stable Release (Recommended)","text":"<p>Install the latest stable release from PyPI:</p> <pre><code>pip install hydroutils\n</code></pre> <p>This is the preferred method as it installs the most recent stable release with all dependencies.</p>"},{"location":"installation/#2-development-version","title":"2. Development Version","text":"<p>For the latest features and bug fixes, install from GitHub:</p> <pre><code>pip install git+https://github.com/zhuanglaihong/hydroutils.git\n</code></pre>"},{"location":"installation/#3-from-source","title":"3. From Source","text":"<p>If you want to contribute or modify the code:</p> <pre><code># Clone the repository\ngit clone https://github.com/zhuanglaihong/hydroutils.git\ncd hydroutils\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"installation/#4-with-optional-dependencies","title":"4. With Optional Dependencies","text":"<p>To install with all optional dependencies:</p> <pre><code>pip install hydroutils[all]\n</code></pre> <p>Or install specific optional dependencies:</p> <pre><code>pip install hydroutils[aws]     # For S3 functionality\npip install hydroutils[viz]     # For advanced visualization\npip install hydroutils[dev]     # For development tools\n</code></pre>"},{"location":"installation/#virtual-environment-setup","title":"Virtual Environment Setup","text":"<p>We recommend using a virtual environment to avoid dependency conflicts:</p>"},{"location":"installation/#using-conda","title":"Using conda","text":"<pre><code># Create a new environment\nconda create -n hydroutils python=3.10\nconda activate hydroutils\n\n# Install hydroutils\npip install hydroutils\n</code></pre>"},{"location":"installation/#using-venv","title":"Using venv","text":"<pre><code># Create a new environment\npython -m venv hydroutils-env\n\n# Activate the environment\n# On Windows:\nhydroutils-env\\Scripts\\activate\n# On macOS/Linux:\nsource hydroutils-env/bin/activate\n\n# Install hydroutils\npip install hydroutils\n</code></pre>"},{"location":"installation/#verification","title":"Verification","text":"<p>Test your installation:</p> <pre><code>import hydroutils as hu\nprint(hu.__version__)\n\n# Quick functionality test\nimport numpy as np\nobs = np.random.rand(100)\nsim = obs + np.random.normal(0, 0.1, 100)\nstats = hu.stat_error(obs, sim)\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Import Error: Make sure all dependencies are installed:    <pre><code>pip install --upgrade hydroutils\n</code></pre></p> </li> <li> <p>Permission Denied: Use <code>--user</code> flag:    <pre><code>pip install --user hydroutils\n</code></pre></p> </li> <li> <p>SSL Certificate Error: Try with trusted hosts:    <pre><code>pip install --trusted-host pypi.org --trusted-host pypi.python.org hydroutils\n</code></pre></p> </li> </ol>"},{"location":"installation/#platform-specific-notes","title":"Platform-Specific Notes","text":"<p>Windows Users: - Consider using Anaconda for easier scientific package management - Some dependencies may require Visual C++ Build Tools</p> <p>macOS Users: - Xcode command line tools may be required for some dependencies - Use Homebrew to install system-level dependencies if needed</p> <p>Linux Users: - Install system dependencies for scientific packages:   <pre><code># Ubuntu/Debian\nsudo apt-get install python3-dev gfortran libopenblas-dev\n\n# CentOS/RHEL\nsudo yum install python3-devel gcc-gfortran openblas-devel\n</code></pre></p>"},{"location":"installation/#getting-help","title":"Getting Help","text":"<p>If you encounter any installation issues:</p> <ol> <li>Check the FAQ for common solutions</li> <li>Search existing issues</li> <li>Create a new issue with:</li> <li>Your operating system and Python version</li> <li>Complete error message</li> <li>Steps to reproduce the problem</li> </ol>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide provides practical examples of how to use <code>hydroutils</code> for common hydrological analysis tasks.</p>"},{"location":"usage/#getting-started","title":"Getting Started","text":"<pre><code>import hydroutils as hu\nimport numpy as np\nimport pandas as pd\n</code></pre>"},{"location":"usage/#1-statistical-analysis","title":"1. Statistical Analysis","text":""},{"location":"usage/#basic-hydrological-statistics","title":"Basic Hydrological Statistics","text":"<p>Calculate common hydrological performance metrics:</p> <pre><code># Sample data\nobserved = np.array([10.5, 12.3, 8.7, 15.2, 11.8, 9.4, 13.6])\nsimulated = np.array([10.1, 12.8, 8.9, 14.7, 11.2, 9.8, 13.1])\n\n# Calculate comprehensive statistics\nstats = hu.stat_error(observed, simulated)\n\nprint(f\"Nash-Sutcliffe Efficiency (NSE): {stats['NSE'][0]:.3f}\")\nprint(f\"Root Mean Square Error (RMSE): {stats['RMSE'][0]:.3f}\")\nprint(f\"Bias: {stats['Bias'][0]:.3f}\")\nprint(f\"Correlation: {stats['Corr'][0]:.3f}\")\nprint(f\"Kling-Gupta Efficiency (KGE): {stats['KGE'][0]:.3f}\")\n</code></pre>"},{"location":"usage/#kling-gupta-efficiency","title":"Kling-Gupta Efficiency","text":"<p>Calculate KGE individually:</p> <pre><code>kge_value = hu.KGE(simulated, observed)\nprint(f\"KGE: {kge_value:.3f}\")\n</code></pre>"},{"location":"usage/#flow-duration-curve-analysis","title":"Flow Duration Curve Analysis","text":"<pre><code># Calculate flow duration curve slope\nfms_value = hu.fms(observed, simulated, lower=0.2, upper=0.7)\nprint(f\"Flow Duration Curve Middle Slope: {fms_value:.3f}\")\n</code></pre>"},{"location":"usage/#2-time-series-processing","title":"2. Time Series Processing","text":""},{"location":"usage/#unit-conversions","title":"Unit Conversions","text":"<p>Convert between different streamflow units:</p> <pre><code># Convert cubic meters per second to cubic feet per second\nflow_cms = np.array([10.5, 12.3, 8.7, 15.2])\nflow_cfs = hu.streamflow_unit_conv(flow_cms, from_unit='cms', to_unit='cfs')\nprint(f\"Flow in CFS: {flow_cfs}\")\n\n# Detect time interval\ntime_series = pd.date_range('2020-01-01', periods=100, freq='D')\ninterval = hu.detect_time_interval(time_series)\nprint(f\"Detected interval: {interval}\")\n</code></pre>"},{"location":"usage/#time-interval-validation","title":"Time Interval Validation","text":"<pre><code># Validate unit compatibility\nis_compatible = hu.validate_unit_compatibility('cms', 'streamflow')\nprint(f\"CMS compatible with streamflow: {is_compatible}\")\n\n# Get time interval information\ninterval_info = hu.get_time_interval_info('1D')\nprint(f\"Daily interval info: {interval_info}\")\n</code></pre>"},{"location":"usage/#3-data-processing-with-files","title":"3. Data Processing with Files","text":""},{"location":"usage/#reading-and-processing-data","title":"Reading and Processing Data","text":"<pre><code># Example of processing a CSV file with hydrological data\ndata = pd.read_csv('streamflow_data.csv', parse_dates=['date'])\n\n# Calculate statistics for multiple stations\nstations = ['station_001', 'station_002', 'station_003']\nresults = {}\n\nfor station in stations:\n    if f'{station}_obs' in data.columns and f'{station}_sim' in data.columns:\n        obs = data[f'{station}_obs'].dropna()\n        sim = data[f'{station}_sim'].dropna()\n\n        # Align data\n        min_length = min(len(obs), len(sim))\n        obs = obs[:min_length]\n        sim = sim[:min_length]\n\n        results[station] = hu.stat_error(obs.values, sim.values)\n\n# Display results\nfor station, stats in results.items():\n    print(f\"\\n{station}:\")\n    print(f\"  NSE: {stats['NSE'][0]:.3f}\")\n    print(f\"  RMSE: {stats['RMSE'][0]:.3f}\")\n</code></pre>"},{"location":"usage/#4-advanced-statistical-analysis","title":"4. Advanced Statistical Analysis","text":""},{"location":"usage/#statistical-transformations","title":"Statistical Transformations","text":"<pre><code># Calculate statistical properties\nflow_data = np.random.lognormal(2, 1, 1000)  # Log-normal distributed flow\n\n# Basic statistics\nbasic_stats = hu.cal_stat(flow_data)\nprint(f\"Basic statistics: {basic_stats}\")\n\n# Gamma transformation statistics\ngamma_stats = hu.cal_stat_gamma(flow_data)\nprint(f\"Gamma-transformed statistics: {gamma_stats}\")\n\n# Four key statistical indices\nfour_stats = hu.cal_4_stat_inds(flow_data)\nprint(f\"P10, P90, Mean, Std: {four_stats}\")\n</code></pre>"},{"location":"usage/#empirical-cumulative-distribution-function","title":"Empirical Cumulative Distribution Function","text":"<pre><code># Calculate ECDF\nsorted_data, probabilities = hu.ecdf(flow_data)\n\n# Plot ECDF (requires matplotlib)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8, 6))\nplt.plot(sorted_data, probabilities)\nplt.xlabel('Flow')\nplt.ylabel('Probability')\nplt.title('Empirical Cumulative Distribution Function')\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"usage/#5-working-with-multiple-time-series","title":"5. Working with Multiple Time Series","text":""},{"location":"usage/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple time series\nobserved_series = np.random.rand(5, 100)  # 5 stations, 100 time steps\nsimulated_series = observed_series + np.random.normal(0, 0.1, (5, 100))\n\n# Calculate statistics for all series\nall_stats = hu.stat_errors(observed_series, simulated_series)\n\n# Extract NSE values for all stations\nnse_values = [stats['NSE'][0] for stats in all_stats]\nprint(f\"NSE values for all stations: {nse_values}\")\n</code></pre>"},{"location":"usage/#6-practical-example-complete-workflow","title":"6. Practical Example: Complete Workflow","text":"<p>Here's a complete example of a typical hydrological analysis workflow:</p> <pre><code>import hydroutils as hu\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 1. Load data\ndef load_sample_data():\n    \"\"\"Generate sample hydrological data\"\"\"\n    dates = pd.date_range('2020-01-01', '2022-12-31', freq='D')\n    # Simulate observed streamflow with seasonal pattern\n    base_flow = 10 + 5 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\n    observed = base_flow + np.random.normal(0, 2, len(dates))\n\n    # Simulate model predictions with some bias and error\n    simulated = observed * 0.95 + np.random.normal(0, 1.5, len(dates))\n\n    return pd.DataFrame({\n        'date': dates,\n        'observed': observed,\n        'simulated': simulated\n    })\n\n# 2. Load and prepare data\ndf = load_sample_data()\nprint(f\"Data shape: {df.shape}\")\nprint(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n\n# 3. Calculate comprehensive statistics\nstats = hu.stat_error(df['observed'].values, df['simulated'].values)\n\nprint(\"\\nPerformance Metrics:\")\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\nprint(f\"KGE: {stats['KGE'][0]:.3f}\")\nprint(f\"RMSE: {stats['RMSE'][0]:.3f}\")\nprint(f\"Bias: {stats['Bias'][0]:.3f}\")\nprint(f\"Correlation: {stats['Corr'][0]:.3f}\")\n\n# 4. Additional analysis\nkge_individual = hu.KGE(df['simulated'].values, df['observed'].values)\nprint(f\"KGE (individual calculation): {kge_individual:.3f}\")\n\n# 5. Unit conversion example\nflow_cfs = hu.streamflow_unit_conv(df['observed'].values, 'cms', 'cfs')\nprint(f\"Mean flow: {df['observed'].mean():.1f} cms = {flow_cfs.mean():.1f} cfs\")\n\n# 6. Visualization (optional)\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(df['date'], df['observed'], label='Observed', alpha=0.7)\nplt.plot(df['date'], df['simulated'], label='Simulated', alpha=0.7)\nplt.ylabel('Streamflow (cms)')\nplt.title('Time Series Comparison')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(2, 1, 2)\nplt.scatter(df['observed'], df['simulated'], alpha=0.5)\nplt.plot([df['observed'].min(), df['observed'].max()], \n         [df['observed'].min(), df['observed'].max()], 'r--')\nplt.xlabel('Observed (cms)')\nplt.ylabel('Simulated (cms)')\nplt.title(f'Scatter Plot (NSE: {stats[\"NSE\"][0]:.3f})')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nAnalysis complete!\")\n</code></pre>"},{"location":"usage/#7-error-handling-and-best-practices","title":"7. Error Handling and Best Practices","text":""},{"location":"usage/#handling-missing-data","title":"Handling Missing Data","text":"<pre><code># Sample data with NaN values\nobs_with_nan = np.array([1.0, 2.0, np.nan, 4.0, 5.0])\nsim_with_nan = np.array([1.1, 2.2, 3.1, 4.2, np.nan])\n\n# The stat_error function automatically handles NaN values\ntry:\n    stats = hu.stat_error(obs_with_nan, sim_with_nan)\n    print(\"Statistics calculated successfully with NaN handling\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"usage/#data-validation","title":"Data Validation","text":"<pre><code># Validate input data before analysis\ndef validate_data(observed, simulated):\n    \"\"\"Validate input data for hydrological analysis\"\"\"\n\n    if len(observed) != len(simulated):\n        raise ValueError(\"Observed and simulated data must have same length\")\n\n    if len(observed) == 0:\n        raise ValueError(\"Data arrays cannot be empty\")\n\n    valid_obs = ~np.isnan(observed)\n    valid_sim = ~np.isnan(simulated)\n    valid_both = valid_obs &amp; valid_sim\n\n    if np.sum(valid_both) &lt; 10:\n        print(\"Warning: Less than 10 valid data points\")\n\n    return valid_both\n\n# Example usage\nobs = np.random.rand(100)\nsim = obs + np.random.normal(0, 0.1, 100)\n\n# Add some NaN values\nobs[5:10] = np.nan\nsim[15:20] = np.nan\n\nvalid_mask = validate_data(obs, sim)\nprint(f\"Valid data points: {np.sum(valid_mask)}/{len(obs)}\")\n</code></pre>"},{"location":"usage/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the complete API Reference for all available functions</li> <li>Check out specific module documentation for specialized features</li> <li>See Contributing Guidelines if you want to add new features</li> <li>Visit FAQ for common questions and troubleshooting</li> </ul>"},{"location":"api/hydro_arithmetric/","title":"hydro_arithmetric","text":"<p>The <code>hydro_arithmetric</code> module provides mathematical utilities for array operations in hydrological calculations.</p>"},{"location":"api/hydro_arithmetric/#functions","title":"Functions","text":""},{"location":"api/hydro_arithmetric/#random_choice_no_return","title":"random_choice_no_return","text":"<pre><code>def random_choice_no_return(arr: Union[list, np.ndarray], num_lst: list) -&gt; list\n</code></pre> <p>Performs multiple sampling without replacement from an array.</p> <p>Args: - <code>arr</code>: The source array to sample from - <code>num_lst</code>: List of integers specifying the number of elements to sample in each iteration</p> <p>Returns: - List of numpy arrays, where each array contains the sampled elements for that iteration</p> <p>Example: <pre><code>import hydroutils as hu\nimport numpy as np\n\n# Sample array\narr = [1, 2, 3, 4, 5]\nnum_lst = [2, 1]  # First sample 2 elements, then 1 element\n\n# Perform sampling\nresult = hu.random_choice_no_return(arr, num_lst)\n# result[0] contains 2 elements\n# result[1] contains 1 element\n</code></pre></p>"},{"location":"api/hydro_file/","title":"hydro_file","text":"<p>The <code>hydro_file</code> module provides utilities for file operations, including downloading, compression, serialization, and cache management.</p>"},{"location":"api/hydro_file/#download-functions","title":"Download Functions","text":""},{"location":"api/hydro_file/#download_zip_files","title":"download_zip_files","text":"<pre><code>def download_zip_files(urls: list, the_dir: Path) -&gt; None\n</code></pre> <p>Downloads multiple files from multiple URLs in parallel.</p> <p>Example: <pre><code>from pathlib import Path\nurls = [\n    'https://example.com/file1.zip',\n    'https://example.com/file2.zip'\n]\ndownload_zip_files(urls, Path('./downloads'))\n</code></pre></p>"},{"location":"api/hydro_file/#download_one_zip","title":"download_one_zip","text":"<pre><code>def download_one_zip(data_url: str, data_dir: str) -&gt; list\n</code></pre> <p>Downloads and extracts a zip file from a URL.</p> <p>Example: <pre><code>files = download_one_zip('https://example.com/data.zip', './downloads')\nprint(f\"Downloaded and extracted: {files}\")\n</code></pre></p>"},{"location":"api/hydro_file/#download_small_zip","title":"download_small_zip","text":"<pre><code>def download_small_zip(data_url: str, data_dir: str) -&gt; None\n</code></pre> <p>Downloads and extracts a small zip file using urllib.</p>"},{"location":"api/hydro_file/#download_small_file","title":"download_small_file","text":"<pre><code>def download_small_file(data_url: str, temp_file: str) -&gt; None\n</code></pre> <p>Downloads a small text file from a URL.</p>"},{"location":"api/hydro_file/#download_excel","title":"download_excel","text":"<pre><code>def download_excel(data_url: str, temp_file: str) -&gt; None\n</code></pre> <p>Downloads an Excel file from a URL.</p>"},{"location":"api/hydro_file/#download_a_file_from_google_drive","title":"download_a_file_from_google_drive","text":"<pre><code>def download_a_file_from_google_drive(drive, dir_id: str, download_dir: str) -&gt; None\n</code></pre> <p>Downloads files and folders from Google Drive recursively.</p>"},{"location":"api/hydro_file/#compression-functions","title":"Compression Functions","text":""},{"location":"api/hydro_file/#zip_extract","title":"zip_extract","text":"<pre><code>def zip_extract(the_dir: Path) -&gt; None\n</code></pre> <p>Extracts all zip files in a directory.</p>"},{"location":"api/hydro_file/#unzip_file","title":"unzip_file","text":"<pre><code>def unzip_file(data_zip: str, path_unzip: str) -&gt; None\n</code></pre> <p>Extracts a zip file to a specified directory.</p>"},{"location":"api/hydro_file/#unzip_nested_zip","title":"unzip_nested_zip","text":"<pre><code>def unzip_nested_zip(dataset_zip: str, path_unzip: str) -&gt; None\n</code></pre> <p>Recursively extracts a zip file and any nested zip files within it.</p>"},{"location":"api/hydro_file/#json-functions","title":"JSON Functions","text":""},{"location":"api/hydro_file/#serialize_json","title":"serialize_json","text":"<pre><code>def serialize_json(my_dict: dict, my_file: str, encoding: str = \"utf-8\", ensure_ascii: bool = True) -&gt; None\n</code></pre> <p>Saves a dictionary to a JSON file.</p>"},{"location":"api/hydro_file/#unserialize_json","title":"unserialize_json","text":"<pre><code>def unserialize_json(my_file: str) -&gt; dict\n</code></pre> <p>Loads a JSON file into a dictionary.</p>"},{"location":"api/hydro_file/#unserialize_json_ordered","title":"unserialize_json_ordered","text":"<pre><code>def unserialize_json_ordered(my_file: str) -&gt; OrderedDict\n</code></pre> <p>Loads a JSON file into an OrderedDict, preserving key order.</p>"},{"location":"api/hydro_file/#serialize_json_np","title":"serialize_json_np","text":"<pre><code>def serialize_json_np(my_dict: dict, my_file: str) -&gt; None\n</code></pre> <p>Saves a dictionary containing NumPy arrays to a JSON file.</p>"},{"location":"api/hydro_file/#pickle-functions","title":"Pickle Functions","text":""},{"location":"api/hydro_file/#serialize_pickle","title":"serialize_pickle","text":"<pre><code>def serialize_pickle(my_object: object, my_file: str) -&gt; None\n</code></pre> <p>Saves an object to a pickle file.</p>"},{"location":"api/hydro_file/#unserialize_pickle","title":"unserialize_pickle","text":"<pre><code>def unserialize_pickle(my_file: str) -&gt; object\n</code></pre> <p>Loads an object from a pickle file.</p>"},{"location":"api/hydro_file/#numpy-array-functions","title":"NumPy Array Functions","text":""},{"location":"api/hydro_file/#serialize_numpy","title":"serialize_numpy","text":"<pre><code>def serialize_numpy(my_array: np.ndarray, my_file: str) -&gt; None\n</code></pre> <p>Saves a NumPy array to a .npy file.</p>"},{"location":"api/hydro_file/#unserialize_numpy","title":"unserialize_numpy","text":"<pre><code>def unserialize_numpy(my_file: str) -&gt; np.ndarray\n</code></pre> <p>Loads a NumPy array from a .npy file.</p>"},{"location":"api/hydro_file/#file-management-functions","title":"File Management Functions","text":""},{"location":"api/hydro_file/#get_lastest_file_in_a_dir","title":"get_lastest_file_in_a_dir","text":"<pre><code>def get_lastest_file_in_a_dir(dir_path: str) -&gt; str\n</code></pre> <p>Gets the most recently modified .pth file in a directory.</p>"},{"location":"api/hydro_file/#get_latest_file_in_a_lst","title":"get_latest_file_in_a_lst","text":"<pre><code>def get_latest_file_in_a_lst(lst: list) -&gt; str\n</code></pre> <p>Gets the most recently modified file from a list of files.</p>"},{"location":"api/hydro_file/#get_cache_dir","title":"get_cache_dir","text":"<pre><code>def get_cache_dir(app_name: str = \"hydro\") -&gt; str\n</code></pre> <p>Gets the appropriate cache directory for the current platform.</p>"},{"location":"api/hydro_file/#classes","title":"Classes","text":""},{"location":"api/hydro_file/#numpyarrayencoder","title":"NumpyArrayEncoder","text":"<pre><code>class NumpyArrayEncoder(json.JSONEncoder)\n</code></pre> <p>JSON encoder that handles NumPy arrays and scalars.</p> <p>Example: <pre><code>import numpy as np\ndata = {'array': np.array([1, 2, 3])}\njson_str = json.dumps(data, cls=NumpyArrayEncoder)\n</code></pre></p>"},{"location":"api/hydro_log/","title":"hydro_log","text":"<p>The <code>hydro_log</code> module provides logging utilities with rich formatting and file/console output capabilities.</p>"},{"location":"api/hydro_log/#classes","title":"Classes","text":""},{"location":"api/hydro_log/#hydrowarning","title":"HydroWarning","text":"<p>A class for handling and displaying hydrology-related warnings and messages with rich formatting.</p> <pre><code>class HydroWarning:\n    def __init__(self)\n    def no_directory(directory_name: str, message: Text = None) -&gt; None\n    def file_not_found(file_name: str, message: Text = None) -&gt; None\n    def operation_successful(operation_detail: str, message: Text = None) -&gt; None\n</code></pre> <p>Example: <pre><code>from hydroutils import HydroWarning\n\nwarning = HydroWarning()\n\n# Display directory not found warning\nwarning.no_directory(\"/path/to/missing/dir\")\n\n# Display file not found warning\nwarning.file_not_found(\"data.csv\")\n\n# Display success message\nwarning.operation_successful(\"Data processing complete\")\n</code></pre></p>"},{"location":"api/hydro_log/#decorators","title":"Decorators","text":""},{"location":"api/hydro_log/#hydro_logger","title":"@hydro_logger","text":"<p>A class decorator that adds logging capabilities to a class.</p> <p>Example: <pre><code>from hydroutils import hydro_logger\n\n@hydro_logger\nclass MyHydroClass:\n    def process_data(self):\n        self.logger.info(\"Starting data processing...\")\n        # Processing logic here\n        self.logger.debug(\"Processing complete\")\n\n# The class now has both file and console logging\nobj = MyHydroClass()\nobj.process_data()  # Logs will be written to file and console\n</code></pre></p> <p>Features: - Automatically creates log directory in cache - Timestamps in log filenames - Both file (DEBUG level) and console (INFO level) output - Standard logging format with timestamp, module name, and log level</p>"},{"location":"api/hydro_plot/","title":"hydro_plot - Visualization Tools","text":"<p>The <code>hydro_plot</code> module provides specialized plotting functions for visualizing hydrological data and analysis results.</p>"},{"location":"api/hydro_plot/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>Time Series Plots: Visualize streamflow, precipitation, and other time series data</li> <li>Statistical Plots: Create plots for model performance assessment</li> <li>Flow Analysis Plots: Flow duration curves, hydrographs, and flow statistics</li> <li>Comparison Plots: Side-by-side comparisons of observed vs simulated data</li> </ul>"},{"location":"api/hydro_plot/#quick-example","title":"Quick Example","text":"<pre><code>import hydroutils as hu\nimport pandas as pd\nimport numpy as np\n\n# Sample data\ndates = pd.date_range('2020-01-01', '2020-12-31', freq='D')\nobserved = 10 + 5 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\nsimulated = observed * 0.95 + np.random.normal(0, 1.5, len(dates))\n\n# Create time series plot\nfig, ax = hu.plot_timeseries(\n    dates, observed, simulated,\n    labels=['Observed', 'Simulated'],\n    title='Streamflow Comparison'\n)\n\n# Create performance scatter plot\nfig, ax = hu.plot_scatter_performance(\n    observed, simulated,\n    add_stats=True,  # Add NSE, R\u00b2, etc.\n    add_1to1_line=True\n)\n</code></pre>"},{"location":"api/hydro_plot/#api-reference","title":"API Reference","text":"<p>Author: Wenyu Ouyang Date: 2022-12-02 10:59:30 LastEditTime: 2025-01-17 17:30:55 LastEditors: Wenyu Ouyang Description: Some common plots for hydrology FilePath: /hydroutils/hydroutils/hydro_plot.py Copyright (c) 2021-2022 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.create_median_labels","title":"<code>create_median_labels(ax, medians_value, percent25value=None, percent75value=None, size='small')</code>","text":"<p>\"create median labels for boxes in a boxplot Parameters</p> <p>ax : plt.AxesSubplot     an ax in a fig medians_value : np.array     description percent25value : type, optional     description, by default None percent75value : type, optional     description, by default None size : str, optional     the size of median-value labels, by default small</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def create_median_labels(\n    ax, medians_value, percent25value=None, percent75value=None, size=\"small\"\n):\n    \"\"\" \"create median labels for boxes in a boxplot\n    Parameters\n    ----------\n    ax : plt.AxesSubplot\n        an ax in a fig\n    medians_value : np.array\n        _description_\n    percent25value : _type_, optional\n        _description_, by default None\n    percent75value : _type_, optional\n        _description_, by default None\n    size : str, optional\n        the size of median-value labels, by default small\n    \"\"\"\n    decimal_places = \"2\"\n    if percent25value is None or percent75value is None:\n        vertical_offset = np.min(medians_value * 0.01)  # offset from median for display\n    else:\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        vertical_offset = (per75max - per25min) * 0.01\n    median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n    pos = range(len(medians_value))\n    for xtick in ax.get_xticks():\n        ax.text(\n            pos[xtick],\n            medians_value[xtick] + vertical_offset,\n            median_labels[xtick],\n            horizontalalignment=\"center\",\n            color=\"w\",\n            # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n            size=size,\n            weight=\"semibold\",\n        )\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_boxes_matplotlib","title":"<code>plot_boxes_matplotlib(data, label1=None, label2=None, leg_col=None, colorlst='rbgcmywrbgcmyw', title=None, figsize=(8, 6), sharey=False, xticklabel=None, axin=None, ylim=None, ylabel=None, notch=False, widths=0.5, subplots_adjust_wspace=0.2, show_median=True, median_line_color='black', median_font_size='small')</code>","text":"<p>Creates multiple boxplots for comparing multiple indicators or groups.</p> <p>This function generates a sophisticated boxplot visualization with multiple customization options, including median display, notched boxes, and flexible layout options. It's particularly useful for comparing distributions across different groups or indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>List of arrays, where each array contains the data for one indicator or group to be displayed as a boxplot.</p> required <code>label1</code> <code>list</code> <p>Labels for each subplot. Defaults to None.</p> <code>None</code> <code>label2</code> <code>list</code> <p>Legend labels for boxes within each subplot. Defaults to None.</p> <code>None</code> <code>leg_col</code> <code>int</code> <p>Number of columns in the legend. Defaults to None.</p> <code>None</code> <code>colorlst</code> <code>str</code> <p>String of color characters for box colors. Defaults to \"rbgcmywrbgcmyw\".</p> <code>'rbgcmywrbgcmyw'</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to None.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>sharey</code> <code>bool</code> <p>If True, all subplots share the same y-axis scale. Defaults to False.</p> <code>False</code> <code>xticklabel</code> <code>list</code> <p>Custom x-axis tick labels. Defaults to None.</p> <code>None</code> <code>axin</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>list</code> <p>Y-axis labels for each subplot. Defaults to None.</p> <code>None</code> <code>notch</code> <code>bool</code> <p>If True, creates notched boxes. Defaults to False.</p> <code>False</code> <code>widths</code> <code>float</code> <p>Width of the boxes. Defaults to 0.5.</p> <code>0.5</code> <code>subplots_adjust_wspace</code> <code>float</code> <p>Width space between subplots. Defaults to 0.2.</p> <code>0.2</code> <code>show_median</code> <code>bool</code> <p>If True, displays median values. Defaults to True.</p> <code>True</code> <code>median_line_color</code> <code>str</code> <p>Color of median lines. Defaults to \"black\".</p> <code>'black'</code> <code>median_font_size</code> <code>str</code> <p>Font size for median values. Defaults to \"small\".</p> <code>'small'</code> <p>Returns:</p> Type Description <p>Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]: If axin is None, returns the Figure object. If axin is provided, returns a tuple of (Axes, boxplot_dict).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n&gt;&gt;&gt; fig = plot_boxes_matplotlib(\n...     data,\n...     label1=['Group A', 'Group B', 'Group C'],\n...     show_median=True,\n...     notch=True\n... )\n</code></pre> Notes <ul> <li>The function automatically handles NaN values in the data.</li> <li>Median values can be displayed with customizable formatting.</li> <li>Supports both single and multiple subplot layouts.</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxes_matplotlib(\n    data: list,\n    label1: list = None,\n    label2: list = None,\n    leg_col: int = None,\n    colorlst=\"rbgcmywrbgcmyw\",\n    title=None,\n    figsize=(8, 6),\n    sharey=False,\n    xticklabel=None,\n    axin=None,\n    ylim=None,\n    ylabel=None,\n    notch=False,\n    widths=0.5,\n    subplots_adjust_wspace=0.2,\n    show_median=True,\n    median_line_color=\"black\",\n    median_font_size=\"small\",\n):\n    \"\"\"Creates multiple boxplots for comparing multiple indicators or groups.\n\n    This function generates a sophisticated boxplot visualization with multiple customization\n    options, including median display, notched boxes, and flexible layout options. It's\n    particularly useful for comparing distributions across different groups or indicators.\n\n    Args:\n        data (list): List of arrays, where each array contains the data for one indicator\n            or group to be displayed as a boxplot.\n        label1 (list, optional): Labels for each subplot. Defaults to None.\n        label2 (list, optional): Legend labels for boxes within each subplot. Defaults to None.\n        leg_col (int, optional): Number of columns in the legend. Defaults to None.\n        colorlst (str, optional): String of color characters for box colors. Defaults to\n            \"rbgcmywrbgcmyw\".\n        title (str, optional): Title of the plot. Defaults to None.\n        figsize (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        sharey (bool, optional): If True, all subplots share the same y-axis scale.\n            Defaults to False.\n        xticklabel (list, optional): Custom x-axis tick labels. Defaults to None.\n        axin (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        ylabel (list, optional): Y-axis labels for each subplot. Defaults to None.\n        notch (bool, optional): If True, creates notched boxes. Defaults to False.\n        widths (float, optional): Width of the boxes. Defaults to 0.5.\n        subplots_adjust_wspace (float, optional): Width space between subplots.\n            Defaults to 0.2.\n        show_median (bool, optional): If True, displays median values. Defaults to True.\n        median_line_color (str, optional): Color of median lines. Defaults to \"black\".\n        median_font_size (str, optional): Font size for median values. Defaults to \"small\".\n\n    Returns:\n        Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]:\n            If axin is None, returns the Figure object.\n            If axin is provided, returns a tuple of (Axes, boxplot_dict).\n\n    Examples:\n        &gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n        &gt;&gt;&gt; fig = plot_boxes_matplotlib(\n        ...     data,\n        ...     label1=['Group A', 'Group B', 'Group C'],\n        ...     show_median=True,\n        ...     notch=True\n        ... )\n\n    Notes:\n        - The function automatically handles NaN values in the data.\n        - Median values can be displayed with customizable formatting.\n        - Supports both single and multiple subplot layouts.\n    \"\"\"\n    nc = len(data)\n    if axin is None:\n        fig, axes = plt.subplots(\n            ncols=nc, sharey=sharey, figsize=figsize, constrained_layout=False\n        )\n    else:\n        axes = axin\n\n    # the next few lines are for showing median values\n    decimal_places = \"2\"\n    for k in range(nc):\n        ax = axes[k] if nc &gt; 1 else axes\n        temp = data[k]\n        if type(temp) is list:\n            for kk in range(len(temp)):\n                tt = temp[kk]\n                if tt is not None and len(tt) &gt; 0:\n                    tt = tt[~np.isnan(tt)]\n                    temp[kk] = tt\n                else:\n                    temp[kk] = []\n        else:\n            temp = temp[~np.isnan(temp)]\n        bp = ax.boxplot(\n            temp, patch_artist=True, notch=notch, showfliers=False, widths=widths\n        )\n        for median in bp[\"medians\"]:\n            median.set_color(median_line_color)\n        medians_value = [np.median(tmp) for tmp in temp]\n        percent25value = [np.percentile(tmp, 25) for tmp in temp]\n        percent75value = [np.percentile(tmp, 75) for tmp in temp]\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n        pos = range(len(medians_value))\n        if show_median:\n            for tick, label in zip(pos, ax.get_xticklabels()):\n                # params of ax.text could be seen here: https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                ax.text(\n                    pos[tick] + 1,\n                    medians_value[tick] + (per75max - per25min) * 0.01,\n                    median_labels[tick],\n                    horizontalalignment=\"center\",\n                    # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                    size=median_font_size,\n                    weight=\"semibold\",\n                    color=median_line_color,\n                )\n        for kk in range(len(bp[\"boxes\"])):\n            plt.setp(bp[\"boxes\"][kk], facecolor=colorlst[kk])\n\n        if label1 is not None:\n            ax.set_xlabel(label1[k])\n        else:\n            ax.set_xlabel(str(k))\n        if xticklabel is None:\n            ax.set_xticks([])\n        else:\n            ax.set_xticks([y + 1 for y in range(0, len(data[k]), 2)])\n            ax.set_xticklabels(xticklabel)\n        if ylabel is not None:\n            ax.set_ylabel(ylabel[k])\n        if ylim is not None:\n            ax.set_ylim(ylim[k])\n    if label2 is not None:\n        plt.legend(\n            bp[\"boxes\"],\n            label2,\n            # explanation for bbox_to_anchor: https://zhuanlan.zhihu.com/p/101059179\n            bbox_to_anchor=(1.0, 1.02, 0.25, 0.05),\n            loc=\"upper right\",\n            borderaxespad=0,\n            ncol=len(label2) if leg_col is None else leg_col,\n            frameon=False,\n            fontsize=12,\n        )\n    if title is not None:\n        # fig.suptitle(title)\n        ax.set_title(title)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=subplots_adjust_wspace)\n    return fig if axin is None else (ax, bp)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_boxs","title":"<code>plot_boxs(data, x_name, y_name, uniform_color=None, swarm_plot=False, hue=None, colormap=False, xlim=None, ylim=None, order=None, font='serif', rotation=45, show_median=False)</code>","text":"<p>plot multiple boxes in one ax with seaborn Parameters</p> <p>data : pd.DataFrame     a tidy pandas dataframe;     if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data x_name : str     the names of each box y_name : str     what is shown uniform_color : str, optional     unified color for all boxes, by default None swarm_plot : bool, optional     description, by default False hue : type, optional     description, by default None colormap : bool, optional     description, by default False xlim : type, optional     description, by default None ylim : type, optional     description, by default None order : type, optional     description, by default None font : str, optional     description, by default \"serif\" rotation : int, optional     rotation for labels in x-axis, by default 45 show_median: bool, optional     if True, show median value for each box, by default False Returns</p> <p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxs(\n    data: pd.DataFrame,\n    x_name: str,\n    y_name: str,\n    uniform_color=None,\n    swarm_plot=False,\n    hue=None,\n    colormap=False,\n    xlim=None,\n    ylim=None,\n    order=None,\n    font=\"serif\",\n    rotation=45,\n    show_median=False,\n):\n    \"\"\"plot multiple boxes in one ax with seaborn\n    Parameters\n    ----------\n    data : pd.DataFrame\n        a tidy pandas dataframe;\n        if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data\n    x_name : str\n        the names of each box\n    y_name : str\n        what is shown\n    uniform_color : str, optional\n        unified color for all boxes, by default None\n    swarm_plot : bool, optional\n        _description_, by default False\n    hue : _type_, optional\n        _description_, by default None\n    colormap : bool, optional\n        _description_, by default False\n    xlim : _type_, optional\n        _description_, by default None\n    ylim : _type_, optional\n        _description_, by default None\n    order : _type_, optional\n        _description_, by default None\n    font : str, optional\n        _description_, by default \"serif\"\n    rotation : int, optional\n        rotation for labels in x-axis, by default 45\n    show_median: bool, optional\n        if True, show median value for each box, by default False\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    fig = plt.figure()\n    sns.set(style=\"ticks\", palette=\"pastel\", font=font, font_scale=1.5)\n    # Draw a nested boxplot to show bills by day and time\n    if uniform_color is not None:\n        sns_box = sns.boxplot(\n            x=x_name,\n            y=y_name,\n            data=data,\n            color=uniform_color,\n            showfliers=False,\n            order=order,\n        )\n    else:\n        sns_box = sns.boxplot(\n            x=x_name, y=y_name, data=data, showfliers=False, order=order\n        )\n    if swarm_plot:\n        if hue is None:\n            sns_box = sns.swarmplot(\n                x=x_name, y=y_name, data=data, color=\".2\", order=order\n            )\n        elif colormap:\n            # Create a matplotlib colormap from the sns seagreen color palette\n            cmap = sns.light_palette(\"seagreen\", reverse=False, as_cmap=True)\n            # Normalize to the range of possible values from df[\"c\"]\n            norm = matplotlib.colors.Normalize(\n                vmin=data[hue].min(), vmax=data[hue].max()\n            )\n            colors = {cval: cmap(norm(cval)) for cval in data[hue]}\n            # plot the swarmplot with the colors dictionary as palette, s=2 means size is 2\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=colors,\n                order=order,\n            )\n            # remove the legend, because we want to set a colorbar instead\n            plt.gca().legend_.remove()\n            # create colorbar\n            divider = make_axes_locatable(plt.gca())\n            ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)\n            fig = sns_box.get_figure()\n            fig.add_axes(ax_cb)\n            cb1 = matplotlib.colorbar.ColorbarBase(\n                ax_cb, cmap=cmap, norm=norm, orientation=\"vertical\"\n            )\n            cb1.set_label(\"Some Units\")\n        else:\n            palette = sns.light_palette(\"seagreen\", reverse=False, n_colors=10)\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=palette,\n                order=order,\n            )\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    if show_median:\n        medians = data.groupby([x_name], sort=False)[y_name].median().values\n        create_median_labels(sns_box, medians_value=medians, size=\"x-small\")\n    sns.despine()\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=rotation)\n    # plt.show()\n    return sns_box.get_figure()\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_diff_boxes","title":"<code>plot_diff_boxes(data, row_and_col=None, y_col=None, x_col=None, hspace=0.3, wspace=1, title_str=None, title_font_size=14)</code>","text":"<p>plot boxplots in rows and cols</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_diff_boxes(\n    data,\n    row_and_col=None,\n    y_col=None,\n    x_col=None,\n    hspace=0.3,\n    wspace=1,\n    title_str=None,\n    title_font_size=14,\n):\n    \"\"\"plot boxplots in rows and cols\"\"\"\n    # matplotlib.use('TkAgg')\n    if type(data) is not pd.DataFrame:\n        data = pd.DataFrame(data)\n    subplot_num = data.shape[1] if y_col is None else len(y_col)\n    if row_and_col is None:\n        row_num = 1\n        col_num = subplot_num\n        f, axes = plt.subplots(row_num, col_num)\n        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n    else:\n        assert subplot_num &lt;= row_and_col[0] * row_and_col[1]\n        row_num = row_and_col[0]\n        col_num = row_and_col[1]\n        f, axes = plt.subplots(row_num, col_num)\n        f.tight_layout()\n    for i in range(subplot_num):\n        if y_col is None:\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    width=0.5,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                ).set(xlabel=data.columns.values[i], ylabel=\"\")\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n        else:\n            assert x_col is not None\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                )\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n    if title_str is not None:\n        f.suptitle(title_str, fontsize=title_font_size)\n    return f\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ecdf","title":"<code>plot_ecdf(mydataframe, mycolumn, save_file=None)</code>","text":"<p>Creates an empirical cumulative distribution function (ECDF) plot for a single column.</p> <p>This function generates an ECDF plot for a single column of data from a pandas DataFrame. It provides a simple interface for quick visualization of data distributions.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create ECDF for.</p> required <code>save_file</code> <code>str</code> <p>Path to save the plot. If None, plot is only displayed. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n&gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n</code></pre> Notes <ul> <li>Uses seaborn's styling for better visualization</li> <li>Automatically handles NaN values</li> <li>Plot range is set to [0, 1] for both axes</li> <li>Uses 0.05 intervals for axis ticks</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdf(mydataframe, mycolumn, save_file=None):\n    \"\"\"Creates an empirical cumulative distribution function (ECDF) plot for a single column.\n\n    This function generates an ECDF plot for a single column of data from a pandas\n    DataFrame. It provides a simple interface for quick visualization of data\n    distributions.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create ECDF for.\n        save_file (str, optional): Path to save the plot. If None, plot is only\n            displayed. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n        &gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n\n    Notes:\n        - Uses seaborn's styling for better visualization\n        - Automatically handles NaN values\n        - Plot range is set to [0, 1] for both axes\n        - Uses 0.05 intervals for axis ticks\n    \"\"\"\n    x, y = ecdf(mydataframe[mycolumn])\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    sns.lineplot(x=\"x\", y=\"y\", data=df, estimator=None).set(\n        xlim=(0, 1), xticks=np.arange(0, 1, 0.05), yticks=np.arange(0, 1, 0.05)\n    )\n    plt.show()\n    if save_file is not None:\n        plt.savefig(save_file)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ecdfs","title":"<code>plot_ecdfs(xs, ys, legends=None, style=None, case_str='case', event_str='event', x_str='x', y_str='y', ax_as_subplot=None, interval=0.1)</code>","text":"<p>Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.</p> <p>This function generates ECDF plots for multiple datasets with customizable styling and labeling options. It's particularly useful for comparing distributions of different datasets or experimental conditions.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>style</code> <code>list[str]</code> <p>Line styles for each ECDF. Defaults to None.</p> <code>None</code> <code>case_str</code> <code>str</code> <p>Label for different cases in the plot. Defaults to \"case\".</p> <code>'case'</code> <code>event_str</code> <code>str</code> <p>Label for different events in the plot. Defaults to \"event\".</p> <code>'event'</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>ax_as_subplot</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>interval</code> <code>float</code> <p>Interval for axis ticks. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare two distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n&gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Distribution 1', 'Distribution 2'],\n...     x_str='Value',\n...     y_str='Cumulative Probability'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple distributions with different styles\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Group A', 'Group B'],\n...     style=['-', '--'],\n...     interval=0.2\n... )\n</code></pre> Notes <ul> <li>Input arrays must be sorted in ascending order</li> <li>Function automatically validates data ordering</li> <li>Supports both single and multiple subplot layouts</li> <li>Uses seaborn for enhanced visual styling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs(\n    xs,\n    ys,\n    legends=None,\n    style=None,\n    case_str=\"case\",\n    event_str=\"event\",\n    x_str=\"x\",\n    y_str=\"y\",\n    ax_as_subplot=None,\n    interval=0.1,\n):\n    \"\"\"Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.\n\n    This function generates ECDF plots for multiple datasets with customizable styling\n    and labeling options. It's particularly useful for comparing distributions of\n    different datasets or experimental conditions.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        style (list[str], optional): Line styles for each ECDF. Defaults to None.\n        case_str (str, optional): Label for different cases in the plot.\n            Defaults to \"case\".\n        event_str (str, optional): Label for different events in the plot.\n            Defaults to \"event\".\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        ax_as_subplot (matplotlib.axes.Axes, optional): Existing axes to plot on.\n            Defaults to None.\n        interval (float, optional): Interval for axis ticks. Defaults to 0.1.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare two distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n        &gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Distribution 1', 'Distribution 2'],\n        ...     x_str='Value',\n        ...     y_str='Cumulative Probability'\n        ... )\n\n        &gt;&gt;&gt; # Multiple distributions with different styles\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Group A', 'Group B'],\n        ...     style=['-', '--'],\n        ...     interval=0.2\n        ... )\n\n    Notes:\n        - Input arrays must be sorted in ascending order\n        - Function automatically validates data ordering\n        - Supports both single and multiple subplot layouts\n        - Uses seaborn for enhanced visual styling\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list)\n        assert len(ys) == len(legends)\n    if style is not None:\n        assert isinstance(style, list)\n        assert len(ys) == len(style)\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    frames = []\n    for i in range(len(xs)):\n        str_i = x_str + str(i) if legends is None else legends[i]\n        assert all(xi &lt; yi for xi, yi in zip(xs[i], xs[i][1:]))\n        df_dict_i = {\n            x_str: xs[i],\n            y_str: ys[i],\n            case_str: np.full([xs[i].size], str_i),\n        }\n        if style is not None:\n            df_dict_i[event_str] = np.full([xs[i].size], style[i])\n        df_i = pd.DataFrame(df_dict_i)\n        frames.append(df_i)\n    df = pd.concat(frames)\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    if style is None:\n        return (\n            sns.lineplot(x=x_str, y=y_str, hue=case_str, data=df, estimator=None).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n            if ax_as_subplot is None\n            else sns.lineplot(\n                ax=ax_as_subplot,\n                x=x_str,\n                y=y_str,\n                hue=case_str,\n                data=df,\n                estimator=None,\n            ).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n        )\n    elif ax_as_subplot is None:\n        return sns.lineplot(\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n    else:\n        return sns.lineplot(\n            ax=ax_as_subplot,\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ecdfs_matplot","title":"<code>plot_ecdfs_matplot(xs, ys, legends=None, colors='rbkgcmy', dash_lines=None, x_str='x', y_str='y', x_interval=0.1, y_interval=0.1, x_lim=(0, 1), y_lim=(0, 1), show_legend=True, legend_font_size=16, fig_size=(8, 6))</code>","text":"<p>Creates ECDF plots using matplotlib with extensive customization options.</p> <p>This function provides a more customizable alternative to the seaborn-based ECDF plotting functions, offering direct control over matplotlib parameters and styling.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>colors</code> <code>str</code> <p>String of color characters for different lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which lines should be dashed. Defaults to None.</p> <code>None</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>x_interval</code> <code>float</code> <p>Interval for x-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>y_interval</code> <code>float</code> <p>Interval for y-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>x_lim</code> <code>tuple</code> <p>X-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>y_lim</code> <code>tuple</code> <p>Y-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>show_legend</code> <code>bool</code> <p>Whether to show legend. Defaults to True.</p> <code>True</code> <code>legend_font_size</code> <code>int</code> <p>Font size for legend. Defaults to 16.</p> <code>16</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare multiple distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n...     x_str='Value',\n...     y_str='Probability',\n...     x_lim=(-3, 3)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     colors='rb',\n...     dash_lines=[False, True],\n...     legend_font_size=12,\n...     fig_size=(10, 8)\n... )\n</code></pre> Notes <ul> <li>Uses clean plotting style with minimal spines</li> <li>Supports both continuous and dashed lines</li> <li>Provides fine-grained control over axis properties</li> <li>Input arrays must be sorted in ascending order</li> <li>Automatically validates data ordering</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs_matplot(\n    xs,\n    ys,\n    legends=None,\n    colors=\"rbkgcmy\",\n    dash_lines=None,\n    x_str=\"x\",\n    y_str=\"y\",\n    x_interval=0.1,\n    y_interval=0.1,\n    x_lim=(0, 1),\n    y_lim=(0, 1),\n    show_legend=True,\n    legend_font_size=16,\n    fig_size=(8, 6),\n):\n    \"\"\"Creates ECDF plots using matplotlib with extensive customization options.\n\n    This function provides a more customizable alternative to the seaborn-based ECDF\n    plotting functions, offering direct control over matplotlib parameters and styling.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        colors (str, optional): String of color characters for different lines.\n            Defaults to \"rbkgcmy\".\n        dash_lines (list[bool], optional): Specifies which lines should be dashed.\n            Defaults to None.\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        x_interval (float, optional): Interval for x-axis ticks. Defaults to 0.1.\n        y_interval (float, optional): Interval for y-axis ticks. Defaults to 0.1.\n        x_lim (tuple, optional): X-axis limits as (min, max). Defaults to (0, 1).\n        y_lim (tuple, optional): Y-axis limits as (min, max). Defaults to (0, 1).\n        show_legend (bool, optional): Whether to show legend. Defaults to True.\n        legend_font_size (int, optional): Font size for legend. Defaults to 16.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare multiple distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n        ...     x_str='Value',\n        ...     y_str='Probability',\n        ...     x_lim=(-3, 3)\n        ... )\n\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     colors='rb',\n        ...     dash_lines=[False, True],\n        ...     legend_font_size=12,\n        ...     fig_size=(10, 8)\n        ... )\n\n    Notes:\n        - Uses clean plotting style with minimal spines\n        - Supports both continuous and dashed lines\n        - Provides fine-grained control over axis properties\n        - Input arrays must be sorted in ascending order\n        - Automatically validates data ordering\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list) and len(ys) == len(legends)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(xs), False).tolist()\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    fig = plt.figure(figsize=fig_size)\n    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n    for i in range(len(xs)):\n        if (\n            np.nanmax(np.array(xs[i])) == np.inf\n            or np.nanmin(np.array(xs[i])) == -np.inf\n        ):\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        else:\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        (line_i,) = ax.plot(xs[i], ys[i], color=colors[i], label=legends[i])\n        if dash_lines[i]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    plt.xlabel(x_str, fontsize=18)\n    plt.ylabel(y_str, fontsize=18)\n    ax.set_xlim(x_lim[0], x_lim[1])\n    ax.set_ylim(y_lim[0], y_lim[1])\n    # set x y number font size\n    plt.xticks(np.arange(x_lim[0], x_lim[1] + x_lim[1] / 100, x_interval), fontsize=16)\n    plt.yticks(np.arange(y_lim[0], y_lim[1] + y_lim[1] / 100, y_interval), fontsize=16)\n    if show_legend:\n        ax.legend()\n        plt.legend(prop={\"size\": legend_font_size})\n    plt.grid()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_heat_map","title":"<code>plot_heat_map(data, mask=None, fig_size=None, fmt='d', square=True, annot=True, xticklabels=True, yticklabels=True)</code>","text":"<p>Creates a heatmap visualization of 2D data using seaborn.</p> <p>This function creates a heatmap visualization with customizable formatting, annotations, and masking options. It uses seaborn's heatmap function with additional customization options.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>2D array or DataFrame to be visualized.</p> required <code>mask</code> <code>array</code> <p>Boolean array of same shape as data. True values will be masked (not shown). Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to None.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>String formatting code for cell annotations. Defaults to \"d\" for integer formatting.</p> <code>'d'</code> <code>square</code> <code>bool</code> <p>If True, set the Axes aspect to \"equal\". Defaults to True.</p> <code>True</code> <code>annot</code> <code>bool</code> <p>If True, write the data value in each cell. Defaults to True.</p> <code>True</code> <code>xticklabels</code> <code>bool</code> <p>If True, show x-axis labels. Defaults to True.</p> <code>True</code> <code>yticklabels</code> <code>bool</code> <p>If True, show y-axis labels. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n&gt;&gt;&gt; plot_heat_map(\n...     data,\n...     fmt='.2f',\n...     fig_size=(8, 6),\n...     annot=True\n... )\n</code></pre> Notes <p>The function uses a red-blue diverging colormap ('RdBu_r') by default. For more details on the underlying implementation, see: https://zhuanlan.zhihu.com/p/96040773</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_heat_map(\n    data,\n    mask=None,\n    fig_size=None,\n    fmt=\"d\",\n    square=True,\n    annot=True,\n    xticklabels=True,\n    yticklabels=True,\n):\n    \"\"\"Creates a heatmap visualization of 2D data using seaborn.\n\n    This function creates a heatmap visualization with customizable formatting,\n    annotations, and masking options. It uses seaborn's heatmap function with\n    additional customization options.\n\n    Args:\n        data (pd.DataFrame): 2D array or DataFrame to be visualized.\n        mask (np.array, optional): Boolean array of same shape as data. True values will\n            be masked (not shown). Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to None.\n        fmt (str, optional): String formatting code for cell annotations. Defaults to \"d\"\n            for integer formatting.\n        square (bool, optional): If True, set the Axes aspect to \"equal\". Defaults to True.\n        annot (bool, optional): If True, write the data value in each cell. Defaults to True.\n        xticklabels (bool, optional): If True, show x-axis labels. Defaults to True.\n        yticklabels (bool, optional): If True, show y-axis labels. Defaults to True.\n\n    Returns:\n        matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.\n\n    Examples:\n        &gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n        &gt;&gt;&gt; plot_heat_map(\n        ...     data,\n        ...     fmt='.2f',\n        ...     fig_size=(8, 6),\n        ...     annot=True\n        ... )\n\n    Notes:\n        The function uses a red-blue diverging colormap ('RdBu_r') by default.\n        For more details on the underlying implementation, see:\n        https://zhuanlan.zhihu.com/p/96040773\n    \"\"\"\n    if fig_size is not None:\n        fig = plt.figure(figsize=fig_size)\n    ax = sns.heatmap(\n        data=data,\n        square=square,\n        annot=annot,\n        fmt=fmt,\n        cmap=\"RdBu_r\",\n        mask=mask,\n        xticklabels=xticklabels,\n        yticklabels=yticklabels,\n    )\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_map_carto","title":"<code>plot_map_carto(data, lat, lon, fig=None, ax=None, pertile_range=None, value_range=None, fig_size=(8, 8), need_colorbar=True, colorbar_size=[0.91, 0.318, 0.02, 0.354], cmap_str='jet', idx_lst=None, markers=None, marker_size=20, is_discrete=False, colors='rbkgcmywrbkgcmyw', category_names=None, legend_font_size=None, colorbar_font_size=None)</code>","text":"<p>Creates a cartographic map visualization using Cartopy with extensive customization options.</p> <p>This function generates a map visualization for spatial data with support for continuous and discrete color scales, multiple marker types, and various styling options. It's particularly useful for visualizing hydrological data in a geographic context.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array</code> <p>1-D array of values to be plotted on the map.</p> required <code>lat</code> <code>array</code> <p>1-D array of latitude values for each data point.</p> required <code>lon</code> <code>array</code> <p>1-D array of longitude values for each data point.</p> required <code>fig</code> <code>Figure</code> <p>Existing figure to plot on. Defaults to None.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling, e.g., [25, 75] for interquartile range. Defaults to None.</p> <code>None</code> <code>value_range</code> <code>list</code> <p>Explicit value range for color scaling. Takes precedence over pertile_range. Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 8).</p> <code>(8, 8)</code> <code>need_colorbar</code> <code>bool</code> <p>Whether to add a colorbar. Defaults to True.</p> <code>True</code> <code>colorbar_size</code> <code>list</code> <p>Colorbar dimensions [left, bottom, width, height]. Defaults to [0.91, 0.318, 0.02, 0.354].</p> <code>[0.91, 0.318, 0.02, 0.354]</code> <code>cmap_str</code> <code>str</code> <p>Colormap name. Defaults to \"jet\".</p> <code>'jet'</code> <code>idx_lst</code> <code>list</code> <p>List of index arrays for plotting multiple point categories. Defaults to None.</p> <code>None</code> <code>markers</code> <code>list</code> <p>Marker styles for each category. Defaults to None.</p> <code>None</code> <code>marker_size</code> <code>Union[int, list]</code> <p>Size(s) of markers. Defaults to 20.</p> <code>20</code> <code>is_discrete</code> <code>bool</code> <p>If True, uses discrete colors with legend instead of continuous colorbar. Defaults to False.</p> <code>False</code> <code>colors</code> <code>str</code> <p>Color characters for discrete categories. Defaults to \"rbkgcmywrbkgcmyw\".</p> <code>'rbkgcmywrbkgcmyw'</code> <code>category_names</code> <code>list</code> <p>Names for discrete categories in legend. Defaults to None.</p> <code>None</code> <code>legend_font_size</code> <code>float</code> <p>Font size for legend. Defaults to None.</p> <code>None</code> <code>colorbar_font_size</code> <code>float</code> <p>Font size for colorbar. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the map.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple continuous color map\n&gt;&gt;&gt; data = np.random.rand(100)\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     value_range=[0, 1],\n...     cmap_str='viridis'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Discrete categories with custom markers\n&gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n&gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     idx_lst=idx_lst,\n...     markers=['o', 's', '^'],\n...     is_discrete=True,\n...     category_names=['Low', 'Medium', 'High']\n... )\n</code></pre> Notes <ul> <li>Uses Cartopy for map projections and features</li> <li>Automatically adds state boundaries and coastlines</li> <li>Supports both continuous and categorical data visualization</li> <li>Handles NaN values appropriately</li> <li>Provides flexible control over color scaling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_map_carto(\n    data,\n    lat,\n    lon,\n    fig=None,\n    ax=None,\n    pertile_range=None,\n    value_range=None,\n    fig_size=(8, 8),\n    need_colorbar=True,\n    colorbar_size=[0.91, 0.318, 0.02, 0.354],\n    cmap_str=\"jet\",\n    idx_lst=None,\n    markers=None,\n    marker_size=20,\n    is_discrete=False,\n    colors=\"rbkgcmywrbkgcmyw\",\n    category_names=None,\n    legend_font_size=None,\n    colorbar_font_size=None,\n):\n    \"\"\"Creates a cartographic map visualization using Cartopy with extensive customization options.\n\n    This function generates a map visualization for spatial data with support for continuous\n    and discrete color scales, multiple marker types, and various styling options. It's\n    particularly useful for visualizing hydrological data in a geographic context.\n\n    Args:\n        data (np.array): 1-D array of values to be plotted on the map.\n        lat (np.array): 1-D array of latitude values for each data point.\n        lon (np.array): 1-D array of longitude values for each data point.\n        fig (matplotlib.figure.Figure, optional): Existing figure to plot on.\n            Defaults to None.\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        pertile_range (list, optional): Percentile range for color scaling, e.g.,\n            [25, 75] for interquartile range. Defaults to None.\n        value_range (list, optional): Explicit value range for color scaling. Takes\n            precedence over pertile_range. Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 8).\n        need_colorbar (bool, optional): Whether to add a colorbar. Defaults to True.\n        colorbar_size (list, optional): Colorbar dimensions [left, bottom, width, height].\n            Defaults to [0.91, 0.318, 0.02, 0.354].\n        cmap_str (str, optional): Colormap name. Defaults to \"jet\".\n        idx_lst (list, optional): List of index arrays for plotting multiple point\n            categories. Defaults to None.\n        markers (list, optional): Marker styles for each category. Defaults to None.\n        marker_size (Union[int, list], optional): Size(s) of markers. Defaults to 20.\n        is_discrete (bool, optional): If True, uses discrete colors with legend instead\n            of continuous colorbar. Defaults to False.\n        colors (str, optional): Color characters for discrete categories.\n            Defaults to \"rbkgcmywrbkgcmyw\".\n        category_names (list, optional): Names for discrete categories in legend.\n            Defaults to None.\n        legend_font_size (float, optional): Font size for legend. Defaults to None.\n        colorbar_font_size (float, optional): Font size for colorbar. Defaults to None.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the map.\n\n    Examples:\n        &gt;&gt;&gt; # Simple continuous color map\n        &gt;&gt;&gt; data = np.random.rand(100)\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     value_range=[0, 1],\n        ...     cmap_str='viridis'\n        ... )\n\n        &gt;&gt;&gt; # Discrete categories with custom markers\n        &gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n        &gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     idx_lst=idx_lst,\n        ...     markers=['o', 's', '^'],\n        ...     is_discrete=True,\n        ...     category_names=['Low', 'Medium', 'High']\n        ... )\n\n    Notes:\n        - Uses Cartopy for map projections and features\n        - Automatically adds state boundaries and coastlines\n        - Supports both continuous and categorical data visualization\n        - Handles NaN values appropriately\n        - Provides flexible control over color scaling\n    \"\"\"\n    if value_range is not None:\n        vmin = value_range[0]\n        vmax = value_range[1]\n    elif pertile_range is None:\n        # https://blog.csdn.net/chenirene510/article/details/111318539\n        mask_data = np.ma.masked_invalid(data)\n        vmin = np.min(mask_data)\n        vmax = np.max(mask_data)\n    else:\n        assert 0 &lt;= pertile_range[0] &lt; pertile_range[1] &lt;= 100\n        vmin = np.nanpercentile(data, pertile_range[0])\n        vmax = np.nanpercentile(data, pertile_range[1])\n    llcrnrlat = (np.min(lat),)\n    urcrnrlat = (np.max(lat),)\n    llcrnrlon = (np.min(lon),)\n    urcrnrlon = (np.max(lon),)\n    extent = [llcrnrlon[0], urcrnrlon[0], llcrnrlat[0], urcrnrlat[0]]\n    # Figure\n    if fig is None or ax is None:\n        fig, ax = plt.subplots(\n            1, 1, figsize=fig_size, subplot_kw={\"projection\": ccrs.PlateCarree()}\n        )\n    ax.set_extent(extent)\n    states = NaturalEarthFeature(\n        category=\"cultural\",\n        scale=\"50m\",\n        facecolor=\"none\",\n        name=\"admin_1_states_provinces_shp\",\n    )\n    ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n    ax.coastlines(\"50m\", linewidth=0.8)\n    if idx_lst is not None:\n        if isinstance(marker_size, list):\n            assert len(marker_size) == len(idx_lst)\n        else:\n            marker_size = np.full(len(idx_lst), marker_size).tolist()\n        if not isinstance(marker_size, list):\n            markers = np.full(len(idx_lst), markers).tolist()\n        else:\n            assert len(markers) == len(idx_lst)\n        if not isinstance(cmap_str, list):\n            cmap_str = np.full(len(idx_lst), cmap_str).tolist()\n        else:\n            assert len(cmap_str) == len(idx_lst)\n        if is_discrete:\n            for i in range(len(idx_lst)):\n                ax.plot(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    marker=markers[i],\n                    ms=marker_size[i],\n                    label=category_names[i],\n                    c=colors[i],\n                    linestyle=\"\",\n                )\n                ax.legend(prop=dict(size=legend_font_size))\n        else:\n            scatter = []\n            for i in range(len(idx_lst)):\n                scat = ax.scatter(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    c=data[idx_lst[i]],\n                    marker=markers[i],\n                    s=marker_size[i],\n                    cmap=cmap_str[i],\n                    vmin=vmin,\n                    vmax=vmax,\n                )\n                scatter.append(scat)\n            if need_colorbar:\n                if colorbar_size is not None:\n                    cbar_ax = fig.add_axes(colorbar_size)\n                    cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n                else:\n                    cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n                if colorbar_font_size is not None:\n                    cbar.ax.tick_params(labelsize=colorbar_font_size)\n            if category_names is not None:\n                ax.legend(\n                    scatter, category_names, prop=dict(size=legend_font_size), ncol=2\n                )\n    elif is_discrete:\n        scatter = ax.scatter(lon, lat, c=data, s=marker_size)\n        # produce a legend with the unique colors from the scatter\n        legend1 = ax.legend(\n            *scatter.legend_elements(), loc=\"lower left\", title=\"Classes\"\n        )\n        ax.add_artist(legend1)\n    else:\n        scat = plt.scatter(\n            lon, lat, c=data, s=marker_size, cmap=cmap_str, vmin=vmin, vmax=vmax\n        )\n        if need_colorbar:\n            if colorbar_size is not None:\n                cbar_ax = fig.add_axes(colorbar_size)\n                cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n            else:\n                cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n            if colorbar_font_size is not None:\n                cbar.ax.tick_params(labelsize=colorbar_font_size)\n    return ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_pdf_cdf","title":"<code>plot_pdf_cdf(mydataframe, mycolumn)</code>","text":"<p>Creates side-by-side plots of probability density function (PDF) and cumulative distribution function (CDF).</p> <p>This function generates a figure with two subplots: a PDF plot on the left and a CDF plot on the right. The PDF includes both histogram and kernel density estimation, while the CDF shows the cumulative histogram.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create distributions for.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'values': np.concatenate([\n...         np.random.normal(0.3, 0.1, 1000),\n...         np.random.normal(0.7, 0.1, 1000)\n...     ])\n... })\n&gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n</code></pre> Notes <ul> <li>Uses seaborn's distplot for both PDF and CDF</li> <li>PDF includes both histogram and kernel density estimation</li> <li>CDF shows cumulative histogram with step-style line</li> <li>Both plots are set to range [0, 1] on x-axis</li> <li>CDF y-axis is also set to range [0, 1]</li> <li>High DPI (320) for publication-quality figures</li> <li>Large figure size (18x6) for clear visualization</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_pdf_cdf(mydataframe, mycolumn):\n    \"\"\"Creates side-by-side plots of probability density function (PDF) and cumulative\n    distribution function (CDF).\n\n    This function generates a figure with two subplots: a PDF plot on the left and\n    a CDF plot on the right. The PDF includes both histogram and kernel density\n    estimation, while the CDF shows the cumulative histogram.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create distributions for.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; df = pd.DataFrame({\n        ...     'values': np.concatenate([\n        ...         np.random.normal(0.3, 0.1, 1000),\n        ...         np.random.normal(0.7, 0.1, 1000)\n        ...     ])\n        ... })\n        &gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n\n    Notes:\n        - Uses seaborn's distplot for both PDF and CDF\n        - PDF includes both histogram and kernel density estimation\n        - CDF shows cumulative histogram with step-style line\n        - Both plots are set to range [0, 1] on x-axis\n        - CDF y-axis is also set to range [0, 1]\n        - High DPI (320) for publication-quality figures\n        - Large figure size (18x6) for clear visualization\n    \"\"\"\n    # settings\n    f, axes = plt.subplots(1, 2, figsize=(18, 6), dpi=320)\n    axes[0].set_ylabel(\"fraction (PDF)\")\n    axes[1].set_ylabel(\"fraction (CDF)\")\n\n    # left plot (PDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=True,\n        axlabel=mycolumn,\n        hist_kws={\"density\": True},\n        ax=axes[0],\n    ).set(xlim=(0, 1))\n\n    # right plot (CDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=False,\n        axlabel=mycolumn,\n        hist_kws={\n            \"density\": True,\n            \"cumulative\": True,\n            \"histtype\": \"step\",\n            \"linewidth\": 4,\n        },\n        ax=axes[1],\n    ).set(xlim=(0, 1), ylim=(0, 1))\n    plt.show()\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_quiver","title":"<code>plot_quiver(exps_q_ssm_result_show, exps_ssm_q_result_show, q_diff_show, ssm_diff_show, x_label, y_label)</code>","text":"<p>Creates a quiver plot showing vector field with normalized arrows.</p> <p>This function generates a quiver plot where arrows represent the direction and magnitude of differences between two variables. The arrows are normalized to have uniform length, with color indicating the actual magnitude of the difference.</p> <p>Parameters:</p> Name Type Description Default <code>exps_q_ssm_result_show</code> <code>array</code> <p>X-coordinates for arrow origins.</p> required <code>exps_ssm_q_result_show</code> <code>array</code> <p>Y-coordinates for arrow origins.</p> required <code>q_diff_show</code> <code>array</code> <p>X-components of the difference vectors.</p> required <code>ssm_diff_show</code> <code>array</code> <p>Y-components of the difference vectors.</p> required <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the quiver plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; x = np.random.rand(50)\n&gt;&gt;&gt; y = np.random.rand(50)\n&gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; fig, ax = plot_quiver(\n...     x, y, dx, dy,\n...     'X Variable',\n...     'Y Variable'\n... )\n</code></pre> Notes <ul> <li>Arrows are normalized to uniform length for better visualization</li> <li>Color indicates the actual magnitude of the difference vector</li> <li>Plot includes a colorbar showing the magnitude scale</li> <li>Uses clean plotting style with minimal spines</li> <li>Default plot range is [0, 1] for both axes</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_quiver(\n    exps_q_ssm_result_show,\n    exps_ssm_q_result_show,\n    q_diff_show,\n    ssm_diff_show,\n    x_label,\n    y_label,\n):\n    \"\"\"Creates a quiver plot showing vector field with normalized arrows.\n\n    This function generates a quiver plot where arrows represent the direction and\n    magnitude of differences between two variables. The arrows are normalized to have\n    uniform length, with color indicating the actual magnitude of the difference.\n\n    Args:\n        exps_q_ssm_result_show (np.array): X-coordinates for arrow origins.\n        exps_ssm_q_result_show (np.array): Y-coordinates for arrow origins.\n        q_diff_show (np.array): X-components of the difference vectors.\n        ssm_diff_show (np.array): Y-components of the difference vectors.\n        x_label (str): Label for x-axis.\n        y_label (str): Label for y-axis.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the quiver plot.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; x = np.random.rand(50)\n        &gt;&gt;&gt; y = np.random.rand(50)\n        &gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; fig, ax = plot_quiver(\n        ...     x, y, dx, dy,\n        ...     'X Variable',\n        ...     'Y Variable'\n        ... )\n\n    Notes:\n        - Arrows are normalized to uniform length for better visualization\n        - Color indicates the actual magnitude of the difference vector\n        - Plot includes a colorbar showing the magnitude scale\n        - Uses clean plotting style with minimal spines\n        - Default plot range is [0, 1] for both axes\n    \"\"\"\n    fig, ax = plt.subplots()\n    color = np.sqrt(q_diff_show**2 + ssm_diff_show**2)\n    # normalize to get same length arrows\n    r = np.power(np.add(np.power(q_diff_show, 2), np.power(ssm_diff_show, 2)), 0.5)\n    plt.quiver(\n        exps_q_ssm_result_show,\n        exps_ssm_q_result_show,\n        q_diff_show / r,\n        ssm_diff_show / r,\n        color,\n        scale=25,\n        width=0.005,\n    )\n    # Defining color\n    plt.xlim(-0.01, 1)\n    plt.ylim(-0.01, 1)\n    plt.colorbar()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.xlabel(x_label, fontsize=18)\n    plt.ylabel(y_label, fontsize=18)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_rainfall_runoff","title":"<code>plot_rainfall_runoff(t, p, qs, fig_size=(8, 6), c_lst='rbkgcmy', leg_lst=None, dash_lines=None, title=None, xlabel=None, ylabel=None, prcp_ylabel='prcp(mm/day)', linewidth=1, prcp_interval=20)</code>","text":"<p>Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.</p> <p>This function generates a dual-axis plot showing precipitation as inverted bars from the top and streamflow as lines on the bottom. This is a common visualization in hydrology for analyzing rainfall-runoff relationships.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Union[array, List[array]]</code> <p>Time values. If multiple streamflow series are provided, t can be a list of time arrays matching qs.</p> required <code>p</code> <code>array</code> <p>Precipitation time series data in mm/day.</p> required <code>qs</code> <code>Union[array, List[array]]</code> <p>Streamflow time series data. Can be a single array or list of arrays for multiple streamflow series.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>c_lst</code> <code>str</code> <p>String of color characters for streamflow lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels for streamflow series. Defaults to None.</p> <code>None</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which streamflow lines should be dashed. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>X-axis label. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to None.</p> <code>None</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <code>linewidth</code> <code>int</code> <p>Width of streamflow lines. Defaults to 1.</p> <code>1</code> <code>prcp_interval</code> <code>int</code> <p>Interval for precipitation y-axis ticks. Defaults to 20.</p> <code>20</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple rainfall-runoff plot\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, q,\n...     title='Rainfall-Runoff Analysis',\n...     xlabel='Date',\n...     ylabel='Streamflow (m\u00b3/s)'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple streamflow series\n&gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, qs,\n...     leg_lst=['Observed', 'Simulated'],\n...     dash_lines=[False, True]\n... )\n</code></pre> Notes <ul> <li>Precipitation is plotted as blue bars from the top of the plot</li> <li>Streamflow is plotted as lines on the bottom</li> <li>The precipitation y-axis is inverted for better visualization</li> <li>Grid lines are added automatically</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff(\n    t,\n    p,\n    qs,\n    fig_size=(8, 6),\n    c_lst=\"rbkgcmy\",\n    leg_lst=None,\n    dash_lines=None,\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    prcp_ylabel=\"prcp(mm/day)\",\n    linewidth=1,\n    prcp_interval=20,\n):\n    \"\"\"Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.\n\n    This function generates a dual-axis plot showing precipitation as inverted bars from\n    the top and streamflow as lines on the bottom. This is a common visualization in\n    hydrology for analyzing rainfall-runoff relationships.\n\n    Args:\n        t (Union[np.array, List[np.array]]): Time values. If multiple streamflow series\n            are provided, t can be a list of time arrays matching qs.\n        p (np.array): Precipitation time series data in mm/day.\n        qs (Union[np.array, List[np.array]]): Streamflow time series data. Can be a\n            single array or list of arrays for multiple streamflow series.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        c_lst (str, optional): String of color characters for streamflow lines.\n            Defaults to \"rbkgcmy\".\n        leg_lst (list, optional): Legend labels for streamflow series. Defaults to None.\n        dash_lines (list[bool], optional): Specifies which streamflow lines should be\n            dashed. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n        xlabel (str, optional): X-axis label. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to None.\n        prcp_ylabel (str, optional): Y-axis label for precipitation. Defaults to\n            \"prcp(mm/day)\".\n        linewidth (int, optional): Width of streamflow lines. Defaults to 1.\n        prcp_interval (int, optional): Interval for precipitation y-axis ticks.\n            Defaults to 20.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the plot.\n\n    Examples:\n        &gt;&gt;&gt; # Simple rainfall-runoff plot\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, q,\n        ...     title='Rainfall-Runoff Analysis',\n        ...     xlabel='Date',\n        ...     ylabel='Streamflow (m\u00b3/s)'\n        ... )\n\n        &gt;&gt;&gt; # Multiple streamflow series\n        &gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, qs,\n        ...     leg_lst=['Observed', 'Simulated'],\n        ...     dash_lines=[False, True]\n        ... )\n\n    Notes:\n        - Precipitation is plotted as blue bars from the top of the plot\n        - Streamflow is plotted as lines on the bottom\n        - The precipitation y-axis is inverted for better visualization\n        - Grid lines are added automatically\n    \"\"\"\n    fig, ax = plt.subplots(figsize=fig_size)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(qs), False).tolist()\n    for k in range(len(qs)):\n        tt = t[k] if type(t) is list else t\n        q = qs[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        (line_i,) = ax.plot(tt, q, color=c_lst[k], label=leg_str, linewidth=linewidth)\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    ax.set_ylim(ax.get_ylim()[0], ax.get_ylim()[1] * 1.2)\n    # Create second axes, in order to get the bars from the top you can multiply by -1\n    ax2 = ax.twinx()\n    # ax2.bar(tt, -p, color=\"b\")\n    ax2.fill_between(tt, 0, -p, step=\"mid\", color=\"b\", alpha=0.5)\n    # ax2.plot(tt, -p, color=\"b\", alpha=0.7, linewidth=1.5)\n\n    # Now need to fix the axis labels\n    # max_pre = max(p)\n    max_pre = p.max().item()\n    ax2.set_ylim(-max_pre * 5, 0)\n    y2_ticks = np.arange(0, max_pre, prcp_interval)\n    y2_ticklabels = [str(i) for i in y2_ticks]\n    ax2.set_yticks(-1 * y2_ticks)\n    ax2.set_yticklabels(y2_ticklabels, fontsize=16)\n    # ax2.set_yticklabels([lab.get_text()[1:] for lab in ax2.get_yticklabels()])\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    if ylabel is not None:\n        ax.set_ylabel(ylabel, fontsize=18)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel, fontsize=18)\n    ax2.set_ylabel(prcp_ylabel, fontsize=8, loc=\"top\")\n    # ax2.set_ylabel(\"precipitation (mm/day)\", fontsize=12, loc='top')\n    # https://github.com/matplotlib/matplotlib/issues/12318\n    ax.tick_params(axis=\"x\", labelsize=16)\n    ax.tick_params(axis=\"y\", labelsize=16)\n    ax.legend(bbox_to_anchor=(0.01, 0.85), loc=\"upper left\", fontsize=16)\n    ax.grid()\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_rainfall_runoff_chai","title":"<code>plot_rainfall_runoff_chai(t, ps, qs, c_lst='rbkgcmy', title='Observation of Precipitation and Streamflow', alpha_lst=None, p_labels=None, q_labels=None)</code>","text":"<p>Creates a two-panel rainfall-runoff plot following Chai's style.</p> <p>This function generates a figure with two vertically stacked panels: precipitation on top and streamflow below. It supports multiple precipitation sources and streamflow series with customizable styling.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>ps</code> <code>list[array]</code> <p>List of precipitation arrays from different sources.</p> required <code>qs</code> <code>list[array]</code> <p>List of streamflow arrays (e.g., observed and simulated).</p> required <code>c_lst</code> <code>str</code> <p>String of color characters. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>title</code> <code>str</code> <p>Figure title. Defaults to \"Observation of Precipitation and Streamflow\".</p> <code>'Observation of Precipitation and Streamflow'</code> <code>alpha_lst</code> <code>list[float]</code> <p>Transparency values for each series. Defaults to [0.5, 0.5].</p> <code>None</code> <code>p_labels</code> <code>list[str]</code> <p>Labels for precipitation sources. Defaults to [\"era5land\", \"gauge\"].</p> <code>None</code> <code>q_labels</code> <code>list[str]</code> <p>Labels for streamflow series. Defaults to [\"observation\", \"simulation\"].</p> <code>None</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom axes (streamflow plot).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n&gt;&gt;&gt; # Two precipitation sources\n&gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n&gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n&gt;&gt;&gt; # Observed and simulated streamflow\n&gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n&gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n&gt;&gt;&gt; \n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n...     t, [p1, p2], [q_obs, q_sim],\n...     title='2020 Rainfall-Runoff Comparison',\n...     p_labels=['ERA5', 'Rain Gauge'],\n...     q_labels=['Observed', 'Simulated']\n... )\n</code></pre> Notes <ul> <li>Top panel shows precipitation with bars</li> <li>Bottom panel shows streamflow with lines</li> <li>Precipitation y-axis is inverted and blue</li> <li>Streamflow y-axis is red</li> <li>Both panels share x-axis limits</li> <li>Legends included for both panels</li> <li>Uses large figure size (20x8) by default</li> <li>Includes \"Streamflow\" text box in bottom panel</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_chai(\n    t,\n    ps,\n    qs,\n    c_lst=\"rbkgcmy\",\n    title=\"Observation of Precipitation and Streamflow\",\n    alpha_lst=None,\n    p_labels=None,\n    q_labels=None,\n):\n    \"\"\"Creates a two-panel rainfall-runoff plot following Chai's style.\n\n    This function generates a figure with two vertically stacked panels: precipitation\n    on top and streamflow below. It supports multiple precipitation sources and\n    streamflow series with customizable styling.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        ps (list[np.array]): List of precipitation arrays from different sources.\n        qs (list[np.array]): List of streamflow arrays (e.g., observed and simulated).\n        c_lst (str, optional): String of color characters. Defaults to \"rbkgcmy\".\n        title (str, optional): Figure title. Defaults to \"Observation of Precipitation\n            and Streamflow\".\n        alpha_lst (list[float], optional): Transparency values for each series.\n            Defaults to [0.5, 0.5].\n        p_labels (list[str], optional): Labels for precipitation sources.\n            Defaults to [\"era5land\", \"gauge\"].\n        q_labels (list[str], optional): Labels for streamflow series.\n            Defaults to [\"observation\", \"simulation\"].\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom\n            axes (streamflow plot).\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n        &gt;&gt;&gt; # Two precipitation sources\n        &gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n        &gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n        &gt;&gt;&gt; # Observed and simulated streamflow\n        &gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n        &gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n        ...     t, [p1, p2], [q_obs, q_sim],\n        ...     title='2020 Rainfall-Runoff Comparison',\n        ...     p_labels=['ERA5', 'Rain Gauge'],\n        ...     q_labels=['Observed', 'Simulated']\n        ... )\n\n    Notes:\n        - Top panel shows precipitation with bars\n        - Bottom panel shows streamflow with lines\n        - Precipitation y-axis is inverted and blue\n        - Streamflow y-axis is red\n        - Both panels share x-axis limits\n        - Legends included for both panels\n        - Uses large figure size (20x8) by default\n        - Includes \"Streamflow\" text box in bottom panel\n    \"\"\"\n    if alpha_lst is None:\n        alpha_lst = [0.5, 0.5]\n    if p_labels is None:\n        p_labels = [\"era5land\", \"gauge\"]\n    if q_labels is None:\n        q_labels = [\"observation\", \"simulation\"]\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 8))\n    fig.suptitle(title, fontsize=16)\n    for i, p in enumerate(ps):\n        ax1.bar(\n            t,\n            p,\n            color=c_lst[i],\n            label=p_labels[i],\n            width=0.9,\n            alpha=alpha_lst[i],\n        )\n    ax1.set_xlabel(\"Time\")\n    ax1.set_ylabel(\"Precipitation (mm/d)\", color=\"b\")\n    ax1.invert_yaxis()\n    ax1.tick_params(axis=\"y\", labelcolor=\"b\")\n    ax1.legend()\n\n    for j, q in enumerate(qs):\n        ax2.plot(t, q, color=c_lst[j], label=q_labels[j], alpha=alpha_lst[j])\n    ax2.set_xlabel(\"Time\")\n    ax2.set_ylabel(\"Streamflow (m$^3$/s)\", color=\"r\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"r\")\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.text(\n        0.05,\n        0.95,\n        \"Streamflow\",\n        transform=ax2.transAxes,\n        fontsize=12,\n        verticalalignment=\"top\",\n        bbox=dict(facecolor=\"white\", alpha=0.5),\n    )\n    ax2.legend()\n\n    fig.tight_layout()\n    return fig, ax2\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_rainfall_runoff_xu","title":"<code>plot_rainfall_runoff_xu(t, p, qs, fig_size=(10, 6), title='prcp-streamflow', leg_lst=None, ylabel='streamflow(m^3/s)', prcp_ylabel='prcp(mm/day)')</code>","text":"<p>Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.</p> <p>This function generates a specialized plot with precipitation bars from the top and streamflow lines on the bottom, following Xu's visualization style. It uses dual y-axes with color-coded labels and ticks.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>p</code> <code>array</code> <p>Precipitation values.</p> required <code>qs</code> <code>tuple</code> <p>Tuple of (observed, predicted) streamflow values.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (10, 6).</p> <code>(10, 6)</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to \"prcp-streamflow\".</p> <code>'prcp-streamflow'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".</p> <code>'streamflow(m^3/s)'</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n&gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n&gt;&gt;&gt; plot_rainfall_runoff_xu(\n...     t, p, (obs, pred),\n...     title='2020 Rainfall-Runoff Analysis'\n... )\n</code></pre> Notes <ul> <li>Precipitation shown as blue bars from top</li> <li>Observed streamflow as solid green line</li> <li>Predicted streamflow as dashed red line</li> <li>Y-axes labels and ticks color-coded</li> <li>Precipitation axis inverted</li> <li>Legend positioned at upper left</li> <li>Precipitation bars semi-transparent (alpha=0.6)</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_xu(\n    t,\n    p,\n    qs,\n    fig_size=(10, 6),\n    title=\"prcp-streamflow\",\n    leg_lst=None,\n    ylabel=\"streamflow(m^3/s)\",\n    prcp_ylabel=\"prcp(mm/day)\",\n):\n    \"\"\"Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.\n\n    This function generates a specialized plot with precipitation bars from the top\n    and streamflow lines on the bottom, following Xu's visualization style. It uses\n    dual y-axes with color-coded labels and ticks.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        p (np.array): Precipitation values.\n        qs (tuple): Tuple of (observed, predicted) streamflow values.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (10, 6).\n        title (str, optional): Plot title. Defaults to \"prcp-streamflow\".\n        leg_lst (list, optional): Legend labels. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".\n        prcp_ylabel (str, optional): Y-axis label for precipitation.\n            Defaults to \"prcp(mm/day)\".\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n        &gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n        &gt;&gt;&gt; plot_rainfall_runoff_xu(\n        ...     t, p, (obs, pred),\n        ...     title='2020 Rainfall-Runoff Analysis'\n        ... )\n\n    Notes:\n        - Precipitation shown as blue bars from top\n        - Observed streamflow as solid green line\n        - Predicted streamflow as dashed red line\n        - Y-axes labels and ticks color-coded\n        - Precipitation axis inverted\n        - Legend positioned at upper left\n        - Precipitation bars semi-transparent (alpha=0.6)\n    \"\"\"\n    obs, pred = qs\n\n    fig, ax1 = plt.subplots(figsize=fig_size)\n\n    ax1.bar(t, p, width=0.1, color=\"blue\", alpha=0.6, label=\"Precipitation\")\n    ax1.set_ylabel(prcp_ylabel, color=\"blue\")\n    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n\n    ax1.set_ylim(0, p.max() * 5)\n    ax1.invert_yaxis()\n\n    ax2 = ax1.twinx()\n\n    # transform the unit of obs and pred\n    ax2.plot(\n        t,\n        obs,\n        color=\"green\",\n        linestyle=\"-\",\n        label=\"observed value\",\n    )\n    ax2.plot(\n        t,\n        pred,\n        color=\"red\",\n        linestyle=\"--\",\n        label=\"predicted value\",\n    )\n\n    ax2.set_ylabel(ylabel, color=\"red\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n\n    plt.title(title)\n\n    plt.legend(loc=\"upper left\")\n    return fig, (ax1, ax2)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_scatter_with_11line","title":"<code>plot_scatter_with_11line(x, y, point_color='blue', line_color='black', xlim=[0.0, 1.0], ylim=[0.0, 1.0], xlabel=None, ylabel=None)</code>","text":"<p>Creates a scatter plot comparing two variables with a 1:1 line.</p> <p>This function generates a scatter plot with a 1:1 line (diagonal) for comparing two variables, commonly used in model evaluation to compare observed vs predicted values. The plot includes customizable colors, axis limits, and labels.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array</code> <p>First variable to be plotted (typically observed values).</p> required <code>y</code> <code>array</code> <p>Second variable to be plotted (typically predicted values).</p> required <code>point_color</code> <code>str</code> <p>Color of scatter points. Defaults to \"blue\".</p> <code>'blue'</code> <code>line_color</code> <code>str</code> <p>Color of the 1:1 line. Defaults to \"black\".</p> <code>'black'</code> <code>xlim</code> <code>list</code> <p>X-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>ylim</code> <code>list</code> <p>Y-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>xlabel</code> <code>str</code> <p>Label for x-axis. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Label for y-axis. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]:  A tuple containing the figure and axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n&gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n...     obs, pred,\n...     xlabel='Observed',\n...     ylabel='Predicted',\n...     xlim=[0, 6],\n...     ylim=[0, 6]\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_with_11line(\n    x: np.array,\n    y: np.array,\n    point_color=\"blue\",\n    line_color=\"black\",\n    xlim=[0.0, 1.0],\n    ylim=[0.0, 1.0],\n    xlabel=None,\n    ylabel=None,\n):\n    \"\"\"Creates a scatter plot comparing two variables with a 1:1 line.\n\n    This function generates a scatter plot with a 1:1 line (diagonal) for comparing\n    two variables, commonly used in model evaluation to compare observed vs predicted values.\n    The plot includes customizable colors, axis limits, and labels.\n\n    Args:\n        x (np.array): First variable to be plotted (typically observed values).\n        y (np.array): Second variable to be plotted (typically predicted values).\n        point_color (str, optional): Color of scatter points. Defaults to \"blue\".\n        line_color (str, optional): Color of the 1:1 line. Defaults to \"black\".\n        xlim (list, optional): X-axis range as [min, max]. Defaults to [0.0, 1.0].\n        ylim (list, optional): Y-axis range as [min, max]. Defaults to [0.0, 1.0].\n        xlabel (str, optional): Label for x-axis. Defaults to None.\n        ylabel (str, optional): Label for y-axis. Defaults to None.\n\n    Returns:\n        tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: \n            A tuple containing the figure and axes objects.\n\n    Examples:\n        &gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n        &gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n        &gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n        ...     obs, pred,\n        ...     xlabel='Observed',\n        ...     ylabel='Predicted',\n        ...     xlim=[0, 6],\n        ...     ylim=[0, 6]\n        ... )\n    \"\"\"\n    fig, ax = plt.subplots()\n    # set background color for ax\n    ax.set_facecolor(\"whitesmoke\")\n    # plot the grid of the figure\n    # plt.grid(color=\"whitesmoke\")\n    ax.scatter(x, y, c=point_color, s=10)\n    line = mlines.Line2D([0, 1], [0, 1], color=line_color, linestyle=\"--\")\n    transform = ax.transAxes\n    line.set_transform(transform)\n    ax.add_line(line)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    plt.xticks(np.arange(xlim[0], xlim[1], 0.1), fontsize=16)\n    plt.yticks(np.arange(ylim[0], ylim[1], 0.1), fontsize=16)\n    # set xlable and ylabel\n    if xlabel is not None:\n        plt.xlabel(xlabel, fontsize=16)\n    if ylabel is not None:\n        plt.ylabel(ylabel, fontsize=16)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_scatter_xyc","title":"<code>plot_scatter_xyc(x_label, x, y_label, y, c_label=None, c=None, size=20, is_reg=False, xlim=None, ylim=None, quadrant=None)</code>","text":"<p>Creates a scatter plot with optional color mapping and quadrant analysis.</p> <p>This function generates a scatter plot with optional color mapping for points, regression line, and quadrant analysis. It's particularly useful for analyzing relationships between variables with an additional dimension represented by color.</p> <p>Parameters:</p> Name Type Description Default <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>x</code> <code>Union[array, List[array]]</code> <p>X-axis data values.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <code>y</code> <code>Union[array, List[array]]</code> <p>Y-axis data values.</p> required <code>c_label</code> <code>Union[str, List[str]]</code> <p>Label(s) for color mapping or multiple series. Defaults to None.</p> <code>None</code> <code>c</code> <code>Union[array, List[str]]</code> <p>Values for color mapping or colors for multiple series. Defaults to None.</p> <code>None</code> <code>size</code> <code>int</code> <p>Size of scatter points. Defaults to 20.</p> <code>20</code> <code>is_reg</code> <code>bool</code> <p>If True, adds regression line. Defaults to False.</p> <code>False</code> <code>xlim</code> <code>list</code> <p>X-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>quadrant</code> <code>list</code> <p>Reference points [x, y] for quadrant analysis. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple scatter plot\n&gt;&gt;&gt; x = np.random.rand(100)\n&gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X Values', x,\n...     'Y Values', y,\n...     is_reg=True\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Scatter plot with color mapping\n&gt;&gt;&gt; c = np.random.rand(100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     c_label='Z Values',\n...     c=c\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Quadrant analysis\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     quadrant=[0.5, 0.5],\n...     xlim=[0, 1],\n...     ylim=[0, 1]\n... )\n</code></pre> Notes <ul> <li>Supports both single and multiple series plotting</li> <li>Automatically handles NaN values</li> <li>Provides quadrant statistics when quadrant analysis is enabled</li> <li>Uses clean plotting style with minimal spines</li> <li>Supports regression line with seaborn's regplot</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_xyc(\n    x_label,\n    x,\n    y_label,\n    y,\n    c_label=None,\n    c=None,\n    size=20,\n    is_reg=False,\n    xlim=None,\n    ylim=None,\n    quadrant=None,\n):\n    \"\"\"Creates a scatter plot with optional color mapping and quadrant analysis.\n\n    This function generates a scatter plot with optional color mapping for points,\n    regression line, and quadrant analysis. It's particularly useful for analyzing\n    relationships between variables with an additional dimension represented by color.\n\n    Args:\n        x_label (str): Label for x-axis.\n        x (Union[np.array, List[np.array]]): X-axis data values.\n        y_label (str): Label for y-axis.\n        y (Union[np.array, List[np.array]]): Y-axis data values.\n        c_label (Union[str, List[str]], optional): Label(s) for color mapping or\n            multiple series. Defaults to None.\n        c (Union[np.array, List[str]], optional): Values for color mapping or\n            colors for multiple series. Defaults to None.\n        size (int, optional): Size of scatter points. Defaults to 20.\n        is_reg (bool, optional): If True, adds regression line. Defaults to False.\n        xlim (list, optional): X-axis limits as [min, max]. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        quadrant (list, optional): Reference points [x, y] for quadrant analysis.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Simple scatter plot\n        &gt;&gt;&gt; x = np.random.rand(100)\n        &gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X Values', x,\n        ...     'Y Values', y,\n        ...     is_reg=True\n        ... )\n\n        &gt;&gt;&gt; # Scatter plot with color mapping\n        &gt;&gt;&gt; c = np.random.rand(100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     c_label='Z Values',\n        ...     c=c\n        ... )\n\n        &gt;&gt;&gt; # Quadrant analysis\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     quadrant=[0.5, 0.5],\n        ...     xlim=[0, 1],\n        ...     ylim=[0, 1]\n        ... )\n\n    Notes:\n        - Supports both single and multiple series plotting\n        - Automatically handles NaN values\n        - Provides quadrant statistics when quadrant analysis is enabled\n        - Uses clean plotting style with minimal spines\n        - Supports regression line with seaborn's regplot\n    \"\"\"\n    fig, ax = plt.subplots()\n    if type(x) is list:\n        for i in range(len(x)):\n            ax.plot(\n                x[i], y[i], marker=\"o\", linestyle=\"\", ms=size, label=c_label[i], c=c[i]\n            )\n        ax.legend()\n\n    elif c is None:\n        df = pd.DataFrame({x_label: x, y_label: y})\n        points = plt.scatter(df[x_label], df[y_label], s=size)\n        if quadrant is not None:\n            plt.axvline(quadrant[0], c=\"grey\", lw=1, linestyle=\"--\")\n            plt.axhline(quadrant[1], c=\"grey\", lw=1, linestyle=\"--\")\n            q2 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q3 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q4 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q5 = df[(df[x_label] == 0) &amp; (df[y_label] == 0)].shape[0]\n            q1 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q = q1 + q2 + q3 + q4 + q5\n            r1 = int(round(q1 / q, 2) * 100)\n            r2 = int(round(q2 / q, 2) * 100)\n            r3 = int(round(q3 / q, 2) * 100)\n            r4 = int(round(q4 / q, 2) * 100)\n            r5 = 100 - r1 - r2 - r3 - r4\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r1}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r2}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r3}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r4}%\",\n                fontsize=16,\n            )\n            plt.text(0.2, 0.02, f\"{str(r5)}%\", fontsize=16)\n    else:\n        df = pd.DataFrame({x_label: x, y_label: y, c_label: c})\n        points = plt.scatter(\n            df[x_label], df[y_label], c=df[c_label], s=size, cmap=\"Spectral\"\n        )  # set style options\n        # add a color bar\n        plt.colorbar(points)\n\n    # set limits\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    # build the regression plot\n    if is_reg:\n        plot = sns.regplot(x_label, y_label, data=df, scatter=False)  # , color=\".1\"\n        plot = plot.set(xlabel=x_label, ylabel=y_label)  # add labels\n    else:\n        plt.xlabel(x_label, fontsize=18)\n        plt.ylabel(y_label, fontsize=18)\n        plt.xticks(fontsize=16)\n        plt.yticks(fontsize=16)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts","title":"<code>plot_ts(t, y, ax=None, t_bar=None, title=None, xlabel=None, ylabel=None, fig_size=(12, 4), c_lst='rbkgcmyrbkgcmyrbkgcmy', leg_lst=None, marker_lst=None, linewidth=2, linespec=None, dash_lines=None, alpha=1)</code>","text":"<p>Plot time series for multi arrays with matplotlib</p>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts--parameters","title":"Parameters","text":"<p>t : Union[list, np.array]     time series but not just date; it can also be numbers like 1, 2, 3, ... y : Union[list, np.array]     shown data series; the len of y should be equal to t's ax : type, optional     description, by default None t_bar : type, optional     description, by default None title : type, optional     description, by default None xlabel: str, optional     the name of x axis, by default None ylabel : str, optional     the name of y axis, by default None fig_size : tuple, optional     description, by default (12, 4) c_lst : str, optional     description, by default \"rbkgcmy\" leg_lst : type, optional     description, by default None marker_lst : type, optional     description, by default None linewidth : int, optional     description, by default 2 linespec : type, optional     description, by default None dash_lines : type, optional     if dash_line, then we will plot dashed line, by default None</p>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts--returns","title":"Returns","text":"<p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts(\n    t: Union[list, np.array],\n    y: Union[list, np.array],\n    ax=None,\n    t_bar=None,\n    title=None,\n    xlabel: str = None,\n    ylabel: str = None,\n    fig_size=(12, 4),\n    c_lst=\"rbkgcmyrbkgcmyrbkgcmy\",\n    leg_lst=None,\n    marker_lst=None,\n    linewidth=2,\n    linespec=None,\n    dash_lines=None,\n    alpha=1,\n):\n    \"\"\"Plot time series for multi arrays with matplotlib\n\n    Parameters\n    ----------\n    t : Union[list, np.array]\n        time series but not just date; it can also be numbers like 1, 2, 3, ...\n    y : Union[list, np.array]\n        shown data series; the len of y should be equal to t's\n    ax : _type_, optional\n        _description_, by default None\n    t_bar : _type_, optional\n        _description_, by default None\n    title : _type_, optional\n        _description_, by default None\n    xlabel: str, optional\n        the name of x axis, by default None\n    ylabel : str, optional\n        the name of y axis, by default None\n    fig_size : tuple, optional\n        _description_, by default (12, 4)\n    c_lst : str, optional\n        _description_, by default \"rbkgcmy\"\n    leg_lst : _type_, optional\n        _description_, by default None\n    marker_lst : _type_, optional\n        _description_, by default None\n    linewidth : int, optional\n        _description_, by default 2\n    linespec : _type_, optional\n        _description_, by default None\n    dash_lines : _type_, optional\n        if dash_line, then we will plot dashed line, by default None\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    is_new_fig = False\n    if ax is None:\n        fig = plt.figure(figsize=fig_size)\n        ax = fig.subplots()\n        is_new_fig = True\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(t), False).tolist()\n        # dash_lines[-1] = True\n    if type(y) is np.ndarray:\n        y = [y]\n    if type(linewidth) is not list:\n        linewidth = [linewidth] * len(y)\n    if type(alpha) is not list:\n        alpha = [alpha] * len(y)\n    for k in range(len(y)):\n        tt = t[k] if type(t) is list else t\n        yy = y[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        if marker_lst is None:\n            (line_i,) = (\n                ax.plot(tt, yy, \"*\", color=c_lst[k], label=leg_str, alpha=alpha[k])\n                if True in np.isnan(yy)\n                else ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linewidth=linewidth[k],\n                    alpha=alpha[k],\n                )\n            )\n        elif marker_lst[k] == \"-\":\n            if linespec is not None:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linestyle=linespec[k],\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n            else:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n        else:\n            (line_i,) = ax.plot(\n                tt,\n                yy,\n                color=c_lst[k],\n                label=leg_str,\n                marker=marker_lst[k],\n                lw=linewidth[k],\n                alpha=alpha[k],\n            )\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n        if ylabel is not None:\n            ax.set_ylabel(ylabel, fontsize=18)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel, fontsize=18)\n    if t_bar is not None:\n        ylim = ax.get_ylim()\n        t_bar = [t_bar] if type(t_bar) is not list else t_bar\n        for tt in t_bar:\n            ax.plot([tt, tt], ylim, \"-k\")\n\n    if leg_lst is not None:\n        ax.legend(loc=\"upper right\", frameon=False)\n        plt.legend(prop={\"size\": 16})\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    # plot the grid of the figure\n    plt.grid()\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.tight_layout()\n    return (fig, ax) if is_new_fig else ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts_map","title":"<code>plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None)</code>","text":"<p>Creates an interactive map with linked time series plots.</p> <p>This function generates a figure with two subplots: a map on top and a time series plot below. Clicking on a location in the map updates the time series plot to show data from the nearest site.</p> <p>Parameters:</p> Name Type Description Default <code>dataMap</code> <code>list</code> <p>Data values to be shown on the map.</p> required <code>dataTs</code> <code>list</code> <p>List of time series data for each site.</p> required <code>lat</code> <code>array</code> <p>Latitude values for each site.</p> required <code>lon</code> <code>array</code> <p>Longitude values for each site.</p> required <code>t</code> <code>list</code> <p>Time points for x-axis of time series.</p> required <code>sites_id</code> <code>list</code> <p>Identifiers for each site.</p> required <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling on map. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; n_sites = 10\n&gt;&gt;&gt; n_times = 100\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n&gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Generate sample time series for each site\n&gt;&gt;&gt; t = list(range(n_times))\n&gt;&gt;&gt; dataTs = []\n&gt;&gt;&gt; for i in range(n_sites):\n...     pred = np.sin(np.array(t)/10 + i/5)\n...     obs = pred + np.random.normal(0, 0.1, n_times)\n...     dataTs.append([pred, obs])\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Map data could be mean values\n&gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n&gt;&gt;&gt; \n&gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n</code></pre> Notes <ul> <li>Uses TkAgg backend for interactive display</li> <li>Map uses Cartopy for proper geographic projection</li> <li>Time series updates automatically on map click</li> <li>Shows site ID and coordinates in time series title</li> <li>Finds nearest site to click location</li> <li>Both predicted and observed values shown in time series</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None):\n    \"\"\"Creates an interactive map with linked time series plots.\n\n    This function generates a figure with two subplots: a map on top and a time series\n    plot below. Clicking on a location in the map updates the time series plot to show\n    data from the nearest site.\n\n    Args:\n        dataMap (list): Data values to be shown on the map.\n        dataTs (list): List of time series data for each site.\n        lat (np.array): Latitude values for each site.\n        lon (np.array): Longitude values for each site.\n        t (list): Time points for x-axis of time series.\n        sites_id (list): Identifiers for each site.\n        pertile_range (list, optional): Percentile range for color scaling on map.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; n_sites = 10\n        &gt;&gt;&gt; n_times = 100\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n        &gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Generate sample time series for each site\n        &gt;&gt;&gt; t = list(range(n_times))\n        &gt;&gt;&gt; dataTs = []\n        &gt;&gt;&gt; for i in range(n_sites):\n        ...     pred = np.sin(np.array(t)/10 + i/5)\n        ...     obs = pred + np.random.normal(0, 0.1, n_times)\n        ...     dataTs.append([pred, obs])\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Map data could be mean values\n        &gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n\n    Notes:\n        - Uses TkAgg backend for interactive display\n        - Map uses Cartopy for proper geographic projection\n        - Time series updates automatically on map click\n        - Shows site ID and coordinates in time series title\n        - Finds nearest site to click location\n        - Both predicted and observed values shown in time series\n    \"\"\"\n    # show the map in a pop-up window\n    matplotlib.use(\"TkAgg\")\n    assert isinstance(dataMap, list)\n    assert isinstance(dataTs, list)\n    # setup axes\n    fig = plt.figure(figsize=(8, 8), dpi=100)\n    gs = gridspec.GridSpec(2, 1)\n    # plt.subplots_adjust(left=0.13, right=0.89, bottom=0.05)\n    # plot maps\n    ax1 = plt.subplot(gs[0], projection=ccrs.PlateCarree())\n    ax1 = plot_map_carto(\n        dataMap, lat=lat, lon=lon, fig=fig, ax=ax1, pertile_range=pertile_range\n    )\n    # line plot\n    ax2 = plt.subplot(gs[1])\n\n    # plot ts\n    def onclick(event):\n        print(\"click event\")\n        # refresh the ax2, then new ts data can be showed without previous one\n        ax2.cla()\n        xClick = event.xdata\n        yClick = event.ydata\n        d = np.sqrt((xClick - lon) ** 2 + (yClick - lat) ** 2)\n        ind = np.argmin(d)\n        titleStr = \"site_id %s, lat %.3f, lon %.3f\" % (\n            sites_id[ind],\n            lat[ind],\n            lon[ind],\n        )\n        tsLst = dataTs[ind]\n        plot_ts_matplot(t, tsLst, ax=ax2, title=titleStr)\n        # following funcs both work\n        fig.canvas.draw()\n        # plt.draw()\n\n    fig.canvas.mpl_connect(\"button_press_event\", onclick)\n    plt.show()\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts_matplot","title":"<code>plot_ts_matplot(t, y, color='r', ax=None, title=None)</code>","text":"<p>Creates a simple time series plot comparing predicted and observed values.</p> <p>This function provides a straightforward way to plot and compare two time series, typically used for showing predicted vs observed values. It supports both creating new figures and adding to existing axes.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>list</code> <p>Time points for x-axis.</p> required <code>y</code> <code>list</code> <p>List containing two arrays: [predicted_values, observed_values].</p> required <code>color</code> <code>str</code> <p>Color for predicted values line. Defaults to \"r\".</p> <code>'r'</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]: If ax is None, returns (fig, ax), otherwise returns ax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create new plot\n&gt;&gt;&gt; t = list(range(100))\n&gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n&gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n</code></pre> <pre><code>&gt;&gt;&gt; # Add to existing axes\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n...                     title='Sine Wave Prediction')\n</code></pre> Notes <ul> <li>Predicted values are plotted first with specified color</li> <li>Observed values are plotted second with default color</li> <li>Legend is automatically added with \"pred\" and \"obs\" labels</li> <li>Title is centered if provided</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_matplot(t, y, color=\"r\", ax=None, title=None):\n    \"\"\"Creates a simple time series plot comparing predicted and observed values.\n\n    This function provides a straightforward way to plot and compare two time series,\n    typically used for showing predicted vs observed values. It supports both creating\n    new figures and adding to existing axes.\n\n    Args:\n        t (list): Time points for x-axis.\n        y (list): List containing two arrays: [predicted_values, observed_values].\n        color (str, optional): Color for predicted values line. Defaults to \"r\".\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n\n    Returns:\n        Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]:\n            If ax is None, returns (fig, ax), otherwise returns ax.\n\n    Examples:\n        &gt;&gt;&gt; # Create new plot\n        &gt;&gt;&gt; t = list(range(100))\n        &gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n        &gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n\n        &gt;&gt;&gt; # Add to existing axes\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n        ...                     title='Sine Wave Prediction')\n\n    Notes:\n        - Predicted values are plotted first with specified color\n        - Observed values are plotted second with default color\n        - Legend is automatically added with \"pred\" and \"obs\" labels\n        - Title is centered if provided\n    \"\"\"\n    assert isinstance(t, list)\n    assert isinstance(y, list)\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.subplots()\n    ax.plot(t, y[0], color=color, label=\"pred\")\n    ax.plot(t, y[1], label=\"obs\")\n    ax.legend()\n    if title is not None:\n        ax.set_title(title, loc=\"center\")\n    return (fig, ax) if ax is None else ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.swarmplot_without_legend","title":"<code>swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs)</code>","text":"<p>Creates a swarm plot using seaborn with colorbar instead of legend.</p> <p>This function creates a swarm plot where points are colored according to a continuous variable, replacing the default legend with a colorbar for better visualization of the color scale.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Values for x-axis categories.</p> required <code>y</code> <p>Values for y-axis.</p> required <code>hue</code> <p>Values determining the color of each point.</p> required <code>vmin</code> <code>float</code> <p>Minimum value for color normalization.</p> required <code>vmax</code> <code>float</code> <p>Maximum value for color normalization.</p> required <code>cmap</code> <code>str</code> <p>Colormap name or matplotlib colormap object.</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to sns.swarmplot.</p> <code>{}</code> <p>Returns:</p> Type Description <p>matplotlib.figure.Figure: The figure containing the swarm plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n&gt;&gt;&gt; y = [1, 2, 3, 4]\n&gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n&gt;&gt;&gt; fig = swarmplot_without_legend(\n...     x, y, hue,\n...     vmin=0, vmax=1,\n...     cmap='viridis'\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs):\n    \"\"\"Creates a swarm plot using seaborn with colorbar instead of legend.\n\n    This function creates a swarm plot where points are colored according to a continuous\n    variable, replacing the default legend with a colorbar for better visualization of\n    the color scale.\n\n    Args:\n        x: Values for x-axis categories.\n        y: Values for y-axis.\n        hue: Values determining the color of each point.\n        vmin (float): Minimum value for color normalization.\n        vmax (float): Maximum value for color normalization.\n        cmap (str): Colormap name or matplotlib colormap object.\n        **kwargs: Additional keyword arguments passed to sns.swarmplot.\n\n    Returns:\n        matplotlib.figure.Figure: The figure containing the swarm plot.\n\n    Examples:\n        &gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n        &gt;&gt;&gt; y = [1, 2, 3, 4]\n        &gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n        &gt;&gt;&gt; fig = swarmplot_without_legend(\n        ...     x, y, hue,\n        ...     vmin=0, vmax=1,\n        ...     cmap='viridis'\n        ... )\n    \"\"\"\n    fig = plt.gcf()\n    ax = sns.swarmplot(x, y, hue, **kwargs)\n    # remove the legend, because we want to set a colorbar instead\n    ax.legend().remove()\n    norm = plt.Normalize(vmin, vmax)\n    sm = ScalarMappable(norm=norm, cmap=cmap)\n    return fig\n</code></pre>"},{"location":"api/hydro_s3/","title":"hydro_s3","text":"<p>The <code>hydro_s3</code> module provides utilities for interacting with S3-compatible storage services, supporting both MinIO and AWS S3.</p>"},{"location":"api/hydro_s3/#minio-functions","title":"MinIO Functions","text":""},{"location":"api/hydro_s3/#minio_upload_file","title":"minio_upload_file","text":"<pre><code>def minio_upload_file(client: Minio, bucket_name: str, object_name: str, file_path: str) -&gt; list\n</code></pre> <p>Uploads a file to MinIO S3-compatible storage.</p> <p>Example: <pre><code>from minio import Minio\nclient = Minio('play.min.io', access_key='...', secret_key='...')\nobjects = minio_upload_file(client, 'mybucket', 'data.csv', './data.csv')\nprint(f\"Bucket contents: {objects}\")\n</code></pre></p>"},{"location":"api/hydro_s3/#minio_download_file","title":"minio_download_file","text":"<pre><code>def minio_download_file(client: Minio, bucket_name: str, object_name: str, file_path: str, version_id: str = None) -&gt; None\n</code></pre> <p>Downloads a file from MinIO S3-compatible storage.</p> <p>Example: <pre><code>from minio import Minio\nclient = Minio('play.min.io', access_key='...', secret_key='...')\nminio_download_file(client, 'mybucket', 'data.csv', './downloaded.csv')\n</code></pre></p>"},{"location":"api/hydro_s3/#aws-s3-functions","title":"AWS S3 Functions","text":""},{"location":"api/hydro_s3/#boto3_upload_file","title":"boto3_upload_file","text":"<pre><code>def boto3_upload_file(client, bucket_name: str, object_name: str, file_path: str) -&gt; list\n</code></pre> <p>Uploads a file to AWS S3 using boto3.</p> <p>Example: <pre><code>import boto3\nclient = boto3.client('s3')\nobjects = boto3_upload_file(client, 'mybucket', 'data.csv', './data.csv')\nprint(f\"Bucket contents: {objects}\")\n</code></pre></p>"},{"location":"api/hydro_s3/#boto3_download_file","title":"boto3_download_file","text":"<pre><code>def boto3_download_file(client, bucket_name: str, object_name: str, file_path: str) -&gt; None\n</code></pre> <p>Downloads a file from AWS S3 using boto3.</p> <p>Example: <pre><code>import boto3\nclient = boto3.client('s3')\nboto3_download_file(client, 'mybucket', 'data.csv', './downloaded.csv')\n</code></pre></p>"},{"location":"api/hydro_s3/#common-features","title":"Common Features","text":"<ul> <li>Automatic bucket creation if not exists</li> <li>UTF-8 text file handling</li> <li>Version control support (MinIO)</li> <li>List bucket contents after upload</li> <li>Simple and consistent API for both services</li> </ul>"},{"location":"api/hydro_stat/","title":"hydro_stat","text":"<p>The <code>hydro_stat</code> module provides statistical functions for hydrological data analysis, including error metrics, flow duration curves, and data transformations.</p>"},{"location":"api/hydro_stat/#error-metrics","title":"Error Metrics","text":""},{"location":"api/hydro_stat/#stat_error","title":"stat_error","text":"<pre><code>def stat_error(target: np.ndarray, pred: np.ndarray, fill_nan: str = \"no\") -&gt; dict\n</code></pre> <p>Calculates multiple error metrics between predicted and target values.</p> <p>Example: <pre><code>obs = np.array([[1, 2, 3], [4, 5, 6]])  # 2 basins, 3 timesteps\npred = np.array([[1.1, 2.1, 3.1], [4.2, 5.1, 5.9]])\nmetrics = stat_error(obs, pred)\nprint(f\"Mean RMSE: {np.mean(metrics['RMSE']):.2f}\")\n</code></pre></p>"},{"location":"api/hydro_stat/#stat_errors","title":"stat_errors","text":"<pre><code>def stat_errors(target: np.ndarray, pred: np.ndarray, fill_nan: list = None) -&gt; list\n</code></pre> <p>Similar to stat_error but handles 3D arrays for multiple variables.</p>"},{"location":"api/hydro_stat/#kge","title":"KGE","text":"<pre><code>def KGE(xs: np.ndarray, xo: np.ndarray) -&gt; float\n</code></pre> <p>Calculates Kling-Gupta Efficiency between simulated and observed values.</p>"},{"location":"api/hydro_stat/#flow-duration-curves","title":"Flow Duration Curves","text":""},{"location":"api/hydro_stat/#cal_fdc","title":"cal_fdc","text":"<pre><code>def cal_fdc(data: np.ndarray, quantile_num: int = 100) -&gt; np.ndarray\n</code></pre> <p>Calculates flow duration curves for multiple time series.</p> <p>Example: <pre><code>flows = np.random.lognormal(0, 1, (2, 365))  # 2 locations, 365 days\nfdcs = cal_fdc(flows, quantile_num=100)\n</code></pre></p>"},{"location":"api/hydro_stat/#fms","title":"fms","text":"<pre><code>def fms(obs: np.ndarray, sim: np.ndarray, lower: float = 0.2, upper: float = 0.7) -&gt; float\n</code></pre> <p>Calculates the slope of the middle section of the flow duration curve.</p>"},{"location":"api/hydro_stat/#peak-analysis","title":"Peak Analysis","text":""},{"location":"api/hydro_stat/#mean_peak_timing","title":"mean_peak_timing","text":"<pre><code>def mean_peak_timing(\n    obs: np.ndarray,\n    sim: np.ndarray,\n    window: int = None,\n    resolution: str = \"1D\",\n    datetime_coord: str = None\n) -&gt; float\n</code></pre> <p>Calculates mean difference in peak flow timing between observed and simulated flows.</p>"},{"location":"api/hydro_stat/#statistical-tests","title":"Statistical Tests","text":""},{"location":"api/hydro_stat/#wilcoxon_t_test","title":"wilcoxon_t_test","text":"<pre><code>def wilcoxon_t_test(xs: np.ndarray, xo: np.ndarray) -&gt; tuple\n</code></pre> <p>Performs Wilcoxon signed-rank test on paired samples.</p>"},{"location":"api/hydro_stat/#wilcoxon_t_test_for_lst","title":"wilcoxon_t_test_for_lst","text":"<pre><code>def wilcoxon_t_test_for_lst(x_lst: list, rnd_num: int = 2) -&gt; tuple\n</code></pre> <p>Performs pairwise Wilcoxon tests between all arrays in a list.</p>"},{"location":"api/hydro_stat/#data-transformations","title":"Data Transformations","text":""},{"location":"api/hydro_stat/#cal_stat_gamma","title":"cal_stat_gamma","text":"<pre><code>def cal_stat_gamma(x: np.ndarray) -&gt; list\n</code></pre> <p>Transforms data to approximate normal distribution and calculates statistics.</p>"},{"location":"api/hydro_stat/#cal_stat_prcp_norm","title":"cal_stat_prcp_norm","text":"<pre><code>def cal_stat_prcp_norm(x: np.ndarray, meanprep: np.ndarray) -&gt; list\n</code></pre> <p>Normalizes data by mean precipitation and calculates statistics.</p>"},{"location":"api/hydro_stat/#trans_norm","title":"trans_norm","text":"<pre><code>def trans_norm(\n    x: np.ndarray,\n    var_lst: Union[str, list],\n    stat_dict: dict,\n    *,\n    to_norm: bool\n) -&gt; np.ndarray\n</code></pre> <p>Normalizes or denormalizes data using pre-computed statistics.</p>"},{"location":"api/hydro_stat/#basic-statistics","title":"Basic Statistics","text":""},{"location":"api/hydro_stat/#cal_4_stat_inds","title":"cal_4_stat_inds","text":"<pre><code>def cal_4_stat_inds(b: np.ndarray) -&gt; list\n</code></pre> <p>Calculates four basic statistical indices for an array.</p>"},{"location":"api/hydro_stat/#cal_stat","title":"cal_stat","text":"<pre><code>def cal_stat(x: np.ndarray) -&gt; list\n</code></pre> <p>Calculates basic statistics for an array, ignoring NaN values.</p>"},{"location":"api/hydro_stat/#data-processing","title":"Data Processing","text":""},{"location":"api/hydro_stat/#remove_abnormal_data","title":"remove_abnormal_data","text":"<pre><code>def remove_abnormal_data(\n    data: np.ndarray,\n    *,\n    q1: float = 0.00001,\n    q2: float = 0.99999\n) -&gt; np.ndarray\n</code></pre> <p>Removes extreme values from data using quantile thresholds.</p>"},{"location":"api/hydro_stat/#month_stat_for_daily_df","title":"month_stat_for_daily_df","text":"<pre><code>def month_stat_for_daily_df(df: pd.DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Calculates monthly statistics from daily data.</p>"},{"location":"api/hydro_stat/#distribution-functions","title":"Distribution Functions","text":""},{"location":"api/hydro_stat/#ecdf","title":"ecdf","text":"<pre><code>def ecdf(data: np.ndarray) -&gt; tuple\n</code></pre> <p>Computes empirical cumulative distribution function (ECDF).</p>"},{"location":"api/hydro_time/","title":"hydro_time","text":"<p>The <code>hydro_time</code> module provides utilities for handling time-related operations in hydrological data processing.</p>"},{"location":"api/hydro_time/#date-conversion-functions","title":"Date Conversion Functions","text":""},{"location":"api/hydro_time/#t2str","title":"t2str","text":"<pre><code>def t2str(t_: Union[str, datetime.datetime]) -&gt; Union[datetime.datetime, str]\n</code></pre> <p>Converts between datetime string and datetime object.</p> <p>Example: <pre><code># String to datetime\ndt = t2str('2023-01-01')  # Returns datetime(2023, 1, 1)\n\n# Datetime to string\ns = t2str(datetime(2023, 1, 1))  # Returns '2023-01-01'\n</code></pre></p>"},{"location":"api/hydro_time/#date_to_julian","title":"date_to_julian","text":"<pre><code>def date_to_julian(a_time: Union[str, datetime.datetime]) -&gt; int\n</code></pre> <p>Converts a date to its Julian day (day of year).</p> <p>Example: <pre><code>day = date_to_julian('2023-02-01')  # Returns 32\n</code></pre></p>"},{"location":"api/hydro_time/#date-range-functions","title":"Date Range Functions","text":""},{"location":"api/hydro_time/#t_range_days","title":"t_range_days","text":"<pre><code>def t_range_days(t_range: list, *, step: np.timedelta64 = np.timedelta64(1, \"D\")) -&gt; np.array\n</code></pre> <p>Creates a uniformly-spaced array of dates from a date range.</p> <p>Example: <pre><code>dates = t_range_days(['2000-01-01', '2000-01-05'])\n# Returns array(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04'])\n</code></pre></p>"},{"location":"api/hydro_time/#t_range_days_timedelta","title":"t_range_days_timedelta","text":"<pre><code>def t_range_days_timedelta(t_array: np.array, td: int = 12, td_type: str = \"h\") -&gt; np.array\n</code></pre> <p>Adds a time delta to each date in an array.</p> <p>Example: <pre><code>dates = t_range_days(['2000-01-01', '2000-01-03'])\nshifted = t_range_days_timedelta(dates, td=12, td_type='h')\n</code></pre></p>"},{"location":"api/hydro_time/#generate_start0101_time_range","title":"generate_start0101_time_range","text":"<pre><code>def generate_start0101_time_range(\n    start_time: Union[str, pd.Timestamp],\n    end_time: Union[str, pd.Timestamp],\n    freq: str = \"8D\"\n) -&gt; pd.DatetimeIndex\n</code></pre> <p>Generates a time range that resets to January 1st each year.</p> <p>Example: <pre><code># Generate 8-day intervals, resetting to Jan 1st each year\ndates = generate_start0101_time_range('2023-01-15', '2024-02-01', freq='8D')\n</code></pre></p>"},{"location":"api/hydro_time/#time-range-operations","title":"Time Range Operations","text":""},{"location":"api/hydro_time/#t_days_lst2range","title":"t_days_lst2range","text":"<pre><code>def t_days_lst2range(t_array: list) -&gt; list\n</code></pre> <p>Converts a list of dates to a date range [start, end].</p> <p>Example: <pre><code>dates = ['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nrange = t_days_lst2range(dates)  # Returns ['2000-01-01', '2000-01-04']\n</code></pre></p>"},{"location":"api/hydro_time/#assign_time_start_end","title":"assign_time_start_end","text":"<pre><code>def assign_time_start_end(time_ranges: list, assign_way: str = \"intersection\") -&gt; tuple\n</code></pre> <p>Determines overall start and end times from multiple time ranges.</p> <p>Example: <pre><code>ranges = [\n    ['2023-01-01', '2023-12-31'],\n    ['2023-03-01', '2024-02-28']\n]\n\n# Get intersection (common period)\nstart, end = assign_time_start_end(ranges, 'intersection')\n# Returns ('2023-03-01', '2023-12-31')\n</code></pre></p>"},{"location":"api/hydro_time/#timezone-functions","title":"Timezone Functions","text":""},{"location":"api/hydro_time/#calculate_utc_offset","title":"calculate_utc_offset","text":"<pre><code>def calculate_utc_offset(lat: float, lng: float, date: datetime.datetime = None) -&gt; int\n</code></pre> <p>Calculates UTC offset for a location using tzfpy.</p> <p>Example: <pre><code># Get current UTC offset for New York\noffset = calculate_utc_offset(40.7128, -74.0060)\nprint(f\"New York is UTC{offset:+d}\")  # e.g., \"UTC-4\"\n</code></pre></p>"},{"location":"api/hydro_time/#utility-functions","title":"Utility Functions","text":""},{"location":"api/hydro_time/#get_year","title":"get_year","text":"<pre><code>def get_year(a_time: Union[datetime.date, np.datetime64, str]) -&gt; int\n</code></pre> <p>Extracts the year from various date formats.</p> <p>Example: <pre><code>year = get_year('2023-01-01')  # Returns 2023\n</code></pre></p>"},{"location":"api/hydro_time/#intersect","title":"intersect","text":"<pre><code>def intersect(t_lst1: np.array, t_lst2: np.array) -&gt; tuple\n</code></pre> <p>Finds indices where two time arrays intersect.</p> <p>Example: <pre><code>t1 = np.array(['2000-01-01', '2000-01-02', '2000-01-03'])\nt2 = np.array(['2000-01-02', '2000-01-03', '2000-01-04'])\nidx1, idx2 = intersect(t1, t2)\n# idx1 = [1, 2] (indices in t1)\n# idx2 = [0, 1] (indices in t2)\n</code></pre></p>"},{"location":"api/hydroutils/","title":"API Reference","text":"<p>This section provides detailed documentation for all modules and functions in the <code>hydroutils</code> package.</p>"},{"location":"api/hydroutils/#core-module","title":"Core Module","text":"<p>Author: Wenyu Ouyang Date: 2022-12-02 10:42:19 LastEditTime: 2023-10-27 14:53:16 LastEditors: Wenyu Ouyang Description: Top-level package for hydroutils. FilePath: /hydroutils/hydroutils/init.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydroutils/#hydroutils.HydroWarning","title":"<code>HydroWarning</code>","text":"<p>A class for handling and displaying hydrology-related warnings and messages.</p> <p>This class provides methods for displaying formatted warning messages and operation status using the rich library's console features.</p> <p>Attributes:</p> Name Type Description <code>console</code> <p>A rich.console.Console instance for formatted terminal output.</p> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>class HydroWarning:\n    \"\"\"A class for handling and displaying hydrology-related warnings and messages.\n\n    This class provides methods for displaying formatted warning messages and operation\n    status using the rich library's console features.\n\n    Attributes:\n        console: A rich.console.Console instance for formatted terminal output.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initializes the HydroWarning with a rich console.\"\"\"\n        self.console = Console()\n\n    def no_directory(self, directory_name: str, message: Text = None) -&gt; None:\n        \"\"\"Displays a warning message for a missing directory.\n\n        Args:\n            directory_name: Name of the directory that was not found.\n            message: Optional custom message. If None, a default message is used.\n        \"\"\"\n        if message is None:\n            message = Text(\n                f\"There is no such directory: {directory_name}\", style=\"bold red\"\n            )\n        self.console.print(message)\n\n    def file_not_found(self, file_name: str, message: Text = None) -&gt; None:\n        \"\"\"Displays a warning message for a missing file.\n\n        Args:\n            file_name: Name of the file that was not found.\n            message: Optional custom message. If None, a default message is used.\n        \"\"\"\n        if message is None:\n            message = Text(\n                f\"We didn't find this file: {file_name}\", style=\"bold yellow\"\n            )\n        self.console.print(message)\n\n    def operation_successful(self, operation_detail: str, message: Text = None) -&gt; None:\n        \"\"\"Displays a success message for a completed operation.\n\n        Args:\n            operation_detail: Description of the successful operation.\n            message: Optional custom message. If None, a default message is used.\n        \"\"\"\n        if message is None:\n            message = Text(f\"Operation Success: {operation_detail}\", style=\"bold green\")\n        self.console.print(message)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydroWarning.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the HydroWarning with a rich console.</p> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def __init__(self):\n    \"\"\"Initializes the HydroWarning with a rich console.\"\"\"\n    self.console = Console()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydroWarning.file_not_found","title":"<code>file_not_found(file_name, message=None)</code>","text":"<p>Displays a warning message for a missing file.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>Name of the file that was not found.</p> required <code>message</code> <code>Text</code> <p>Optional custom message. If None, a default message is used.</p> <code>None</code> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def file_not_found(self, file_name: str, message: Text = None) -&gt; None:\n    \"\"\"Displays a warning message for a missing file.\n\n    Args:\n        file_name: Name of the file that was not found.\n        message: Optional custom message. If None, a default message is used.\n    \"\"\"\n    if message is None:\n        message = Text(\n            f\"We didn't find this file: {file_name}\", style=\"bold yellow\"\n        )\n    self.console.print(message)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydroWarning.no_directory","title":"<code>no_directory(directory_name, message=None)</code>","text":"<p>Displays a warning message for a missing directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory_name</code> <code>str</code> <p>Name of the directory that was not found.</p> required <code>message</code> <code>Text</code> <p>Optional custom message. If None, a default message is used.</p> <code>None</code> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def no_directory(self, directory_name: str, message: Text = None) -&gt; None:\n    \"\"\"Displays a warning message for a missing directory.\n\n    Args:\n        directory_name: Name of the directory that was not found.\n        message: Optional custom message. If None, a default message is used.\n    \"\"\"\n    if message is None:\n        message = Text(\n            f\"There is no such directory: {directory_name}\", style=\"bold red\"\n        )\n    self.console.print(message)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydroWarning.operation_successful","title":"<code>operation_successful(operation_detail, message=None)</code>","text":"<p>Displays a success message for a completed operation.</p> <p>Parameters:</p> Name Type Description Default <code>operation_detail</code> <code>str</code> <p>Description of the successful operation.</p> required <code>message</code> <code>Text</code> <p>Optional custom message. If None, a default message is used.</p> <code>None</code> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def operation_successful(self, operation_detail: str, message: Text = None) -&gt; None:\n    \"\"\"Displays a success message for a completed operation.\n\n    Args:\n        operation_detail: Description of the successful operation.\n        message: Optional custom message. If None, a default message is used.\n    \"\"\"\n    if message is None:\n        message = Text(f\"Operation Success: {operation_detail}\", style=\"bold green\")\n    self.console.print(message)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydrographCorrector","title":"<code>HydrographCorrector</code>","text":"<p>\u6d2a\u6c34\u8fc7\u7a0b\u7ebf\u4ea4\u4e92\u5f0f\u4fee\u6b63\u5668</p> <p>\u57fa\u4e8e\u300a\u6d2a\u6c34\u9884\u62a5\u8fc7\u7a0b\u7684\u4ea4\u4e92\u5f0f\u4fee\u6b63\u6280\u672f\u7814\u7a76\u300b(\u7ae0\u56db\u9f99, 2006) \u5b9e\u73b0\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\u548c\u4e09\u6b21\u6837\u6761\u63d2\u503c\u7684\u7ec4\u5408\u7b97\u6cd5</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>class HydrographCorrector:\n    \"\"\"\n    \u6d2a\u6c34\u8fc7\u7a0b\u7ebf\u4ea4\u4e92\u5f0f\u4fee\u6b63\u5668\n\n    \u57fa\u4e8e\u300a\u6d2a\u6c34\u9884\u62a5\u8fc7\u7a0b\u7684\u4ea4\u4e92\u5f0f\u4fee\u6b63\u6280\u672f\u7814\u7a76\u300b(\u7ae0\u56db\u9f99, 2006)\n    \u5b9e\u73b0\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\u548c\u4e09\u6b21\u6837\u6761\u63d2\u503c\u7684\u7ec4\u5408\u7b97\u6cd5\n    \"\"\"\n\n    def __init__(self, time_points: np.ndarray, discharge_values: np.ndarray):\n        \"\"\"\n        \u521d\u59cb\u5316\u4fee\u6b63\u5668\n\n        Args:\n            time_points: \u65f6\u95f4\u70b9\u6570\u7ec4\n            discharge_values: \u5f84\u6d41\u503c\u6570\u7ec4\n        \"\"\"\n        self.time_points = np.asarray(time_points)\n        self.discharge_original = np.asarray(discharge_values)\n        self.n_points = len(discharge_values)\n\n        # \u9884\u8ba1\u7b97\u5e73\u6ed1\u77e9\u9635\uff08\u53ea\u9700\u8ba1\u7b97\u4e00\u6b21\uff09\n        self.smoothing_matrix = self._create_smoothing_matrix()\n\n    def _create_smoothing_matrix(self) -&gt; sparse.csr_matrix:\n        \"\"\"\n        \u6784\u9020\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\u77e9\u9635\n\n        \u6839\u636e\u8bba\u6587\u516c\u5f0f(5)-(7)\u6784\u9020\u7a00\u758f\u77e9\u9635\uff0c\u6bcf\u884c\u5bf9\u5e94\u4e00\u4e2a\u8f93\u51fa\u70b9\u7684\u5e73\u6ed1\u7cfb\u6570\n\n        Returns:\n            \u7a00\u758f\u5e73\u6ed1\u77e9\u9635 (n x n)\n        \"\"\"\n        n = self.n_points\n        if n &lt; 5:\n            # \u5bf9\u4e8e\u5c11\u4e8e5\u4e2a\u70b9\u7684\u6570\u636e\uff0c\u8fd4\u56de\u5355\u4f4d\u77e9\u9635\uff08\u4e0d\u8fdb\u884c\u5e73\u6ed1\uff09\n            return sparse.eye(n, format=\"csr\")\n\n        # \u6784\u9020\u7a00\u758f\u77e9\u9635\u7684\u884c\u3001\u5217\u3001\u6570\u636e\n        rows, cols, data = [], [], []\n\n        # \u7b2c\u4e00\u4e2a\u70b9 (\u7d22\u5f150) - \u516c\u5f0f(6)\u7b2c\u4e00\u4e2a\n        # y_{-2} = (31y_{-2} + 9y_{-1} - 3y_0 - 5y_1 + 3y_2) / 35\n        coeffs_0 = np.array([31, 9, -3, -5, 3]) / 35\n        for j, coeff in enumerate(coeffs_0):\n            rows.append(0)\n            cols.append(j)\n            data.append(coeff)\n\n        # \u7b2c\u4e8c\u4e2a\u70b9 (\u7d22\u5f151) - \u516c\u5f0f(6)\u7b2c\u4e8c\u4e2a\n        # y_{-1} = (9y_{-2} + 13y_{-1} + 12y_0 + 6y_1 - 5y_2) / 35\n        coeffs_1 = np.array([9, 13, 12, 6, -5]) / 35\n        for j, coeff in enumerate(coeffs_1):\n            rows.append(1)\n            cols.append(j)\n            data.append(coeff)\n\n        # \u4e2d\u95f4\u70b9 (\u7d22\u5f152\u5230n-3) - \u516c\u5f0f(5)\n        # y_0 = [-3(y_{-2} + y_2) + 12(y_{-1} + y_1) + 17y_0] / 35\n        coeffs_mid = np.array([-3, 12, 17, 12, -3]) / 35\n        for i in range(2, n - 2):\n            for j, coeff in enumerate(coeffs_mid):\n                rows.append(i)\n                cols.append(i - 2 + j)\n                data.append(coeff)\n\n        # \u5012\u6570\u7b2c\u4e8c\u4e2a\u70b9 (\u7d22\u5f15n-2) - \u516c\u5f0f(7)\u7b2c\u4e00\u4e2a\n        # y_1 = (-5y_{-2} + 6y_{-1} + 12y_0 + 13y_1 + 9y_2) / 35\n        coeffs_n2 = np.array([-5, 6, 12, 13, 9]) / 35\n        for j, coeff in enumerate(coeffs_n2):\n            rows.append(n - 2)\n            cols.append(n - 5 + j)\n            data.append(coeff)\n\n        # \u6700\u540e\u4e00\u4e2a\u70b9 (\u7d22\u5f15n-1) - \u516c\u5f0f(7)\u7b2c\u4e8c\u4e2a\n        # y_2 = (3y_{-2} - 5y_{-1} - 3y_0 + 9y_1 + 31y_2) / 35\n        coeffs_n1 = np.array([3, -5, -3, 9, 31]) / 35\n        for j, coeff in enumerate(coeffs_n1):\n            rows.append(n - 1)\n            cols.append(n - 5 + j)\n            data.append(coeff)\n\n        return sparse.csr_matrix((data, (rows, cols)), shape=(n, n))\n\n    def five_point_smooth(self, discharge_values: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        \u5bf9\u5f84\u6d41\u6570\u636e\u8fdb\u884c\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\n\n        Args:\n            discharge_values: \u5f84\u6d41\u503c\u6570\u7ec4\n\n        Returns:\n            \u5e73\u6ed1\u540e\u7684\u5f84\u6d41\u503c\u6570\u7ec4\n        \"\"\"\n        discharge_values = np.asarray(discharge_values)\n        if len(discharge_values) != self.n_points:\n            msg = f\"\u8f93\u5165\u6570\u636e\u957f\u5ea6 {len(discharge_values)} \u4e0e\u521d\u59cb\u5316\u957f\u5ea6 {self.n_points} \u4e0d\u5339\u914d\"\n            raise ValueError(msg)\n\n        # \u4f7f\u7528\u9884\u8ba1\u7b97\u7684\u7a00\u758f\u77e9\u9635\u8fdb\u884c\u5411\u91cf\u5316\u5e73\u6ed1\n        smoothed = self.smoothing_matrix @ discharge_values\n\n        # \u786e\u4fdd\u7ed3\u679c\u975e\u8d1f\uff08\u5f84\u6d41\u4e0d\u80fd\u4e3a\u8d1f\uff09\n        return np.maximum(smoothed, 0.0)\n\n    def _build_spline_system(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        y_prime_start: float = 0.0,\n        y_prime_end: float = 0.0,\n    ) -&gt; Tuple[sparse.csr_matrix, np.ndarray]:\n        \"\"\"\n        \u6784\u9020\u4e09\u6b21\u6837\u6761\u63d2\u503c\u7684\u7ebf\u6027\u65b9\u7a0b\u7ec4\n\n        \u6839\u636e\u8bba\u6587\u516c\u5f0f(17)-(21)\u6784\u9020\u4e09\u5bf9\u89d2\u65b9\u7a0b\u7ec4 A\u00b7M = \u03b2\n\n        Args:\n            x: \u8282\u70b9\u4f4d\u7f6e\u6570\u7ec4\n            y: \u8282\u70b9\u503c\u6570\u7ec4\n            y_prime_start: \u8d77\u59cb\u70b9\u4e00\u9636\u5bfc\u6570\u8fb9\u754c\u6761\u4ef6\n            y_prime_end: \u7ec8\u70b9\u4e00\u9636\u5bfc\u6570\u8fb9\u754c\u6761\u4ef6\n\n        Returns:\n            \u7cfb\u6570\u77e9\u9635A\u548c\u53f3\u7aef\u5411\u91cf\u03b2\n        \"\"\"\n        n = len(x) - 1  # \u533a\u95f4\u6570\n        h = np.diff(x)  # h[i] = x[i+1] - x[i]\n\n        # \u6784\u9020\u4e09\u5bf9\u89d2\u77e9\u9635 A\n        main_diag = np.ones(n + 1) * 2.0\n\n        # \u6784\u9020\u4e0a\u4e0b\u5bf9\u89d2\u7ebf\n        upper_diag = np.zeros(n)  # \u957f\u5ea6\u4e3an\u7684\u4e0a\u5bf9\u89d2\u7ebf\n        lower_diag = np.zeros(n)  # \u957f\u5ea6\u4e3an\u7684\u4e0b\u5bf9\u89d2\u7ebf\n\n        # \u8fb9\u754c\u6761\u4ef6\n        if n &gt; 0:\n            upper_diag[0] = 1.0  # \u7b2c\u4e00\u884c\u7684\u8fb9\u754c\u6761\u4ef6\n            lower_diag[-1] = 1.0  # \u6700\u540e\u4e00\u884c\u7684\u8fb9\u754c\u6761\u4ef6\n\n        # \u5185\u8282\u70b9\u7684\u03b1\u7cfb\u6570\n        if n &gt; 1:\n            alpha = h[1:] / (h[:-1] + h[1:])  # \u03b1_i = h_{i+1}/(h_i + h_{i+1})\n\n            # \u586b\u5145\u5185\u8282\u70b9\u7684\u7cfb\u6570\n            for i in range(len(alpha)):\n                if i + 1 &lt; len(upper_diag):\n                    upper_diag[i + 1] = alpha[i]\n                if i &lt; len(lower_diag) - 1:\n                    lower_diag[i] = 1 - alpha[i]\n\n        # \u6784\u9020\u7a00\u758f\u4e09\u5bf9\u89d2\u77e9\u9635\n        diagonals = [lower_diag, main_diag, upper_diag]\n        offsets = [-1, 0, 1]\n        A = sparse.diags(diagonals, offsets, shape=(n + 1, n + 1), format=\"csr\")\n\n        # \u6784\u9020\u53f3\u7aef\u5411\u91cf\u03b2\n        beta = np.zeros(n + 1)\n\n        # \u8fb9\u754c\u6761\u4ef6 - \u516c\u5f0f(19)(20)\n        if n &gt; 0:\n            beta[0] = 6.0 / h[0] * ((y[1] - y[0]) / h[0] - y_prime_start)\n            beta[-1] = 6.0 / h[-1] * (y_prime_end - (y[-1] - y[-2]) / h[-1])\n\n        # \u5185\u8282\u70b9\u7684\u03b2\u503c - \u516c\u5f0f(17)\n        for i in range(1, n):\n            beta[i] = (\n                6.0\n                / (h[i - 1] + h[i])\n                * ((y[i + 1] - y[i]) / h[i] - (y[i] - y[i - 1]) / h[i - 1])\n            )\n\n        return A, beta\n\n    def _solve_spline_coefficients(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        y_prime_start: float = 0.0,\n        y_prime_end: float = 0.0,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        \u6c42\u89e3\u4e09\u6b21\u6837\u6761\u63d2\u503c\u7684\u4e8c\u9636\u5bfc\u6570\u7cfb\u6570\n\n        Args:\n            x: \u8282\u70b9\u4f4d\u7f6e\n            y: \u8282\u70b9\u503c\n            y_prime_start: \u8d77\u59cb\u70b9\u5bfc\u6570\u8fb9\u754c\u6761\u4ef6\n            y_prime_end: \u7ec8\u70b9\u5bfc\u6570\u8fb9\u754c\u6761\u4ef6\n\n        Returns:\n            \u8282\u70b9\u5904\u7684\u4e8c\u9636\u5bfc\u6570\u503cM\n        \"\"\"\n        A, beta = self._build_spline_system(x, y, y_prime_start, y_prime_end)\n\n        # \u4f7f\u7528\u7a00\u758f\u77e9\u9635\u6c42\u89e3\u5668\uff08\u8ffd\u8d76\u6cd5\u7684\u9ad8\u6548\u5b9e\u73b0\uff09\n        M = spsolve(A, beta)\n\n        return M\n\n    def _evaluate_spline(\n        self, x_nodes: np.ndarray, y_nodes: np.ndarray, M: np.ndarray, x_new: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"\n        \u8ba1\u7b97\u4e09\u6b21\u6837\u6761\u51fd\u6570\u5728\u65b0\u70b9\u5904\u7684\u503c\n\n        \u4f7f\u7528\u8bba\u6587\u516c\u5f0f(15)\u7684\u5411\u91cf\u5316\u5b9e\u73b0\n\n        Args:\n            x_nodes: \u539f\u59cb\u8282\u70b9\u4f4d\u7f6e\n            y_nodes: \u539f\u59cb\u8282\u70b9\u503c\n            M: \u8282\u70b9\u5904\u4e8c\u9636\u5bfc\u6570\n            x_new: \u65b0\u7684\u63d2\u503c\u70b9\u4f4d\u7f6e\n\n        Returns:\n            \u63d2\u503c\u7ed3\u679c\n        \"\"\"\n        h = np.diff(x_nodes)\n        n = len(x_nodes) - 1\n\n        # \u627e\u5230\u6bcf\u4e2a\u65b0\u70b9\u6240\u5728\u7684\u533a\u95f4\n        indices = np.searchsorted(x_nodes[1:], x_new)\n        indices = np.clip(indices, 0, n - 1)\n\n        # \u5411\u91cf\u5316\u8ba1\u7b97 - \u516c\u5f0f(15)\n        x_left = x_nodes[indices]\n        x_right = x_nodes[indices + 1]\n        y_left = y_nodes[indices]\n        y_right = y_nodes[indices + 1]\n        M_left = M[indices]\n        M_right = M[indices + 1]\n        h_seg = h[indices]\n\n        # \u6837\u6761\u516c\u5f0f\u7684\u5411\u91cf\u5316\u5b9e\u73b0\n        t1 = (x_right - x_new) / h_seg\n        t2 = (x_new - x_left) / h_seg\n\n        result = (\n            (t1**3 * M_left + t2**3 * M_right) * h_seg**2 / 6.0\n            + (y_left - M_left * h_seg**2 / 6.0) * t1\n            + (y_right - M_right * h_seg**2 / 6.0) * t2\n        )\n\n        return result\n\n    def cubic_spline_interpolation(\n        self, x: np.ndarray, y: np.ndarray, x_new: Optional[np.ndarray] = None\n    ) -&gt; np.ndarray:\n        \"\"\"\n        \u4e09\u6b21\u6837\u6761\u63d2\u503c\n\n        Args:\n            x: \u539f\u59cb\u65f6\u95f4\u70b9\n            y: \u539f\u59cb\u5f84\u6d41\u503c\n            x_new: \u65b0\u7684\u65f6\u95f4\u70b9\uff08\u5982\u679c\u4e3aNone\uff0c\u5219\u4f7f\u7528\u539f\u59cb\u65f6\u95f4\u70b9\uff09\n\n        Returns:\n            \u63d2\u503c\u540e\u7684\u5f84\u6d41\u503c\n        \"\"\"\n        x = np.asarray(x)\n        y = np.asarray(y)\n\n        if x_new is None:\n            x_new = x\n        else:\n            x_new = np.asarray(x_new)\n\n        if len(x) &lt; 3:\n            # \u5bf9\u4e8e\u5c11\u4e8e3\u4e2a\u70b9\u7684\u6570\u636e\uff0c\u4f7f\u7528\u7ebf\u6027\u63d2\u503c\n            from scipy.interpolate import interp1d\n\n            f = interp1d(x, y, kind=\"linear\", fill_value=\"extrapolate\")\n            return f(x_new)\n\n        # \u8bbe\u7f6e\u8fb9\u754c\u6761\u4ef6\uff08\u81ea\u7136\u8fb9\u754c\uff1a\u4e8c\u9636\u5bfc\u6570\u4e3a0\uff09\n        y_prime_start = 0.0\n        y_prime_end = 0.0\n\n        # \u6c42\u89e3\u6837\u6761\u7cfb\u6570\n        M = self._solve_spline_coefficients(x, y, y_prime_start, y_prime_end)\n\n        # \u8ba1\u7b97\u63d2\u503c\u7ed3\u679c\n        result = self._evaluate_spline(x, y, M, x_new)\n\n        # \u786e\u4fdd\u7ed3\u679c\u975e\u8d1f\n        return np.maximum(result, 0.0)\n\n    def apply_correction(\n        self,\n        modified_discharge: np.ndarray,\n        smoothing_enabled: bool = True,\n        interpolation_enabled: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        \u5e94\u7528\u5b8c\u6574\u7684\u4fee\u6b63\u7b97\u6cd5\n\n        Args:\n            modified_discharge: \u4fee\u6539\u540e\u7684\u5f84\u6d41\u6570\u636e\n            smoothing_enabled: \u662f\u5426\u542f\u7528\u4e94\u70b9\u5e73\u6ed1\n            interpolation_enabled: \u662f\u5426\u542f\u7528\u6837\u6761\u63d2\u503c\n\n        Returns:\n            \u4fee\u6b63\u540e\u7684\u5f84\u6d41\u6570\u636e\n        \"\"\"\n        result = np.asarray(modified_discharge).copy()\n\n        # \u6b65\u9aa41\uff1a\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\n        if smoothing_enabled and self.n_points &gt;= 5:\n            result = self.five_point_smooth(result)\n\n        # \u6b65\u9aa42\uff1a\u4e09\u6b21\u6837\u6761\u63d2\u503c\n        if interpolation_enabled and self.n_points &gt;= 3:\n            result = self.cubic_spline_interpolation(self.time_points, result)\n\n        return result\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydrographCorrector.__init__","title":"<code>__init__(time_points, discharge_values)</code>","text":"<p>\u521d\u59cb\u5316\u4fee\u6b63\u5668</p> <p>Parameters:</p> Name Type Description Default <code>time_points</code> <code>ndarray</code> <p>\u65f6\u95f4\u70b9\u6570\u7ec4</p> required <code>discharge_values</code> <code>ndarray</code> <p>\u5f84\u6d41\u503c\u6570\u7ec4</p> required Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def __init__(self, time_points: np.ndarray, discharge_values: np.ndarray):\n    \"\"\"\n    \u521d\u59cb\u5316\u4fee\u6b63\u5668\n\n    Args:\n        time_points: \u65f6\u95f4\u70b9\u6570\u7ec4\n        discharge_values: \u5f84\u6d41\u503c\u6570\u7ec4\n    \"\"\"\n    self.time_points = np.asarray(time_points)\n    self.discharge_original = np.asarray(discharge_values)\n    self.n_points = len(discharge_values)\n\n    # \u9884\u8ba1\u7b97\u5e73\u6ed1\u77e9\u9635\uff08\u53ea\u9700\u8ba1\u7b97\u4e00\u6b21\uff09\n    self.smoothing_matrix = self._create_smoothing_matrix()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydrographCorrector.apply_correction","title":"<code>apply_correction(modified_discharge, smoothing_enabled=True, interpolation_enabled=True)</code>","text":"<p>\u5e94\u7528\u5b8c\u6574\u7684\u4fee\u6b63\u7b97\u6cd5</p> <p>Parameters:</p> Name Type Description Default <code>modified_discharge</code> <code>ndarray</code> <p>\u4fee\u6539\u540e\u7684\u5f84\u6d41\u6570\u636e</p> required <code>smoothing_enabled</code> <code>bool</code> <p>\u662f\u5426\u542f\u7528\u4e94\u70b9\u5e73\u6ed1</p> <code>True</code> <code>interpolation_enabled</code> <code>bool</code> <p>\u662f\u5426\u542f\u7528\u6837\u6761\u63d2\u503c</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>\u4fee\u6b63\u540e\u7684\u5f84\u6d41\u6570\u636e</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def apply_correction(\n    self,\n    modified_discharge: np.ndarray,\n    smoothing_enabled: bool = True,\n    interpolation_enabled: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"\n    \u5e94\u7528\u5b8c\u6574\u7684\u4fee\u6b63\u7b97\u6cd5\n\n    Args:\n        modified_discharge: \u4fee\u6539\u540e\u7684\u5f84\u6d41\u6570\u636e\n        smoothing_enabled: \u662f\u5426\u542f\u7528\u4e94\u70b9\u5e73\u6ed1\n        interpolation_enabled: \u662f\u5426\u542f\u7528\u6837\u6761\u63d2\u503c\n\n    Returns:\n        \u4fee\u6b63\u540e\u7684\u5f84\u6d41\u6570\u636e\n    \"\"\"\n    result = np.asarray(modified_discharge).copy()\n\n    # \u6b65\u9aa41\uff1a\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\n    if smoothing_enabled and self.n_points &gt;= 5:\n        result = self.five_point_smooth(result)\n\n    # \u6b65\u9aa42\uff1a\u4e09\u6b21\u6837\u6761\u63d2\u503c\n    if interpolation_enabled and self.n_points &gt;= 3:\n        result = self.cubic_spline_interpolation(self.time_points, result)\n\n    return result\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydrographCorrector.cubic_spline_interpolation","title":"<code>cubic_spline_interpolation(x, y, x_new=None)</code>","text":"<p>\u4e09\u6b21\u6837\u6761\u63d2\u503c</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>\u539f\u59cb\u65f6\u95f4\u70b9</p> required <code>y</code> <code>ndarray</code> <p>\u539f\u59cb\u5f84\u6d41\u503c</p> required <code>x_new</code> <code>Optional[ndarray]</code> <p>\u65b0\u7684\u65f6\u95f4\u70b9\uff08\u5982\u679c\u4e3aNone\uff0c\u5219\u4f7f\u7528\u539f\u59cb\u65f6\u95f4\u70b9\uff09</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>\u63d2\u503c\u540e\u7684\u5f84\u6d41\u503c</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def cubic_spline_interpolation(\n    self, x: np.ndarray, y: np.ndarray, x_new: Optional[np.ndarray] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    \u4e09\u6b21\u6837\u6761\u63d2\u503c\n\n    Args:\n        x: \u539f\u59cb\u65f6\u95f4\u70b9\n        y: \u539f\u59cb\u5f84\u6d41\u503c\n        x_new: \u65b0\u7684\u65f6\u95f4\u70b9\uff08\u5982\u679c\u4e3aNone\uff0c\u5219\u4f7f\u7528\u539f\u59cb\u65f6\u95f4\u70b9\uff09\n\n    Returns:\n        \u63d2\u503c\u540e\u7684\u5f84\u6d41\u503c\n    \"\"\"\n    x = np.asarray(x)\n    y = np.asarray(y)\n\n    if x_new is None:\n        x_new = x\n    else:\n        x_new = np.asarray(x_new)\n\n    if len(x) &lt; 3:\n        # \u5bf9\u4e8e\u5c11\u4e8e3\u4e2a\u70b9\u7684\u6570\u636e\uff0c\u4f7f\u7528\u7ebf\u6027\u63d2\u503c\n        from scipy.interpolate import interp1d\n\n        f = interp1d(x, y, kind=\"linear\", fill_value=\"extrapolate\")\n        return f(x_new)\n\n    # \u8bbe\u7f6e\u8fb9\u754c\u6761\u4ef6\uff08\u81ea\u7136\u8fb9\u754c\uff1a\u4e8c\u9636\u5bfc\u6570\u4e3a0\uff09\n    y_prime_start = 0.0\n    y_prime_end = 0.0\n\n    # \u6c42\u89e3\u6837\u6761\u7cfb\u6570\n    M = self._solve_spline_coefficients(x, y, y_prime_start, y_prime_end)\n\n    # \u8ba1\u7b97\u63d2\u503c\u7ed3\u679c\n    result = self._evaluate_spline(x, y, M, x_new)\n\n    # \u786e\u4fdd\u7ed3\u679c\u975e\u8d1f\n    return np.maximum(result, 0.0)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.HydrographCorrector.five_point_smooth","title":"<code>five_point_smooth(discharge_values)</code>","text":"<p>\u5bf9\u5f84\u6d41\u6570\u636e\u8fdb\u884c\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1</p> <p>Parameters:</p> Name Type Description Default <code>discharge_values</code> <code>ndarray</code> <p>\u5f84\u6d41\u503c\u6570\u7ec4</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>\u5e73\u6ed1\u540e\u7684\u5f84\u6d41\u503c\u6570\u7ec4</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def five_point_smooth(self, discharge_values: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    \u5bf9\u5f84\u6d41\u6570\u636e\u8fdb\u884c\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\n\n    Args:\n        discharge_values: \u5f84\u6d41\u503c\u6570\u7ec4\n\n    Returns:\n        \u5e73\u6ed1\u540e\u7684\u5f84\u6d41\u503c\u6570\u7ec4\n    \"\"\"\n    discharge_values = np.asarray(discharge_values)\n    if len(discharge_values) != self.n_points:\n        msg = f\"\u8f93\u5165\u6570\u636e\u957f\u5ea6 {len(discharge_values)} \u4e0e\u521d\u59cb\u5316\u957f\u5ea6 {self.n_points} \u4e0d\u5339\u914d\"\n        raise ValueError(msg)\n\n    # \u4f7f\u7528\u9884\u8ba1\u7b97\u7684\u7a00\u758f\u77e9\u9635\u8fdb\u884c\u5411\u91cf\u5316\u5e73\u6ed1\n    smoothed = self.smoothing_matrix @ discharge_values\n\n    # \u786e\u4fdd\u7ed3\u679c\u975e\u8d1f\uff08\u5f84\u6d41\u4e0d\u80fd\u4e3a\u8d1f\uff09\n    return np.maximum(smoothed, 0.0)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.NumpyArrayEncoder","title":"<code>NumpyArrayEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>JSON encoder that handles NumPy arrays and scalars.</p> <p>This encoder converts NumPy arrays and scalars to native Python types that can be serialized to JSON.</p> Example <pre><code>import numpy as np\ndata = {'array': np.array([1, 2, 3])}\njson_str = json.dumps(data, cls=NumpyArrayEncoder)\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>class NumpyArrayEncoder(json.JSONEncoder):\n    \"\"\"JSON encoder that handles NumPy arrays and scalars.\n\n    This encoder converts NumPy arrays and scalars to native Python types\n    that can be serialized to JSON.\n\n    Example:\n        ```python\n        import numpy as np\n        data = {'array': np.array([1, 2, 3])}\n        json_str = json.dumps(data, cls=NumpyArrayEncoder)\n        ```\n    \"\"\"\n\n    def default(self, obj):\n        \"\"\"Converts NumPy objects to JSON-serializable types.\n\n        Args:\n            obj: Object to convert.\n\n        Returns:\n            JSON-serializable version of the object.\n        \"\"\"\n        if isinstance(obj, np.ndarray):\n            return self.convert_ndarray(obj)\n        elif isinstance(obj, (np.integer, np.floating)):\n            return obj.item()\n        return json.JSONEncoder.default(self, obj)\n\n    def convert_ndarray(self, array):\n        \"\"\"Recursively converts a NumPy array to a Python list.\n\n        Args:\n            array: NumPy array to convert.\n\n        Returns:\n            Python list or scalar value.\n        \"\"\"\n        if array.ndim == 0:\n            return array.item()\n        return [\n            (\n                self.convert_ndarray(element)\n                if isinstance(element, np.ndarray)\n                else element\n            )\n            for element in array\n        ]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.NumpyArrayEncoder.convert_ndarray","title":"<code>convert_ndarray(array)</code>","text":"<p>Recursively converts a NumPy array to a Python list.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <p>NumPy array to convert.</p> required <p>Returns:</p> Type Description <p>Python list or scalar value.</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def convert_ndarray(self, array):\n    \"\"\"Recursively converts a NumPy array to a Python list.\n\n    Args:\n        array: NumPy array to convert.\n\n    Returns:\n        Python list or scalar value.\n    \"\"\"\n    if array.ndim == 0:\n        return array.item()\n    return [\n        (\n            self.convert_ndarray(element)\n            if isinstance(element, np.ndarray)\n            else element\n        )\n        for element in array\n    ]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.NumpyArrayEncoder.default","title":"<code>default(obj)</code>","text":"<p>Converts NumPy objects to JSON-serializable types.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>Object to convert.</p> required <p>Returns:</p> Type Description <p>JSON-serializable version of the object.</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def default(self, obj):\n    \"\"\"Converts NumPy objects to JSON-serializable types.\n\n    Args:\n        obj: Object to convert.\n\n    Returns:\n        JSON-serializable version of the object.\n    \"\"\"\n    if isinstance(obj, np.ndarray):\n        return self.convert_ndarray(obj)\n    elif isinstance(obj, (np.integer, np.floating)):\n        return obj.item()\n    return json.JSONEncoder.default(self, obj)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.KGE","title":"<code>KGE(xs, xo)</code>","text":"<p>Calculates Kling-Gupta Efficiency between simulated and observed values.</p> <p>KGE combines correlation, bias, and variability to evaluate model performance. KGE = 1 - sqrt((r-1)\u00b2 + (\u03b1-1)\u00b2 + (\u03b2-1)\u00b2) where: - r is Pearson correlation - \u03b1 is ratio of simulated to observed standard deviation - \u03b2 is ratio of simulated to observed mean</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>ndarray</code> <p>Simulated values.</p> required <code>xo</code> <code>ndarray</code> <p>Observed values.</p> required <p>Returns:</p> Type Description <code>float</code> <p>KGE score (-\u221e to 1, where 1 is perfect).</p> Example <pre><code>obs = np.array([1, 2, 3, 4, 5])\nsim = np.array([1.1, 2.1, 2.9, 4.2, 5.1])\nkge = KGE(sim, obs)  # Returns value close to 1\n</code></pre> Note <p>Based on Gupta et al. (2009), doi:10.1016/j.jhydrol.2009.08.003</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def KGE(xs: np.ndarray, xo: np.ndarray) -&gt; float:\n    \"\"\"Calculates Kling-Gupta Efficiency between simulated and observed values.\n\n    KGE combines correlation, bias, and variability to evaluate model performance.\n    KGE = 1 - sqrt((r-1)\u00b2 + (\u03b1-1)\u00b2 + (\u03b2-1)\u00b2)\n    where:\n    - r is Pearson correlation\n    - \u03b1 is ratio of simulated to observed standard deviation\n    - \u03b2 is ratio of simulated to observed mean\n\n    Args:\n        xs: Simulated values.\n        xo: Observed values.\n\n    Returns:\n        KGE score (-\u221e to 1, where 1 is perfect).\n\n    Example:\n        ```python\n        obs = np.array([1, 2, 3, 4, 5])\n        sim = np.array([1.1, 2.1, 2.9, 4.2, 5.1])\n        kge = KGE(sim, obs)  # Returns value close to 1\n        ```\n\n    Note:\n        Based on Gupta et al. (2009), doi:10.1016/j.jhydrol.2009.08.003\n    \"\"\"\n    r = np.corrcoef(xo, xs)[0, 1]\n    alpha = np.std(xs) / np.std(xo)\n    beta = np.mean(xs) / np.mean(xo)\n    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.apply_smooth_correction","title":"<code>apply_smooth_correction(original_data, modified_data, discharge_column='gen_discharge', time_column='time')</code>","text":"<p>\u5e94\u7528\u57fa\u4e8e\u8bba\u6587\u7684\u5e73\u6ed1\u4fee\u6b63\u7b97\u6cd5</p> <p>\u8fd9\u662f\u4e3b\u8981\u7684\u63a5\u53e3\u51fd\u6570\uff0c\u652f\u6301\u591a\u70b9\u540c\u65f6\u4fee\u6539\u7684\u60c5\u51b5\uff0c\u4f7f\u7528\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\u548c\u4e09\u6b21\u6837\u6761\u63d2\u503c</p> <p>Parameters:</p> Name Type Description Default <code>original_data</code> <code>DataFrame</code> <p>\u539f\u59cb\u6570\u636eDataFrame</p> required <code>modified_data</code> <code>DataFrame</code> <p>\u4fee\u6539\u540e\u7684\u6570\u636eDataFrame</p> required <code>discharge_column</code> <code>str</code> <p>\u5f84\u6d41\u6570\u636e\u5217\u540d</p> <code>'gen_discharge'</code> <code>time_column</code> <code>str</code> <p>\u65f6\u95f4\u5217\u540d</p> <code>'time'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>\u5e73\u6ed1\u4fee\u6b63\u540e\u7684\u6570\u636eDataFrame</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def apply_smooth_correction(\n    original_data: pd.DataFrame,\n    modified_data: pd.DataFrame,\n    discharge_column: str = \"gen_discharge\",\n    time_column: str = \"time\",\n) -&gt; pd.DataFrame:\n    \"\"\"\n    \u5e94\u7528\u57fa\u4e8e\u8bba\u6587\u7684\u5e73\u6ed1\u4fee\u6b63\u7b97\u6cd5\n\n    \u8fd9\u662f\u4e3b\u8981\u7684\u63a5\u53e3\u51fd\u6570\uff0c\u652f\u6301\u591a\u70b9\u540c\u65f6\u4fee\u6539\u7684\u60c5\u51b5\uff0c\u4f7f\u7528\u4e94\u70b9\u4e8c\u6b21\u5e73\u6ed1\u548c\u4e09\u6b21\u6837\u6761\u63d2\u503c\n\n    Args:\n        original_data: \u539f\u59cb\u6570\u636eDataFrame\n        modified_data: \u4fee\u6539\u540e\u7684\u6570\u636eDataFrame\n        discharge_column: \u5f84\u6d41\u6570\u636e\u5217\u540d\n        time_column: \u65f6\u95f4\u5217\u540d\n\n    Returns:\n        \u5e73\u6ed1\u4fee\u6b63\u540e\u7684\u6570\u636eDataFrame\n    \"\"\"\n    if discharge_column not in modified_data.columns:\n        raise ValueError(f\"\u6570\u636e\u4e2d\u7f3a\u5c11\u5f84\u6d41\u5217: {discharge_column}\")\n\n    if time_column not in modified_data.columns:\n        raise ValueError(f\"\u6570\u636e\u4e2d\u7f3a\u5c11\u65f6\u95f4\u5217: {time_column}\")\n\n    # \u63d0\u53d6\u65f6\u95f4\u548c\u5f84\u6d41\u6570\u636e\n    time_points = (\n        pd.to_datetime(modified_data[time_column]).astype(np.int64) / 1e9\n    )  # \u8f6c\u6362\u4e3a\u79d2\u6570\n    discharge_values = modified_data[discharge_column].values\n\n    # \u521b\u5efa\u4fee\u6b63\u5668\n    corrector = HydrographCorrector(time_points, discharge_values)\n\n    # \u5e94\u7528\u4fee\u6b63\u7b97\u6cd5\n    corrected_discharge = corrector.apply_correction(\n        discharge_values, smoothing_enabled=True, interpolation_enabled=True\n    )\n\n    # \u521b\u5efa\u7ed3\u679cDataFrame\n    result_data = modified_data.copy()\n    result_data[discharge_column] = corrected_discharge\n\n    return result_data\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.apply_water_balance_correction","title":"<code>apply_water_balance_correction(original_data, modified_data, discharge_column='gen_discharge', time_column='time')</code>","text":"<p>\u5e94\u7528\u771f\u6b63\u7684\u6c34\u91cf\u5e73\u8861\u4fee\u6b63\u7b97\u6cd5</p> <p>TODO: \u8fd9\u91cc\u662f\u7b80\u5316\u5b9e\u73b0\uff0c\u540e\u7eed\u9700\u8981\u8865\u5145\u5177\u4f53\u7684\u6c34\u91cf\u5e73\u8861\u8ba1\u7b97\u903b\u8f91</p> <p>Parameters:</p> Name Type Description Default <code>original_data</code> <code>DataFrame</code> <p>\u539f\u59cb\u6570\u636eDataFrame</p> required <code>modified_data</code> <code>DataFrame</code> <p>\u4fee\u6539\u540e\u7684\u6570\u636eDataFrame</p> required <code>discharge_column</code> <code>str</code> <p>\u5f84\u6d41\u6570\u636e\u5217\u540d</p> <code>'gen_discharge'</code> <code>time_column</code> <code>str</code> <p>\u65f6\u95f4\u5217\u540d</p> <code>'time'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>\u6c34\u91cf\u5e73\u8861\u4fee\u6b63\u540e\u7684\u6570\u636eDataFrame</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def apply_water_balance_correction(\n    original_data: pd.DataFrame,\n    modified_data: pd.DataFrame,\n    discharge_column: str = \"gen_discharge\",\n    time_column: str = \"time\",\n) -&gt; pd.DataFrame:\n    \"\"\"\n    \u5e94\u7528\u771f\u6b63\u7684\u6c34\u91cf\u5e73\u8861\u4fee\u6b63\u7b97\u6cd5\n\n    TODO: \u8fd9\u91cc\u662f\u7b80\u5316\u5b9e\u73b0\uff0c\u540e\u7eed\u9700\u8981\u8865\u5145\u5177\u4f53\u7684\u6c34\u91cf\u5e73\u8861\u8ba1\u7b97\u903b\u8f91\n\n    Args:\n        original_data: \u539f\u59cb\u6570\u636eDataFrame\n        modified_data: \u4fee\u6539\u540e\u7684\u6570\u636eDataFrame\n        discharge_column: \u5f84\u6d41\u6570\u636e\u5217\u540d\n        time_column: \u65f6\u95f4\u5217\u540d\n\n    Returns:\n        \u6c34\u91cf\u5e73\u8861\u4fee\u6b63\u540e\u7684\u6570\u636eDataFrame\n    \"\"\"\n    if discharge_column not in modified_data.columns:\n        raise ValueError(f\"\u6570\u636e\u4e2d\u7f3a\u5c11\u5f84\u6d41\u5217: {discharge_column}\")\n\n    # \u7b80\u5316\u5b9e\u73b0\uff1a\u7b2c\u4e00\u4e2a\u6570\u636e\u52a01\uff0c\u5176\u4ed6\u6570\u636e\u4fdd\u6301\u4e0d\u53d8\n    result_data = modified_data.copy()\n    if len(result_data) &gt; 0:\n        result_data.iloc[0, result_data.columns.get_loc(discharge_column)] += 1.0\n\n    return result_data\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.assign_time_start_end","title":"<code>assign_time_start_end(time_ranges, assign_way='intersection')</code>","text":"<p>Determines overall start and end times from multiple time ranges.</p> <p>Parameters:</p> Name Type Description Default <code>time_ranges</code> <code>list</code> <p>List of [start, end] time ranges.</p> required <code>assign_way</code> <code>str</code> <p>Method to combine ranges: - \"intersection\": Use latest start and earliest end - \"union\": Use earliest start and latest end</p> <code>'intersection'</code> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of (start_time, end_time).</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If assign_way is not \"intersection\" or \"union\".</p> Example <pre><code>ranges = [\n    ['2023-01-01', '2023-12-31'],\n    ['2023-03-01', '2024-02-28']\n]\n\n# Get intersection (common period)\nstart, end = assign_time_start_end(ranges, 'intersection')\n# Returns ('2023-03-01', '2023-12-31')\n\n# Get union (total span)\nstart, end = assign_time_start_end(ranges, 'union')\n# Returns ('2023-01-01', '2024-02-28')\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def assign_time_start_end(time_ranges: list, assign_way: str = \"intersection\") -&gt; tuple:\n    \"\"\"Determines overall start and end times from multiple time ranges.\n\n    Args:\n        time_ranges: List of [start, end] time ranges.\n        assign_way: Method to combine ranges:\n            - \"intersection\": Use latest start and earliest end\n            - \"union\": Use earliest start and latest end\n\n    Returns:\n        Tuple of (start_time, end_time).\n\n    Raises:\n        NotImplementedError: If assign_way is not \"intersection\" or \"union\".\n\n    Example:\n        ```python\n        ranges = [\n            ['2023-01-01', '2023-12-31'],\n            ['2023-03-01', '2024-02-28']\n        ]\n\n        # Get intersection (common period)\n        start, end = assign_time_start_end(ranges, 'intersection')\n        # Returns ('2023-03-01', '2023-12-31')\n\n        # Get union (total span)\n        start, end = assign_time_start_end(ranges, 'union')\n        # Returns ('2023-01-01', '2024-02-28')\n        ```\n    \"\"\"\n    if assign_way == \"intersection\":\n        time_start = max(t[0] for t in time_ranges)\n        time_end = min(t[1] for t in time_ranges)\n    elif assign_way == \"union\":\n        time_start = min(t[0] for t in time_ranges)\n        time_end = max(t[1] for t in time_ranges)\n    else:\n        raise NotImplementedError(\"We don't support this assign_way yet\")\n    return time_start, time_end\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.boto3_download_file","title":"<code>boto3_download_file(client, bucket_name, object_name, file_path)</code>","text":"<p>Downloads a file from AWS S3 using boto3.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <p>boto3 S3 client instance.</p> required <code>bucket_name</code> <code>str</code> <p>Name of the bucket containing the object.</p> required <code>object_name</code> <code>str</code> <p>Name of the object to download.</p> required <code>file_path</code> <code>str</code> <p>Local path where the file should be saved.</p> required Example <pre><code>import boto3\nclient = boto3.client('s3')\nboto3_download_file(client, 'mybucket', 'data.csv', './downloaded.csv')\n</code></pre> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def boto3_download_file(client, bucket_name: str, object_name: str, file_path: str) -&gt; None:\n    \"\"\"Downloads a file from AWS S3 using boto3.\n\n    Args:\n        client: boto3 S3 client instance.\n        bucket_name: Name of the bucket containing the object.\n        object_name: Name of the object to download.\n        file_path: Local path where the file should be saved.\n\n    Example:\n        ```python\n        import boto3\n        client = boto3.client('s3')\n        boto3_download_file(client, 'mybucket', 'data.csv', './downloaded.csv')\n        ```\n    \"\"\"\n    client.download_file(bucket_name, object_name, file_path)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.boto3_upload_file","title":"<code>boto3_upload_file(client, bucket_name, object_name, file_path)</code>","text":"<p>Uploads a file to AWS S3 using boto3.</p> <p>Creates the bucket if it doesn't exist, uploads the file, and returns a list of all objects in the bucket.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <p>boto3 S3 client instance.</p> required <code>bucket_name</code> <code>str</code> <p>Name of the bucket to upload to.</p> required <code>object_name</code> <code>str</code> <p>Name to give the object in S3.</p> required <code>file_path</code> <code>str</code> <p>Local path of the file to upload.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of object keys in the bucket after upload.</p> Example <pre><code>import boto3\nclient = boto3.client('s3')\nobjects = boto3_upload_file(client, 'mybucket', 'data.csv', './data.csv')\nprint(f\"Bucket contents: {objects}\")\n</code></pre> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def boto3_upload_file(client, bucket_name: str, object_name: str, file_path: str) -&gt; list:\n    \"\"\"Uploads a file to AWS S3 using boto3.\n\n    Creates the bucket if it doesn't exist, uploads the file, and returns a list of\n    all objects in the bucket.\n\n    Args:\n        client: boto3 S3 client instance.\n        bucket_name: Name of the bucket to upload to.\n        object_name: Name to give the object in S3.\n        file_path: Local path of the file to upload.\n\n    Returns:\n        List of object keys in the bucket after upload.\n\n    Example:\n        ```python\n        import boto3\n        client = boto3.client('s3')\n        objects = boto3_upload_file(client, 'mybucket', 'data.csv', './data.csv')\n        print(f\"Bucket contents: {objects}\")\n        ```\n    \"\"\"\n    # Make a bucket\n    bucket_names = [dic[\"Name\"] for dic in client.list_buckets()[\"Buckets\"]]\n    if bucket_name not in bucket_names:\n        client.create_bucket(Bucket=bucket_name)\n    # Upload an object\n    client.upload_file(file_path, bucket_name, object_name)\n    return [dic[\"Key\"] for dic in client.list_objects(Bucket=bucket_name)[\"Contents\"]]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_4_stat_inds","title":"<code>cal_4_stat_inds(b)</code>","text":"<p>Calculates four basic statistical indices for an array.</p> <p>Parameters:</p> Name Type Description Default <code>b</code> <code>ndarray</code> <p>Input array of numerical values.</p> required <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing [10th percentile, 90th percentile, mean, standard deviation].</p> <code>List[float]</code> <p>If std &lt; 0.001, returns 1 for std to avoid numerical issues.</p> Example <pre><code>data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\np10, p90, mean, std = cal_4_stat_inds(data)\nprint(f\"Mean: {mean:.1f}, Std: {std:.1f}\")\nprint(f\"10th-90th percentile range: [{p10:.1f}, {p90:.1f}]\")\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_4_stat_inds(b: np.ndarray) -&gt; List[float]:\n    \"\"\"Calculates four basic statistical indices for an array.\n\n    Args:\n        b: Input array of numerical values.\n\n    Returns:\n        List containing [10th percentile, 90th percentile, mean, standard deviation].\n        If std &lt; 0.001, returns 1 for std to avoid numerical issues.\n\n    Example:\n        ```python\n        data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        p10, p90, mean, std = cal_4_stat_inds(data)\n        print(f\"Mean: {mean:.1f}, Std: {std:.1f}\")\n        print(f\"10th-90th percentile range: [{p10:.1f}, {p90:.1f}]\")\n        ```\n    \"\"\"\n    p10 = np.percentile(b, 10).astype(float)\n    p90 = np.percentile(b, 90).astype(float)\n    mean = np.mean(b).astype(float)\n    std = np.std(b).astype(float)\n    if std &lt; 0.001:\n        std = 1\n    return [p10, p90, mean, std]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_fdc","title":"<code>cal_fdc(data, quantile_num=100)</code>","text":"<p>Calculates flow duration curves for multiple time series.</p> <p>For each location/grid point, computes a flow duration curve by sorting flows from highest to lowest and selecting evenly spaced quantiles.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Flow data array of shape [n_locations, n_timesteps].</p> required <code>quantile_num</code> <code>int</code> <p>Number of quantile points to compute. Defaults to 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of shape [n_locations, quantile_num] containing flow duration curves.</p> <code>ndarray</code> <p>Each row represents the FDC for one location.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If output flow array length doesn't match quantile_num.</p> Example <pre><code># Flow data for 2 locations, 365 days\nflows = np.random.lognormal(0, 1, (2, 365))\n\n# Calculate FDCs with 100 points\nfdcs = cal_fdc(flows, quantile_num=100)\n\n# Plot first FDC\nplt.plot(np.linspace(0, 100, 100), fdcs[0])\nplt.xlabel('Exceedance Probability (%)')\nplt.ylabel('Flow')\n</code></pre> Note <ul> <li>Handles NaN values by removing them</li> <li>For locations with no valid data, returns zeros</li> <li>Flow values are sorted from highest to lowest</li> </ul> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_fdc(data: np.ndarray, quantile_num: int = 100) -&gt; np.ndarray:\n    \"\"\"Calculates flow duration curves for multiple time series.\n\n    For each location/grid point, computes a flow duration curve by sorting flows\n    from highest to lowest and selecting evenly spaced quantiles.\n\n    Args:\n        data: Flow data array of shape [n_locations, n_timesteps].\n        quantile_num: Number of quantile points to compute. Defaults to 100.\n\n    Returns:\n        Array of shape [n_locations, quantile_num] containing flow duration curves.\n        Each row represents the FDC for one location.\n\n    Raises:\n        Exception: If output flow array length doesn't match quantile_num.\n\n    Example:\n        ```python\n        # Flow data for 2 locations, 365 days\n        flows = np.random.lognormal(0, 1, (2, 365))\n\n        # Calculate FDCs with 100 points\n        fdcs = cal_fdc(flows, quantile_num=100)\n\n        # Plot first FDC\n        plt.plot(np.linspace(0, 100, 100), fdcs[0])\n        plt.xlabel('Exceedance Probability (%)')\n        plt.ylabel('Flow')\n        ```\n\n    Note:\n        - Handles NaN values by removing them\n        - For locations with no valid data, returns zeros\n        - Flow values are sorted from highest to lowest\n    \"\"\"\n    # data = n_grid * n_day\n    n_grid, n_day = data.shape\n    fdc = np.full([n_grid, quantile_num], np.nan)\n    for ii in range(n_grid):\n        temp_data0 = data[ii, :]\n        temp_data = temp_data0[~np.isnan(temp_data0)]\n        # deal with no data case for some gages\n        if len(temp_data) == 0:\n            temp_data = np.full(n_day, 0)\n        # sort from large to small\n        temp_sort = np.sort(temp_data)[::-1]\n        # select quantile_num quantile points\n        n_len = len(temp_data)\n        ind = (np.arange(quantile_num) / quantile_num * n_len).astype(int)\n        fdc_flow = temp_sort[ind]\n        if len(fdc_flow) != quantile_num:\n            raise Exception(\"unknown assimilation variable\")\n        else:\n            fdc[ii, :] = fdc_flow\n\n    return fdc\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_stat","title":"<code>cal_stat(x)</code>","text":"<p>Calculates basic statistics for an array, ignoring NaN values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array. Can contain NaN values.</p> required <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing [10th percentile, 90th percentile, mean, standard deviation].</p> <code>List[float]</code> <p>If array is empty or all NaN, returns statistics for [0].</p> Example <pre><code>data = np.array([1, 2, np.nan, 4, 5])\nstats = cal_stat(data)  # Calculates stats ignoring NaN\nprint(f\"Mean (excluding NaN): {stats[2]:.1f}\")\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat(x: np.ndarray) -&gt; List[float]:\n    \"\"\"Calculates basic statistics for an array, ignoring NaN values.\n\n    Args:\n        x: Input array. Can contain NaN values.\n\n    Returns:\n        List containing [10th percentile, 90th percentile, mean, standard deviation].\n        If array is empty or all NaN, returns statistics for [0].\n\n    Example:\n        ```python\n        data = np.array([1, 2, np.nan, 4, 5])\n        stats = cal_stat(data)  # Calculates stats ignoring NaN\n        print(f\"Mean (excluding NaN): {stats[2]:.1f}\")\n        ```\n    \"\"\"\n    a = x.flatten()\n    b = a[~np.isnan(a)]\n    if b.size == 0:\n        # if b is [], then give it a 0 value\n        b = np.array([0])\n    return cal_4_stat_inds(b)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_stat_gamma","title":"<code>cal_stat_gamma(x)</code>","text":"<p>Transforms data to approximate normal distribution and calculates statistics.</p> <p>Applies a transformation (log10(sqrt(x) + 0.1)) to handle gamma-distributed data like streamflow, precipitation, and evapotranspiration.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array, typically daily hydrology data.</p> required <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing [10th percentile, 90th percentile, mean, standard deviation]</p> <code>List[float]</code> <p>of the transformed data.</p> Example <pre><code>flow = np.array([0.1, 0.5, 1.0, 2.0, 5.0])  # Gamma-like distribution\nstats = cal_stat_gamma(flow)  # Stats of transformed data\nprint(f\"Mean of transformed data: {stats[2]:.2f}\")\n</code></pre> Note <ul> <li>Ignores NaN values</li> <li>Transformation: log10(sqrt(x) + 0.1)</li> <li>Suitable for positively skewed data</li> </ul> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat_gamma(x: np.ndarray) -&gt; List[float]:\n    \"\"\"Transforms data to approximate normal distribution and calculates statistics.\n\n    Applies a transformation (log10(sqrt(x) + 0.1)) to handle gamma-distributed data\n    like streamflow, precipitation, and evapotranspiration.\n\n    Args:\n        x: Input array, typically daily hydrology data.\n\n    Returns:\n        List containing [10th percentile, 90th percentile, mean, standard deviation]\n        of the transformed data.\n\n    Example:\n        ```python\n        flow = np.array([0.1, 0.5, 1.0, 2.0, 5.0])  # Gamma-like distribution\n        stats = cal_stat_gamma(flow)  # Stats of transformed data\n        print(f\"Mean of transformed data: {stats[2]:.2f}\")\n        ```\n\n    Note:\n        - Ignores NaN values\n        - Transformation: log10(sqrt(x) + 0.1)\n        - Suitable for positively skewed data\n    \"\"\"\n    a = x.flatten()\n    b = a[~np.isnan(a)]  # kick out Nan\n    b = np.log10(\n        np.sqrt(b) + 0.1\n    )  # do some tranformation to change gamma characteristics\n    return cal_4_stat_inds(b)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_stat_prcp_norm","title":"<code>cal_stat_prcp_norm(x, meanprep)</code>","text":"<p>Normalizes data by mean precipitation and calculates statistics.</p> <p>Divides data by mean precipitation to remove rainfall magnitude influence, reducing bias between dry and wet basins. Then applies gamma transformation and calculates statistics.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Data to normalize, typically hydrological variables.</p> required <code>meanprep</code> <code>ndarray</code> <p>Mean precipitation for each location/basin.</p> required <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing [10th percentile, 90th percentile, mean, standard deviation]</p> <code>List[float]</code> <p>of the normalized and transformed data.</p> Example <pre><code>flow = np.array([[1.0, 2.0], [3.0, 4.0]])  # 2 basins, 2 timesteps\nmean_precip = np.array([100, 200])  # Mean annual precip for each basin\nstats = cal_stat_prcp_norm(flow, mean_precip)\nprint(f\"Mean of normalized data: {stats[2]:.3f}\")\n</code></pre> Note <ul> <li>Normalizes by precipitation: x / meanprep</li> <li>Then applies gamma transformation</li> <li>Useful for comparing basins with different rainfall regimes</li> </ul> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat_prcp_norm(x: np.ndarray, meanprep: np.ndarray) -&gt; List[float]:\n    \"\"\"Normalizes data by mean precipitation and calculates statistics.\n\n    Divides data by mean precipitation to remove rainfall magnitude influence,\n    reducing bias between dry and wet basins. Then applies gamma transformation\n    and calculates statistics.\n\n    Args:\n        x: Data to normalize, typically hydrological variables.\n        meanprep: Mean precipitation for each location/basin.\n\n    Returns:\n        List containing [10th percentile, 90th percentile, mean, standard deviation]\n        of the normalized and transformed data.\n\n    Example:\n        ```python\n        flow = np.array([[1.0, 2.0], [3.0, 4.0]])  # 2 basins, 2 timesteps\n        mean_precip = np.array([100, 200])  # Mean annual precip for each basin\n        stats = cal_stat_prcp_norm(flow, mean_precip)\n        print(f\"Mean of normalized data: {stats[2]:.3f}\")\n        ```\n\n    Note:\n        - Normalizes by precipitation: x / meanprep\n        - Then applies gamma transformation\n        - Useful for comparing basins with different rainfall regimes\n    \"\"\"\n    # meanprep = readAttr(gageDict['id'], ['q_mean'])\n    tempprep = np.tile(meanprep, (1, x.shape[1]))\n    # unit (mm/day)/(mm/day)\n    flowua = x / tempprep\n    return cal_stat_gamma(flowua)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.calculate_utc_offset","title":"<code>calculate_utc_offset(lat, lng, date=None)</code>","text":"<p>Calculates UTC offset for a location using tzfpy.</p> <p>Parameters:</p> Name Type Description Default <code>lat</code> <code>float</code> <p>Latitude in decimal degrees.</p> required <code>lng</code> <code>float</code> <p>Longitude in decimal degrees.</p> required <code>date</code> <code>datetime</code> <p>Optional date for timezone calculation. Uses current date if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>UTC offset in hours, or None if timezone cannot be determined.</p> Example <pre><code># Get current UTC offset for New York\noffset = calculate_utc_offset(40.7128, -74.0060)\nprint(f\"New York is UTC{offset:+d}\")  # e.g., \"UTC-4\"\n\n# Get offset for specific date\ndate = datetime(2023, 1, 1)\noffset = calculate_utc_offset(40.7128, -74.0060, date)\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def calculate_utc_offset(lat: float, lng: float, date: datetime.datetime = None) -&gt; int:\n    \"\"\"Calculates UTC offset for a location using tzfpy.\n\n    Args:\n        lat: Latitude in decimal degrees.\n        lng: Longitude in decimal degrees.\n        date: Optional date for timezone calculation. Uses current date if not provided.\n\n    Returns:\n        UTC offset in hours, or None if timezone cannot be determined.\n\n    Example:\n        ```python\n        # Get current UTC offset for New York\n        offset = calculate_utc_offset(40.7128, -74.0060)\n        print(f\"New York is UTC{offset:+d}\")  # e.g., \"UTC-4\"\n\n        # Get offset for specific date\n        date = datetime(2023, 1, 1)\n        offset = calculate_utc_offset(40.7128, -74.0060, date)\n        ```\n    \"\"\"\n    if date is None:\n        date = datetime.datetime.utcnow()\n\n    if timezone_str := tzfpy.get_tz(lng, lat):\n        # Get the timezone object using pytz\n        tz = pytz.timezone(timezone_str)\n        # Get the UTC offset for the specified date\n        offset = tz.utcoffset(date)\n        if offset is not None:\n            return int(offset.total_seconds() / 3600)\n    return None\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.calculate_water_balance_metrics","title":"<code>calculate_water_balance_metrics(data, net_rain_column='net_rain', discharge_column='gen_discharge', time_step_hours=1.0)</code>","text":"<p>\u8ba1\u7b97\u6c34\u91cf\u5e73\u8861\u6307\u6807</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>\u6570\u636eDataFrame</p> required <code>net_rain_column</code> <code>str</code> <p>\u51c0\u96e8\u5217\u540d</p> <code>'net_rain'</code> <code>discharge_column</code> <code>str</code> <p>\u5f84\u6d41\u5217\u540d</p> <code>'gen_discharge'</code> <code>time_step_hours</code> <code>float</code> <p>\u65f6\u95f4\u6b65\u957f\uff08\u5c0f\u65f6\uff09</p> <code>1.0</code> <p>Returns:</p> Type Description <code>dict</code> <p>\u6c34\u91cf\u5e73\u8861\u6307\u6807\u5b57\u5178</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def calculate_water_balance_metrics(\n    data: pd.DataFrame,\n    net_rain_column: str = \"net_rain\",\n    discharge_column: str = \"gen_discharge\",\n    time_step_hours: float = 1.0,\n) -&gt; dict:\n    \"\"\"\n    \u8ba1\u7b97\u6c34\u91cf\u5e73\u8861\u6307\u6807\n\n    Args:\n        data: \u6570\u636eDataFrame\n        net_rain_column: \u51c0\u96e8\u5217\u540d\n        discharge_column: \u5f84\u6d41\u5217\u540d\n        time_step_hours: \u65f6\u95f4\u6b65\u957f\uff08\u5c0f\u65f6\uff09\n\n    Returns:\n        \u6c34\u91cf\u5e73\u8861\u6307\u6807\u5b57\u5178\n    \"\"\"\n    metrics = {}\n\n    # \u8ba1\u7b97\u51c0\u96e8\u603b\u91cf\uff08mm\uff09\n    if net_rain_column in data.columns:\n        total_net_rain = data[net_rain_column].sum()\n        metrics[\"total_net_rain_mm\"] = total_net_rain\n\n    # \u8ba1\u7b97\u5f84\u6d41\u603b\u91cf\uff08\u8f6c\u6362\u4e3amm\uff09\n    if discharge_column in data.columns:\n        # \u5047\u8bbe\u5355\u4f4d\u6d41\u57df\u9762\u79ef\uff081 km\u00b2\uff09\n        # \u6d41\u91cf m\u00b3/s \u00d7 \u65f6\u95f4\u6b65\u957f(h) \u00d7 3600(s/h) / 1000000(m\u00b2/km\u00b2) \u00d7 1000(mm/m) = mm\n        time_step_seconds = time_step_hours * 3600\n        discharge_volume_mm = data[discharge_column].sum() * time_step_seconds / 1000\n        metrics[\"total_discharge_mm\"] = discharge_volume_mm\n\n        # \u8ba1\u7b97\u6c34\u91cf\u5e73\u8861\u8bef\u5dee\n        if net_rain_column in data.columns and total_net_rain &gt; 0:\n            balance_error = (\n                (discharge_volume_mm - total_net_rain) / total_net_rain * 100\n            )\n            metrics[\"balance_error_percent\"] = balance_error\n\n    # \u5f84\u6d41\u7edf\u8ba1\n    if discharge_column in data.columns:\n        discharge_stats = {\n            \"mean\": data[discharge_column].mean(),\n            \"max\": data[discharge_column].max(),\n            \"min\": data[discharge_column].min(),\n            \"std\": data[discharge_column].std(),\n            \"peak_time_index\": data[discharge_column].idxmax(),\n        }\n        metrics[\"discharge_stats\"] = discharge_stats\n\n    return metrics\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.create_median_labels","title":"<code>create_median_labels(ax, medians_value, percent25value=None, percent75value=None, size='small')</code>","text":"<p>\"create median labels for boxes in a boxplot Parameters</p> <p>ax : plt.AxesSubplot     an ax in a fig medians_value : np.array     description percent25value : type, optional     description, by default None percent75value : type, optional     description, by default None size : str, optional     the size of median-value labels, by default small</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def create_median_labels(\n    ax, medians_value, percent25value=None, percent75value=None, size=\"small\"\n):\n    \"\"\" \"create median labels for boxes in a boxplot\n    Parameters\n    ----------\n    ax : plt.AxesSubplot\n        an ax in a fig\n    medians_value : np.array\n        _description_\n    percent25value : _type_, optional\n        _description_, by default None\n    percent75value : _type_, optional\n        _description_, by default None\n    size : str, optional\n        the size of median-value labels, by default small\n    \"\"\"\n    decimal_places = \"2\"\n    if percent25value is None or percent75value is None:\n        vertical_offset = np.min(medians_value * 0.01)  # offset from median for display\n    else:\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        vertical_offset = (per75max - per25min) * 0.01\n    median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n    pos = range(len(medians_value))\n    for xtick in ax.get_xticks():\n        ax.text(\n            pos[xtick],\n            medians_value[xtick] + vertical_offset,\n            median_labels[xtick],\n            horizontalalignment=\"center\",\n            color=\"w\",\n            # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n            size=size,\n            weight=\"semibold\",\n        )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.date_to_julian","title":"<code>date_to_julian(a_time)</code>","text":"<p>Converts a date to its Julian day (day of year).</p> <p>Parameters:</p> Name Type Description Default <code>a_time</code> <code>Union[str, datetime]</code> <p>Date as either: - string in 'YYYY-MM-DD' format - datetime object</p> required <p>Returns:</p> Type Description <code>int</code> <p>Day of year (1-366).</p> Example <pre><code># From string\nday = date_to_julian('2023-02-01')  # Returns 32\n\n# From datetime\nday = date_to_julian(datetime(2023, 2, 1))  # Returns 32\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def date_to_julian(a_time: Union[str, datetime.datetime]) -&gt; int:\n    \"\"\"Converts a date to its Julian day (day of year).\n\n    Args:\n        a_time: Date as either:\n            - string in 'YYYY-MM-DD' format\n            - datetime object\n\n    Returns:\n        Day of year (1-366).\n\n    Example:\n        ```python\n        # From string\n        day = date_to_julian('2023-02-01')  # Returns 32\n\n        # From datetime\n        day = date_to_julian(datetime(2023, 2, 1))  # Returns 32\n        ```\n    \"\"\"\n    if type(a_time) == str:\n        fmt = \"%Y-%m-%d\"\n        dt = datetime.datetime.strptime(a_time, fmt)\n    else:\n        dt = a_time\n    tt = dt.timetuple()\n    return tt.tm_yday\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_a_file_from_google_drive","title":"<code>download_a_file_from_google_drive(drive, dir_id, download_dir)</code>","text":"<p>Downloads files and folders from Google Drive recursively.</p> <p>Parameters:</p> Name Type Description Default <code>drive</code> <p>Google Drive API client instance.</p> required <code>dir_id</code> <code>str</code> <p>ID of the Google Drive folder to download from.</p> required <code>download_dir</code> <code>str</code> <p>Local directory where files should be saved.</p> required Example <pre><code>from pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\n\ngauth = GoogleAuth()\ngauth.LocalWebserverAuth()\ndrive = GoogleDrive(gauth)\n\n# Download folder with ID '1234...' to './downloads'\ndownload_a_file_from_google_drive(drive, '1234...', './downloads')\n</code></pre> Note <ul> <li>Handles both files and folders recursively</li> <li>Skips already downloaded files</li> <li>Creates subdirectories as needed</li> <li>Prints progress information</li> </ul> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_a_file_from_google_drive(drive, dir_id: str, download_dir: str) -&gt; None:\n    \"\"\"Downloads files and folders from Google Drive recursively.\n\n    Args:\n        drive: Google Drive API client instance.\n        dir_id: ID of the Google Drive folder to download from.\n        download_dir: Local directory where files should be saved.\n\n    Example:\n        ```python\n        from pydrive.auth import GoogleAuth\n        from pydrive.drive import GoogleDrive\n\n        gauth = GoogleAuth()\n        gauth.LocalWebserverAuth()\n        drive = GoogleDrive(gauth)\n\n        # Download folder with ID '1234...' to './downloads'\n        download_a_file_from_google_drive(drive, '1234...', './downloads')\n        ```\n\n    Note:\n        - Handles both files and folders recursively\n        - Skips already downloaded files\n        - Creates subdirectories as needed\n        - Prints progress information\n    \"\"\"\n    file_list = drive.ListFile(\n        {\"q\": f\"'{dir_id}' in parents and trashed=false\"}\n    ).GetList()\n    for file in file_list:\n        print(f'title: {file[\"title\"]}, id: {file[\"id\"]}')\n        file_dl = drive.CreateFile({\"id\": file[\"id\"]})\n        print(f'mimetype is {file_dl[\"mimeType\"]}')\n        if file_dl[\"mimeType\"] == \"application/vnd.google-apps.folder\":\n            download_dir_sub = os.path.join(download_dir, file_dl[\"title\"])\n            if not os.path.isdir(download_dir_sub):\n                os.makedirs(download_dir_sub)\n            download_a_file_from_google_drive(drive, file_dl[\"id\"], download_dir_sub)\n        else:\n            # download\n            temp_file = os.path.join(download_dir, file_dl[\"title\"])\n            if os.path.isfile(temp_file):\n                print(\"file has been downloaded\")\n                continue\n            file_dl.GetContentFile(os.path.join(download_dir, file_dl[\"title\"]))\n            print(\"Downloading file finished\")\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_excel","title":"<code>download_excel(data_url, temp_file)</code>","text":"<p>Downloads an Excel file from a URL.</p> <p>Parameters:</p> Name Type Description Default <code>data_url</code> <code>str</code> <p>URL of the Excel file.</p> required <code>temp_file</code> <code>str</code> <p>Path where the file should be saved.</p> required Example <pre><code>url = 'https://example.com/data.xlsx'\ndownload_excel(url, './data.xlsx')\n</code></pre> Note <p>Only downloads if the file doesn't already exist locally.</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_excel(data_url: str, temp_file: str) -&gt; None:\n    \"\"\"Downloads an Excel file from a URL.\n\n    Args:\n        data_url: URL of the Excel file.\n        temp_file: Path where the file should be saved.\n\n    Example:\n        ```python\n        url = 'https://example.com/data.xlsx'\n        download_excel(url, './data.xlsx')\n        ```\n\n    Note:\n        Only downloads if the file doesn't already exist locally.\n    \"\"\"\n    if not os.path.isfile(temp_file):\n        urllib.request.urlretrieve(data_url, temp_file)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_one_zip","title":"<code>download_one_zip(data_url, data_dir)</code>","text":"<p>Downloads and extracts a zip file from a URL.</p> <p>Creates the target directory and bucket if they don't exist.</p> <p>Parameters:</p> Name Type Description Default <code>data_url</code> <code>str</code> <p>URL of the zip file to download.</p> required <code>data_dir</code> <code>str</code> <p>Directory where the file should be downloaded and extracted.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of object names in the extracted contents.</p> Example <pre><code>url = 'https://example.com/data.zip'\nfiles = download_one_zip(url, './downloads')\nprint(f\"Downloaded and extracted: {files}\")\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_one_zip(data_url: str, data_dir: str) -&gt; list:\n    \"\"\"Downloads and extracts a zip file from a URL.\n\n    Creates the target directory and bucket if they don't exist.\n\n    Args:\n        data_url: URL of the zip file to download.\n        data_dir: Directory where the file should be downloaded and extracted.\n\n    Returns:\n        List of object names in the extracted contents.\n\n    Example:\n        ```python\n        url = 'https://example.com/data.zip'\n        files = download_one_zip(url, './downloads')\n        print(f\"Downloaded and extracted: {files}\")\n        ```\n    \"\"\"\n\n    zipfile_path, unzip_dir = zip_file_name_from_url(data_url, data_dir)\n    if not is_there_file(zipfile_path, unzip_dir):\n        if not os.path.isdir(unzip_dir):\n            os.makedirs(unzip_dir)\n        r = requests.get(data_url, stream=True)\n        with open(zipfile_path, \"wb\") as py_file:\n            for chunk in r.iter_content(chunk_size=1024):  # 1024 bytes\n                if chunk:\n                    py_file.write(chunk)\n        unzip_nested_zip(zipfile_path, unzip_dir)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_small_file","title":"<code>download_small_file(data_url, temp_file)</code>","text":"<p>Downloads a small text file from a URL.</p> <p>Parameters:</p> Name Type Description Default <code>data_url</code> <code>str</code> <p>URL of the file to download.</p> required <code>temp_file</code> <code>str</code> <p>Path where the file should be saved.</p> required Example <pre><code>url = 'https://example.com/data.txt'\ndownload_small_file(url, './data.txt')\n</code></pre> Note <p>This function is designed for text files. For binary files, use download_small_zip or download_one_zip instead.</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_small_file(data_url: str, temp_file: str) -&gt; None:\n    \"\"\"Downloads a small text file from a URL.\n\n    Args:\n        data_url: URL of the file to download.\n        temp_file: Path where the file should be saved.\n\n    Example:\n        ```python\n        url = 'https://example.com/data.txt'\n        download_small_file(url, './data.txt')\n        ```\n\n    Note:\n        This function is designed for text files. For binary files,\n        use download_small_zip or download_one_zip instead.\n    \"\"\"\n    r = requests.get(data_url)\n    with open(temp_file, \"w\") as f:\n        f.write(r.text)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_small_zip","title":"<code>download_small_zip(data_url, data_dir)</code>","text":"<p>Downloads and extracts a small zip file using urllib.</p> <p>This function is optimized for small files. For large files, use download_one_zip instead.</p> <p>Parameters:</p> Name Type Description Default <code>data_url</code> <code>str</code> <p>URL of the zip file to download.</p> required <code>data_dir</code> <code>str</code> <p>Directory where the file should be downloaded and extracted.</p> required Example <pre><code>url = 'https://example.com/small_data.zip'\ndownload_small_zip(url, './downloads')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_small_zip(data_url: str, data_dir: str) -&gt; None:\n    \"\"\"Downloads and extracts a small zip file using urllib.\n\n    This function is optimized for small files. For large files,\n    use download_one_zip instead.\n\n    Args:\n        data_url: URL of the zip file to download.\n        data_dir: Directory where the file should be downloaded and extracted.\n\n    Example:\n        ```python\n        url = 'https://example.com/small_data.zip'\n        download_small_zip(url, './downloads')\n        ```\n    \"\"\"\n    zipfile_path, unzip_dir = zip_file_name_from_url(data_url, data_dir)\n    if not is_there_file(zipfile_path, unzip_dir):\n        if not os.path.isdir(unzip_dir):\n            os.mkdir(unzip_dir)\n        zipfile_path, _ = urllib.request.urlretrieve(data_url, zipfile_path)\n        unzip_nested_zip(zipfile_path, unzip_dir)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_zip_files","title":"<code>download_zip_files(urls, the_dir)</code>","text":"<p>Downloads multiple files from multiple URLs.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>list</code> <p>List of URLs to download from.</p> required <code>the_dir</code> <code>Path</code> <p>Directory where downloaded files will be saved.</p> required Example <pre><code>from pathlib import Path\nurls = [\n    'https://example.com/file1.zip',\n    'https://example.com/file2.zip'\n]\ndownload_dir = Path('./downloads')\ndownload_zip_files(urls, download_dir)\n</code></pre> Note <p>Uses async_retriever for efficient parallel downloads. Files are named based on the last component of their URLs.</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_zip_files(urls: list, the_dir: Path) -&gt; None:\n    \"\"\"Downloads multiple files from multiple URLs.\n\n    Args:\n        urls: List of URLs to download from.\n        the_dir: Directory where downloaded files will be saved.\n\n    Example:\n        ```python\n        from pathlib import Path\n        urls = [\n            'https://example.com/file1.zip',\n            'https://example.com/file2.zip'\n        ]\n        download_dir = Path('./downloads')\n        download_zip_files(urls, download_dir)\n        ```\n\n    Note:\n        Uses async_retriever for efficient parallel downloads.\n        Files are named based on the last component of their URLs.\n    \"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        cache_names = Path(tmpdir).joinpath(f\"{the_dir.stem}.sqlite\")\n        r = ar.retrieve(urls, \"binary\", cache_name=cache_names, ssl=False)\n        files = [the_dir.joinpath(url.split(\"/\")[-1]) for url in urls]\n        [files[i].write_bytes(io.BytesIO(r[i]).getbuffer()) for i in range(len(files))]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.ecdf","title":"<code>ecdf(data)</code>","text":"<p>Computes empirical cumulative distribution function (ECDF).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input array of values.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of (sorted_values, cumulative_probabilities).</p> Example <pre><code>data = np.array([1, 2, 2, 3, 4, 4, 5])\nx, y = ecdf(data)\n# x = [1, 2, 2, 3, 4, 4, 5]  # Sorted values\n# y \u2248 [0.14, 0.29, 0.43, 0.57, 0.71, 0.86, 1.0]  # Probabilities\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def ecdf(data: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Computes empirical cumulative distribution function (ECDF).\n\n    Args:\n        data: Input array of values.\n\n    Returns:\n        Tuple of (sorted_values, cumulative_probabilities).\n\n    Example:\n        ```python\n        data = np.array([1, 2, 2, 3, 4, 4, 5])\n        x, y = ecdf(data)\n        # x = [1, 2, 2, 3, 4, 4, 5]  # Sorted values\n        # y \u2248 [0.14, 0.29, 0.43, 0.57, 0.71, 0.86, 1.0]  # Probabilities\n        ```\n    \"\"\"\n    x = np.sort(data)\n    n = x.size\n    y = np.arange(1, n + 1) / n\n    return (x, y)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.fms","title":"<code>fms(obs, sim, lower=0.2, upper=0.7)</code>","text":"<p>Calculates the slope of the middle section of the flow duration curve.</p> <p>Computes the bias in the slope of the middle section of the flow duration curve (FDC) between simulated and observed flows. The middle section is defined by the lower and upper percentiles.</p> <p>The formula used is: BiasFMS = (|log(Qs_lower) - log(Qs_upper)| - |log(Qo_lower) - log(Qo_upper)|) /           |log(Qs_lower) - log(Qs_upper)| \u00d7 100</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observed flow time series.</p> required <code>sim</code> <code>ndarray</code> <p>Simulated flow time series.</p> required <code>lower</code> <code>float</code> <p>Lower percentile bound (0-1). Defaults to 0.2 (20th percentile).</p> <code>0.2</code> <code>upper</code> <code>float</code> <p>Upper percentile bound (0-1). Defaults to 0.7 (70th percentile).</p> <code>0.7</code> <p>Returns:</p> Type Description <code>float</code> <p>Percentage bias in the FDC slope.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If lower/upper bounds are not in range (0,1) or if lower &gt;= upper.</p> Example <pre><code>obs = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\nsim = np.array([1.2, 2.1, 2.9, 4.2, 5.1])\nbias = fms(obs, sim, lower=0.2, upper=0.7)\n</code></pre> Note <p>Based on Yilmaz et al. (2008), doi:10.1029/2007WR006716</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def fms(obs: np.ndarray, sim: np.ndarray, lower: float = 0.2, upper: float = 0.7) -&gt; float:\n    \"\"\"Calculates the slope of the middle section of the flow duration curve.\n\n    Computes the bias in the slope of the middle section of the flow duration curve (FDC)\n    between simulated and observed flows. The middle section is defined by the lower\n    and upper percentiles.\n\n    The formula used is:\n    BiasFMS = (|log(Qs_lower) - log(Qs_upper)| - |log(Qo_lower) - log(Qo_upper)|) /\n              |log(Qs_lower) - log(Qs_upper)| \u00d7 100\n\n    Args:\n        obs: Observed flow time series.\n        sim: Simulated flow time series.\n        lower: Lower percentile bound (0-1). Defaults to 0.2 (20th percentile).\n        upper: Upper percentile bound (0-1). Defaults to 0.7 (70th percentile).\n\n    Returns:\n        Percentage bias in the FDC slope.\n\n    Raises:\n        ValueError: If lower/upper bounds are not in range (0,1) or if lower &gt;= upper.\n\n    Example:\n        ```python\n        obs = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n        sim = np.array([1.2, 2.1, 2.9, 4.2, 5.1])\n        bias = fms(obs, sim, lower=0.2, upper=0.7)\n        ```\n\n    Note:\n        Based on Yilmaz et al. (2008), doi:10.1029/2007WR006716\n    \"\"\"\n    if len(obs) &lt; 1:\n        return np.nan\n\n    if any((x &lt;= 0) or (x &gt;= 1) for x in [upper, lower]):\n        raise ValueError(\"upper and lower have to be in range ]0,1[\")\n\n    if lower &gt;= upper:\n        raise ValueError(\"The lower threshold has to be smaller than the upper.\")\n\n    # get arrays of sorted (descending) discharges\n    obs = np.sort(obs)\n    sim = np.sort(sim)\n\n    # for numerical reasons change 0s to 1e-6. Simulations can still contain negatives, so also reset those.\n    sim[sim &lt;= 0] = 1e-6\n    obs[obs == 0] = 1e-6\n\n    # calculate fms part by part\n    qsm_lower = np.log(sim[np.round(lower * len(sim)).astype(int)])\n    qsm_upper = np.log(sim[np.round(upper * len(sim)).astype(int)])\n    qom_lower = np.log(obs[np.round(lower * len(obs)).astype(int)])\n    qom_upper = np.log(obs[np.round(upper * len(obs)).astype(int)])\n\n    fms = ((qsm_lower - qsm_upper) - (qom_lower - qom_upper)) / (\n        qom_lower - qom_upper + 1e-6\n    )\n\n    return fms * 100\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.generate_start0101_time_range","title":"<code>generate_start0101_time_range(start_time, end_time, freq='8D')</code>","text":"<p>Generates a time range that resets to January 1st each year.</p> <p>Creates a sequence of dates with specified frequency, but ensures that each year starts from January 1st regardless of the frequency interval.</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>Union[str, Timestamp]</code> <p>Start date as string ('YYYY-MM-DD') or pandas Timestamp.</p> required <code>end_time</code> <code>Union[str, Timestamp]</code> <p>End date as string ('YYYY-MM-DD') or pandas Timestamp.</p> required <code>freq</code> <code>str</code> <p>Time frequency (e.g., '8D' for 8 days, '7D' for weekly).</p> <code>'8D'</code> <p>Returns:</p> Type Description <code>DatetimeIndex</code> <p>DatetimeIndex with specified frequency and annual reset to January 1st.</p> Example <pre><code># Generate 8-day intervals, resetting to Jan 1st each year\ndates = generate_start0101_time_range('2023-01-15', '2024-02-01', freq='8D')\n\n# Generate weekly intervals\ndates = generate_start0101_time_range('2023-01-15', '2024-02-01', freq='7D')\n</code></pre> Note <p>If an interval would cross into a new year, it's truncated and the next interval starts from January 1st of the new year.</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def generate_start0101_time_range(\n    start_time: Union[str, pd.Timestamp],\n    end_time: Union[str, pd.Timestamp],\n    freq: str = \"8D\"\n) -&gt; pd.DatetimeIndex:\n    \"\"\"Generates a time range that resets to January 1st each year.\n\n    Creates a sequence of dates with specified frequency, but ensures that each year\n    starts from January 1st regardless of the frequency interval.\n\n    Args:\n        start_time: Start date as string ('YYYY-MM-DD') or pandas Timestamp.\n        end_time: End date as string ('YYYY-MM-DD') or pandas Timestamp.\n        freq: Time frequency (e.g., '8D' for 8 days, '7D' for weekly).\n\n    Returns:\n        DatetimeIndex with specified frequency and annual reset to January 1st.\n\n    Example:\n        ```python\n        # Generate 8-day intervals, resetting to Jan 1st each year\n        dates = generate_start0101_time_range('2023-01-15', '2024-02-01', freq='8D')\n\n        # Generate weekly intervals\n        dates = generate_start0101_time_range('2023-01-15', '2024-02-01', freq='7D')\n        ```\n\n    Note:\n        If an interval would cross into a new year, it's truncated and the next\n        interval starts from January 1st of the new year.\n    \"\"\"\n    all_dates = []\n\n    # Ensure the start and end times are of type pd.Timestamp\n    current_time = pd.Timestamp(start_time)\n    end_time = pd.Timestamp(end_time)\n\n    # Parse the frequency interval correctly\n    interval_days = pd.Timedelta(freq)  # Ensure it's a Timedelta\n\n    while current_time &lt;= end_time:\n        all_dates.append(current_time)\n\n        # Calculate next date with the specified interval\n        next_time = current_time + interval_days\n\n        # If next_time crosses into a new year, reset to 01-01 of the new year\n        if next_time.year &gt; current_time.year:\n            next_time = pd.Timestamp(f\"{next_time.year}-01-01\")\n\n        current_time = next_time\n\n    return pd.to_datetime(all_dates)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.get_cache_dir","title":"<code>get_cache_dir(app_name='hydro')</code>","text":"<p>Gets the appropriate cache directory for the current platform.</p> <p>Creates the directory if it doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>app_name</code> <code>str</code> <p>Name of the application (used in path). Defaults to \"hydro\".</p> <code>'hydro'</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the cache directory.</p> Example <pre><code># Get default cache directory\ncache_dir = get_cache_dir()\n\n# Get cache directory for custom app\ncache_dir = get_cache_dir('myapp')\n</code></pre> Note <p>Uses platform-specific paths: - Windows: ~/AppData/Local/{app_name}/Cache - macOS: ~/Library/Caches/{app_name} - Linux/Unix: ~/.cache/{app_name}</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_cache_dir(app_name: str = \"hydro\") -&gt; str:\n    \"\"\"Gets the appropriate cache directory for the current platform.\n\n    Creates the directory if it doesn't exist.\n\n    Args:\n        app_name: Name of the application (used in path). Defaults to \"hydro\".\n\n    Returns:\n        Path to the cache directory.\n\n    Example:\n        ```python\n        # Get default cache directory\n        cache_dir = get_cache_dir()\n\n        # Get cache directory for custom app\n        cache_dir = get_cache_dir('myapp')\n        ```\n\n    Note:\n        Uses platform-specific paths:\n        - Windows: ~/AppData/Local/{app_name}/Cache\n        - macOS: ~/Library/Caches/{app_name}\n        - Linux/Unix: ~/.cache/{app_name}\n    \"\"\"\n    home = os.path.expanduser(\"~\")\n    system = platform.system()\n\n    if system == \"Windows\":\n        cache_dir = os.path.join(home, \"AppData\", \"Local\", app_name, \"Cache\")\n    elif system == \"Darwin\":\n        cache_dir = os.path.join(home, \"Library\", \"Caches\", app_name)\n    else:\n        cache_dir = os.path.join(home, \".cache\", app_name)\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.get_lastest_file_in_a_dir","title":"<code>get_lastest_file_in_a_dir(dir_path)</code>","text":"<p>Gets the most recently modified .pth file in a directory.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>str</code> <p>Directory to search in.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the most recently modified .pth file.</p> Example <pre><code># Get latest model weights file\nlatest = get_lastest_file_in_a_dir('./models')\nprint(f\"Latest weights: {latest}\")\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_lastest_file_in_a_dir(dir_path: str) -&gt; str:\n    \"\"\"Gets the most recently modified .pth file in a directory.\n\n    Args:\n        dir_path: Directory to search in.\n\n    Returns:\n        Path to the most recently modified .pth file.\n\n    Example:\n        ```python\n        # Get latest model weights file\n        latest = get_lastest_file_in_a_dir('./models')\n        print(f\"Latest weights: {latest}\")\n        ```\n    \"\"\"\n    pth_files_lst = [\n        os.path.join(dir_path, file)\n        for file in os.listdir(dir_path)\n        if fnmatch.fnmatch(file, \"*.pth\")\n    ]\n    return get_latest_file_in_a_lst(pth_files_lst)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.get_latest_file_in_a_lst","title":"<code>get_latest_file_in_a_lst(lst)</code>","text":"<p>Gets the most recently modified file from a list of files.</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list</code> <p>List of file paths.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the most recently modified file.</p> Example <pre><code>files = ['model_v1.pth', 'model_v2.pth', 'model_v3.pth']\nlatest = get_latest_file_in_a_lst(files)\nprint(f\"Latest version: {latest}\")\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_latest_file_in_a_lst(lst: list) -&gt; str:\n    \"\"\"Gets the most recently modified file from a list of files.\n\n    Args:\n        lst: List of file paths.\n\n    Returns:\n        Path to the most recently modified file.\n\n    Example:\n        ```python\n        files = ['model_v1.pth', 'model_v2.pth', 'model_v3.pth']\n        latest = get_latest_file_in_a_lst(files)\n        print(f\"Latest version: {latest}\")\n        ```\n    \"\"\"\n    lst_ctime = [os.path.getctime(file) for file in lst]\n    sort_idx = np.argsort(lst_ctime)\n    return lst[sort_idx[-1]]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.get_year","title":"<code>get_year(a_time)</code>","text":"<p>Extracts the year from various date formats.</p> <p>Parameters:</p> Name Type Description Default <code>a_time</code> <code>Union[date, datetime64, str]</code> <p>Date in one of these formats: - datetime.date object - numpy.datetime64 object - string in 'YYYY-MM-DD' format</p> required <p>Returns:</p> Type Description <code>int</code> <p>Year as integer.</p> Example <pre><code># From datetime.date\nyear = get_year(datetime.date(2023, 1, 1))  # Returns 2023\n\n# From numpy.datetime64\nyear = get_year(np.datetime64('2023-01-01'))  # Returns 2023\n\n# From string\nyear = get_year('2023-01-01')  # Returns 2023\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def get_year(a_time: Union[datetime.date, np.datetime64, str]) -&gt; int:\n    \"\"\"Extracts the year from various date formats.\n\n    Args:\n        a_time: Date in one of these formats:\n            - datetime.date object\n            - numpy.datetime64 object\n            - string in 'YYYY-MM-DD' format\n\n    Returns:\n        Year as integer.\n\n    Example:\n        ```python\n        # From datetime.date\n        year = get_year(datetime.date(2023, 1, 1))  # Returns 2023\n\n        # From numpy.datetime64\n        year = get_year(np.datetime64('2023-01-01'))  # Returns 2023\n\n        # From string\n        year = get_year('2023-01-01')  # Returns 2023\n        ```\n    \"\"\"\n    if isinstance(a_time, datetime.date):\n        return a_time.year\n    elif isinstance(a_time, np.datetime64):\n        return a_time.astype(\"datetime64[Y]\").astype(int) + 1970\n    else:\n        return int(a_time[:4])\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.hydro_logger","title":"<code>hydro_logger(cls)</code>","text":"<p>A class decorator that adds logging capabilities to a class.</p> <p>This decorator sets up both file and console logging for the decorated class. Logs are stored in a cache directory with timestamps in the filename.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <p>The class to be decorated.</p> required <p>Returns:</p> Type Description <p>The decorated class with an added logger attribute.</p> Example <pre><code>@hydro_logger\nclass MyHydroClass:\n    def some_method(self):\n        self.logger.info(\"Processing data...\")\n        # Method implementation\n        self.logger.debug(\"Processing complete\")\n</code></pre> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def hydro_logger(cls):\n    \"\"\"A class decorator that adds logging capabilities to a class.\n\n    This decorator sets up both file and console logging for the decorated class.\n    Logs are stored in a cache directory with timestamps in the filename.\n\n    Args:\n        cls: The class to be decorated.\n\n    Returns:\n        The decorated class with an added logger attribute.\n\n    Example:\n        ```python\n        @hydro_logger\n        class MyHydroClass:\n            def some_method(self):\n                self.logger.info(\"Processing data...\")\n                # Method implementation\n                self.logger.debug(\"Processing complete\")\n        ```\n    \"\"\"\n    # Use the class name as the logger name\n    logger_name = f\"{cls.__module__}.{cls.__name__}\"\n    logger = logging.getLogger(logger_name)\n    logger.setLevel(logging.DEBUG)\n    cache_dir = get_cache_dir()\n    log_dir = os.path.join(cache_dir, \"logs\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_file = os.path.join(log_dir, f\"{logger_name}_{current_time}.log\")\n    # Check if handlers have already been added to avoid duplication\n    if not logger.handlers:\n        # Create a file handler to write logs to the specified file\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setLevel(logging.DEBUG)\n\n        # Create a console handler to output logs to the console (optional)\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(logging.INFO)\n\n        # set the format of the log\n        formatter = logging.Formatter(\n            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n        )\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n\n        # Add handlers to the logger\n        logger.addHandler(file_handler)\n        logger.addHandler(console_handler)\n\n    # Bind the logger to the class attribute\n    cls.logger = logger\n    return cls\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.intersect","title":"<code>intersect(t_lst1, t_lst2)</code>","text":"<p>Finds indices where two time arrays intersect.</p> <p>Parameters:</p> Name Type Description Default <code>t_lst1</code> <code>array</code> <p>First time array.</p> required <code>t_lst2</code> <code>array</code> <p>Second time array.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of (indices_in_t_lst1, indices_in_t_lst2) where values match.</p> Example <pre><code>t1 = np.array(['2000-01-01', '2000-01-02', '2000-01-03'])\nt2 = np.array(['2000-01-02', '2000-01-03', '2000-01-04'])\nidx1, idx2 = intersect(t1, t2)\n# idx1 = [1, 2] (indices in t1)\n# idx2 = [0, 1] (indices in t2)\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def intersect(t_lst1: np.array, t_lst2: np.array) -&gt; tuple:\n    \"\"\"Finds indices where two time arrays intersect.\n\n    Args:\n        t_lst1: First time array.\n        t_lst2: Second time array.\n\n    Returns:\n        Tuple of (indices_in_t_lst1, indices_in_t_lst2) where values match.\n\n    Example:\n        ```python\n        t1 = np.array(['2000-01-01', '2000-01-02', '2000-01-03'])\n        t2 = np.array(['2000-01-02', '2000-01-03', '2000-01-04'])\n        idx1, idx2 = intersect(t1, t2)\n        # idx1 = [1, 2] (indices in t1)\n        # idx2 = [0, 1] (indices in t2)\n        ```\n    \"\"\"\n    C, ind1, ind2 = np.intersect1d(t_lst1, t_lst2, return_indices=True)\n    return ind1, ind2\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.is_there_file","title":"<code>is_there_file(zipfile_path, unzip_dir)</code>","text":"<p>Checks if a zip file exists and is properly extracted.</p> <p>If the zip file exists but hasn't been extracted, extracts it.</p> <p>Parameters:</p> Name Type Description Default <code>zipfile_path</code> <code>str</code> <p>Path to the zip file.</p> required <code>unzip_dir</code> <code>str</code> <p>Directory where the file should be/has been extracted.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file exists (and is extracted), False otherwise.</p> Example <pre><code>if is_there_file('data.zip', './extracted'):\n    print('File exists and is extracted')\nelse:\n    print('File not found')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def is_there_file(zipfile_path: str, unzip_dir: str) -&gt; bool:\n    \"\"\"Checks if a zip file exists and is properly extracted.\n\n    If the zip file exists but hasn't been extracted, extracts it.\n\n    Args:\n        zipfile_path: Path to the zip file.\n        unzip_dir: Directory where the file should be/has been extracted.\n\n    Returns:\n        True if the file exists (and is extracted), False otherwise.\n\n    Example:\n        ```python\n        if is_there_file('data.zip', './extracted'):\n            print('File exists and is extracted')\n        else:\n            print('File not found')\n        ```\n    \"\"\"\n    if os.path.isfile(zipfile_path):\n        if os.path.isdir(unzip_dir):\n            return True\n        unzip_nested_zip(zipfile_path, unzip_dir)\n        return True\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.mean_peak_timing","title":"<code>mean_peak_timing(obs, sim, window=None, resolution='1D', datetime_coord=None)</code>","text":"<p>Calculates mean difference in peak flow timing between observed and simulated flows.</p> <p>Uses peak detection to find significant peaks in the observed time series and compares their timing with corresponding peaks in the simulated series.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observed flow time series.</p> required <code>sim</code> <code>ndarray</code> <p>Simulated flow time series.</p> required <code>window</code> <code>int</code> <p>Search window size for matching peaks. If None, uses resolution-dependent defaults (e.g., 3 for daily, 12 for hourly data).</p> <code>None</code> <code>resolution</code> <code>str</code> <p>Time step size ('1D' for daily, '1H' for hourly, etc.).</p> <code>'1D'</code> <code>datetime_coord</code> <code>str</code> <p>Name of datetime coordinate. Inferred if not specified.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>Mean absolute time difference between observed and simulated peaks.</p> Example <pre><code>obs = np.array([1, 2, 5, 2, 1])  # Peak at index 2\nsim = np.array([1, 4, 2, 1, 1])  # Peak at index 1\ndiff = mean_peak_timing(obs, sim, window=1)  # Returns 1 (time step difference)\n</code></pre> Note <p>Based on Kratzert et al. (2020), https://doi.org/10.5194/hess-2020-221 Peaks are filtered by prominence and minimum distance requirements.</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def mean_peak_timing(\n    obs: np.ndarray,\n    sim: np.ndarray,\n    window: int = None,\n    resolution: str = \"1D\",\n    datetime_coord: str = None\n) -&gt; float:\n    \"\"\"Calculates mean difference in peak flow timing between observed and simulated flows.\n\n    Uses peak detection to find significant peaks in the observed time series and\n    compares their timing with corresponding peaks in the simulated series.\n\n    Args:\n        obs: Observed flow time series.\n        sim: Simulated flow time series.\n        window: Search window size for matching peaks. If None, uses resolution-dependent\n            defaults (e.g., 3 for daily, 12 for hourly data).\n        resolution: Time step size ('1D' for daily, '1H' for hourly, etc.).\n        datetime_coord: Name of datetime coordinate. Inferred if not specified.\n\n    Returns:\n        Mean absolute time difference between observed and simulated peaks.\n\n    Example:\n        ```python\n        obs = np.array([1, 2, 5, 2, 1])  # Peak at index 2\n        sim = np.array([1, 4, 2, 1, 1])  # Peak at index 1\n        diff = mean_peak_timing(obs, sim, window=1)  # Returns 1 (time step difference)\n        ```\n\n    Note:\n        Based on Kratzert et al. (2020), https://doi.org/10.5194/hess-2020-221\n        Peaks are filtered by prominence and minimum distance requirements.\n    \"\"\"\n    # verify inputs\n    _validate_inputs(obs, sim)\n\n    # get time series with only valid observations (scipy's find_peaks doesn't guarantee correctness with NaNs)\n    obs, sim = _mask_valid(obs, sim)\n\n    # heuristic to get indices of peaks and their corresponding height.\n    peaks, _ = signal.find_peaks(\n        obs.values, distance=100, prominence=np.std(obs.values)\n    )\n\n    # infer name of datetime index\n    if datetime_coord is None:\n        datetime_coord = utils.infer_datetime_coord(obs)\n\n    if window is None:\n        # infer a reasonable window size\n        window = max(int(utils.get_frequency_factor(\"12H\", resolution)), 3)\n\n    # evaluate timing\n    timing_errors = []\n    for idx in peaks:\n        # skip peaks at the start and end of the sequence and peaks around missing observations\n        # (NaNs that were removed in obs &amp; sim would result in windows that span too much time).\n        if (\n            (idx - window &lt; 0)\n            or (idx + window &gt;= len(obs))\n            or (\n                pd.date_range(\n                    obs[idx - window][datetime_coord].values,\n                    obs[idx + window][datetime_coord].values,\n                    freq=resolution,\n                ).size\n                != 2 * window + 1\n            )\n        ):\n            continue\n\n        # check if the value at idx is a peak (both neighbors must be smaller)\n        if (sim[idx] &gt; sim[idx - 1]) and (sim[idx] &gt; sim[idx + 1]):\n            peak_sim = sim[idx]\n        else:\n            # define peak around idx as the max value inside of the window\n            values = sim[idx - window : idx + window + 1]\n            peak_sim = values[values.argmax()]\n\n        # get xarray object of qobs peak, for getting the date and calculating the datetime offset\n        peak_obs = obs[idx]\n\n        # calculate the time difference between the peaks\n        delta = peak_obs.coords[datetime_coord] - peak_sim.coords[datetime_coord]\n\n        timing_error = np.abs(delta.values / pd.to_timedelta(resolution))\n\n        timing_errors.append(timing_error)\n\n    return np.mean(timing_errors) if timing_errors else np.nan\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.minio_download_file","title":"<code>minio_download_file(client, bucket_name, object_name, file_path, version_id=None)</code>","text":"<p>Downloads a file from MinIO S3-compatible storage.</p> <p>Downloads an object from S3 and saves it to a local file. Handles UTF-8 encoded text files.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Minio</code> <p>MinIO client instance.</p> required <code>bucket_name</code> <code>str</code> <p>Name of the bucket containing the object.</p> required <code>object_name</code> <code>str</code> <p>Name of the object to download.</p> required <code>file_path</code> <code>str</code> <p>Local path where the file should be saved.</p> required <code>version_id</code> <code>str</code> <p>Optional version ID for versioned objects.</p> <code>None</code> Example <pre><code>from minio import Minio\nclient = Minio('play.min.io', access_key='...', secret_key='...')\nminio_download_file(client, 'mybucket', 'data.csv', './downloaded.csv')\n</code></pre> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def minio_download_file(\n    client: Minio, bucket_name: str, object_name: str, file_path: str, version_id: str = None\n) -&gt; None:\n    \"\"\"Downloads a file from MinIO S3-compatible storage.\n\n    Downloads an object from S3 and saves it to a local file. Handles UTF-8 encoded text files.\n\n    Args:\n        client: MinIO client instance.\n        bucket_name: Name of the bucket containing the object.\n        object_name: Name of the object to download.\n        file_path: Local path where the file should be saved.\n        version_id: Optional version ID for versioned objects.\n\n    Example:\n        ```python\n        from minio import Minio\n        client = Minio('play.min.io', access_key='...', secret_key='...')\n        minio_download_file(client, 'mybucket', 'data.csv', './downloaded.csv')\n        ```\n    \"\"\"\n    try:\n        response = client.get_object(bucket_name, object_name, version_id)\n        res_csv: str = response.data.decode(\"utf8\")\n        with open(file_path, \"w+\") as fp:\n            fp.write(res_csv)\n    finally:\n        response.close()\n        response.release_conn()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.minio_upload_file","title":"<code>minio_upload_file(client, bucket_name, object_name, file_path)</code>","text":"<p>Uploads a file to MinIO S3-compatible storage.</p> <p>Creates the bucket if it doesn't exist, uploads the file, and returns a list of all objects in the bucket.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Minio</code> <p>MinIO client instance.</p> required <code>bucket_name</code> <code>str</code> <p>Name of the bucket to upload to.</p> required <code>object_name</code> <code>str</code> <p>Name to give the object in S3.</p> required <code>file_path</code> <code>str</code> <p>Local path of the file to upload.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of object names in the bucket after upload.</p> Example <pre><code>from minio import Minio\nclient = Minio('play.min.io', access_key='...', secret_key='...')\nobjects = minio_upload_file(client, 'mybucket', 'data.csv', './data.csv')\nprint(f\"Bucket contents: {objects}\")\n</code></pre> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def minio_upload_file(client: Minio, bucket_name: str, object_name: str, file_path: str) -&gt; list:\n    \"\"\"Uploads a file to MinIO S3-compatible storage.\n\n    Creates the bucket if it doesn't exist, uploads the file, and returns a list of\n    all objects in the bucket.\n\n    Args:\n        client: MinIO client instance.\n        bucket_name: Name of the bucket to upload to.\n        object_name: Name to give the object in S3.\n        file_path: Local path of the file to upload.\n\n    Returns:\n        List of object names in the bucket after upload.\n\n    Example:\n        ```python\n        from minio import Minio\n        client = Minio('play.min.io', access_key='...', secret_key='...')\n        objects = minio_upload_file(client, 'mybucket', 'data.csv', './data.csv')\n        print(f\"Bucket contents: {objects}\")\n        ```\n    \"\"\"\n    # Make a bucket\n    bucket_names = [bucket.name for bucket in client.list_buckets()]\n    if bucket_name not in bucket_names:\n        client.make_bucket(bucket_name)\n    # Upload an object\n    client.fput_object(bucket_name, object_name, file_path)\n    # List objects\n    objects = client.list_objects(bucket_name, recursive=True)\n    return [obj.object_name for obj in objects]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.month_stat_for_daily_df","title":"<code>month_stat_for_daily_df(df)</code>","text":"<p>Calculates monthly statistics from daily data.</p> <p>Resamples daily data to monthly frequency using mean values. Automatically converts index to datetime if needed.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with daily data and datetime index.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with monthly statistics (means).</p> Example <pre><code># Daily flow data\ndaily = pd.DataFrame({\n    'flow': [1, 2, 3, 4, ...],  # 365 values\n    'temp': [20, 21, 19, 22, ...]\n}, index=pd.date_range('2023-01-01', periods=365))\n\n# Convert to monthly means\nmonthly = month_stat_for_daily_df(daily)\nprint(f\"Number of months: {len(monthly)}\")  # 12\n</code></pre> Note <p>Uses pandas resample with 'MS' (month start) frequency and mean aggregation.</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def month_stat_for_daily_df(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculates monthly statistics from daily data.\n\n    Resamples daily data to monthly frequency using mean values.\n    Automatically converts index to datetime if needed.\n\n    Args:\n        df: DataFrame with daily data and datetime index.\n\n    Returns:\n        DataFrame with monthly statistics (means).\n\n    Example:\n        ```python\n        # Daily flow data\n        daily = pd.DataFrame({\n            'flow': [1, 2, 3, 4, ...],  # 365 values\n            'temp': [20, 21, 19, 22, ...]\n        }, index=pd.date_range('2023-01-01', periods=365))\n\n        # Convert to monthly means\n        monthly = month_stat_for_daily_df(daily)\n        print(f\"Number of months: {len(monthly)}\")  # 12\n        ```\n\n    Note:\n        Uses pandas resample with 'MS' (month start) frequency\n        and mean aggregation.\n    \"\"\"\n    # guarantee the index is datetime\n    df.index = pd.to_datetime(df.index)\n    return df.resample(\"MS\").mean()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_boxes_matplotlib","title":"<code>plot_boxes_matplotlib(data, label1=None, label2=None, leg_col=None, colorlst='rbgcmywrbgcmyw', title=None, figsize=(8, 6), sharey=False, xticklabel=None, axin=None, ylim=None, ylabel=None, notch=False, widths=0.5, subplots_adjust_wspace=0.2, show_median=True, median_line_color='black', median_font_size='small')</code>","text":"<p>Creates multiple boxplots for comparing multiple indicators or groups.</p> <p>This function generates a sophisticated boxplot visualization with multiple customization options, including median display, notched boxes, and flexible layout options. It's particularly useful for comparing distributions across different groups or indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>List of arrays, where each array contains the data for one indicator or group to be displayed as a boxplot.</p> required <code>label1</code> <code>list</code> <p>Labels for each subplot. Defaults to None.</p> <code>None</code> <code>label2</code> <code>list</code> <p>Legend labels for boxes within each subplot. Defaults to None.</p> <code>None</code> <code>leg_col</code> <code>int</code> <p>Number of columns in the legend. Defaults to None.</p> <code>None</code> <code>colorlst</code> <code>str</code> <p>String of color characters for box colors. Defaults to \"rbgcmywrbgcmyw\".</p> <code>'rbgcmywrbgcmyw'</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to None.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>sharey</code> <code>bool</code> <p>If True, all subplots share the same y-axis scale. Defaults to False.</p> <code>False</code> <code>xticklabel</code> <code>list</code> <p>Custom x-axis tick labels. Defaults to None.</p> <code>None</code> <code>axin</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>list</code> <p>Y-axis labels for each subplot. Defaults to None.</p> <code>None</code> <code>notch</code> <code>bool</code> <p>If True, creates notched boxes. Defaults to False.</p> <code>False</code> <code>widths</code> <code>float</code> <p>Width of the boxes. Defaults to 0.5.</p> <code>0.5</code> <code>subplots_adjust_wspace</code> <code>float</code> <p>Width space between subplots. Defaults to 0.2.</p> <code>0.2</code> <code>show_median</code> <code>bool</code> <p>If True, displays median values. Defaults to True.</p> <code>True</code> <code>median_line_color</code> <code>str</code> <p>Color of median lines. Defaults to \"black\".</p> <code>'black'</code> <code>median_font_size</code> <code>str</code> <p>Font size for median values. Defaults to \"small\".</p> <code>'small'</code> <p>Returns:</p> Type Description <p>Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]: If axin is None, returns the Figure object. If axin is provided, returns a tuple of (Axes, boxplot_dict).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n&gt;&gt;&gt; fig = plot_boxes_matplotlib(\n...     data,\n...     label1=['Group A', 'Group B', 'Group C'],\n...     show_median=True,\n...     notch=True\n... )\n</code></pre> Notes <ul> <li>The function automatically handles NaN values in the data.</li> <li>Median values can be displayed with customizable formatting.</li> <li>Supports both single and multiple subplot layouts.</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxes_matplotlib(\n    data: list,\n    label1: list = None,\n    label2: list = None,\n    leg_col: int = None,\n    colorlst=\"rbgcmywrbgcmyw\",\n    title=None,\n    figsize=(8, 6),\n    sharey=False,\n    xticklabel=None,\n    axin=None,\n    ylim=None,\n    ylabel=None,\n    notch=False,\n    widths=0.5,\n    subplots_adjust_wspace=0.2,\n    show_median=True,\n    median_line_color=\"black\",\n    median_font_size=\"small\",\n):\n    \"\"\"Creates multiple boxplots for comparing multiple indicators or groups.\n\n    This function generates a sophisticated boxplot visualization with multiple customization\n    options, including median display, notched boxes, and flexible layout options. It's\n    particularly useful for comparing distributions across different groups or indicators.\n\n    Args:\n        data (list): List of arrays, where each array contains the data for one indicator\n            or group to be displayed as a boxplot.\n        label1 (list, optional): Labels for each subplot. Defaults to None.\n        label2 (list, optional): Legend labels for boxes within each subplot. Defaults to None.\n        leg_col (int, optional): Number of columns in the legend. Defaults to None.\n        colorlst (str, optional): String of color characters for box colors. Defaults to\n            \"rbgcmywrbgcmyw\".\n        title (str, optional): Title of the plot. Defaults to None.\n        figsize (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        sharey (bool, optional): If True, all subplots share the same y-axis scale.\n            Defaults to False.\n        xticklabel (list, optional): Custom x-axis tick labels. Defaults to None.\n        axin (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        ylabel (list, optional): Y-axis labels for each subplot. Defaults to None.\n        notch (bool, optional): If True, creates notched boxes. Defaults to False.\n        widths (float, optional): Width of the boxes. Defaults to 0.5.\n        subplots_adjust_wspace (float, optional): Width space between subplots.\n            Defaults to 0.2.\n        show_median (bool, optional): If True, displays median values. Defaults to True.\n        median_line_color (str, optional): Color of median lines. Defaults to \"black\".\n        median_font_size (str, optional): Font size for median values. Defaults to \"small\".\n\n    Returns:\n        Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]:\n            If axin is None, returns the Figure object.\n            If axin is provided, returns a tuple of (Axes, boxplot_dict).\n\n    Examples:\n        &gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n        &gt;&gt;&gt; fig = plot_boxes_matplotlib(\n        ...     data,\n        ...     label1=['Group A', 'Group B', 'Group C'],\n        ...     show_median=True,\n        ...     notch=True\n        ... )\n\n    Notes:\n        - The function automatically handles NaN values in the data.\n        - Median values can be displayed with customizable formatting.\n        - Supports both single and multiple subplot layouts.\n    \"\"\"\n    nc = len(data)\n    if axin is None:\n        fig, axes = plt.subplots(\n            ncols=nc, sharey=sharey, figsize=figsize, constrained_layout=False\n        )\n    else:\n        axes = axin\n\n    # the next few lines are for showing median values\n    decimal_places = \"2\"\n    for k in range(nc):\n        ax = axes[k] if nc &gt; 1 else axes\n        temp = data[k]\n        if type(temp) is list:\n            for kk in range(len(temp)):\n                tt = temp[kk]\n                if tt is not None and len(tt) &gt; 0:\n                    tt = tt[~np.isnan(tt)]\n                    temp[kk] = tt\n                else:\n                    temp[kk] = []\n        else:\n            temp = temp[~np.isnan(temp)]\n        bp = ax.boxplot(\n            temp, patch_artist=True, notch=notch, showfliers=False, widths=widths\n        )\n        for median in bp[\"medians\"]:\n            median.set_color(median_line_color)\n        medians_value = [np.median(tmp) for tmp in temp]\n        percent25value = [np.percentile(tmp, 25) for tmp in temp]\n        percent75value = [np.percentile(tmp, 75) for tmp in temp]\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n        pos = range(len(medians_value))\n        if show_median:\n            for tick, label in zip(pos, ax.get_xticklabels()):\n                # params of ax.text could be seen here: https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                ax.text(\n                    pos[tick] + 1,\n                    medians_value[tick] + (per75max - per25min) * 0.01,\n                    median_labels[tick],\n                    horizontalalignment=\"center\",\n                    # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                    size=median_font_size,\n                    weight=\"semibold\",\n                    color=median_line_color,\n                )\n        for kk in range(len(bp[\"boxes\"])):\n            plt.setp(bp[\"boxes\"][kk], facecolor=colorlst[kk])\n\n        if label1 is not None:\n            ax.set_xlabel(label1[k])\n        else:\n            ax.set_xlabel(str(k))\n        if xticklabel is None:\n            ax.set_xticks([])\n        else:\n            ax.set_xticks([y + 1 for y in range(0, len(data[k]), 2)])\n            ax.set_xticklabels(xticklabel)\n        if ylabel is not None:\n            ax.set_ylabel(ylabel[k])\n        if ylim is not None:\n            ax.set_ylim(ylim[k])\n    if label2 is not None:\n        plt.legend(\n            bp[\"boxes\"],\n            label2,\n            # explanation for bbox_to_anchor: https://zhuanlan.zhihu.com/p/101059179\n            bbox_to_anchor=(1.0, 1.02, 0.25, 0.05),\n            loc=\"upper right\",\n            borderaxespad=0,\n            ncol=len(label2) if leg_col is None else leg_col,\n            frameon=False,\n            fontsize=12,\n        )\n    if title is not None:\n        # fig.suptitle(title)\n        ax.set_title(title)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=subplots_adjust_wspace)\n    return fig if axin is None else (ax, bp)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_boxs","title":"<code>plot_boxs(data, x_name, y_name, uniform_color=None, swarm_plot=False, hue=None, colormap=False, xlim=None, ylim=None, order=None, font='serif', rotation=45, show_median=False)</code>","text":"<p>plot multiple boxes in one ax with seaborn Parameters</p> <p>data : pd.DataFrame     a tidy pandas dataframe;     if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data x_name : str     the names of each box y_name : str     what is shown uniform_color : str, optional     unified color for all boxes, by default None swarm_plot : bool, optional     description, by default False hue : type, optional     description, by default None colormap : bool, optional     description, by default False xlim : type, optional     description, by default None ylim : type, optional     description, by default None order : type, optional     description, by default None font : str, optional     description, by default \"serif\" rotation : int, optional     rotation for labels in x-axis, by default 45 show_median: bool, optional     if True, show median value for each box, by default False Returns</p> <p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxs(\n    data: pd.DataFrame,\n    x_name: str,\n    y_name: str,\n    uniform_color=None,\n    swarm_plot=False,\n    hue=None,\n    colormap=False,\n    xlim=None,\n    ylim=None,\n    order=None,\n    font=\"serif\",\n    rotation=45,\n    show_median=False,\n):\n    \"\"\"plot multiple boxes in one ax with seaborn\n    Parameters\n    ----------\n    data : pd.DataFrame\n        a tidy pandas dataframe;\n        if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data\n    x_name : str\n        the names of each box\n    y_name : str\n        what is shown\n    uniform_color : str, optional\n        unified color for all boxes, by default None\n    swarm_plot : bool, optional\n        _description_, by default False\n    hue : _type_, optional\n        _description_, by default None\n    colormap : bool, optional\n        _description_, by default False\n    xlim : _type_, optional\n        _description_, by default None\n    ylim : _type_, optional\n        _description_, by default None\n    order : _type_, optional\n        _description_, by default None\n    font : str, optional\n        _description_, by default \"serif\"\n    rotation : int, optional\n        rotation for labels in x-axis, by default 45\n    show_median: bool, optional\n        if True, show median value for each box, by default False\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    fig = plt.figure()\n    sns.set(style=\"ticks\", palette=\"pastel\", font=font, font_scale=1.5)\n    # Draw a nested boxplot to show bills by day and time\n    if uniform_color is not None:\n        sns_box = sns.boxplot(\n            x=x_name,\n            y=y_name,\n            data=data,\n            color=uniform_color,\n            showfliers=False,\n            order=order,\n        )\n    else:\n        sns_box = sns.boxplot(\n            x=x_name, y=y_name, data=data, showfliers=False, order=order\n        )\n    if swarm_plot:\n        if hue is None:\n            sns_box = sns.swarmplot(\n                x=x_name, y=y_name, data=data, color=\".2\", order=order\n            )\n        elif colormap:\n            # Create a matplotlib colormap from the sns seagreen color palette\n            cmap = sns.light_palette(\"seagreen\", reverse=False, as_cmap=True)\n            # Normalize to the range of possible values from df[\"c\"]\n            norm = matplotlib.colors.Normalize(\n                vmin=data[hue].min(), vmax=data[hue].max()\n            )\n            colors = {cval: cmap(norm(cval)) for cval in data[hue]}\n            # plot the swarmplot with the colors dictionary as palette, s=2 means size is 2\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=colors,\n                order=order,\n            )\n            # remove the legend, because we want to set a colorbar instead\n            plt.gca().legend_.remove()\n            # create colorbar\n            divider = make_axes_locatable(plt.gca())\n            ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)\n            fig = sns_box.get_figure()\n            fig.add_axes(ax_cb)\n            cb1 = matplotlib.colorbar.ColorbarBase(\n                ax_cb, cmap=cmap, norm=norm, orientation=\"vertical\"\n            )\n            cb1.set_label(\"Some Units\")\n        else:\n            palette = sns.light_palette(\"seagreen\", reverse=False, n_colors=10)\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=palette,\n                order=order,\n            )\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    if show_median:\n        medians = data.groupby([x_name], sort=False)[y_name].median().values\n        create_median_labels(sns_box, medians_value=medians, size=\"x-small\")\n    sns.despine()\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=rotation)\n    # plt.show()\n    return sns_box.get_figure()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_diff_boxes","title":"<code>plot_diff_boxes(data, row_and_col=None, y_col=None, x_col=None, hspace=0.3, wspace=1, title_str=None, title_font_size=14)</code>","text":"<p>plot boxplots in rows and cols</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_diff_boxes(\n    data,\n    row_and_col=None,\n    y_col=None,\n    x_col=None,\n    hspace=0.3,\n    wspace=1,\n    title_str=None,\n    title_font_size=14,\n):\n    \"\"\"plot boxplots in rows and cols\"\"\"\n    # matplotlib.use('TkAgg')\n    if type(data) is not pd.DataFrame:\n        data = pd.DataFrame(data)\n    subplot_num = data.shape[1] if y_col is None else len(y_col)\n    if row_and_col is None:\n        row_num = 1\n        col_num = subplot_num\n        f, axes = plt.subplots(row_num, col_num)\n        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n    else:\n        assert subplot_num &lt;= row_and_col[0] * row_and_col[1]\n        row_num = row_and_col[0]\n        col_num = row_and_col[1]\n        f, axes = plt.subplots(row_num, col_num)\n        f.tight_layout()\n    for i in range(subplot_num):\n        if y_col is None:\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    width=0.5,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                ).set(xlabel=data.columns.values[i], ylabel=\"\")\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n        else:\n            assert x_col is not None\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                )\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n    if title_str is not None:\n        f.suptitle(title_str, fontsize=title_font_size)\n    return f\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ecdf","title":"<code>plot_ecdf(mydataframe, mycolumn, save_file=None)</code>","text":"<p>Creates an empirical cumulative distribution function (ECDF) plot for a single column.</p> <p>This function generates an ECDF plot for a single column of data from a pandas DataFrame. It provides a simple interface for quick visualization of data distributions.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create ECDF for.</p> required <code>save_file</code> <code>str</code> <p>Path to save the plot. If None, plot is only displayed. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n&gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n</code></pre> Notes <ul> <li>Uses seaborn's styling for better visualization</li> <li>Automatically handles NaN values</li> <li>Plot range is set to [0, 1] for both axes</li> <li>Uses 0.05 intervals for axis ticks</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdf(mydataframe, mycolumn, save_file=None):\n    \"\"\"Creates an empirical cumulative distribution function (ECDF) plot for a single column.\n\n    This function generates an ECDF plot for a single column of data from a pandas\n    DataFrame. It provides a simple interface for quick visualization of data\n    distributions.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create ECDF for.\n        save_file (str, optional): Path to save the plot. If None, plot is only\n            displayed. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n        &gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n\n    Notes:\n        - Uses seaborn's styling for better visualization\n        - Automatically handles NaN values\n        - Plot range is set to [0, 1] for both axes\n        - Uses 0.05 intervals for axis ticks\n    \"\"\"\n    x, y = ecdf(mydataframe[mycolumn])\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    sns.lineplot(x=\"x\", y=\"y\", data=df, estimator=None).set(\n        xlim=(0, 1), xticks=np.arange(0, 1, 0.05), yticks=np.arange(0, 1, 0.05)\n    )\n    plt.show()\n    if save_file is not None:\n        plt.savefig(save_file)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ecdfs","title":"<code>plot_ecdfs(xs, ys, legends=None, style=None, case_str='case', event_str='event', x_str='x', y_str='y', ax_as_subplot=None, interval=0.1)</code>","text":"<p>Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.</p> <p>This function generates ECDF plots for multiple datasets with customizable styling and labeling options. It's particularly useful for comparing distributions of different datasets or experimental conditions.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>style</code> <code>list[str]</code> <p>Line styles for each ECDF. Defaults to None.</p> <code>None</code> <code>case_str</code> <code>str</code> <p>Label for different cases in the plot. Defaults to \"case\".</p> <code>'case'</code> <code>event_str</code> <code>str</code> <p>Label for different events in the plot. Defaults to \"event\".</p> <code>'event'</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>ax_as_subplot</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>interval</code> <code>float</code> <p>Interval for axis ticks. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare two distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n&gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Distribution 1', 'Distribution 2'],\n...     x_str='Value',\n...     y_str='Cumulative Probability'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple distributions with different styles\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Group A', 'Group B'],\n...     style=['-', '--'],\n...     interval=0.2\n... )\n</code></pre> Notes <ul> <li>Input arrays must be sorted in ascending order</li> <li>Function automatically validates data ordering</li> <li>Supports both single and multiple subplot layouts</li> <li>Uses seaborn for enhanced visual styling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs(\n    xs,\n    ys,\n    legends=None,\n    style=None,\n    case_str=\"case\",\n    event_str=\"event\",\n    x_str=\"x\",\n    y_str=\"y\",\n    ax_as_subplot=None,\n    interval=0.1,\n):\n    \"\"\"Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.\n\n    This function generates ECDF plots for multiple datasets with customizable styling\n    and labeling options. It's particularly useful for comparing distributions of\n    different datasets or experimental conditions.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        style (list[str], optional): Line styles for each ECDF. Defaults to None.\n        case_str (str, optional): Label for different cases in the plot.\n            Defaults to \"case\".\n        event_str (str, optional): Label for different events in the plot.\n            Defaults to \"event\".\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        ax_as_subplot (matplotlib.axes.Axes, optional): Existing axes to plot on.\n            Defaults to None.\n        interval (float, optional): Interval for axis ticks. Defaults to 0.1.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare two distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n        &gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Distribution 1', 'Distribution 2'],\n        ...     x_str='Value',\n        ...     y_str='Cumulative Probability'\n        ... )\n\n        &gt;&gt;&gt; # Multiple distributions with different styles\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Group A', 'Group B'],\n        ...     style=['-', '--'],\n        ...     interval=0.2\n        ... )\n\n    Notes:\n        - Input arrays must be sorted in ascending order\n        - Function automatically validates data ordering\n        - Supports both single and multiple subplot layouts\n        - Uses seaborn for enhanced visual styling\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list)\n        assert len(ys) == len(legends)\n    if style is not None:\n        assert isinstance(style, list)\n        assert len(ys) == len(style)\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    frames = []\n    for i in range(len(xs)):\n        str_i = x_str + str(i) if legends is None else legends[i]\n        assert all(xi &lt; yi for xi, yi in zip(xs[i], xs[i][1:]))\n        df_dict_i = {\n            x_str: xs[i],\n            y_str: ys[i],\n            case_str: np.full([xs[i].size], str_i),\n        }\n        if style is not None:\n            df_dict_i[event_str] = np.full([xs[i].size], style[i])\n        df_i = pd.DataFrame(df_dict_i)\n        frames.append(df_i)\n    df = pd.concat(frames)\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    if style is None:\n        return (\n            sns.lineplot(x=x_str, y=y_str, hue=case_str, data=df, estimator=None).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n            if ax_as_subplot is None\n            else sns.lineplot(\n                ax=ax_as_subplot,\n                x=x_str,\n                y=y_str,\n                hue=case_str,\n                data=df,\n                estimator=None,\n            ).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n        )\n    elif ax_as_subplot is None:\n        return sns.lineplot(\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n    else:\n        return sns.lineplot(\n            ax=ax_as_subplot,\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ecdfs_matplot","title":"<code>plot_ecdfs_matplot(xs, ys, legends=None, colors='rbkgcmy', dash_lines=None, x_str='x', y_str='y', x_interval=0.1, y_interval=0.1, x_lim=(0, 1), y_lim=(0, 1), show_legend=True, legend_font_size=16, fig_size=(8, 6))</code>","text":"<p>Creates ECDF plots using matplotlib with extensive customization options.</p> <p>This function provides a more customizable alternative to the seaborn-based ECDF plotting functions, offering direct control over matplotlib parameters and styling.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>colors</code> <code>str</code> <p>String of color characters for different lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which lines should be dashed. Defaults to None.</p> <code>None</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>x_interval</code> <code>float</code> <p>Interval for x-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>y_interval</code> <code>float</code> <p>Interval for y-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>x_lim</code> <code>tuple</code> <p>X-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>y_lim</code> <code>tuple</code> <p>Y-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>show_legend</code> <code>bool</code> <p>Whether to show legend. Defaults to True.</p> <code>True</code> <code>legend_font_size</code> <code>int</code> <p>Font size for legend. Defaults to 16.</p> <code>16</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare multiple distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n...     x_str='Value',\n...     y_str='Probability',\n...     x_lim=(-3, 3)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     colors='rb',\n...     dash_lines=[False, True],\n...     legend_font_size=12,\n...     fig_size=(10, 8)\n... )\n</code></pre> Notes <ul> <li>Uses clean plotting style with minimal spines</li> <li>Supports both continuous and dashed lines</li> <li>Provides fine-grained control over axis properties</li> <li>Input arrays must be sorted in ascending order</li> <li>Automatically validates data ordering</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs_matplot(\n    xs,\n    ys,\n    legends=None,\n    colors=\"rbkgcmy\",\n    dash_lines=None,\n    x_str=\"x\",\n    y_str=\"y\",\n    x_interval=0.1,\n    y_interval=0.1,\n    x_lim=(0, 1),\n    y_lim=(0, 1),\n    show_legend=True,\n    legend_font_size=16,\n    fig_size=(8, 6),\n):\n    \"\"\"Creates ECDF plots using matplotlib with extensive customization options.\n\n    This function provides a more customizable alternative to the seaborn-based ECDF\n    plotting functions, offering direct control over matplotlib parameters and styling.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        colors (str, optional): String of color characters for different lines.\n            Defaults to \"rbkgcmy\".\n        dash_lines (list[bool], optional): Specifies which lines should be dashed.\n            Defaults to None.\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        x_interval (float, optional): Interval for x-axis ticks. Defaults to 0.1.\n        y_interval (float, optional): Interval for y-axis ticks. Defaults to 0.1.\n        x_lim (tuple, optional): X-axis limits as (min, max). Defaults to (0, 1).\n        y_lim (tuple, optional): Y-axis limits as (min, max). Defaults to (0, 1).\n        show_legend (bool, optional): Whether to show legend. Defaults to True.\n        legend_font_size (int, optional): Font size for legend. Defaults to 16.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare multiple distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n        ...     x_str='Value',\n        ...     y_str='Probability',\n        ...     x_lim=(-3, 3)\n        ... )\n\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     colors='rb',\n        ...     dash_lines=[False, True],\n        ...     legend_font_size=12,\n        ...     fig_size=(10, 8)\n        ... )\n\n    Notes:\n        - Uses clean plotting style with minimal spines\n        - Supports both continuous and dashed lines\n        - Provides fine-grained control over axis properties\n        - Input arrays must be sorted in ascending order\n        - Automatically validates data ordering\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list) and len(ys) == len(legends)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(xs), False).tolist()\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    fig = plt.figure(figsize=fig_size)\n    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n    for i in range(len(xs)):\n        if (\n            np.nanmax(np.array(xs[i])) == np.inf\n            or np.nanmin(np.array(xs[i])) == -np.inf\n        ):\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        else:\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        (line_i,) = ax.plot(xs[i], ys[i], color=colors[i], label=legends[i])\n        if dash_lines[i]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    plt.xlabel(x_str, fontsize=18)\n    plt.ylabel(y_str, fontsize=18)\n    ax.set_xlim(x_lim[0], x_lim[1])\n    ax.set_ylim(y_lim[0], y_lim[1])\n    # set x y number font size\n    plt.xticks(np.arange(x_lim[0], x_lim[1] + x_lim[1] / 100, x_interval), fontsize=16)\n    plt.yticks(np.arange(y_lim[0], y_lim[1] + y_lim[1] / 100, y_interval), fontsize=16)\n    if show_legend:\n        ax.legend()\n        plt.legend(prop={\"size\": legend_font_size})\n    plt.grid()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_heat_map","title":"<code>plot_heat_map(data, mask=None, fig_size=None, fmt='d', square=True, annot=True, xticklabels=True, yticklabels=True)</code>","text":"<p>Creates a heatmap visualization of 2D data using seaborn.</p> <p>This function creates a heatmap visualization with customizable formatting, annotations, and masking options. It uses seaborn's heatmap function with additional customization options.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>2D array or DataFrame to be visualized.</p> required <code>mask</code> <code>array</code> <p>Boolean array of same shape as data. True values will be masked (not shown). Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to None.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>String formatting code for cell annotations. Defaults to \"d\" for integer formatting.</p> <code>'d'</code> <code>square</code> <code>bool</code> <p>If True, set the Axes aspect to \"equal\". Defaults to True.</p> <code>True</code> <code>annot</code> <code>bool</code> <p>If True, write the data value in each cell. Defaults to True.</p> <code>True</code> <code>xticklabels</code> <code>bool</code> <p>If True, show x-axis labels. Defaults to True.</p> <code>True</code> <code>yticklabels</code> <code>bool</code> <p>If True, show y-axis labels. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n&gt;&gt;&gt; plot_heat_map(\n...     data,\n...     fmt='.2f',\n...     fig_size=(8, 6),\n...     annot=True\n... )\n</code></pre> Notes <p>The function uses a red-blue diverging colormap ('RdBu_r') by default. For more details on the underlying implementation, see: https://zhuanlan.zhihu.com/p/96040773</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_heat_map(\n    data,\n    mask=None,\n    fig_size=None,\n    fmt=\"d\",\n    square=True,\n    annot=True,\n    xticklabels=True,\n    yticklabels=True,\n):\n    \"\"\"Creates a heatmap visualization of 2D data using seaborn.\n\n    This function creates a heatmap visualization with customizable formatting,\n    annotations, and masking options. It uses seaborn's heatmap function with\n    additional customization options.\n\n    Args:\n        data (pd.DataFrame): 2D array or DataFrame to be visualized.\n        mask (np.array, optional): Boolean array of same shape as data. True values will\n            be masked (not shown). Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to None.\n        fmt (str, optional): String formatting code for cell annotations. Defaults to \"d\"\n            for integer formatting.\n        square (bool, optional): If True, set the Axes aspect to \"equal\". Defaults to True.\n        annot (bool, optional): If True, write the data value in each cell. Defaults to True.\n        xticklabels (bool, optional): If True, show x-axis labels. Defaults to True.\n        yticklabels (bool, optional): If True, show y-axis labels. Defaults to True.\n\n    Returns:\n        matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.\n\n    Examples:\n        &gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n        &gt;&gt;&gt; plot_heat_map(\n        ...     data,\n        ...     fmt='.2f',\n        ...     fig_size=(8, 6),\n        ...     annot=True\n        ... )\n\n    Notes:\n        The function uses a red-blue diverging colormap ('RdBu_r') by default.\n        For more details on the underlying implementation, see:\n        https://zhuanlan.zhihu.com/p/96040773\n    \"\"\"\n    if fig_size is not None:\n        fig = plt.figure(figsize=fig_size)\n    ax = sns.heatmap(\n        data=data,\n        square=square,\n        annot=annot,\n        fmt=fmt,\n        cmap=\"RdBu_r\",\n        mask=mask,\n        xticklabels=xticklabels,\n        yticklabels=yticklabels,\n    )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_map_carto","title":"<code>plot_map_carto(data, lat, lon, fig=None, ax=None, pertile_range=None, value_range=None, fig_size=(8, 8), need_colorbar=True, colorbar_size=[0.91, 0.318, 0.02, 0.354], cmap_str='jet', idx_lst=None, markers=None, marker_size=20, is_discrete=False, colors='rbkgcmywrbkgcmyw', category_names=None, legend_font_size=None, colorbar_font_size=None)</code>","text":"<p>Creates a cartographic map visualization using Cartopy with extensive customization options.</p> <p>This function generates a map visualization for spatial data with support for continuous and discrete color scales, multiple marker types, and various styling options. It's particularly useful for visualizing hydrological data in a geographic context.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array</code> <p>1-D array of values to be plotted on the map.</p> required <code>lat</code> <code>array</code> <p>1-D array of latitude values for each data point.</p> required <code>lon</code> <code>array</code> <p>1-D array of longitude values for each data point.</p> required <code>fig</code> <code>Figure</code> <p>Existing figure to plot on. Defaults to None.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling, e.g., [25, 75] for interquartile range. Defaults to None.</p> <code>None</code> <code>value_range</code> <code>list</code> <p>Explicit value range for color scaling. Takes precedence over pertile_range. Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 8).</p> <code>(8, 8)</code> <code>need_colorbar</code> <code>bool</code> <p>Whether to add a colorbar. Defaults to True.</p> <code>True</code> <code>colorbar_size</code> <code>list</code> <p>Colorbar dimensions [left, bottom, width, height]. Defaults to [0.91, 0.318, 0.02, 0.354].</p> <code>[0.91, 0.318, 0.02, 0.354]</code> <code>cmap_str</code> <code>str</code> <p>Colormap name. Defaults to \"jet\".</p> <code>'jet'</code> <code>idx_lst</code> <code>list</code> <p>List of index arrays for plotting multiple point categories. Defaults to None.</p> <code>None</code> <code>markers</code> <code>list</code> <p>Marker styles for each category. Defaults to None.</p> <code>None</code> <code>marker_size</code> <code>Union[int, list]</code> <p>Size(s) of markers. Defaults to 20.</p> <code>20</code> <code>is_discrete</code> <code>bool</code> <p>If True, uses discrete colors with legend instead of continuous colorbar. Defaults to False.</p> <code>False</code> <code>colors</code> <code>str</code> <p>Color characters for discrete categories. Defaults to \"rbkgcmywrbkgcmyw\".</p> <code>'rbkgcmywrbkgcmyw'</code> <code>category_names</code> <code>list</code> <p>Names for discrete categories in legend. Defaults to None.</p> <code>None</code> <code>legend_font_size</code> <code>float</code> <p>Font size for legend. Defaults to None.</p> <code>None</code> <code>colorbar_font_size</code> <code>float</code> <p>Font size for colorbar. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the map.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple continuous color map\n&gt;&gt;&gt; data = np.random.rand(100)\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     value_range=[0, 1],\n...     cmap_str='viridis'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Discrete categories with custom markers\n&gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n&gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     idx_lst=idx_lst,\n...     markers=['o', 's', '^'],\n...     is_discrete=True,\n...     category_names=['Low', 'Medium', 'High']\n... )\n</code></pre> Notes <ul> <li>Uses Cartopy for map projections and features</li> <li>Automatically adds state boundaries and coastlines</li> <li>Supports both continuous and categorical data visualization</li> <li>Handles NaN values appropriately</li> <li>Provides flexible control over color scaling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_map_carto(\n    data,\n    lat,\n    lon,\n    fig=None,\n    ax=None,\n    pertile_range=None,\n    value_range=None,\n    fig_size=(8, 8),\n    need_colorbar=True,\n    colorbar_size=[0.91, 0.318, 0.02, 0.354],\n    cmap_str=\"jet\",\n    idx_lst=None,\n    markers=None,\n    marker_size=20,\n    is_discrete=False,\n    colors=\"rbkgcmywrbkgcmyw\",\n    category_names=None,\n    legend_font_size=None,\n    colorbar_font_size=None,\n):\n    \"\"\"Creates a cartographic map visualization using Cartopy with extensive customization options.\n\n    This function generates a map visualization for spatial data with support for continuous\n    and discrete color scales, multiple marker types, and various styling options. It's\n    particularly useful for visualizing hydrological data in a geographic context.\n\n    Args:\n        data (np.array): 1-D array of values to be plotted on the map.\n        lat (np.array): 1-D array of latitude values for each data point.\n        lon (np.array): 1-D array of longitude values for each data point.\n        fig (matplotlib.figure.Figure, optional): Existing figure to plot on.\n            Defaults to None.\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        pertile_range (list, optional): Percentile range for color scaling, e.g.,\n            [25, 75] for interquartile range. Defaults to None.\n        value_range (list, optional): Explicit value range for color scaling. Takes\n            precedence over pertile_range. Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 8).\n        need_colorbar (bool, optional): Whether to add a colorbar. Defaults to True.\n        colorbar_size (list, optional): Colorbar dimensions [left, bottom, width, height].\n            Defaults to [0.91, 0.318, 0.02, 0.354].\n        cmap_str (str, optional): Colormap name. Defaults to \"jet\".\n        idx_lst (list, optional): List of index arrays for plotting multiple point\n            categories. Defaults to None.\n        markers (list, optional): Marker styles for each category. Defaults to None.\n        marker_size (Union[int, list], optional): Size(s) of markers. Defaults to 20.\n        is_discrete (bool, optional): If True, uses discrete colors with legend instead\n            of continuous colorbar. Defaults to False.\n        colors (str, optional): Color characters for discrete categories.\n            Defaults to \"rbkgcmywrbkgcmyw\".\n        category_names (list, optional): Names for discrete categories in legend.\n            Defaults to None.\n        legend_font_size (float, optional): Font size for legend. Defaults to None.\n        colorbar_font_size (float, optional): Font size for colorbar. Defaults to None.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the map.\n\n    Examples:\n        &gt;&gt;&gt; # Simple continuous color map\n        &gt;&gt;&gt; data = np.random.rand(100)\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     value_range=[0, 1],\n        ...     cmap_str='viridis'\n        ... )\n\n        &gt;&gt;&gt; # Discrete categories with custom markers\n        &gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n        &gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     idx_lst=idx_lst,\n        ...     markers=['o', 's', '^'],\n        ...     is_discrete=True,\n        ...     category_names=['Low', 'Medium', 'High']\n        ... )\n\n    Notes:\n        - Uses Cartopy for map projections and features\n        - Automatically adds state boundaries and coastlines\n        - Supports both continuous and categorical data visualization\n        - Handles NaN values appropriately\n        - Provides flexible control over color scaling\n    \"\"\"\n    if value_range is not None:\n        vmin = value_range[0]\n        vmax = value_range[1]\n    elif pertile_range is None:\n        # https://blog.csdn.net/chenirene510/article/details/111318539\n        mask_data = np.ma.masked_invalid(data)\n        vmin = np.min(mask_data)\n        vmax = np.max(mask_data)\n    else:\n        assert 0 &lt;= pertile_range[0] &lt; pertile_range[1] &lt;= 100\n        vmin = np.nanpercentile(data, pertile_range[0])\n        vmax = np.nanpercentile(data, pertile_range[1])\n    llcrnrlat = (np.min(lat),)\n    urcrnrlat = (np.max(lat),)\n    llcrnrlon = (np.min(lon),)\n    urcrnrlon = (np.max(lon),)\n    extent = [llcrnrlon[0], urcrnrlon[0], llcrnrlat[0], urcrnrlat[0]]\n    # Figure\n    if fig is None or ax is None:\n        fig, ax = plt.subplots(\n            1, 1, figsize=fig_size, subplot_kw={\"projection\": ccrs.PlateCarree()}\n        )\n    ax.set_extent(extent)\n    states = NaturalEarthFeature(\n        category=\"cultural\",\n        scale=\"50m\",\n        facecolor=\"none\",\n        name=\"admin_1_states_provinces_shp\",\n    )\n    ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n    ax.coastlines(\"50m\", linewidth=0.8)\n    if idx_lst is not None:\n        if isinstance(marker_size, list):\n            assert len(marker_size) == len(idx_lst)\n        else:\n            marker_size = np.full(len(idx_lst), marker_size).tolist()\n        if not isinstance(marker_size, list):\n            markers = np.full(len(idx_lst), markers).tolist()\n        else:\n            assert len(markers) == len(idx_lst)\n        if not isinstance(cmap_str, list):\n            cmap_str = np.full(len(idx_lst), cmap_str).tolist()\n        else:\n            assert len(cmap_str) == len(idx_lst)\n        if is_discrete:\n            for i in range(len(idx_lst)):\n                ax.plot(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    marker=markers[i],\n                    ms=marker_size[i],\n                    label=category_names[i],\n                    c=colors[i],\n                    linestyle=\"\",\n                )\n                ax.legend(prop=dict(size=legend_font_size))\n        else:\n            scatter = []\n            for i in range(len(idx_lst)):\n                scat = ax.scatter(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    c=data[idx_lst[i]],\n                    marker=markers[i],\n                    s=marker_size[i],\n                    cmap=cmap_str[i],\n                    vmin=vmin,\n                    vmax=vmax,\n                )\n                scatter.append(scat)\n            if need_colorbar:\n                if colorbar_size is not None:\n                    cbar_ax = fig.add_axes(colorbar_size)\n                    cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n                else:\n                    cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n                if colorbar_font_size is not None:\n                    cbar.ax.tick_params(labelsize=colorbar_font_size)\n            if category_names is not None:\n                ax.legend(\n                    scatter, category_names, prop=dict(size=legend_font_size), ncol=2\n                )\n    elif is_discrete:\n        scatter = ax.scatter(lon, lat, c=data, s=marker_size)\n        # produce a legend with the unique colors from the scatter\n        legend1 = ax.legend(\n            *scatter.legend_elements(), loc=\"lower left\", title=\"Classes\"\n        )\n        ax.add_artist(legend1)\n    else:\n        scat = plt.scatter(\n            lon, lat, c=data, s=marker_size, cmap=cmap_str, vmin=vmin, vmax=vmax\n        )\n        if need_colorbar:\n            if colorbar_size is not None:\n                cbar_ax = fig.add_axes(colorbar_size)\n                cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n            else:\n                cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n            if colorbar_font_size is not None:\n                cbar.ax.tick_params(labelsize=colorbar_font_size)\n    return ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_pdf_cdf","title":"<code>plot_pdf_cdf(mydataframe, mycolumn)</code>","text":"<p>Creates side-by-side plots of probability density function (PDF) and cumulative distribution function (CDF).</p> <p>This function generates a figure with two subplots: a PDF plot on the left and a CDF plot on the right. The PDF includes both histogram and kernel density estimation, while the CDF shows the cumulative histogram.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create distributions for.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'values': np.concatenate([\n...         np.random.normal(0.3, 0.1, 1000),\n...         np.random.normal(0.7, 0.1, 1000)\n...     ])\n... })\n&gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n</code></pre> Notes <ul> <li>Uses seaborn's distplot for both PDF and CDF</li> <li>PDF includes both histogram and kernel density estimation</li> <li>CDF shows cumulative histogram with step-style line</li> <li>Both plots are set to range [0, 1] on x-axis</li> <li>CDF y-axis is also set to range [0, 1]</li> <li>High DPI (320) for publication-quality figures</li> <li>Large figure size (18x6) for clear visualization</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_pdf_cdf(mydataframe, mycolumn):\n    \"\"\"Creates side-by-side plots of probability density function (PDF) and cumulative\n    distribution function (CDF).\n\n    This function generates a figure with two subplots: a PDF plot on the left and\n    a CDF plot on the right. The PDF includes both histogram and kernel density\n    estimation, while the CDF shows the cumulative histogram.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create distributions for.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; df = pd.DataFrame({\n        ...     'values': np.concatenate([\n        ...         np.random.normal(0.3, 0.1, 1000),\n        ...         np.random.normal(0.7, 0.1, 1000)\n        ...     ])\n        ... })\n        &gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n\n    Notes:\n        - Uses seaborn's distplot for both PDF and CDF\n        - PDF includes both histogram and kernel density estimation\n        - CDF shows cumulative histogram with step-style line\n        - Both plots are set to range [0, 1] on x-axis\n        - CDF y-axis is also set to range [0, 1]\n        - High DPI (320) for publication-quality figures\n        - Large figure size (18x6) for clear visualization\n    \"\"\"\n    # settings\n    f, axes = plt.subplots(1, 2, figsize=(18, 6), dpi=320)\n    axes[0].set_ylabel(\"fraction (PDF)\")\n    axes[1].set_ylabel(\"fraction (CDF)\")\n\n    # left plot (PDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=True,\n        axlabel=mycolumn,\n        hist_kws={\"density\": True},\n        ax=axes[0],\n    ).set(xlim=(0, 1))\n\n    # right plot (CDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=False,\n        axlabel=mycolumn,\n        hist_kws={\n            \"density\": True,\n            \"cumulative\": True,\n            \"histtype\": \"step\",\n            \"linewidth\": 4,\n        },\n        ax=axes[1],\n    ).set(xlim=(0, 1), ylim=(0, 1))\n    plt.show()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_quiver","title":"<code>plot_quiver(exps_q_ssm_result_show, exps_ssm_q_result_show, q_diff_show, ssm_diff_show, x_label, y_label)</code>","text":"<p>Creates a quiver plot showing vector field with normalized arrows.</p> <p>This function generates a quiver plot where arrows represent the direction and magnitude of differences between two variables. The arrows are normalized to have uniform length, with color indicating the actual magnitude of the difference.</p> <p>Parameters:</p> Name Type Description Default <code>exps_q_ssm_result_show</code> <code>array</code> <p>X-coordinates for arrow origins.</p> required <code>exps_ssm_q_result_show</code> <code>array</code> <p>Y-coordinates for arrow origins.</p> required <code>q_diff_show</code> <code>array</code> <p>X-components of the difference vectors.</p> required <code>ssm_diff_show</code> <code>array</code> <p>Y-components of the difference vectors.</p> required <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the quiver plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; x = np.random.rand(50)\n&gt;&gt;&gt; y = np.random.rand(50)\n&gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; fig, ax = plot_quiver(\n...     x, y, dx, dy,\n...     'X Variable',\n...     'Y Variable'\n... )\n</code></pre> Notes <ul> <li>Arrows are normalized to uniform length for better visualization</li> <li>Color indicates the actual magnitude of the difference vector</li> <li>Plot includes a colorbar showing the magnitude scale</li> <li>Uses clean plotting style with minimal spines</li> <li>Default plot range is [0, 1] for both axes</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_quiver(\n    exps_q_ssm_result_show,\n    exps_ssm_q_result_show,\n    q_diff_show,\n    ssm_diff_show,\n    x_label,\n    y_label,\n):\n    \"\"\"Creates a quiver plot showing vector field with normalized arrows.\n\n    This function generates a quiver plot where arrows represent the direction and\n    magnitude of differences between two variables. The arrows are normalized to have\n    uniform length, with color indicating the actual magnitude of the difference.\n\n    Args:\n        exps_q_ssm_result_show (np.array): X-coordinates for arrow origins.\n        exps_ssm_q_result_show (np.array): Y-coordinates for arrow origins.\n        q_diff_show (np.array): X-components of the difference vectors.\n        ssm_diff_show (np.array): Y-components of the difference vectors.\n        x_label (str): Label for x-axis.\n        y_label (str): Label for y-axis.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the quiver plot.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; x = np.random.rand(50)\n        &gt;&gt;&gt; y = np.random.rand(50)\n        &gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; fig, ax = plot_quiver(\n        ...     x, y, dx, dy,\n        ...     'X Variable',\n        ...     'Y Variable'\n        ... )\n\n    Notes:\n        - Arrows are normalized to uniform length for better visualization\n        - Color indicates the actual magnitude of the difference vector\n        - Plot includes a colorbar showing the magnitude scale\n        - Uses clean plotting style with minimal spines\n        - Default plot range is [0, 1] for both axes\n    \"\"\"\n    fig, ax = plt.subplots()\n    color = np.sqrt(q_diff_show**2 + ssm_diff_show**2)\n    # normalize to get same length arrows\n    r = np.power(np.add(np.power(q_diff_show, 2), np.power(ssm_diff_show, 2)), 0.5)\n    plt.quiver(\n        exps_q_ssm_result_show,\n        exps_ssm_q_result_show,\n        q_diff_show / r,\n        ssm_diff_show / r,\n        color,\n        scale=25,\n        width=0.005,\n    )\n    # Defining color\n    plt.xlim(-0.01, 1)\n    plt.ylim(-0.01, 1)\n    plt.colorbar()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.xlabel(x_label, fontsize=18)\n    plt.ylabel(y_label, fontsize=18)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_rainfall_runoff","title":"<code>plot_rainfall_runoff(t, p, qs, fig_size=(8, 6), c_lst='rbkgcmy', leg_lst=None, dash_lines=None, title=None, xlabel=None, ylabel=None, prcp_ylabel='prcp(mm/day)', linewidth=1, prcp_interval=20)</code>","text":"<p>Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.</p> <p>This function generates a dual-axis plot showing precipitation as inverted bars from the top and streamflow as lines on the bottom. This is a common visualization in hydrology for analyzing rainfall-runoff relationships.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Union[array, List[array]]</code> <p>Time values. If multiple streamflow series are provided, t can be a list of time arrays matching qs.</p> required <code>p</code> <code>array</code> <p>Precipitation time series data in mm/day.</p> required <code>qs</code> <code>Union[array, List[array]]</code> <p>Streamflow time series data. Can be a single array or list of arrays for multiple streamflow series.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>c_lst</code> <code>str</code> <p>String of color characters for streamflow lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels for streamflow series. Defaults to None.</p> <code>None</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which streamflow lines should be dashed. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>X-axis label. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to None.</p> <code>None</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <code>linewidth</code> <code>int</code> <p>Width of streamflow lines. Defaults to 1.</p> <code>1</code> <code>prcp_interval</code> <code>int</code> <p>Interval for precipitation y-axis ticks. Defaults to 20.</p> <code>20</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple rainfall-runoff plot\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, q,\n...     title='Rainfall-Runoff Analysis',\n...     xlabel='Date',\n...     ylabel='Streamflow (m\u00b3/s)'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple streamflow series\n&gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, qs,\n...     leg_lst=['Observed', 'Simulated'],\n...     dash_lines=[False, True]\n... )\n</code></pre> Notes <ul> <li>Precipitation is plotted as blue bars from the top of the plot</li> <li>Streamflow is plotted as lines on the bottom</li> <li>The precipitation y-axis is inverted for better visualization</li> <li>Grid lines are added automatically</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff(\n    t,\n    p,\n    qs,\n    fig_size=(8, 6),\n    c_lst=\"rbkgcmy\",\n    leg_lst=None,\n    dash_lines=None,\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    prcp_ylabel=\"prcp(mm/day)\",\n    linewidth=1,\n    prcp_interval=20,\n):\n    \"\"\"Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.\n\n    This function generates a dual-axis plot showing precipitation as inverted bars from\n    the top and streamflow as lines on the bottom. This is a common visualization in\n    hydrology for analyzing rainfall-runoff relationships.\n\n    Args:\n        t (Union[np.array, List[np.array]]): Time values. If multiple streamflow series\n            are provided, t can be a list of time arrays matching qs.\n        p (np.array): Precipitation time series data in mm/day.\n        qs (Union[np.array, List[np.array]]): Streamflow time series data. Can be a\n            single array or list of arrays for multiple streamflow series.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        c_lst (str, optional): String of color characters for streamflow lines.\n            Defaults to \"rbkgcmy\".\n        leg_lst (list, optional): Legend labels for streamflow series. Defaults to None.\n        dash_lines (list[bool], optional): Specifies which streamflow lines should be\n            dashed. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n        xlabel (str, optional): X-axis label. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to None.\n        prcp_ylabel (str, optional): Y-axis label for precipitation. Defaults to\n            \"prcp(mm/day)\".\n        linewidth (int, optional): Width of streamflow lines. Defaults to 1.\n        prcp_interval (int, optional): Interval for precipitation y-axis ticks.\n            Defaults to 20.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the plot.\n\n    Examples:\n        &gt;&gt;&gt; # Simple rainfall-runoff plot\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, q,\n        ...     title='Rainfall-Runoff Analysis',\n        ...     xlabel='Date',\n        ...     ylabel='Streamflow (m\u00b3/s)'\n        ... )\n\n        &gt;&gt;&gt; # Multiple streamflow series\n        &gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, qs,\n        ...     leg_lst=['Observed', 'Simulated'],\n        ...     dash_lines=[False, True]\n        ... )\n\n    Notes:\n        - Precipitation is plotted as blue bars from the top of the plot\n        - Streamflow is plotted as lines on the bottom\n        - The precipitation y-axis is inverted for better visualization\n        - Grid lines are added automatically\n    \"\"\"\n    fig, ax = plt.subplots(figsize=fig_size)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(qs), False).tolist()\n    for k in range(len(qs)):\n        tt = t[k] if type(t) is list else t\n        q = qs[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        (line_i,) = ax.plot(tt, q, color=c_lst[k], label=leg_str, linewidth=linewidth)\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    ax.set_ylim(ax.get_ylim()[0], ax.get_ylim()[1] * 1.2)\n    # Create second axes, in order to get the bars from the top you can multiply by -1\n    ax2 = ax.twinx()\n    # ax2.bar(tt, -p, color=\"b\")\n    ax2.fill_between(tt, 0, -p, step=\"mid\", color=\"b\", alpha=0.5)\n    # ax2.plot(tt, -p, color=\"b\", alpha=0.7, linewidth=1.5)\n\n    # Now need to fix the axis labels\n    # max_pre = max(p)\n    max_pre = p.max().item()\n    ax2.set_ylim(-max_pre * 5, 0)\n    y2_ticks = np.arange(0, max_pre, prcp_interval)\n    y2_ticklabels = [str(i) for i in y2_ticks]\n    ax2.set_yticks(-1 * y2_ticks)\n    ax2.set_yticklabels(y2_ticklabels, fontsize=16)\n    # ax2.set_yticklabels([lab.get_text()[1:] for lab in ax2.get_yticklabels()])\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    if ylabel is not None:\n        ax.set_ylabel(ylabel, fontsize=18)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel, fontsize=18)\n    ax2.set_ylabel(prcp_ylabel, fontsize=8, loc=\"top\")\n    # ax2.set_ylabel(\"precipitation (mm/day)\", fontsize=12, loc='top')\n    # https://github.com/matplotlib/matplotlib/issues/12318\n    ax.tick_params(axis=\"x\", labelsize=16)\n    ax.tick_params(axis=\"y\", labelsize=16)\n    ax.legend(bbox_to_anchor=(0.01, 0.85), loc=\"upper left\", fontsize=16)\n    ax.grid()\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_rainfall_runoff_chai","title":"<code>plot_rainfall_runoff_chai(t, ps, qs, c_lst='rbkgcmy', title='Observation of Precipitation and Streamflow', alpha_lst=None, p_labels=None, q_labels=None)</code>","text":"<p>Creates a two-panel rainfall-runoff plot following Chai's style.</p> <p>This function generates a figure with two vertically stacked panels: precipitation on top and streamflow below. It supports multiple precipitation sources and streamflow series with customizable styling.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>ps</code> <code>list[array]</code> <p>List of precipitation arrays from different sources.</p> required <code>qs</code> <code>list[array]</code> <p>List of streamflow arrays (e.g., observed and simulated).</p> required <code>c_lst</code> <code>str</code> <p>String of color characters. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>title</code> <code>str</code> <p>Figure title. Defaults to \"Observation of Precipitation and Streamflow\".</p> <code>'Observation of Precipitation and Streamflow'</code> <code>alpha_lst</code> <code>list[float]</code> <p>Transparency values for each series. Defaults to [0.5, 0.5].</p> <code>None</code> <code>p_labels</code> <code>list[str]</code> <p>Labels for precipitation sources. Defaults to [\"era5land\", \"gauge\"].</p> <code>None</code> <code>q_labels</code> <code>list[str]</code> <p>Labels for streamflow series. Defaults to [\"observation\", \"simulation\"].</p> <code>None</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom axes (streamflow plot).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n&gt;&gt;&gt; # Two precipitation sources\n&gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n&gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n&gt;&gt;&gt; # Observed and simulated streamflow\n&gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n&gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n&gt;&gt;&gt; \n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n...     t, [p1, p2], [q_obs, q_sim],\n...     title='2020 Rainfall-Runoff Comparison',\n...     p_labels=['ERA5', 'Rain Gauge'],\n...     q_labels=['Observed', 'Simulated']\n... )\n</code></pre> Notes <ul> <li>Top panel shows precipitation with bars</li> <li>Bottom panel shows streamflow with lines</li> <li>Precipitation y-axis is inverted and blue</li> <li>Streamflow y-axis is red</li> <li>Both panels share x-axis limits</li> <li>Legends included for both panels</li> <li>Uses large figure size (20x8) by default</li> <li>Includes \"Streamflow\" text box in bottom panel</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_chai(\n    t,\n    ps,\n    qs,\n    c_lst=\"rbkgcmy\",\n    title=\"Observation of Precipitation and Streamflow\",\n    alpha_lst=None,\n    p_labels=None,\n    q_labels=None,\n):\n    \"\"\"Creates a two-panel rainfall-runoff plot following Chai's style.\n\n    This function generates a figure with two vertically stacked panels: precipitation\n    on top and streamflow below. It supports multiple precipitation sources and\n    streamflow series with customizable styling.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        ps (list[np.array]): List of precipitation arrays from different sources.\n        qs (list[np.array]): List of streamflow arrays (e.g., observed and simulated).\n        c_lst (str, optional): String of color characters. Defaults to \"rbkgcmy\".\n        title (str, optional): Figure title. Defaults to \"Observation of Precipitation\n            and Streamflow\".\n        alpha_lst (list[float], optional): Transparency values for each series.\n            Defaults to [0.5, 0.5].\n        p_labels (list[str], optional): Labels for precipitation sources.\n            Defaults to [\"era5land\", \"gauge\"].\n        q_labels (list[str], optional): Labels for streamflow series.\n            Defaults to [\"observation\", \"simulation\"].\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom\n            axes (streamflow plot).\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n        &gt;&gt;&gt; # Two precipitation sources\n        &gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n        &gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n        &gt;&gt;&gt; # Observed and simulated streamflow\n        &gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n        &gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n        ...     t, [p1, p2], [q_obs, q_sim],\n        ...     title='2020 Rainfall-Runoff Comparison',\n        ...     p_labels=['ERA5', 'Rain Gauge'],\n        ...     q_labels=['Observed', 'Simulated']\n        ... )\n\n    Notes:\n        - Top panel shows precipitation with bars\n        - Bottom panel shows streamflow with lines\n        - Precipitation y-axis is inverted and blue\n        - Streamflow y-axis is red\n        - Both panels share x-axis limits\n        - Legends included for both panels\n        - Uses large figure size (20x8) by default\n        - Includes \"Streamflow\" text box in bottom panel\n    \"\"\"\n    if alpha_lst is None:\n        alpha_lst = [0.5, 0.5]\n    if p_labels is None:\n        p_labels = [\"era5land\", \"gauge\"]\n    if q_labels is None:\n        q_labels = [\"observation\", \"simulation\"]\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 8))\n    fig.suptitle(title, fontsize=16)\n    for i, p in enumerate(ps):\n        ax1.bar(\n            t,\n            p,\n            color=c_lst[i],\n            label=p_labels[i],\n            width=0.9,\n            alpha=alpha_lst[i],\n        )\n    ax1.set_xlabel(\"Time\")\n    ax1.set_ylabel(\"Precipitation (mm/d)\", color=\"b\")\n    ax1.invert_yaxis()\n    ax1.tick_params(axis=\"y\", labelcolor=\"b\")\n    ax1.legend()\n\n    for j, q in enumerate(qs):\n        ax2.plot(t, q, color=c_lst[j], label=q_labels[j], alpha=alpha_lst[j])\n    ax2.set_xlabel(\"Time\")\n    ax2.set_ylabel(\"Streamflow (m$^3$/s)\", color=\"r\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"r\")\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.text(\n        0.05,\n        0.95,\n        \"Streamflow\",\n        transform=ax2.transAxes,\n        fontsize=12,\n        verticalalignment=\"top\",\n        bbox=dict(facecolor=\"white\", alpha=0.5),\n    )\n    ax2.legend()\n\n    fig.tight_layout()\n    return fig, ax2\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_rainfall_runoff_xu","title":"<code>plot_rainfall_runoff_xu(t, p, qs, fig_size=(10, 6), title='prcp-streamflow', leg_lst=None, ylabel='streamflow(m^3/s)', prcp_ylabel='prcp(mm/day)')</code>","text":"<p>Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.</p> <p>This function generates a specialized plot with precipitation bars from the top and streamflow lines on the bottom, following Xu's visualization style. It uses dual y-axes with color-coded labels and ticks.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>p</code> <code>array</code> <p>Precipitation values.</p> required <code>qs</code> <code>tuple</code> <p>Tuple of (observed, predicted) streamflow values.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (10, 6).</p> <code>(10, 6)</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to \"prcp-streamflow\".</p> <code>'prcp-streamflow'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".</p> <code>'streamflow(m^3/s)'</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n&gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n&gt;&gt;&gt; plot_rainfall_runoff_xu(\n...     t, p, (obs, pred),\n...     title='2020 Rainfall-Runoff Analysis'\n... )\n</code></pre> Notes <ul> <li>Precipitation shown as blue bars from top</li> <li>Observed streamflow as solid green line</li> <li>Predicted streamflow as dashed red line</li> <li>Y-axes labels and ticks color-coded</li> <li>Precipitation axis inverted</li> <li>Legend positioned at upper left</li> <li>Precipitation bars semi-transparent (alpha=0.6)</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_xu(\n    t,\n    p,\n    qs,\n    fig_size=(10, 6),\n    title=\"prcp-streamflow\",\n    leg_lst=None,\n    ylabel=\"streamflow(m^3/s)\",\n    prcp_ylabel=\"prcp(mm/day)\",\n):\n    \"\"\"Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.\n\n    This function generates a specialized plot with precipitation bars from the top\n    and streamflow lines on the bottom, following Xu's visualization style. It uses\n    dual y-axes with color-coded labels and ticks.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        p (np.array): Precipitation values.\n        qs (tuple): Tuple of (observed, predicted) streamflow values.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (10, 6).\n        title (str, optional): Plot title. Defaults to \"prcp-streamflow\".\n        leg_lst (list, optional): Legend labels. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".\n        prcp_ylabel (str, optional): Y-axis label for precipitation.\n            Defaults to \"prcp(mm/day)\".\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n        &gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n        &gt;&gt;&gt; plot_rainfall_runoff_xu(\n        ...     t, p, (obs, pred),\n        ...     title='2020 Rainfall-Runoff Analysis'\n        ... )\n\n    Notes:\n        - Precipitation shown as blue bars from top\n        - Observed streamflow as solid green line\n        - Predicted streamflow as dashed red line\n        - Y-axes labels and ticks color-coded\n        - Precipitation axis inverted\n        - Legend positioned at upper left\n        - Precipitation bars semi-transparent (alpha=0.6)\n    \"\"\"\n    obs, pred = qs\n\n    fig, ax1 = plt.subplots(figsize=fig_size)\n\n    ax1.bar(t, p, width=0.1, color=\"blue\", alpha=0.6, label=\"Precipitation\")\n    ax1.set_ylabel(prcp_ylabel, color=\"blue\")\n    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n\n    ax1.set_ylim(0, p.max() * 5)\n    ax1.invert_yaxis()\n\n    ax2 = ax1.twinx()\n\n    # transform the unit of obs and pred\n    ax2.plot(\n        t,\n        obs,\n        color=\"green\",\n        linestyle=\"-\",\n        label=\"observed value\",\n    )\n    ax2.plot(\n        t,\n        pred,\n        color=\"red\",\n        linestyle=\"--\",\n        label=\"predicted value\",\n    )\n\n    ax2.set_ylabel(ylabel, color=\"red\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n\n    plt.title(title)\n\n    plt.legend(loc=\"upper left\")\n    return fig, (ax1, ax2)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_scatter_with_11line","title":"<code>plot_scatter_with_11line(x, y, point_color='blue', line_color='black', xlim=[0.0, 1.0], ylim=[0.0, 1.0], xlabel=None, ylabel=None)</code>","text":"<p>Creates a scatter plot comparing two variables with a 1:1 line.</p> <p>This function generates a scatter plot with a 1:1 line (diagonal) for comparing two variables, commonly used in model evaluation to compare observed vs predicted values. The plot includes customizable colors, axis limits, and labels.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array</code> <p>First variable to be plotted (typically observed values).</p> required <code>y</code> <code>array</code> <p>Second variable to be plotted (typically predicted values).</p> required <code>point_color</code> <code>str</code> <p>Color of scatter points. Defaults to \"blue\".</p> <code>'blue'</code> <code>line_color</code> <code>str</code> <p>Color of the 1:1 line. Defaults to \"black\".</p> <code>'black'</code> <code>xlim</code> <code>list</code> <p>X-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>ylim</code> <code>list</code> <p>Y-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>xlabel</code> <code>str</code> <p>Label for x-axis. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Label for y-axis. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]:  A tuple containing the figure and axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n&gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n...     obs, pred,\n...     xlabel='Observed',\n...     ylabel='Predicted',\n...     xlim=[0, 6],\n...     ylim=[0, 6]\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_with_11line(\n    x: np.array,\n    y: np.array,\n    point_color=\"blue\",\n    line_color=\"black\",\n    xlim=[0.0, 1.0],\n    ylim=[0.0, 1.0],\n    xlabel=None,\n    ylabel=None,\n):\n    \"\"\"Creates a scatter plot comparing two variables with a 1:1 line.\n\n    This function generates a scatter plot with a 1:1 line (diagonal) for comparing\n    two variables, commonly used in model evaluation to compare observed vs predicted values.\n    The plot includes customizable colors, axis limits, and labels.\n\n    Args:\n        x (np.array): First variable to be plotted (typically observed values).\n        y (np.array): Second variable to be plotted (typically predicted values).\n        point_color (str, optional): Color of scatter points. Defaults to \"blue\".\n        line_color (str, optional): Color of the 1:1 line. Defaults to \"black\".\n        xlim (list, optional): X-axis range as [min, max]. Defaults to [0.0, 1.0].\n        ylim (list, optional): Y-axis range as [min, max]. Defaults to [0.0, 1.0].\n        xlabel (str, optional): Label for x-axis. Defaults to None.\n        ylabel (str, optional): Label for y-axis. Defaults to None.\n\n    Returns:\n        tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: \n            A tuple containing the figure and axes objects.\n\n    Examples:\n        &gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n        &gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n        &gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n        ...     obs, pred,\n        ...     xlabel='Observed',\n        ...     ylabel='Predicted',\n        ...     xlim=[0, 6],\n        ...     ylim=[0, 6]\n        ... )\n    \"\"\"\n    fig, ax = plt.subplots()\n    # set background color for ax\n    ax.set_facecolor(\"whitesmoke\")\n    # plot the grid of the figure\n    # plt.grid(color=\"whitesmoke\")\n    ax.scatter(x, y, c=point_color, s=10)\n    line = mlines.Line2D([0, 1], [0, 1], color=line_color, linestyle=\"--\")\n    transform = ax.transAxes\n    line.set_transform(transform)\n    ax.add_line(line)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    plt.xticks(np.arange(xlim[0], xlim[1], 0.1), fontsize=16)\n    plt.yticks(np.arange(ylim[0], ylim[1], 0.1), fontsize=16)\n    # set xlable and ylabel\n    if xlabel is not None:\n        plt.xlabel(xlabel, fontsize=16)\n    if ylabel is not None:\n        plt.ylabel(ylabel, fontsize=16)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_scatter_xyc","title":"<code>plot_scatter_xyc(x_label, x, y_label, y, c_label=None, c=None, size=20, is_reg=False, xlim=None, ylim=None, quadrant=None)</code>","text":"<p>Creates a scatter plot with optional color mapping and quadrant analysis.</p> <p>This function generates a scatter plot with optional color mapping for points, regression line, and quadrant analysis. It's particularly useful for analyzing relationships between variables with an additional dimension represented by color.</p> <p>Parameters:</p> Name Type Description Default <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>x</code> <code>Union[array, List[array]]</code> <p>X-axis data values.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <code>y</code> <code>Union[array, List[array]]</code> <p>Y-axis data values.</p> required <code>c_label</code> <code>Union[str, List[str]]</code> <p>Label(s) for color mapping or multiple series. Defaults to None.</p> <code>None</code> <code>c</code> <code>Union[array, List[str]]</code> <p>Values for color mapping or colors for multiple series. Defaults to None.</p> <code>None</code> <code>size</code> <code>int</code> <p>Size of scatter points. Defaults to 20.</p> <code>20</code> <code>is_reg</code> <code>bool</code> <p>If True, adds regression line. Defaults to False.</p> <code>False</code> <code>xlim</code> <code>list</code> <p>X-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>quadrant</code> <code>list</code> <p>Reference points [x, y] for quadrant analysis. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple scatter plot\n&gt;&gt;&gt; x = np.random.rand(100)\n&gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X Values', x,\n...     'Y Values', y,\n...     is_reg=True\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Scatter plot with color mapping\n&gt;&gt;&gt; c = np.random.rand(100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     c_label='Z Values',\n...     c=c\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Quadrant analysis\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     quadrant=[0.5, 0.5],\n...     xlim=[0, 1],\n...     ylim=[0, 1]\n... )\n</code></pre> Notes <ul> <li>Supports both single and multiple series plotting</li> <li>Automatically handles NaN values</li> <li>Provides quadrant statistics when quadrant analysis is enabled</li> <li>Uses clean plotting style with minimal spines</li> <li>Supports regression line with seaborn's regplot</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_xyc(\n    x_label,\n    x,\n    y_label,\n    y,\n    c_label=None,\n    c=None,\n    size=20,\n    is_reg=False,\n    xlim=None,\n    ylim=None,\n    quadrant=None,\n):\n    \"\"\"Creates a scatter plot with optional color mapping and quadrant analysis.\n\n    This function generates a scatter plot with optional color mapping for points,\n    regression line, and quadrant analysis. It's particularly useful for analyzing\n    relationships between variables with an additional dimension represented by color.\n\n    Args:\n        x_label (str): Label for x-axis.\n        x (Union[np.array, List[np.array]]): X-axis data values.\n        y_label (str): Label for y-axis.\n        y (Union[np.array, List[np.array]]): Y-axis data values.\n        c_label (Union[str, List[str]], optional): Label(s) for color mapping or\n            multiple series. Defaults to None.\n        c (Union[np.array, List[str]], optional): Values for color mapping or\n            colors for multiple series. Defaults to None.\n        size (int, optional): Size of scatter points. Defaults to 20.\n        is_reg (bool, optional): If True, adds regression line. Defaults to False.\n        xlim (list, optional): X-axis limits as [min, max]. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        quadrant (list, optional): Reference points [x, y] for quadrant analysis.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Simple scatter plot\n        &gt;&gt;&gt; x = np.random.rand(100)\n        &gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X Values', x,\n        ...     'Y Values', y,\n        ...     is_reg=True\n        ... )\n\n        &gt;&gt;&gt; # Scatter plot with color mapping\n        &gt;&gt;&gt; c = np.random.rand(100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     c_label='Z Values',\n        ...     c=c\n        ... )\n\n        &gt;&gt;&gt; # Quadrant analysis\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     quadrant=[0.5, 0.5],\n        ...     xlim=[0, 1],\n        ...     ylim=[0, 1]\n        ... )\n\n    Notes:\n        - Supports both single and multiple series plotting\n        - Automatically handles NaN values\n        - Provides quadrant statistics when quadrant analysis is enabled\n        - Uses clean plotting style with minimal spines\n        - Supports regression line with seaborn's regplot\n    \"\"\"\n    fig, ax = plt.subplots()\n    if type(x) is list:\n        for i in range(len(x)):\n            ax.plot(\n                x[i], y[i], marker=\"o\", linestyle=\"\", ms=size, label=c_label[i], c=c[i]\n            )\n        ax.legend()\n\n    elif c is None:\n        df = pd.DataFrame({x_label: x, y_label: y})\n        points = plt.scatter(df[x_label], df[y_label], s=size)\n        if quadrant is not None:\n            plt.axvline(quadrant[0], c=\"grey\", lw=1, linestyle=\"--\")\n            plt.axhline(quadrant[1], c=\"grey\", lw=1, linestyle=\"--\")\n            q2 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q3 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q4 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q5 = df[(df[x_label] == 0) &amp; (df[y_label] == 0)].shape[0]\n            q1 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q = q1 + q2 + q3 + q4 + q5\n            r1 = int(round(q1 / q, 2) * 100)\n            r2 = int(round(q2 / q, 2) * 100)\n            r3 = int(round(q3 / q, 2) * 100)\n            r4 = int(round(q4 / q, 2) * 100)\n            r5 = 100 - r1 - r2 - r3 - r4\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r1}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r2}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r3}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r4}%\",\n                fontsize=16,\n            )\n            plt.text(0.2, 0.02, f\"{str(r5)}%\", fontsize=16)\n    else:\n        df = pd.DataFrame({x_label: x, y_label: y, c_label: c})\n        points = plt.scatter(\n            df[x_label], df[y_label], c=df[c_label], s=size, cmap=\"Spectral\"\n        )  # set style options\n        # add a color bar\n        plt.colorbar(points)\n\n    # set limits\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    # build the regression plot\n    if is_reg:\n        plot = sns.regplot(x_label, y_label, data=df, scatter=False)  # , color=\".1\"\n        plot = plot.set(xlabel=x_label, ylabel=y_label)  # add labels\n    else:\n        plt.xlabel(x_label, fontsize=18)\n        plt.ylabel(y_label, fontsize=18)\n        plt.xticks(fontsize=16)\n        plt.yticks(fontsize=16)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ts","title":"<code>plot_ts(t, y, ax=None, t_bar=None, title=None, xlabel=None, ylabel=None, fig_size=(12, 4), c_lst='rbkgcmyrbkgcmyrbkgcmy', leg_lst=None, marker_lst=None, linewidth=2, linespec=None, dash_lines=None, alpha=1)</code>","text":"<p>Plot time series for multi arrays with matplotlib</p>"},{"location":"api/hydroutils/#hydroutils.plot_ts--parameters","title":"Parameters","text":"<p>t : Union[list, np.array]     time series but not just date; it can also be numbers like 1, 2, 3, ... y : Union[list, np.array]     shown data series; the len of y should be equal to t's ax : type, optional     description, by default None t_bar : type, optional     description, by default None title : type, optional     description, by default None xlabel: str, optional     the name of x axis, by default None ylabel : str, optional     the name of y axis, by default None fig_size : tuple, optional     description, by default (12, 4) c_lst : str, optional     description, by default \"rbkgcmy\" leg_lst : type, optional     description, by default None marker_lst : type, optional     description, by default None linewidth : int, optional     description, by default 2 linespec : type, optional     description, by default None dash_lines : type, optional     if dash_line, then we will plot dashed line, by default None</p>"},{"location":"api/hydroutils/#hydroutils.plot_ts--returns","title":"Returns","text":"<p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts(\n    t: Union[list, np.array],\n    y: Union[list, np.array],\n    ax=None,\n    t_bar=None,\n    title=None,\n    xlabel: str = None,\n    ylabel: str = None,\n    fig_size=(12, 4),\n    c_lst=\"rbkgcmyrbkgcmyrbkgcmy\",\n    leg_lst=None,\n    marker_lst=None,\n    linewidth=2,\n    linespec=None,\n    dash_lines=None,\n    alpha=1,\n):\n    \"\"\"Plot time series for multi arrays with matplotlib\n\n    Parameters\n    ----------\n    t : Union[list, np.array]\n        time series but not just date; it can also be numbers like 1, 2, 3, ...\n    y : Union[list, np.array]\n        shown data series; the len of y should be equal to t's\n    ax : _type_, optional\n        _description_, by default None\n    t_bar : _type_, optional\n        _description_, by default None\n    title : _type_, optional\n        _description_, by default None\n    xlabel: str, optional\n        the name of x axis, by default None\n    ylabel : str, optional\n        the name of y axis, by default None\n    fig_size : tuple, optional\n        _description_, by default (12, 4)\n    c_lst : str, optional\n        _description_, by default \"rbkgcmy\"\n    leg_lst : _type_, optional\n        _description_, by default None\n    marker_lst : _type_, optional\n        _description_, by default None\n    linewidth : int, optional\n        _description_, by default 2\n    linespec : _type_, optional\n        _description_, by default None\n    dash_lines : _type_, optional\n        if dash_line, then we will plot dashed line, by default None\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    is_new_fig = False\n    if ax is None:\n        fig = plt.figure(figsize=fig_size)\n        ax = fig.subplots()\n        is_new_fig = True\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(t), False).tolist()\n        # dash_lines[-1] = True\n    if type(y) is np.ndarray:\n        y = [y]\n    if type(linewidth) is not list:\n        linewidth = [linewidth] * len(y)\n    if type(alpha) is not list:\n        alpha = [alpha] * len(y)\n    for k in range(len(y)):\n        tt = t[k] if type(t) is list else t\n        yy = y[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        if marker_lst is None:\n            (line_i,) = (\n                ax.plot(tt, yy, \"*\", color=c_lst[k], label=leg_str, alpha=alpha[k])\n                if True in np.isnan(yy)\n                else ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linewidth=linewidth[k],\n                    alpha=alpha[k],\n                )\n            )\n        elif marker_lst[k] == \"-\":\n            if linespec is not None:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linestyle=linespec[k],\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n            else:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n        else:\n            (line_i,) = ax.plot(\n                tt,\n                yy,\n                color=c_lst[k],\n                label=leg_str,\n                marker=marker_lst[k],\n                lw=linewidth[k],\n                alpha=alpha[k],\n            )\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n        if ylabel is not None:\n            ax.set_ylabel(ylabel, fontsize=18)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel, fontsize=18)\n    if t_bar is not None:\n        ylim = ax.get_ylim()\n        t_bar = [t_bar] if type(t_bar) is not list else t_bar\n        for tt in t_bar:\n            ax.plot([tt, tt], ylim, \"-k\")\n\n    if leg_lst is not None:\n        ax.legend(loc=\"upper right\", frameon=False)\n        plt.legend(prop={\"size\": 16})\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    # plot the grid of the figure\n    plt.grid()\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.tight_layout()\n    return (fig, ax) if is_new_fig else ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ts_map","title":"<code>plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None)</code>","text":"<p>Creates an interactive map with linked time series plots.</p> <p>This function generates a figure with two subplots: a map on top and a time series plot below. Clicking on a location in the map updates the time series plot to show data from the nearest site.</p> <p>Parameters:</p> Name Type Description Default <code>dataMap</code> <code>list</code> <p>Data values to be shown on the map.</p> required <code>dataTs</code> <code>list</code> <p>List of time series data for each site.</p> required <code>lat</code> <code>array</code> <p>Latitude values for each site.</p> required <code>lon</code> <code>array</code> <p>Longitude values for each site.</p> required <code>t</code> <code>list</code> <p>Time points for x-axis of time series.</p> required <code>sites_id</code> <code>list</code> <p>Identifiers for each site.</p> required <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling on map. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; n_sites = 10\n&gt;&gt;&gt; n_times = 100\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n&gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Generate sample time series for each site\n&gt;&gt;&gt; t = list(range(n_times))\n&gt;&gt;&gt; dataTs = []\n&gt;&gt;&gt; for i in range(n_sites):\n...     pred = np.sin(np.array(t)/10 + i/5)\n...     obs = pred + np.random.normal(0, 0.1, n_times)\n...     dataTs.append([pred, obs])\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Map data could be mean values\n&gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n&gt;&gt;&gt; \n&gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n</code></pre> Notes <ul> <li>Uses TkAgg backend for interactive display</li> <li>Map uses Cartopy for proper geographic projection</li> <li>Time series updates automatically on map click</li> <li>Shows site ID and coordinates in time series title</li> <li>Finds nearest site to click location</li> <li>Both predicted and observed values shown in time series</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None):\n    \"\"\"Creates an interactive map with linked time series plots.\n\n    This function generates a figure with two subplots: a map on top and a time series\n    plot below. Clicking on a location in the map updates the time series plot to show\n    data from the nearest site.\n\n    Args:\n        dataMap (list): Data values to be shown on the map.\n        dataTs (list): List of time series data for each site.\n        lat (np.array): Latitude values for each site.\n        lon (np.array): Longitude values for each site.\n        t (list): Time points for x-axis of time series.\n        sites_id (list): Identifiers for each site.\n        pertile_range (list, optional): Percentile range for color scaling on map.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; n_sites = 10\n        &gt;&gt;&gt; n_times = 100\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n        &gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Generate sample time series for each site\n        &gt;&gt;&gt; t = list(range(n_times))\n        &gt;&gt;&gt; dataTs = []\n        &gt;&gt;&gt; for i in range(n_sites):\n        ...     pred = np.sin(np.array(t)/10 + i/5)\n        ...     obs = pred + np.random.normal(0, 0.1, n_times)\n        ...     dataTs.append([pred, obs])\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Map data could be mean values\n        &gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n\n    Notes:\n        - Uses TkAgg backend for interactive display\n        - Map uses Cartopy for proper geographic projection\n        - Time series updates automatically on map click\n        - Shows site ID and coordinates in time series title\n        - Finds nearest site to click location\n        - Both predicted and observed values shown in time series\n    \"\"\"\n    # show the map in a pop-up window\n    matplotlib.use(\"TkAgg\")\n    assert isinstance(dataMap, list)\n    assert isinstance(dataTs, list)\n    # setup axes\n    fig = plt.figure(figsize=(8, 8), dpi=100)\n    gs = gridspec.GridSpec(2, 1)\n    # plt.subplots_adjust(left=0.13, right=0.89, bottom=0.05)\n    # plot maps\n    ax1 = plt.subplot(gs[0], projection=ccrs.PlateCarree())\n    ax1 = plot_map_carto(\n        dataMap, lat=lat, lon=lon, fig=fig, ax=ax1, pertile_range=pertile_range\n    )\n    # line plot\n    ax2 = plt.subplot(gs[1])\n\n    # plot ts\n    def onclick(event):\n        print(\"click event\")\n        # refresh the ax2, then new ts data can be showed without previous one\n        ax2.cla()\n        xClick = event.xdata\n        yClick = event.ydata\n        d = np.sqrt((xClick - lon) ** 2 + (yClick - lat) ** 2)\n        ind = np.argmin(d)\n        titleStr = \"site_id %s, lat %.3f, lon %.3f\" % (\n            sites_id[ind],\n            lat[ind],\n            lon[ind],\n        )\n        tsLst = dataTs[ind]\n        plot_ts_matplot(t, tsLst, ax=ax2, title=titleStr)\n        # following funcs both work\n        fig.canvas.draw()\n        # plt.draw()\n\n    fig.canvas.mpl_connect(\"button_press_event\", onclick)\n    plt.show()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ts_matplot","title":"<code>plot_ts_matplot(t, y, color='r', ax=None, title=None)</code>","text":"<p>Creates a simple time series plot comparing predicted and observed values.</p> <p>This function provides a straightforward way to plot and compare two time series, typically used for showing predicted vs observed values. It supports both creating new figures and adding to existing axes.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>list</code> <p>Time points for x-axis.</p> required <code>y</code> <code>list</code> <p>List containing two arrays: [predicted_values, observed_values].</p> required <code>color</code> <code>str</code> <p>Color for predicted values line. Defaults to \"r\".</p> <code>'r'</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]: If ax is None, returns (fig, ax), otherwise returns ax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create new plot\n&gt;&gt;&gt; t = list(range(100))\n&gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n&gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n</code></pre> <pre><code>&gt;&gt;&gt; # Add to existing axes\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n...                     title='Sine Wave Prediction')\n</code></pre> Notes <ul> <li>Predicted values are plotted first with specified color</li> <li>Observed values are plotted second with default color</li> <li>Legend is automatically added with \"pred\" and \"obs\" labels</li> <li>Title is centered if provided</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_matplot(t, y, color=\"r\", ax=None, title=None):\n    \"\"\"Creates a simple time series plot comparing predicted and observed values.\n\n    This function provides a straightforward way to plot and compare two time series,\n    typically used for showing predicted vs observed values. It supports both creating\n    new figures and adding to existing axes.\n\n    Args:\n        t (list): Time points for x-axis.\n        y (list): List containing two arrays: [predicted_values, observed_values].\n        color (str, optional): Color for predicted values line. Defaults to \"r\".\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n\n    Returns:\n        Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]:\n            If ax is None, returns (fig, ax), otherwise returns ax.\n\n    Examples:\n        &gt;&gt;&gt; # Create new plot\n        &gt;&gt;&gt; t = list(range(100))\n        &gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n        &gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n\n        &gt;&gt;&gt; # Add to existing axes\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n        ...                     title='Sine Wave Prediction')\n\n    Notes:\n        - Predicted values are plotted first with specified color\n        - Observed values are plotted second with default color\n        - Legend is automatically added with \"pred\" and \"obs\" labels\n        - Title is centered if provided\n    \"\"\"\n    assert isinstance(t, list)\n    assert isinstance(y, list)\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.subplots()\n    ax.plot(t, y[0], color=color, label=\"pred\")\n    ax.plot(t, y[1], label=\"obs\")\n    ax.legend()\n    if title is not None:\n        ax.set_title(title, loc=\"center\")\n    return (fig, ax) if ax is None else ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.random_choice_no_return","title":"<code>random_choice_no_return(arr, num_lst)</code>","text":"<p>Performs multiple sampling without replacement from an array.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>Union[list, ndarray]</code> <p>The source array to sample from.</p> required <code>num_lst</code> <code>list</code> <p>List of integers specifying the number of elements to sample in each iteration.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of numpy arrays, where each array contains the sampled elements for that iteration.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the sum of requested samples exceeds the array size.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; arr = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; num_lst = [2, 1]  # First sample 2 elements, then 1 element\n&gt;&gt;&gt; result = random_choice_no_return(arr, num_lst)\n&gt;&gt;&gt; len(result)  # Returns 2 (number of sampling iterations)\n&gt;&gt;&gt; len(result[0])  # Returns 2 (first sample size)\n&gt;&gt;&gt; len(result[1])  # Returns 1 (second sample size)\n</code></pre> Source code in <code>hydroutils/hydro_arithmetric.py</code> <pre><code>def random_choice_no_return(arr, num_lst):\n    \"\"\"Performs multiple sampling without replacement from an array.\n\n    Args:\n        arr (Union[list, np.ndarray]): The source array to sample from.\n        num_lst (list): List of integers specifying the number of elements to sample in each iteration.\n\n    Returns:\n        list: A list of numpy arrays, where each array contains the sampled elements for that iteration.\n\n    Raises:\n        AssertionError: If the sum of requested samples exceeds the array size.\n\n    Examples:\n        &gt;&gt;&gt; arr = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; num_lst = [2, 1]  # First sample 2 elements, then 1 element\n        &gt;&gt;&gt; result = random_choice_no_return(arr, num_lst)\n        &gt;&gt;&gt; len(result)  # Returns 2 (number of sampling iterations)\n        &gt;&gt;&gt; len(result[0])  # Returns 2 (first sample size)\n        &gt;&gt;&gt; len(result[1])  # Returns 1 (second sample size)\n    \"\"\"\n    num_lst_arr = np.array(num_lst)\n    num_sum = num_lst_arr.sum()\n    if type(arr) == list:\n        arr = np.array(arr)\n    assert num_sum &lt;= arr.size\n    results = []\n    arr_residue = np.arange(arr.size)\n    for num in num_lst_arr:\n        idx_chosen = np.random.choice(arr_residue.size, num, replace=False)\n        chosen_idx_in_arr = np.sort(arr_residue[idx_chosen])\n        results.append(arr[chosen_idx_in_arr])\n        arr_residue = np.delete(arr_residue, idx_chosen)\n    return results\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.remove_abnormal_data","title":"<code>remove_abnormal_data(data, *, q1=1e-05, q2=0.99999)</code>","text":"<p>Removes extreme values from data using quantile thresholds.</p> <p>Replaces values below q1 quantile and above q2 quantile with NaN. Useful for removing outliers and extreme values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data array.</p> required <code>q1</code> <code>float</code> <p>Lower quantile threshold (0-1). Defaults to 0.00001.</p> <code>1e-05</code> <code>q2</code> <code>float</code> <p>Upper quantile threshold (0-1). Defaults to 0.99999.</p> <code>0.99999</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with extreme values replaced by NaN.</p> Example <pre><code># Remove extreme values from flow data\nflows = np.array([0.1, 1.0, 2.0, 100.0, 1000.0])\ncleaned = remove_abnormal_data(flows, q1=0.01, q2=0.99)\n# Very low and very high values become NaN\n</code></pre> Note <ul> <li>Values &lt;= q1 quantile become NaN</li> <li>Values &gt;= q2 quantile become NaN</li> <li>Useful for pre-processing hydrological data</li> </ul> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def remove_abnormal_data(\n    data: np.ndarray,\n    *,\n    q1: float = 0.00001,\n    q2: float = 0.99999\n) -&gt; np.ndarray:\n    \"\"\"Removes extreme values from data using quantile thresholds.\n\n    Replaces values below q1 quantile and above q2 quantile with NaN.\n    Useful for removing outliers and extreme values.\n\n    Args:\n        data: Input data array.\n        q1: Lower quantile threshold (0-1). Defaults to 0.00001.\n        q2: Upper quantile threshold (0-1). Defaults to 0.99999.\n\n    Returns:\n        Array with extreme values replaced by NaN.\n\n    Example:\n        ```python\n        # Remove extreme values from flow data\n        flows = np.array([0.1, 1.0, 2.0, 100.0, 1000.0])\n        cleaned = remove_abnormal_data(flows, q1=0.01, q2=0.99)\n        # Very low and very high values become NaN\n        ```\n\n    Note:\n        - Values &lt;= q1 quantile become NaN\n        - Values &gt;= q2 quantile become NaN\n        - Useful for pre-processing hydrological data\n    \"\"\"\n    # remove abnormal data\n    data[data &lt; np.quantile(data, q1)] = np.nan\n    data[data &gt; np.quantile(data, q2)] = np.nan\n    return data\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.serialize_json","title":"<code>serialize_json(my_dict, my_file, encoding='utf-8', ensure_ascii=True)</code>","text":"<p>Saves a dictionary to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>my_dict</code> <code>dict</code> <p>Dictionary to serialize.</p> required <code>my_file</code> <code>str</code> <p>Path where the JSON file should be saved.</p> required <code>encoding</code> <code>str</code> <p>Character encoding for the file. Defaults to UTF-8.</p> <code>'utf-8'</code> <code>ensure_ascii</code> <code>bool</code> <p>If True, escapes non-ASCII characters. Defaults to True.</p> <code>True</code> Example <pre><code>data = {'name': 'John', 'age': 30}\nserialize_json(data, 'person.json', encoding='utf-8')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def serialize_json(my_dict: dict, my_file: str, encoding: str = \"utf-8\", ensure_ascii: bool = True) -&gt; None:\n    \"\"\"Saves a dictionary to a JSON file.\n\n    Args:\n        my_dict: Dictionary to serialize.\n        my_file: Path where the JSON file should be saved.\n        encoding: Character encoding for the file. Defaults to UTF-8.\n        ensure_ascii: If True, escapes non-ASCII characters. Defaults to True.\n\n    Example:\n        ```python\n        data = {'name': 'John', 'age': 30}\n        serialize_json(data, 'person.json', encoding='utf-8')\n        ```\n    \"\"\"\n    with open(my_file, \"w\", encoding=encoding) as FP:\n        json.dump(my_dict, FP, ensure_ascii=ensure_ascii, indent=4)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.serialize_json_np","title":"<code>serialize_json_np(my_dict, my_file)</code>","text":"<p>Saves a dictionary containing NumPy arrays to a JSON file.</p> <p>Uses NumpyArrayEncoder to handle NumPy data types.</p> <p>Parameters:</p> Name Type Description Default <code>my_dict</code> <code>dict</code> <p>Dictionary to serialize (may contain NumPy arrays).</p> required <code>my_file</code> <code>str</code> <p>Path where the JSON file should be saved.</p> required Example <pre><code>import numpy as np\ndata = {\n    'array': np.array([1, 2, 3]),\n    'scalar': np.float32(3.14)\n}\nserialize_json_np(data, 'data.json')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def serialize_json_np(my_dict: dict, my_file: str) -&gt; None:\n    \"\"\"Saves a dictionary containing NumPy arrays to a JSON file.\n\n    Uses NumpyArrayEncoder to handle NumPy data types.\n\n    Args:\n        my_dict: Dictionary to serialize (may contain NumPy arrays).\n        my_file: Path where the JSON file should be saved.\n\n    Example:\n        ```python\n        import numpy as np\n        data = {\n            'array': np.array([1, 2, 3]),\n            'scalar': np.float32(3.14)\n        }\n        serialize_json_np(data, 'data.json')\n        ```\n    \"\"\"\n    with open(my_file, \"w\") as FP:\n        json.dump(my_dict, FP, cls=NumpyArrayEncoder)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.serialize_numpy","title":"<code>serialize_numpy(my_array, my_file)</code>","text":"<p>Saves a NumPy array to a .npy file.</p> <p>Parameters:</p> Name Type Description Default <code>my_array</code> <code>ndarray</code> <p>NumPy array to save.</p> required <code>my_file</code> <code>str</code> <p>Path where the array should be saved.</p> required Example <pre><code>arr = np.array([[1, 2], [3, 4]])\nserialize_numpy(arr, 'array.npy')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def serialize_numpy(my_array: np.ndarray, my_file: str) -&gt; None:\n    \"\"\"Saves a NumPy array to a .npy file.\n\n    Args:\n        my_array: NumPy array to save.\n        my_file: Path where the array should be saved.\n\n    Example:\n        ```python\n        arr = np.array([[1, 2], [3, 4]])\n        serialize_numpy(arr, 'array.npy')\n        ```\n    \"\"\"\n    np.save(my_file, my_array)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.serialize_pickle","title":"<code>serialize_pickle(my_object, my_file)</code>","text":"<p>Saves an object to a pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>my_object</code> <code>object</code> <p>Any Python object to serialize.</p> required <code>my_file</code> <code>str</code> <p>Path where the pickle file should be saved.</p> required Example <pre><code>class MyClass:\n    def __init__(self, value):\n        self.value = value\n\nobj = MyClass(42)\nserialize_pickle(obj, 'object.pkl')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def serialize_pickle(my_object: object, my_file: str) -&gt; None:\n    \"\"\"Saves an object to a pickle file.\n\n    Args:\n        my_object: Any Python object to serialize.\n        my_file: Path where the pickle file should be saved.\n\n    Example:\n        ```python\n        class MyClass:\n            def __init__(self, value):\n                self.value = value\n\n        obj = MyClass(42)\n        serialize_pickle(obj, 'object.pkl')\n        ```\n    \"\"\"\n    with open(my_file, \"wb\") as f:\n        pickle.dump(my_object, f)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.stat_error","title":"<code>stat_error(target, pred, fill_nan='no')</code>","text":"<p>Calculates statistical metrics for multiple time series.</p> <p>Computes error metrics between predicted and target values across multiple basins or time series, with options for handling NaN values.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>ndarray</code> <p>Observed values. Shape: [n_basins, n_timesteps].</p> required <code>pred</code> <code>ndarray</code> <p>Predicted values. Same shape as target.</p> required <code>fill_nan</code> <code>str</code> <p>How to handle NaN values: - \"no\": Ignore NaN values (default) - \"sum\": Sum values in NaN locations - \"mean\": Average values in NaN locations Example: For obs=[1,nan,nan,2] and pred=[0.3,0.3,0.3,1.5]: - \"no\" compares [1,2] vs [0.3,1.5] - \"sum\" compares [1,2] vs [0.9,1.5] - \"mean\" compares [1,2] vs [0.3,1.5]</p> <code>'no'</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of metrics: - Bias: Mean error - RMSE: Root mean square error - ubRMSE: Unbiased RMSE - Corr: Pearson correlation - R2: Coefficient of determination - NSE: Nash-Sutcliffe efficiency - KGE: Kling-Gupta efficiency - FHV: High flow bias (top 2%) - FLV: Low flow bias (bottom 30%)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If inputs have wrong dimensions or invalid fill_nan value.</p> Example <pre><code>obs = np.array([[1, 2, 3], [4, 5, 6]])  # 2 basins, 3 timesteps\npred = np.array([[1.1, 2.1, 3.1], [4.2, 5.1, 5.9]])\nmetrics = stat_error(obs, pred)\nprint(f\"Mean RMSE: {np.mean(metrics['RMSE']):.2f}\")\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_error(target: np.ndarray, pred: np.ndarray, fill_nan: str = \"no\") -&gt; dict:\n    \"\"\"Calculates statistical metrics for multiple time series.\n\n    Computes error metrics between predicted and target values across multiple basins\n    or time series, with options for handling NaN values.\n\n    Args:\n        target: Observed values. Shape: [n_basins, n_timesteps].\n        pred: Predicted values. Same shape as target.\n        fill_nan: How to handle NaN values:\n            - \"no\": Ignore NaN values (default)\n            - \"sum\": Sum values in NaN locations\n            - \"mean\": Average values in NaN locations\n            Example: For obs=[1,nan,nan,2] and pred=[0.3,0.3,0.3,1.5]:\n            - \"no\" compares [1,2] vs [0.3,1.5]\n            - \"sum\" compares [1,2] vs [0.9,1.5]\n            - \"mean\" compares [1,2] vs [0.3,1.5]\n\n    Returns:\n        Dictionary of metrics:\n            - Bias: Mean error\n            - RMSE: Root mean square error\n            - ubRMSE: Unbiased RMSE\n            - Corr: Pearson correlation\n            - R2: Coefficient of determination\n            - NSE: Nash-Sutcliffe efficiency\n            - KGE: Kling-Gupta efficiency\n            - FHV: High flow bias (top 2%)\n            - FLV: Low flow bias (bottom 30%)\n\n    Raises:\n        ValueError: If inputs have wrong dimensions or invalid fill_nan value.\n\n    Example:\n        ```python\n        obs = np.array([[1, 2, 3], [4, 5, 6]])  # 2 basins, 3 timesteps\n        pred = np.array([[1.1, 2.1, 3.1], [4.2, 5.1, 5.9]])\n        metrics = stat_error(obs, pred)\n        print(f\"Mean RMSE: {np.mean(metrics['RMSE']):.2f}\")\n        ```\n    \"\"\"\n    if len(target.shape) == 3:\n        raise ValueError(\n            \"The input data should be 2-dim, not 3-dim. If you want to calculate metrics for 3-d arrays, please use stat_errors function.\"\n        )\n    if type(fill_nan) is not str:\n        raise ValueError(\"fill_nan should be a string.\")\n    if target.shape != pred.shape:\n        raise ValueError(\"The shape of target and pred should be the same.\")\n    if fill_nan != \"no\":\n        each_non_nan_idx = []\n        all_non_nan_idx: list[int] = []\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            non_nan_idx_tmp = [j for j in range(tmp.size) if not np.isnan(tmp[j])]\n            each_non_nan_idx.append(non_nan_idx_tmp)\n            # TODO: now all_non_nan_idx is only set for ET, because of its irregular nan values\n            all_non_nan_idx = all_non_nan_idx + non_nan_idx_tmp\n            non_nan_idx = np.unique(all_non_nan_idx).tolist()\n        # some NaN data appear in different dates in different basins, so we have to calculate the metric for each basin\n        # but for ET, it is not very resonable to calculate the metric for each basin in this way, for example,\n        # the non_nan_idx: [1, 9, 17, 33, 41], then there are 16 elements in 17 -&gt; 33, so use all_non_nan_idx is better\n        # hence we don't use each_non_nan_idx finally\n        out_dict = dict(\n            Bias=[],\n            RMSE=[],\n            ubRMSE=[],\n            Corr=[],\n            R2=[],\n            NSE=[],\n            KGE=[],\n            FHV=[],\n            FLV=[],\n        )\n    if fill_nan == \"sum\":\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            # non_nan_idx = each_non_nan_idx[i]\n            targ_i = tmp[non_nan_idx]\n            pred_i = np.add.reduceat(pred[i], non_nan_idx)\n            dict_i = stat_error_i(targ_i, pred_i)\n            out_dict[\"Bias\"].append(dict_i[\"Bias\"])\n            out_dict[\"RMSE\"].append(dict_i[\"RMSE\"])\n            out_dict[\"ubRMSE\"].append(dict_i[\"ubRMSE\"])\n            out_dict[\"Corr\"].append(dict_i[\"Corr\"])\n            out_dict[\"R2\"].append(dict_i[\"R2\"])\n            out_dict[\"NSE\"].append(dict_i[\"NSE\"])\n            out_dict[\"KGE\"].append(dict_i[\"KGE\"])\n            out_dict[\"FHV\"].append(dict_i[\"FHV\"])\n            out_dict[\"FLV\"].append(dict_i[\"FLV\"])\n        return out_dict\n    elif fill_nan == \"mean\":\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            # non_nan_idx = each_non_nan_idx[i]\n            targ_i = tmp[non_nan_idx]\n            pred_i_sum = np.add.reduceat(pred[i], non_nan_idx)\n            if non_nan_idx[-1] &lt; len(pred[i]):\n                idx4mean = non_nan_idx + [len(pred[i])]\n            else:\n                idx4mean = copy.copy(non_nan_idx)\n            idx_interval = [y - x for x, y in zip(idx4mean, idx4mean[1:])]\n            pred_i = pred_i_sum / idx_interval\n            dict_i = stat_error_i(targ_i, pred_i)\n            out_dict[\"Bias\"].append(dict_i[\"Bias\"])\n            out_dict[\"RMSE\"].append(dict_i[\"RMSE\"])\n            out_dict[\"ubRMSE\"].append(dict_i[\"ubRMSE\"])\n            out_dict[\"Corr\"].append(dict_i[\"Corr\"])\n            out_dict[\"R2\"].append(dict_i[\"R2\"])\n            out_dict[\"NSE\"].append(dict_i[\"NSE\"])\n            out_dict[\"KGE\"].append(dict_i[\"KGE\"])\n            out_dict[\"FHV\"].append(dict_i[\"FHV\"])\n            out_dict[\"FLV\"].append(dict_i[\"FLV\"])\n        return out_dict\n    ngrid, nt = pred.shape\n    # Bias\n    Bias = np.nanmean(pred - target, axis=1)\n    # RMSE\n    RMSE = np.sqrt(np.nanmean((pred - target) ** 2, axis=1))\n    # ubRMSE\n    predMean = np.tile(np.nanmean(pred, axis=1), (nt, 1)).transpose()\n    targetMean = np.tile(np.nanmean(target, axis=1), (nt, 1)).transpose()\n    predAnom = pred - predMean\n    targetAnom = target - targetMean\n    ubRMSE = np.sqrt(np.nanmean((predAnom - targetAnom) ** 2, axis=1))\n    # rho R2 NSE\n    Corr = np.full(ngrid, np.nan)\n    R2 = np.full(ngrid, np.nan)\n    NSE = np.full(ngrid, np.nan)\n    KGe = np.full(ngrid, np.nan)\n    PBiaslow = np.full(ngrid, np.nan)\n    PBiashigh = np.full(ngrid, np.nan)\n    PBias = np.full(ngrid, np.nan)\n    num_lowtarget_zero = 0\n    for k in range(ngrid):\n        x = pred[k, :]\n        y = target[k, :]\n        ind = np.where(np.logical_and(~np.isnan(x), ~np.isnan(y)))[0]\n        if ind.shape[0] &gt; 0:\n            xx = x[ind]\n            yy = y[ind]\n            # percent bias\n            PBias[k] = np.sum(xx - yy) / np.sum(yy) * 100\n            if ind.shape[0] &gt; 1:\n                # Theoretically at least two points for correlation\n                Corr[k] = scipy.stats.pearsonr(xx, yy)[0]\n                yymean = yy.mean()\n                SST = np.sum((yy - yymean) ** 2)\n                SSReg = np.sum((xx - yymean) ** 2)\n                SSRes = np.sum((yy - xx) ** 2)\n                R2[k] = 1 - SSRes / SST\n                NSE[k] = 1 - SSRes / SST\n                KGe[k] = KGE(xx, yy)\n            # FHV the peak flows bias 2%\n            # FLV the low flows bias bottom 30%, log space\n            pred_sort = np.sort(xx)\n            target_sort = np.sort(yy)\n            indexlow = round(0.3 * len(pred_sort))\n            indexhigh = round(0.98 * len(pred_sort))\n            lowpred = pred_sort[:indexlow]\n            highpred = pred_sort[indexhigh:]\n            lowtarget = target_sort[:indexlow]\n            hightarget = target_sort[indexhigh:]\n            if np.sum(lowtarget) == 0:\n                num_lowtarget_zero = num_lowtarget_zero + 1\n            with warnings.catch_warnings():\n                # Sometimes the lowtarget is all 0, which will cause a warning\n                # but I know it is not an error, so I ignore it\n                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                PBiaslow[k] = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n            PBiashigh[k] = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n    outDict = dict(\n        Bias=Bias,\n        RMSE=RMSE,\n        ubRMSE=ubRMSE,\n        Corr=Corr,\n        R2=R2,\n        NSE=NSE,\n        KGE=KGe,\n        FHV=PBiashigh,\n        FLV=PBiaslow,\n    )\n    # \"The CDF of BFLV will not reach 1.0 because some basins have all zero flow observations for the \"\n    # \"30% low flow interval, the percent bias can be infinite\\n\"\n    # \"The number of these cases is \" + str(num_lowtarget_zero)\n    return outDict\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.stat_error_i","title":"<code>stat_error_i(targ_i, pred_i)</code>","text":"<p>Calculates multiple error metrics between predicted and target values.</p> <p>Computes a comprehensive set of error metrics including bias, RMSE, correlation, and flow-specific metrics.</p> <p>Parameters:</p> Name Type Description Default <code>targ_i</code> <code>ndarray</code> <p>Target (observed) values.</p> required <code>pred_i</code> <code>ndarray</code> <p>Predicted (simulated) values.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing: - Bias: Mean error - RMSE: Root mean square error - ubRMSE: Unbiased RMSE - Corr: Pearson correlation - R2: Coefficient of determination - NSE: Nash-Sutcliffe efficiency - KGE: Kling-Gupta efficiency - FHV: High flow bias (top 2%) - FLV: Low flow bias (bottom 30%)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input arrays have less than 2 valid points.</p> Example <pre><code>target = np.array([1, 2, 3, 4, 5])\npred = np.array([1.1, 2.1, 2.9, 4.2, 5.1])\nmetrics = stat_error_i(target, pred)\nprint(f\"RMSE: {metrics['RMSE']:.2f}\")\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_error_i(targ_i: np.ndarray, pred_i: np.ndarray) -&gt; dict:\n    \"\"\"Calculates multiple error metrics between predicted and target values.\n\n    Computes a comprehensive set of error metrics including bias, RMSE, correlation,\n    and flow-specific metrics.\n\n    Args:\n        targ_i: Target (observed) values.\n        pred_i: Predicted (simulated) values.\n\n    Returns:\n        Dictionary containing:\n            - Bias: Mean error\n            - RMSE: Root mean square error\n            - ubRMSE: Unbiased RMSE\n            - Corr: Pearson correlation\n            - R2: Coefficient of determination\n            - NSE: Nash-Sutcliffe efficiency\n            - KGE: Kling-Gupta efficiency\n            - FHV: High flow bias (top 2%)\n            - FLV: Low flow bias (bottom 30%)\n\n    Raises:\n        ValueError: If input arrays have less than 2 valid points.\n\n    Example:\n        ```python\n        target = np.array([1, 2, 3, 4, 5])\n        pred = np.array([1.1, 2.1, 2.9, 4.2, 5.1])\n        metrics = stat_error_i(target, pred)\n        print(f\"RMSE: {metrics['RMSE']:.2f}\")\n        ```\n    \"\"\"\n    ind = np.where(np.logical_and(~np.isnan(pred_i), ~np.isnan(targ_i)))[0]\n    # Theoretically at least two points for correlation\n    if ind.shape[0] &gt; 1:\n        xx = pred_i[ind]\n        yy = targ_i[ind]\n        bias = he.me(xx, yy)\n        # RMSE\n        rmse = he.rmse(xx, yy)\n        # ubRMSE\n        pred_mean = np.nanmean(xx)\n        target_mean = np.nanmean(yy)\n        pred_anom = xx - pred_mean\n        target_anom = yy - target_mean\n        ubrmse = np.sqrt(np.nanmean((pred_anom - target_anom) ** 2))\n        # rho R2 NSE\n        corr = he.pearson_r(xx, yy)\n        r2 = he.r_squared(xx, yy)\n        nse = he.nse(xx, yy)\n        kge = he.kge_2009(xx, yy)\n        # percent bias\n        pbias = np.sum(xx - yy) / np.sum(yy) * 100\n        # FHV the peak flows bias 2%\n        # FLV the low flows bias bottom 30%, log space\n        pred_sort = np.sort(xx)\n        target_sort = np.sort(yy)\n        indexlow = round(0.3 * len(pred_sort))\n        indexhigh = round(0.98 * len(pred_sort))\n        lowpred = pred_sort[:indexlow]\n        highpred = pred_sort[indexhigh:]\n        lowtarget = target_sort[:indexlow]\n        hightarget = target_sort[indexhigh:]\n        pbiaslow = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n        pbiashigh = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n        return dict(\n            Bias=bias,\n            RMSE=rmse,\n            ubRMSE=ubrmse,\n            Corr=corr,\n            R2=r2,\n            NSE=nse,\n            KGE=kge,\n            FHV=pbiashigh,\n            FLV=pbiaslow,\n        )\n    else:\n        raise ValueError(\n            \"The number of data is less than 2, we don't calculate the statistics.\"\n        )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.stat_errors","title":"<code>stat_errors(target, pred, fill_nan=None)</code>","text":"<p>Calculates statistical metrics for multiple variables.</p> <p>Similar to stat_error but handles 3D arrays where the third dimension represents different variables.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>ndarray</code> <p>Observed values. Shape: [n_basins, n_timesteps, n_variables].</p> required <code>pred</code> <code>ndarray</code> <p>Predicted values. Same shape as target.</p> required <code>fill_nan</code> <code>List[str]</code> <p>List of NaN handling methods for each variable: - \"no\": Ignore NaN values - \"sum\": Sum values in NaN locations - \"mean\": Average values in NaN locations If None, defaults to [\"no\"] for all variables.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List of dictionaries, one per variable, each containing: - Bias: Mean error - RMSE: Root mean square error - ubRMSE: Unbiased RMSE - Corr: Pearson correlation - R2: Coefficient of determination - NSE: Nash-Sutcliffe efficiency - KGE: Kling-Gupta efficiency - FHV: High flow bias (top 2%) - FLV: Low flow bias (bottom 30%)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If inputs have wrong dimensions or invalid fill_nan values.</p> Example <pre><code># 2 basins, 3 timesteps, 2 variables\nobs = np.array([[[1,4], [2,5], [3,6]], [[4,7], [5,8], [6,9]]])\npred = np.array([[[1.1,4.1], [2.1,5.1], [3.1,6.1]],\n                [[4.2,7.2], [5.1,8.1], [5.9,9.1]]])\nmetrics = stat_errors(obs, pred, fill_nan=['no', 'no'])\nprint(f\"RMSE for var1: {np.mean(metrics[0]['RMSE']):.2f}\")\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_errors(target: np.ndarray, pred: np.ndarray, fill_nan: List[str] = None) -&gt; List[dict]:\n    \"\"\"Calculates statistical metrics for multiple variables.\n\n    Similar to stat_error but handles 3D arrays where the third dimension represents\n    different variables.\n\n    Args:\n        target: Observed values. Shape: [n_basins, n_timesteps, n_variables].\n        pred: Predicted values. Same shape as target.\n        fill_nan: List of NaN handling methods for each variable:\n            - \"no\": Ignore NaN values\n            - \"sum\": Sum values in NaN locations\n            - \"mean\": Average values in NaN locations\n            If None, defaults to [\"no\"] for all variables.\n\n    Returns:\n        List of dictionaries, one per variable, each containing:\n            - Bias: Mean error\n            - RMSE: Root mean square error\n            - ubRMSE: Unbiased RMSE\n            - Corr: Pearson correlation\n            - R2: Coefficient of determination\n            - NSE: Nash-Sutcliffe efficiency\n            - KGE: Kling-Gupta efficiency\n            - FHV: High flow bias (top 2%)\n            - FLV: Low flow bias (bottom 30%)\n\n    Raises:\n        ValueError: If inputs have wrong dimensions or invalid fill_nan values.\n\n    Example:\n        ```python\n        # 2 basins, 3 timesteps, 2 variables\n        obs = np.array([[[1,4], [2,5], [3,6]], [[4,7], [5,8], [6,9]]])\n        pred = np.array([[[1.1,4.1], [2.1,5.1], [3.1,6.1]],\n                        [[4.2,7.2], [5.1,8.1], [5.9,9.1]]])\n        metrics = stat_errors(obs, pred, fill_nan=['no', 'no'])\n        print(f\"RMSE for var1: {np.mean(metrics[0]['RMSE']):.2f}\")\n        ```\n    \"\"\"\n    if fill_nan is None:\n        fill_nan = [\"no\"]\n    if len(target.shape) != 3:\n        raise ValueError(\n            \"The input data should be 3-dim, not 2-dim. If you want to calculate \"\n            \"metrics for 2-d arrays, please use stat_error function.\"\n        )\n    if target.shape != pred.shape:\n        raise ValueError(\"The shape of target and pred should be the same.\")\n    if type(fill_nan) is not list or len(fill_nan) != target.shape[-1]:\n        raise ValueError(\n            \"Please give same length of fill_nan as the number of variables.\"\n        )\n    dict_list = []\n    for k in range(target.shape[-1]):\n        k_dict = stat_error(target[:, :, k], pred[:, :, k], fill_nan=fill_nan[k])\n        dict_list.append(k_dict)\n    return dict_list\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.swarmplot_without_legend","title":"<code>swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs)</code>","text":"<p>Creates a swarm plot using seaborn with colorbar instead of legend.</p> <p>This function creates a swarm plot where points are colored according to a continuous variable, replacing the default legend with a colorbar for better visualization of the color scale.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Values for x-axis categories.</p> required <code>y</code> <p>Values for y-axis.</p> required <code>hue</code> <p>Values determining the color of each point.</p> required <code>vmin</code> <code>float</code> <p>Minimum value for color normalization.</p> required <code>vmax</code> <code>float</code> <p>Maximum value for color normalization.</p> required <code>cmap</code> <code>str</code> <p>Colormap name or matplotlib colormap object.</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to sns.swarmplot.</p> <code>{}</code> <p>Returns:</p> Type Description <p>matplotlib.figure.Figure: The figure containing the swarm plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n&gt;&gt;&gt; y = [1, 2, 3, 4]\n&gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n&gt;&gt;&gt; fig = swarmplot_without_legend(\n...     x, y, hue,\n...     vmin=0, vmax=1,\n...     cmap='viridis'\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs):\n    \"\"\"Creates a swarm plot using seaborn with colorbar instead of legend.\n\n    This function creates a swarm plot where points are colored according to a continuous\n    variable, replacing the default legend with a colorbar for better visualization of\n    the color scale.\n\n    Args:\n        x: Values for x-axis categories.\n        y: Values for y-axis.\n        hue: Values determining the color of each point.\n        vmin (float): Minimum value for color normalization.\n        vmax (float): Maximum value for color normalization.\n        cmap (str): Colormap name or matplotlib colormap object.\n        **kwargs: Additional keyword arguments passed to sns.swarmplot.\n\n    Returns:\n        matplotlib.figure.Figure: The figure containing the swarm plot.\n\n    Examples:\n        &gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n        &gt;&gt;&gt; y = [1, 2, 3, 4]\n        &gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n        &gt;&gt;&gt; fig = swarmplot_without_legend(\n        ...     x, y, hue,\n        ...     vmin=0, vmax=1,\n        ...     cmap='viridis'\n        ... )\n    \"\"\"\n    fig = plt.gcf()\n    ax = sns.swarmplot(x, y, hue, **kwargs)\n    # remove the legend, because we want to set a colorbar instead\n    ax.legend().remove()\n    norm = plt.Normalize(vmin, vmax)\n    sm = ScalarMappable(norm=norm, cmap=cmap)\n    return fig\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t2str","title":"<code>t2str(t_)</code>","text":"<p>Converts between datetime string and datetime object.</p> <p>Parameters:</p> Name Type Description Default <code>t_</code> <code>Union[str, datetime]</code> <p>Either a date string in 'YYYY-MM-DD' format or a datetime object.</p> required <p>Returns:</p> Type Description <code>Union[datetime, str]</code> <p>If input is string: returns datetime object.</p> <code>Union[datetime, str]</code> <p>If input is datetime: returns date string in 'YYYY-MM-DD' format.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If input type is not supported.</p> Example <pre><code># String to datetime\ndt = t2str('2023-01-01')  # Returns datetime(2023, 1, 1)\n\n# Datetime to string\ns = t2str(datetime(2023, 1, 1))  # Returns '2023-01-01'\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t2str(t_: Union[str, datetime.datetime]) -&gt; Union[datetime.datetime, str]:\n    \"\"\"Converts between datetime string and datetime object.\n\n    Args:\n        t_: Either a date string in 'YYYY-MM-DD' format or a datetime object.\n\n    Returns:\n        If input is string: returns datetime object.\n        If input is datetime: returns date string in 'YYYY-MM-DD' format.\n\n    Raises:\n        NotImplementedError: If input type is not supported.\n\n    Example:\n        ```python\n        # String to datetime\n        dt = t2str('2023-01-01')  # Returns datetime(2023, 1, 1)\n\n        # Datetime to string\n        s = t2str(datetime(2023, 1, 1))  # Returns '2023-01-01'\n        ```\n    \"\"\"\n    if type(t_) is str:\n        return datetime.datetime.strptime(t_, \"%Y-%m-%d\")\n    elif type(t_) is datetime.datetime:\n        return t_.strftime(\"%Y-%m-%d\")\n    else:\n        raise NotImplementedError(\"We don't support this data type yet\")\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_days_lst2range","title":"<code>t_days_lst2range(t_array)</code>","text":"<p>Converts a list of dates to a date range [start, end].</p> <p>Parameters:</p> Name Type Description Default <code>t_array</code> <code>list</code> <p>List of dates, either as np.datetime64 objects or strings in 'YYYY-MM-DD' format.</p> required <p>Returns:</p> Type Description <code>list</code> <p>Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.</p> Example <pre><code># With string dates\ndates = ['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nrange = t_days_lst2range(dates)  # Returns ['2000-01-01', '2000-01-04']\n\n# With datetime64 objects\ndates = np.array(['2000-01-01', '2000-01-04'], dtype='datetime64')\nrange = t_days_lst2range(dates)  # Returns ['2000-01-01', '2000-01-04']\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_days_lst2range(t_array: list) -&gt; list:\n    \"\"\"Converts a list of dates to a date range [start, end].\n\n    Args:\n        t_array: List of dates, either as np.datetime64 objects or strings in 'YYYY-MM-DD' format.\n\n    Returns:\n        Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.\n\n    Example:\n        ```python\n        # With string dates\n        dates = ['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\n        range = t_days_lst2range(dates)  # Returns ['2000-01-01', '2000-01-04']\n\n        # With datetime64 objects\n        dates = np.array(['2000-01-01', '2000-01-04'], dtype='datetime64')\n        range = t_days_lst2range(dates)  # Returns ['2000-01-01', '2000-01-04']\n        ```\n    \"\"\"\n    if type(t_array[0]) == np.datetime64:\n        t0 = t_array[0].astype(datetime.datetime)\n        t1 = t_array[-1].astype(datetime.datetime)\n    else:\n        t0 = t_array[0]\n        t1 = t_array[-1]\n    sd = t0.strftime(\"%Y-%m-%d\")\n    ed = t1.strftime(\"%Y-%m-%d\")\n    return [sd, ed]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_days","title":"<code>t_range_days(t_range, *, step=np.timedelta64(1, 'D'))</code>","text":"<p>Creates a uniformly-spaced array of dates from a date range.</p> <p>Parameters:</p> Name Type Description Default <code>t_range</code> <code>list</code> <p>Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.</p> required <code>step</code> <code>timedelta64</code> <p>Time interval between dates. Defaults to 1 day.</p> <code>timedelta64(1, 'D')</code> <p>Returns:</p> Type Description <code>array</code> <p>Array of datetime64 objects representing the date range.</p> Example <pre><code>dates = t_range_days(['2000-01-01', '2000-01-05'])\n# Returns array(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04'],\n#              dtype='datetime64[D]')\n\n# With custom step\ndates = t_range_days(['2000-01-01', '2000-01-10'], \n                   step=np.timedelta64(2, 'D'))\n# Returns dates with 2-day intervals\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_days(t_range: list, *, step: np.timedelta64 = np.timedelta64(1, \"D\")) -&gt; np.array:\n    \"\"\"Creates a uniformly-spaced array of dates from a date range.\n\n    Args:\n        t_range: Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.\n        step: Time interval between dates. Defaults to 1 day.\n\n    Returns:\n        Array of datetime64 objects representing the date range.\n\n    Example:\n        ```python\n        dates = t_range_days(['2000-01-01', '2000-01-05'])\n        # Returns array(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04'],\n        #              dtype='datetime64[D]')\n\n        # With custom step\n        dates = t_range_days(['2000-01-01', '2000-01-10'], \n                           step=np.timedelta64(2, 'D'))\n        # Returns dates with 2-day intervals\n        ```\n    \"\"\"\n    sd = datetime.datetime.strptime(t_range[0], \"%Y-%m-%d\")\n    ed = datetime.datetime.strptime(t_range[1], \"%Y-%m-%d\")\n    return np.arange(sd, ed, step)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_days_timedelta","title":"<code>t_range_days_timedelta(t_array, td=12, td_type='h')</code>","text":"<p>Adds a time delta to each date in an array.</p> <p>Parameters:</p> Name Type Description Default <code>t_array</code> <code>array</code> <p>Array of datetime64 objects (typically from t_range_days).</p> required <code>td</code> <code>int</code> <p>Number of time units to add.</p> <code>12</code> <code>td_type</code> <code>str</code> <p>Time unit type. One of 'Y'(years), 'M'(months), 'D'(days),     'h'(hours), 'm'(minutes), 's'(seconds).</p> <code>'h'</code> <p>Returns:</p> Type Description <code>array</code> <p>Array of datetime64 objects with added time delta.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If td_type is not one of the supported types.</p> Example <pre><code>dates = t_range_days(['2000-01-01', '2000-01-03'])\n# Add 12 hours to each date\nshifted = t_range_days_timedelta(dates, td=12, td_type='h')\n\n# Add 30 minutes to each date\nshifted = t_range_days_timedelta(dates, td=30, td_type='m')\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_days_timedelta(t_array: np.array, td: int = 12, td_type: str = \"h\") -&gt; np.array:\n    \"\"\"Adds a time delta to each date in an array.\n\n    Args:\n        t_array: Array of datetime64 objects (typically from t_range_days).\n        td: Number of time units to add.\n        td_type: Time unit type. One of 'Y'(years), 'M'(months), 'D'(days),\n                'h'(hours), 'm'(minutes), 's'(seconds).\n\n    Returns:\n        Array of datetime64 objects with added time delta.\n\n    Raises:\n        AssertionError: If td_type is not one of the supported types.\n\n    Example:\n        ```python\n        dates = t_range_days(['2000-01-01', '2000-01-03'])\n        # Add 12 hours to each date\n        shifted = t_range_days_timedelta(dates, td=12, td_type='h')\n\n        # Add 30 minutes to each date\n        shifted = t_range_days_timedelta(dates, td=30, td_type='m')\n        ```\n    \"\"\"\n    assert td_type in [\"Y\", \"M\", \"D\", \"h\", \"m\", \"s\"]\n    t_array_final = [t + np.timedelta64(td, td_type) for t in t_array]\n    return np.array(t_array_final)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_to_julian","title":"<code>t_range_to_julian(t_range)</code>","text":"<p>Converts a date range to a list of Julian days.</p> <p>Parameters:</p> Name Type Description Default <code>t_range</code> <code>list</code> <p>Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of Julian days (days of year) for each date in the range.</p> Example <pre><code>days = t_range_to_julian(['2023-01-31', '2023-02-03'])\n# Returns [31, 32, 33, 34]  # Julian days for Jan 31 - Feb 3\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_to_julian(t_range: list) -&gt; list:\n    \"\"\"Converts a date range to a list of Julian days.\n\n    Args:\n        t_range: Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.\n\n    Returns:\n        List of Julian days (days of year) for each date in the range.\n\n    Example:\n        ```python\n        days = t_range_to_julian(['2023-01-31', '2023-02-03'])\n        # Returns [31, 32, 33, 34]  # Julian days for Jan 31 - Feb 3\n        ```\n    \"\"\"\n    t_array = t_range_days(t_range)\n    t_array_str = np.datetime_as_string(t_array)\n    return [date_to_julian(a_time[:10]) for a_time in t_array_str]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_years","title":"<code>t_range_years(t_range)</code>","text":"<p>Extracts years from a date range, handling year boundaries.</p> <p>The function treats the range as left-closed and right-open. If the end date is not January 1st, the end year is included in the range.</p> <p>Parameters:</p> Name Type Description Default <code>t_range</code> <code>list</code> <p>Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of years included in the range.</p> Example <pre><code># End date is Jan 1st - end year not included\nyears = t_range_years(['2000-01-01', '2003-01-01'])\n# Returns array([2000, 2001, 2002])\n\n# End date is not Jan 1st - end year included\nyears = t_range_years(['2000-01-01', '2003-06-01'])\n# Returns array([2000, 2001, 2002, 2003])\n</code></pre> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_years(t_range: list) -&gt; np.array:\n    \"\"\"Extracts years from a date range, handling year boundaries.\n\n    The function treats the range as left-closed and right-open. If the end date\n    is not January 1st, the end year is included in the range.\n\n    Args:\n        t_range: Two-element list containing start and end dates as strings in 'YYYY-MM-DD' format.\n\n    Returns:\n        Array of years included in the range.\n\n    Example:\n        ```python\n        # End date is Jan 1st - end year not included\n        years = t_range_years(['2000-01-01', '2003-01-01'])\n        # Returns array([2000, 2001, 2002])\n\n        # End date is not Jan 1st - end year included\n        years = t_range_years(['2000-01-01', '2003-06-01'])\n        # Returns array([2000, 2001, 2002, 2003])\n        ```\n    \"\"\"\n    start_year = int(t_range[0].split(\"-\")[0])\n    end_year = int(t_range[1].split(\"-\")[0])\n    end_month = int(t_range[1].split(\"-\")[1])\n    end_day = int(t_range[1].split(\"-\")[2])\n    return (\n        np.arange(start_year, end_year)\n        if end_month == 1 and end_day == 1\n        else np.arange(start_year, end_year + 1)\n    )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.trans_norm","title":"<code>trans_norm(x, var_lst, stat_dict, *, to_norm)</code>","text":"<p>Normalizes or denormalizes data using pre-computed statistics.</p> <p>Performs z-score normalization (x-mean)/std or its inverse on multiple variables. Handles both 2D and 3D arrays.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input data array: - 2D: [n_sites, n_variables] - 3D: [n_sites, n_timesteps, n_variables]</p> required <code>var_lst</code> <code>Union[str, list]</code> <p>Variable name(s) corresponding to the last dimension of x.</p> required <code>stat_dict</code> <code>dict</code> <p>Dictionary containing [p10, p90, mean, std] for each variable.</p> required <code>to_norm</code> <code>bool</code> <p>If True, normalizes data; if False, denormalizes data.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Normalized or denormalized data with same shape as input.</p> Example <pre><code># Normalization\ndata = np.array([[1, 100], [2, 200]])  # 2 sites, 2 variables\nstats = {\n    'flow': [0, 5, 1.5, 0.5],    # [p10, p90, mean, std]\n    'precip': [50, 250, 150, 50]\n}\nnorm_data = trans_norm(data, ['flow', 'precip'], stats, to_norm=True)\n\n# Denormalization\norig_data = trans_norm(norm_data, ['flow', 'precip'], stats, to_norm=False)\n</code></pre> Note <ul> <li>For normalization: (x - mean) / std</li> <li>For denormalization: x * std + mean</li> <li>Handles multiple variables simultaneously</li> </ul> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def trans_norm(\n    x: np.ndarray,\n    var_lst: Union[str, list],\n    stat_dict: dict,\n    *,\n    to_norm: bool\n) -&gt; np.ndarray:\n    \"\"\"Normalizes or denormalizes data using pre-computed statistics.\n\n    Performs z-score normalization (x-mean)/std or its inverse on multiple variables.\n    Handles both 2D and 3D arrays.\n\n    Args:\n        x: Input data array:\n            - 2D: [n_sites, n_variables]\n            - 3D: [n_sites, n_timesteps, n_variables]\n        var_lst: Variable name(s) corresponding to the last dimension of x.\n        stat_dict: Dictionary containing [p10, p90, mean, std] for each variable.\n        to_norm: If True, normalizes data; if False, denormalizes data.\n\n    Returns:\n        Normalized or denormalized data with same shape as input.\n\n    Example:\n        ```python\n        # Normalization\n        data = np.array([[1, 100], [2, 200]])  # 2 sites, 2 variables\n        stats = {\n            'flow': [0, 5, 1.5, 0.5],    # [p10, p90, mean, std]\n            'precip': [50, 250, 150, 50]\n        }\n        norm_data = trans_norm(data, ['flow', 'precip'], stats, to_norm=True)\n\n        # Denormalization\n        orig_data = trans_norm(norm_data, ['flow', 'precip'], stats, to_norm=False)\n        ```\n\n    Note:\n        - For normalization: (x - mean) / std\n        - For denormalization: x * std + mean\n        - Handles multiple variables simultaneously\n    \"\"\"\n    if type(var_lst) is str:\n        var_lst = [var_lst]\n    out = np.zeros(x.shape)\n    for k in range(len(var_lst)):\n        var = var_lst[k]\n        stat = stat_dict[var]\n        if to_norm is True:\n            if len(x.shape) == 3:\n                out[:, :, k] = (x[:, :, k] - stat[2]) / stat[3]\n            elif len(x.shape) == 2:\n                out[:, k] = (x[:, k] - stat[2]) / stat[3]\n        elif len(x.shape) == 3:\n            out[:, :, k] = x[:, :, k] * stat[3] + stat[2]\n        elif len(x.shape) == 2:\n            out[:, k] = x[:, k] * stat[3] + stat[2]\n    return out\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unserialize_json","title":"<code>unserialize_json(my_file)</code>","text":"<p>Loads a JSON file into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>my_file</code> <code>str</code> <p>Path to the JSON file to load.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the JSON data.</p> Example <pre><code>data = unserialize_json('config.json')\nprint(data['settings'])\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unserialize_json(my_file: str) -&gt; dict:\n    \"\"\"Loads a JSON file into a dictionary.\n\n    Args:\n        my_file: Path to the JSON file to load.\n\n    Returns:\n        Dictionary containing the JSON data.\n\n    Example:\n        ```python\n        data = unserialize_json('config.json')\n        print(data['settings'])\n        ```\n    \"\"\"\n    with open(my_file, \"r\") as fp:\n        my_object = json.load(fp)\n    return my_object\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unserialize_json_ordered","title":"<code>unserialize_json_ordered(my_file)</code>","text":"<p>Loads a JSON file into an OrderedDict, preserving key order.</p> <p>Parameters:</p> Name Type Description Default <code>my_file</code> <code>str</code> <p>Path to the JSON file to load.</p> required <p>Returns:</p> Type Description <code>OrderedDict</code> <p>OrderedDict containing the JSON data with preserved key order.</p> Example <pre><code>data = unserialize_json_ordered('config.json')\n# Keys in data maintain their original order from the file\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unserialize_json_ordered(my_file: str) -&gt; OrderedDict:\n    \"\"\"Loads a JSON file into an OrderedDict, preserving key order.\n\n    Args:\n        my_file: Path to the JSON file to load.\n\n    Returns:\n        OrderedDict containing the JSON data with preserved key order.\n\n    Example:\n        ```python\n        data = unserialize_json_ordered('config.json')\n        # Keys in data maintain their original order from the file\n        ```\n    \"\"\"\n    with open(my_file, \"r\") as fp:\n        m_dict = json.load(fp, object_pairs_hook=OrderedDict)\n    return m_dict\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unserialize_numpy","title":"<code>unserialize_numpy(my_file)</code>","text":"<p>Loads a NumPy array from a .npy file.</p> <p>Parameters:</p> Name Type Description Default <code>my_file</code> <code>str</code> <p>Path to the .npy file to load.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The loaded NumPy array.</p> Example <pre><code>arr = unserialize_numpy('array.npy')\nprint(arr.shape)  # Shows array dimensions\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unserialize_numpy(my_file: str) -&gt; np.ndarray:\n    \"\"\"Loads a NumPy array from a .npy file.\n\n    Args:\n        my_file: Path to the .npy file to load.\n\n    Returns:\n        The loaded NumPy array.\n\n    Example:\n        ```python\n        arr = unserialize_numpy('array.npy')\n        print(arr.shape)  # Shows array dimensions\n        ```\n    \"\"\"\n    return np.load(my_file)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unserialize_pickle","title":"<code>unserialize_pickle(my_file)</code>","text":"<p>Loads an object from a pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>my_file</code> <code>str</code> <p>Path to the pickle file to load.</p> required <p>Returns:</p> Type Description <code>object</code> <p>The deserialized Python object.</p> Example <pre><code>obj = unserialize_pickle('object.pkl')\nprint(obj.value)  # Assuming obj has a 'value' attribute\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unserialize_pickle(my_file: str) -&gt; object:\n    \"\"\"Loads an object from a pickle file.\n\n    Args:\n        my_file: Path to the pickle file to load.\n\n    Returns:\n        The deserialized Python object.\n\n    Example:\n        ```python\n        obj = unserialize_pickle('object.pkl')\n        print(obj.value)  # Assuming obj has a 'value' attribute\n        ```\n    \"\"\"\n    with open(my_file, \"rb\") as f:\n        my_object = pickle.load(f)\n    return my_object\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unzip_file","title":"<code>unzip_file(data_zip, path_unzip)</code>","text":"<p>Extracts a zip file to a specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>data_zip</code> <code>str</code> <p>Path to the zip file.</p> required <code>path_unzip</code> <code>str</code> <p>Directory where contents should be extracted.</p> required Example <pre><code>unzip_file('data.zip', './extracted')\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unzip_file(data_zip: str, path_unzip: str) -&gt; None:\n    \"\"\"Extracts a zip file to a specified directory.\n\n    Args:\n        data_zip: Path to the zip file.\n        path_unzip: Directory where contents should be extracted.\n\n    Example:\n        ```python\n        unzip_file('data.zip', './extracted')\n        ```\n    \"\"\"\n    with zipfile.ZipFile(data_zip, \"r\") as zip_temp:\n        zip_temp.extractall(path_unzip)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unzip_nested_zip","title":"<code>unzip_nested_zip(dataset_zip, path_unzip)</code>","text":"<p>Recursively extracts a zip file and any nested zip files within it.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_zip</code> <code>str</code> <p>Path to the zip file.</p> required <code>path_unzip</code> <code>str</code> <p>Directory where contents should be extracted.</p> required Note <p>If a file's name ends with underscore (e.g., \"xxx_\"), the zipfile library may raise an OSError. In such cases, check the extracted files manually.</p> Example <pre><code># Extract main.zip containing nested archives\nunzip_nested_zip('main.zip', './extracted')\n# Extracts:\n# - main.zip -&gt; ./extracted/*\n# - Any *.zip in extracted/* -&gt; ./extracted/*/subdir/*\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unzip_nested_zip(dataset_zip: str, path_unzip: str) -&gt; None:\n    \"\"\"Recursively extracts a zip file and any nested zip files within it.\n\n    Args:\n        dataset_zip: Path to the zip file.\n        path_unzip: Directory where contents should be extracted.\n\n    Note:\n        If a file's name ends with underscore (e.g., \"xxx_\"), the zipfile library\n        may raise an OSError. In such cases, check the extracted files manually.\n\n    Example:\n        ```python\n        # Extract main.zip containing nested archives\n        unzip_nested_zip('main.zip', './extracted')\n        # Extracts:\n        # - main.zip -&gt; ./extracted/*\n        # - Any *.zip in extracted/* -&gt; ./extracted/*/subdir/*\n        ```\n    \"\"\"\n\n    with zipfile.ZipFile(dataset_zip, \"r\") as zfile:\n        try:\n            zfile.extractall(path=path_unzip)\n        except OSError as e:\n            logging.warning(\n                \"Please check the unzipped files manually. There may be some missed important files.\"\n            )\n            logging.warning(f\"The directory is: {path_unzip}\")\n            logging.warning(f\"Error message: {e}\")\n    for root, dirs, files in os.walk(path_unzip):\n        for filename in files:\n            if re.search(r\"\\.zip$\", filename):\n                file_spec = os.path.join(root, filename)\n                new_dir = os.path.join(root, filename[:-4])\n                unzip_nested_zip(file_spec, new_dir)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.validate_correction_quality","title":"<code>validate_correction_quality(original_data, corrected_data, discharge_column='gen_discharge')</code>","text":"<p>\u9a8c\u8bc1\u4fee\u6b63\u8d28\u91cf</p> <p>Parameters:</p> Name Type Description Default <code>original_data</code> <code>DataFrame</code> <p>\u539f\u59cb\u6570\u636e</p> required <code>corrected_data</code> <code>DataFrame</code> <p>\u4fee\u6b63\u540e\u6570\u636e</p> required <code>discharge_column</code> <code>str</code> <p>\u5f84\u6d41\u5217\u540d</p> <code>'gen_discharge'</code> <p>Returns:</p> Type Description <code>dict</code> <p>\u8d28\u91cf\u6307\u6807\u5b57\u5178</p> Source code in <code>hydroutils/hydro_correct.py</code> <pre><code>def validate_correction_quality(\n    original_data: pd.DataFrame,\n    corrected_data: pd.DataFrame,\n    discharge_column: str = \"gen_discharge\",\n) -&gt; dict:\n    \"\"\"\n    \u9a8c\u8bc1\u4fee\u6b63\u8d28\u91cf\n\n    Args:\n        original_data: \u539f\u59cb\u6570\u636e\n        corrected_data: \u4fee\u6b63\u540e\u6570\u636e\n        discharge_column: \u5f84\u6d41\u5217\u540d\n\n    Returns:\n        \u8d28\u91cf\u6307\u6807\u5b57\u5178\n    \"\"\"\n    if (\n        discharge_column not in original_data.columns\n        or discharge_column not in corrected_data.columns\n    ):\n        raise ValueError(f\"\u6570\u636e\u4e2d\u7f3a\u5c11\u5f84\u6d41\u5217: {discharge_column}\")\n\n    original_values = original_data[discharge_column].values\n    corrected_values = corrected_data[discharge_column].values\n\n    # \u8ba1\u7b97\u8d28\u91cf\u6307\u6807\n    mse = np.mean((corrected_values - original_values) ** 2)\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(corrected_values - original_values))\n\n    # \u76f8\u5bf9\u8bef\u5dee\n    relative_error = (\n        np.mean(np.abs(corrected_values - original_values) / (original_values + 1e-8))\n        * 100\n    )\n\n    # \u5cf0\u503c\u4fdd\u6301\u5ea6\n    original_peak = np.max(original_values)\n    corrected_peak = np.max(corrected_values)\n    peak_preservation = corrected_peak / original_peak if original_peak &gt; 0 else 1.0\n\n    return {\n        \"mse\": mse,\n        \"rmse\": rmse,\n        \"mae\": mae,\n        \"relative_error_percent\": relative_error,\n        \"peak_preservation_ratio\": peak_preservation,\n        \"original_peak\": original_peak,\n        \"corrected_peak\": corrected_peak,\n    }\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.wilcoxon_t_test","title":"<code>wilcoxon_t_test(xs, xo)</code>","text":"<p>Performs Wilcoxon signed-rank test on paired samples.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>ndarray</code> <p>First sample array.</p> required <code>xo</code> <code>ndarray</code> <p>Second sample array (same length as xs).</p> required <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Tuple of (test_statistic, p_value).</p> Example <pre><code>x1 = np.array([1, 2, 3, 4, 5])\nx2 = np.array([1.1, 2.2, 2.9, 4.2, 5.1])\nw, p = wilcoxon_t_test(x1, x2)\nprint(f\"p-value: {p:.3f}\")  # Test significance\n</code></pre> Note <p>Tests the null hypothesis that two related paired samples come from the same distribution.</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def wilcoxon_t_test(xs: np.ndarray, xo: np.ndarray) -&gt; Tuple[float, float]:\n    \"\"\"Performs Wilcoxon signed-rank test on paired samples.\n\n    Args:\n        xs: First sample array.\n        xo: Second sample array (same length as xs).\n\n    Returns:\n        Tuple of (test_statistic, p_value).\n\n    Example:\n        ```python\n        x1 = np.array([1, 2, 3, 4, 5])\n        x2 = np.array([1.1, 2.2, 2.9, 4.2, 5.1])\n        w, p = wilcoxon_t_test(x1, x2)\n        print(f\"p-value: {p:.3f}\")  # Test significance\n        ```\n\n    Note:\n        Tests the null hypothesis that two related paired samples\n        come from the same distribution.\n    \"\"\"\n    diff = xs - xo  # same result when using xo-xs\n    w, p = wilcoxon(diff)\n    return w, p\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.wilcoxon_t_test_for_lst","title":"<code>wilcoxon_t_test_for_lst(x_lst, rnd_num=2)</code>","text":"<p>Performs pairwise Wilcoxon tests between all arrays in a list.</p> <p>Parameters:</p> Name Type Description Default <code>x_lst</code> <code>List[ndarray]</code> <p>List of arrays to compare.</p> required <code>rnd_num</code> <code>int</code> <p>Number of decimal places to round results. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Type Description <code>List[float]</code> <p>Tuple of (test_statistics, p_values), where each element is a list of</p> <code>List[float]</code> <p>rounded values for each pairwise comparison.</p> Example <pre><code>arrays = [\n    np.array([1, 2, 3, 4, 5]),\n    np.array([1.1, 2.2, 2.9, 4.2, 5.1]),\n    np.array([1.2, 2.1, 3.1, 4.0, 5.2])\n]\nw, p = wilcoxon_t_test_for_lst(arrays)\n# Returns test statistics and p-values for:\n# - arrays[0] vs arrays[1]\n# - arrays[0] vs arrays[2]\n# - arrays[1] vs arrays[2]\n</code></pre> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def wilcoxon_t_test_for_lst(x_lst: List[np.ndarray], rnd_num: int = 2) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"Performs pairwise Wilcoxon tests between all arrays in a list.\n\n    Args:\n        x_lst: List of arrays to compare.\n        rnd_num: Number of decimal places to round results. Defaults to 2.\n\n    Returns:\n        Tuple of (test_statistics, p_values), where each element is a list of\n        rounded values for each pairwise comparison.\n\n    Example:\n        ```python\n        arrays = [\n            np.array([1, 2, 3, 4, 5]),\n            np.array([1.1, 2.2, 2.9, 4.2, 5.1]),\n            np.array([1.2, 2.1, 3.1, 4.0, 5.2])\n        ]\n        w, p = wilcoxon_t_test_for_lst(arrays)\n        # Returns test statistics and p-values for:\n        # - arrays[0] vs arrays[1]\n        # - arrays[0] vs arrays[2]\n        # - arrays[1] vs arrays[2]\n        ```\n    \"\"\"\n    arr_lst = np.asarray(x_lst)\n    w, p = [], []\n    arr_lst_pair = list(itertools.combinations(arr_lst, 2))\n    for arr_pair in arr_lst_pair:\n        wi, pi = wilcoxon_t_test(arr_pair[0], arr_pair[1])\n        w.append(round(wi, rnd_num))\n        p.append(round(pi, rnd_num))\n    return w, p\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.zip_extract","title":"<code>zip_extract(the_dir)</code>","text":"<p>Extracts all zip files in a directory.</p> <p>Each zip file is extracted to a subdirectory named after the zip file (without the .zip extension).</p> <p>Parameters:</p> Name Type Description Default <code>the_dir</code> <code>Path</code> <p>Directory containing zip files to extract.</p> required Example <pre><code>from pathlib import Path\nzip_extract(Path('./downloads'))\n# Extracts:\n# - ./downloads/file1.zip -&gt; ./downloads/file1/*\n# - ./downloads/file2.zip -&gt; ./downloads/file2/*\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def zip_extract(the_dir: Path) -&gt; None:\n    \"\"\"Extracts all zip files in a directory.\n\n    Each zip file is extracted to a subdirectory named after the zip file\n    (without the .zip extension).\n\n    Args:\n        the_dir: Directory containing zip files to extract.\n\n    Example:\n        ```python\n        from pathlib import Path\n        zip_extract(Path('./downloads'))\n        # Extracts:\n        # - ./downloads/file1.zip -&gt; ./downloads/file1/*\n        # - ./downloads/file2.zip -&gt; ./downloads/file2/*\n        ```\n    \"\"\"\n    for f in the_dir.glob(\"*.zip\"):\n        with zipfile.ZipFile(f) as zf:\n            # extract files to a directory named by f.stem\n            zf.extractall(the_dir.joinpath(f.stem))\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.zip_file_name_from_url","title":"<code>zip_file_name_from_url(data_url, data_dir)</code>","text":"<p>Generates local file paths for a zip file from its URL.</p> <p>Parameters:</p> Name Type Description Default <code>data_url</code> <code>str</code> <p>URL of the zip file.</p> required <code>data_dir</code> <code>str</code> <p>Local directory where the file will be saved.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of (zip_file_path, unzip_directory_path).</p> Example <pre><code>url = 'https://example.com/data.zip'\nzip_path, extract_path = zip_file_name_from_url(url, './downloads')\n# Returns:\n# - zip_path = './downloads/data.zip'\n# - extract_path = './downloads/data'\n</code></pre> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def zip_file_name_from_url(data_url: str, data_dir: str) -&gt; tuple:\n    \"\"\"Generates local file paths for a zip file from its URL.\n\n    Args:\n        data_url: URL of the zip file.\n        data_dir: Local directory where the file will be saved.\n\n    Returns:\n        Tuple of (zip_file_path, unzip_directory_path).\n\n    Example:\n        ```python\n        url = 'https://example.com/data.zip'\n        zip_path, extract_path = zip_file_name_from_url(url, './downloads')\n        # Returns:\n        # - zip_path = './downloads/data.zip'\n        # - extract_path = './downloads/data'\n        ```\n    \"\"\"\n    data_url_str = data_url.split(\"/\")\n    filename = parse.unquote(data_url_str[-1])\n    zipfile_path = os.path.join(data_dir, filename)\n    unzip_dir = os.path.join(data_dir, filename[:-4])\n    return zipfile_path, unzip_dir\n</code></pre>"},{"location":"api/hydroutils/#submodules","title":"Submodules","text":"<p>The <code>hydroutils</code> package consists of several specialized modules:</p> <ul> <li>hydro_stat - Statistical analysis and performance metrics</li> <li>hydro_plot - Visualization tools for hydrological data  </li> <li>hydro_time - Time series processing utilities</li> <li>hydro_file - File I/O operations</li> <li>hydro_arithmetric - Mathematical operations</li> <li>hydro_s3 - AWS S3 integration</li> <li>hydro_log - Logging utilities</li> </ul> <p>Click on any module above for detailed function documentation.</p>"}]}