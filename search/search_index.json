{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to hydroutils","text":"<p>A collection of commonly used utility functions for hydrological modeling and analysis</p> <p><code>hydroutils</code> is a comprehensive Python package that provides essential tools and utilities for hydrological data processing, statistical analysis, and modeling. It is designed to streamline common tasks in hydrology research and engineering applications.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#statistical-analysis","title":"\ud83d\udcca Statistical Analysis","text":"<ul> <li>Comprehensive hydrological statistics (NSE, KGE, RMSE, Bias, etc.)</li> <li>Flow duration curve analysis</li> <li>Peak flow analysis and timing metrics</li> <li>Flood event extraction and characterization</li> </ul>"},{"location":"#time-series-processing","title":"\ud83d\udd50 Time Series Processing","text":"<ul> <li>Time unit conversions and standardization</li> <li>Time interval detection and validation</li> <li>Temporal data manipulation utilities</li> </ul>"},{"location":"#data-visualization","title":"\ud83d\udcc8 Data Visualization","text":"<ul> <li>Specialized plotting functions for hydrological data</li> <li>Flow duration curves</li> <li>Time series plots with hydrological context</li> </ul>"},{"location":"#file-operations","title":"\ud83d\udcc1 File Operations","text":"<ul> <li>NetCDF file handling</li> <li>CSV and text file processing</li> <li>Data import/export utilities</li> </ul>"},{"location":"#cloud-integration","title":"\u2601\ufe0f Cloud Integration","text":"<ul> <li>AWS S3 integration for large dataset handling</li> <li>Cloud-based data storage and retrieval</li> </ul>"},{"location":"#mathematical-operations","title":"\ud83e\uddee Mathematical Operations","text":"<ul> <li>Hydrological unit conversions</li> <li>Mathematical utilities for water resources calculations</li> <li>Array operations optimized for hydrological data</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import hydroutils as hu\n\n# Calculate hydrological statistics\nnse = hu.stat_error(observed, simulated)['NSE']\n\n# Extract flood events\nevents = hu.extract_flood_events(dataframe)\n\n# Convert streamflow units\nconverted = hu.streamflow_unit_conv(data, from_unit='cms', to_unit='cfs')\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install hydroutils\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Installation Guide - Detailed installation instructions</li> <li>Usage Examples - Practical examples and tutorials  </li> <li>API Reference - Complete API documentation</li> <li>Contributing - How to contribute to the project</li> <li>FAQ - Frequently asked questions</li> </ul>"},{"location":"#license-credits","title":"License &amp; Credits","text":"<ul> <li>Free software: MIT license</li> <li>Documentation: https://zhuanglaihong.github.io/hydroutils</li> <li>Created with Cookiecutter and the giswqs/pypackage project template</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to the hydroutils project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#v0014-2025-08-19","title":"v0.0.14 - 2025-08-19","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>\u5b8c\u6574\u7684\u9879\u76ee\u6587\u6863\u7ed3\u6784\uff0c\u5305\u62ecAPI\u53c2\u8003\u3001\u4f7f\u7528\u6307\u5357\u548c\u793a\u4f8b</li> <li>\u65b0\u589e\u6c34\u6587\u7edf\u8ba1\u5206\u6790\u6a21\u5757 (<code>hydro_stat</code>)</li> <li>\u652f\u6301NSE\u3001KGE\u3001RMSE\u7b49\u591a\u79cd\u8bc4\u4ef7\u6307\u6807</li> <li>\u6d2a\u6c34\u4e8b\u4ef6\u63d0\u53d6\u548c\u5206\u6790\u529f\u80fd</li> <li>\u6d41\u91cf\u6301\u7eed\u66f2\u7ebf\u5206\u6790</li> <li>\u65f6\u95f4\u5e8f\u5217\u5904\u7406\u6a21\u5757 (<code>hydro_time</code>)</li> <li>\u65f6\u95f4\u95f4\u9694\u68c0\u6d4b\u548c\u9a8c\u8bc1</li> <li>\u5355\u4f4d\u8f6c\u6362\u529f\u80fd</li> <li>\u53ef\u89c6\u5316\u5de5\u5177\u6a21\u5757 (<code>hydro_plot</code>)</li> <li>\u6c34\u6587\u6570\u636e\u4e13\u7528\u7ed8\u56fe\u51fd\u6570</li> <li>\u6a21\u578b\u8bc4\u4ef7\u53ef\u89c6\u5316\u5de5\u5177</li> <li>\u53d1\u5e03\u7ea7\u522b\u56fe\u8868\u8f93\u51fa</li> <li>AWS S3\u96c6\u6210\u6a21\u5757 (<code>hydro_s3</code>)</li> <li>\u652f\u6301\u5927\u89c4\u6a21\u6c34\u6587\u6570\u636e\u4e91\u5b58\u50a8</li> <li>\u6279\u91cf\u6570\u636e\u4e0a\u4f20\u4e0b\u8f7d</li> <li>\u65e5\u5fd7\u5de5\u5177\u6a21\u5757 (<code>hydro_log</code>)</li> <li>\u4e13\u4e1a\u7684\u6c34\u6587\u5206\u6790\u65e5\u5fd7\u8bb0\u5f55</li> <li>\u6027\u80fd\u76d1\u63a7\u548c\u9519\u8bef\u8ffd\u8e2a</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>\u91cd\u6784\u4e86\u9879\u76ee\u7ed3\u6784\uff0c\u4f18\u5316\u6a21\u5757\u7ec4\u7ec7</li> <li>\u6539\u8fdb\u4e86\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387</li> <li>\u66f4\u65b0\u4e86\u6240\u6709\u4f9d\u8d56\u5305\u7684\u7248\u672c\u8981\u6c42</li> <li>\u7edf\u4e00\u4e86\u4ee3\u7801\u98ce\u683c\u548c\u6587\u6863\u683c\u5f0f</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>\u4fee\u590d\u4e86\u7edf\u8ba1\u8ba1\u7b97\u4e2d\u7684NaN\u503c\u5904\u7406\u95ee\u9898</li> <li>\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u5bf9\u9f50\u7684bug</li> <li>\u4fee\u6b63\u4e86\u5355\u4f4d\u8f6c\u6362\u7684\u7cbe\u5ea6\u95ee\u9898</li> <li>\u4f18\u5316\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u89e3\u51b3\u4e86\u5927\u6570\u636e\u5904\u7406\u65f6\u7684\u5185\u5b58\u6ea2\u51fa</li> </ul>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<ul> <li>\u79fb\u9664\u4e86\u8fc7\u65f6\u7684\u6570\u636e\u683c\u5f0f\u652f\u6301</li> <li>\u5e9f\u5f03\u4e86\u90e8\u5206\u4e0d\u63a8\u8350\u4f7f\u7528\u7684\u51fd\u6570\u63a5\u53e3</li> </ul>"},{"location":"changelog/#v0013-2025-07-15","title":"v0.0.13 - 2025-07-15","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>\u521d\u59cb\u7248\u672c\u53d1\u5e03</li> <li>\u57fa\u7840\u7684\u6c34\u6587\u7edf\u8ba1\u529f\u80fd</li> <li>\u7b80\u5355\u7684\u6570\u636e\u5904\u7406\u5de5\u5177</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>\u57fa\u7840\u529f\u80fd\u5b9e\u73b0\u548c\u6d4b\u8bd5</li> </ul>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#planned","title":"Planned","text":"<ul> <li>\u589e\u52a0\u673a\u5668\u5b66\u4e60\u6a21\u5757\u652f\u6301</li> <li>\u6dfb\u52a0\u66f4\u591a\u6c34\u6587\u6a21\u578b\u8bc4\u4ef7\u6307\u6807</li> <li>\u6539\u8fdb\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd</li> <li>\u4f18\u5316\u5927\u89c4\u6a21\u6570\u636e\u5904\u7406\u6027\u80fd</li> <li>\u6dfb\u52a0\u66f4\u591a\u5355\u5143\u6d4b\u8bd5\u548c\u96c6\u6210\u6d4b\u8bd5</li> </ul>"},{"location":"changelog/#version-number-guide","title":"Version Number Guide","text":"<ul> <li>MAJOR version (x.0.0) - \u4e0d\u517c\u5bb9\u7684API\u4fee\u6539</li> <li>MINOR version (0.x.0) - \u5411\u540e\u517c\u5bb9\u7684\u529f\u80fd\u6027\u65b0\u589e</li> <li>PATCH version (0.0.x) - \u5411\u540e\u517c\u5bb9\u7684\u95ee\u9898\u4fee\u590d</li> </ul>"},{"location":"changelog/#links","title":"Links","text":""},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/zhuanglaihong/hydroutils/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>hydroutils could always use more documentation, whether as part of the official hydroutils docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/zhuanglaihong/hydroutils/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up hydroutils for local development.</p> <ol> <li> <p>Fork the hydroutils repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/hydroutils.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv hydroutils\n$ cd hydroutils/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 hydroutils tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and     for PyPy. Check https://github.com/zhuanglaihong/hydroutils/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"faq/#q-how-do-i-install-hydroutils","title":"Q: How do I install hydroutils?","text":"<p>A: The easiest way is using pip: <pre><code>pip install hydroutils\n</code></pre></p> <p>For the latest development version: <pre><code>pip install git+https://github.com/zhuanglaihong/hydroutils.git\n</code></pre></p>"},{"location":"faq/#q-what-python-versions-are-supported","title":"Q: What Python versions are supported?","text":"<p>A: hydroutils supports Python 3.8 and higher. We recommend using Python 3.10 or later for the best performance and compatibility.</p>"},{"location":"faq/#q-im-getting-import-errors-what-should-i-do","title":"Q: I'm getting import errors. What should I do?","text":"<p>A: First, ensure all dependencies are installed: <pre><code>pip install --upgrade hydroutils\n</code></pre></p> <p>If you're still having issues, try installing in a fresh virtual environment: <pre><code>python -m venv hydroutils-env\nsource hydroutils-env/bin/activate  # On Windows: hydroutils-env\\Scripts\\activate\npip install hydroutils\n</code></pre></p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#q-how-do-i-calculate-basic-hydrological-statistics","title":"Q: How do I calculate basic hydrological statistics?","text":"<p>A: Use the <code>stat_error</code> function: <pre><code>import hydroutils as hu\nimport numpy as np\n\nobserved = np.array([10.5, 12.3, 8.7, 15.2, 11.8])\nsimulated = np.array([10.1, 12.8, 8.9, 14.7, 11.2])\n\nstats = hu.stat_error(observed, simulated)\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\nprint(f\"RMSE: {stats['RMSE'][0]:.3f}\")\n</code></pre></p>"},{"location":"faq/#q-can-i-handle-missing-data-nan-values","title":"Q: Can I handle missing data (NaN values)?","text":"<p>A: Yes, most functions automatically handle NaN values by excluding them from calculations: <pre><code>obs_with_nan = np.array([1.0, 2.0, np.nan, 4.0, 5.0])\nsim_with_nan = np.array([1.1, 2.2, 3.1, 4.2, np.nan])\n\n# This works fine - NaN values are automatically excluded\nstats = hu.stat_error(obs_with_nan, sim_with_nan)\n</code></pre></p>"},{"location":"faq/#q-how-do-i-convert-between-different-flow-units","title":"Q: How do I convert between different flow units?","text":"<p>A: Use the <code>streamflow_unit_conv</code> function: <pre><code># Convert from cubic meters per second to cubic feet per second\nflow_cms = np.array([10.5, 12.3, 8.7])\nflow_cfs = hu.streamflow_unit_conv(flow_cms, from_unit='cms', to_unit='cfs')\n</code></pre></p>"},{"location":"faq/#q-what-performance-metrics-are-available","title":"Q: What performance metrics are available?","text":"<p>A: hydroutils provides many standard hydrological metrics: - NSE: Nash-Sutcliffe Efficiency - KGE: Kling-Gupta Efficiency - RMSE: Root Mean Square Error - Bias: Mean Error - Corr: Pearson Correlation Coefficient - R2: Coefficient of Determination - FHV/FLV: High/Low Flow Volume metrics</p>"},{"location":"faq/#data-processing","title":"Data Processing","text":""},{"location":"faq/#q-how-do-i-process-multiple-time-series-at-once","title":"Q: How do I process multiple time series at once?","text":"<p>A: Use the <code>stat_errors</code> function for batch processing: <pre><code># Multiple stations data (5 stations, 100 time steps each)\nobserved_series = np.random.rand(5, 100)\nsimulated_series = observed_series + np.random.normal(0, 0.1, (5, 100))\n\n# Calculate statistics for all series\nall_stats = hu.stat_errors(observed_series, simulated_series)\n\n# Extract NSE values for all stations\nnse_values = [stats['NSE'][0] for stats in all_stats]\n</code></pre></p>"},{"location":"faq/#q-can-i-work-with-pandas-dataframes","title":"Q: Can I work with pandas DataFrames?","text":"<p>A: Yes, you can easily work with pandas DataFrames: <pre><code>import pandas as pd\n\n# Convert DataFrame columns to numpy arrays\ndf = pd.read_csv('streamflow_data.csv')\nobs = df['observed'].values\nsim = df['simulated'].values\n\nstats = hu.stat_error(obs, sim)\n</code></pre></p>"},{"location":"faq/#q-how-do-i-handle-different-time-intervals","title":"Q: How do I handle different time intervals?","text":"<p>A: Use the time processing functions: <pre><code># Detect time interval automatically\ntime_series = pd.date_range('2020-01-01', periods=100, freq='D')\ninterval = hu.detect_time_interval(time_series)\n\n# Validate unit compatibility\nis_compatible = hu.validate_unit_compatibility('cms', 'streamflow')\n</code></pre></p>"},{"location":"faq/#visualization","title":"Visualization","text":""},{"location":"faq/#q-how-do-i-create-basic-plots","title":"Q: How do I create basic plots?","text":"<p>A: Use the hydro_plot module: <pre><code>import matplotlib.pyplot as plt\n\n# Time series plot\nfig, ax = hu.plot_timeseries(\n    dates, observed, simulated,\n    labels=['Observed', 'Simulated'],\n    title='Streamflow Comparison'\n)\nplt.show()\n\n# Performance scatter plot\nfig, ax = hu.plot_scatter_performance(\n    observed, simulated,\n    add_stats=True,\n    add_1to1_line=True\n)\nplt.show()\n</code></pre></p>"},{"location":"faq/#q-can-i-customize-plot-appearance","title":"Q: Can I customize plot appearance?","text":"<p>A: Yes, hydroutils provides several styling options: <pre><code># Set hydrological plot style\nhu.set_hydro_plot_style()\n\n# Use hydrological color schemes\ncolors = hu.get_hydro_colors(data_type='streamflow')\n</code></pre></p>"},{"location":"faq/#advanced-features","title":"Advanced Features","text":""},{"location":"faq/#q-how-do-i-use-aws-s3-integration","title":"Q: How do I use AWS S3 integration?","text":"<p>A: First configure your AWS credentials, then use S3 functions: <pre><code># Upload data to S3\nhu.upload_to_s3(\n    local_file='data.csv',\n    bucket='my-hydro-data',\n    s3_key='station_001/data.csv'\n)\n\n# Download from S3\nhu.download_from_s3(\n    bucket='my-hydro-data',\n    s3_key='station_001/data.csv',\n    local_file='downloaded_data.csv'\n)\n</code></pre></p>"},{"location":"faq/#q-how-do-i-enable-logging-for-my-analysis","title":"Q: How do I enable logging for my analysis?","text":"<p>A: Use the logging utilities: <pre><code># Setup logger\nlogger = hu.setup_hydro_logger(\n    name='my_analysis',\n    log_file='analysis.log',\n    level='INFO'\n)\n\n# Log your analysis steps\nlogger.info(\"Starting streamflow analysis\")\nstats = hu.stat_error(observed, simulated)\nlogger.info(f\"NSE calculated: {stats['NSE'][0]:.3f}\")\n</code></pre></p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#q-im-getting-unexpected-nse-values-what-could-be-wrong","title":"Q: I'm getting unexpected NSE values. What could be wrong?","text":"<p>A: Check these common issues: 1. Data alignment: Ensure observed and simulated data have the same time periods 2. Missing values: Make sure missing data is properly handled 3. Data quality: Check for outliers or unrealistic values 4. Array dimensions: Verify that arrays have the same shape</p> <pre><code># Debug your data\nprint(f\"Observed shape: {observed.shape}\")\nprint(f\"Simulated shape: {simulated.shape}\")\nprint(f\"NaN count in observed: {np.isnan(observed).sum()}\")\nprint(f\"NaN count in simulated: {np.isnan(simulated).sum()}\")\n</code></pre>"},{"location":"faq/#q-why-am-i-getting-poor-performance-metrics","title":"Q: Why am I getting poor performance metrics?","text":"<p>A: Consider these factors: 1. Model quality: The underlying model may need improvement 2. Data period: Performance can vary by season or flow conditions 3. Metric selection: Different metrics emphasize different aspects of performance 4. Data preprocessing: Check if data normalization or transformation is needed</p>"},{"location":"faq/#q-functions-are-running-slowly-how-can-i-improve-performance","title":"Q: Functions are running slowly. How can I improve performance?","text":"<p>A: Try these optimization strategies: 1. Use appropriate data types: Convert to float32 if high precision isn't needed 2. Process in chunks: For very large datasets, process data in smaller chunks 3. Vectorize operations: Use NumPy operations instead of loops 4. Consider memory usage: Monitor memory consumption for large arrays</p> <pre><code># Example of chunked processing\ndef process_large_dataset(large_array, chunk_size=10000):\n    results = []\n    for i in range(0, len(large_array), chunk_size):\n        chunk = large_array[i:i+chunk_size]\n        result = hu.stat_error(chunk['obs'], chunk['sim'])\n        results.append(result)\n    return results\n</code></pre>"},{"location":"faq/#getting-help","title":"Getting Help","text":""},{"location":"faq/#q-where-can-i-find-more-examples","title":"Q: Where can I find more examples?","text":"<p>A: Check these resources: 1. Usage Guide: Detailed examples in the Usage section 2. API Documentation: Complete function reference in API Reference 3. GitHub Examples: Example notebooks in the repository 4. Community: Ask questions in GitHub Issues</p>"},{"location":"faq/#q-how-do-i-report-bugs-or-request-features","title":"Q: How do I report bugs or request features?","text":"<p>A: Please use the GitHub Issues: 1. Bug Reports: Create a bug report 2. Feature Requests: Request a new feature 3. Questions: Use the Discussions section</p>"},{"location":"faq/#q-can-i-contribute-to-the-project","title":"Q: Can I contribute to the project?","text":"<p>A: Yes! We welcome contributions. See the Contributing Guide for details on: - Setting up a development environment - Code style guidelines - Testing requirements - Submitting pull requests</p>"},{"location":"faq/#q-is-there-a-citation-for-academic-use","title":"Q: Is there a citation for academic use?","text":"<p>A: Yes, if you use hydroutils in academic research, please cite: <pre><code>@software{hydroutils,\n  author = {Your Name},\n  title = {hydroutils: A Python package for hydrological analysis},\n  url = {https://github.com/zhuanglaihong/hydroutils},\n  version = {X.X.X},\n  year = {2024}\n}\n</code></pre></p>"},{"location":"faq/#still-need-help","title":"Still Need Help?","text":"<p>If your question isn't answered here:</p> <ol> <li>Search existing issues: GitHub Issues</li> <li>Ask a question: GitHub Discussions</li> <li>Email support: [Contact Information]</li> </ol> <p>We're here to help you succeed with your hydrological analysis!</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<p><code>hydroutils</code> requires Python 3.8 or higher. The package has been tested on:</p> <ul> <li>Python 3.8, 3.9, 3.10, 3.11</li> <li>Windows, macOS, and Linux</li> </ul>"},{"location":"installation/#core-dependencies","title":"Core Dependencies","text":"<p>The following packages are automatically installed:</p> <ul> <li><code>numpy</code> - Array operations and mathematical functions</li> <li><code>pandas</code> - Data manipulation and analysis</li> <li><code>scipy</code> - Scientific computing</li> <li><code>matplotlib</code> - Plotting and visualization</li> <li><code>xarray</code> - Labeled multi-dimensional arrays</li> <li><code>netCDF4</code> - NetCDF file handling</li> <li><code>HydroErr</code> - Hydrological error metrics</li> </ul>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For extended functionality:</p> <ul> <li><code>boto3</code> - AWS S3 integration (for cloud features)</li> <li><code>jupyter</code> - For notebook examples</li> </ul>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#1-stable-release-recommended","title":"1. Stable Release (Recommended)","text":"<p>Install the latest stable release from PyPI:</p> <pre><code>pip install hydroutils\n</code></pre> <p>This is the preferred method as it installs the most recent stable release with all dependencies.</p>"},{"location":"installation/#2-development-version","title":"2. Development Version","text":"<p>For the latest features and bug fixes, install from GitHub:</p> <pre><code>pip install git+https://github.com/zhuanglaihong/hydroutils.git\n</code></pre>"},{"location":"installation/#3-from-source","title":"3. From Source","text":"<p>If you want to contribute or modify the code:</p> <pre><code># Clone the repository\ngit clone https://github.com/zhuanglaihong/hydroutils.git\ncd hydroutils\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"installation/#4-with-optional-dependencies","title":"4. With Optional Dependencies","text":"<p>To install with all optional dependencies:</p> <pre><code>pip install hydroutils[all]\n</code></pre> <p>Or install specific optional dependencies:</p> <pre><code>pip install hydroutils[aws]     # For S3 functionality\npip install hydroutils[viz]     # For advanced visualization\npip install hydroutils[dev]     # For development tools\n</code></pre>"},{"location":"installation/#virtual-environment-setup","title":"Virtual Environment Setup","text":"<p>We recommend using a virtual environment to avoid dependency conflicts:</p>"},{"location":"installation/#using-conda","title":"Using conda","text":"<pre><code># Create a new environment\nconda create -n hydroutils python=3.10\nconda activate hydroutils\n\n# Install hydroutils\npip install hydroutils\n</code></pre>"},{"location":"installation/#using-venv","title":"Using venv","text":"<pre><code># Create a new environment\npython -m venv hydroutils-env\n\n# Activate the environment\n# On Windows:\nhydroutils-env\\Scripts\\activate\n# On macOS/Linux:\nsource hydroutils-env/bin/activate\n\n# Install hydroutils\npip install hydroutils\n</code></pre>"},{"location":"installation/#verification","title":"Verification","text":"<p>Test your installation:</p> <pre><code>import hydroutils as hu\nprint(hu.__version__)\n\n# Quick functionality test\nimport numpy as np\nobs = np.random.rand(100)\nsim = obs + np.random.normal(0, 0.1, 100)\nstats = hu.stat_error(obs, sim)\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Import Error: Make sure all dependencies are installed:    <pre><code>pip install --upgrade hydroutils\n</code></pre></p> </li> <li> <p>Permission Denied: Use <code>--user</code> flag:    <pre><code>pip install --user hydroutils\n</code></pre></p> </li> <li> <p>SSL Certificate Error: Try with trusted hosts:    <pre><code>pip install --trusted-host pypi.org --trusted-host pypi.python.org hydroutils\n</code></pre></p> </li> </ol>"},{"location":"installation/#platform-specific-notes","title":"Platform-Specific Notes","text":"<p>Windows Users: - Consider using Anaconda for easier scientific package management - Some dependencies may require Visual C++ Build Tools</p> <p>macOS Users: - Xcode command line tools may be required for some dependencies - Use Homebrew to install system-level dependencies if needed</p> <p>Linux Users: - Install system dependencies for scientific packages:   <pre><code># Ubuntu/Debian\nsudo apt-get install python3-dev gfortran libopenblas-dev\n\n# CentOS/RHEL\nsudo yum install python3-devel gcc-gfortran openblas-devel\n</code></pre></p>"},{"location":"installation/#getting-help","title":"Getting Help","text":"<p>If you encounter any installation issues:</p> <ol> <li>Check the FAQ for common solutions</li> <li>Search existing issues</li> <li>Create a new issue with:</li> <li>Your operating system and Python version</li> <li>Complete error message</li> <li>Steps to reproduce the problem</li> </ol>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide provides practical examples of how to use <code>hydroutils</code> for common hydrological analysis tasks.</p>"},{"location":"usage/#getting-started","title":"Getting Started","text":"<pre><code>import hydroutils as hu\nimport numpy as np\nimport pandas as pd\n</code></pre>"},{"location":"usage/#1-statistical-analysis","title":"1. Statistical Analysis","text":""},{"location":"usage/#basic-hydrological-statistics","title":"Basic Hydrological Statistics","text":"<p>Calculate common hydrological performance metrics:</p> <pre><code># Sample data\nobserved = np.array([10.5, 12.3, 8.7, 15.2, 11.8, 9.4, 13.6])\nsimulated = np.array([10.1, 12.8, 8.9, 14.7, 11.2, 9.8, 13.1])\n\n# Calculate comprehensive statistics\nstats = hu.stat_error(observed, simulated)\n\nprint(f\"Nash-Sutcliffe Efficiency (NSE): {stats['NSE'][0]:.3f}\")\nprint(f\"Root Mean Square Error (RMSE): {stats['RMSE'][0]:.3f}\")\nprint(f\"Bias: {stats['Bias'][0]:.3f}\")\nprint(f\"Correlation: {stats['Corr'][0]:.3f}\")\nprint(f\"Kling-Gupta Efficiency (KGE): {stats['KGE'][0]:.3f}\")\n</code></pre>"},{"location":"usage/#kling-gupta-efficiency","title":"Kling-Gupta Efficiency","text":"<p>Calculate KGE individually:</p> <pre><code>kge_value = hu.KGE(simulated, observed)\nprint(f\"KGE: {kge_value:.3f}\")\n</code></pre>"},{"location":"usage/#flow-duration-curve-analysis","title":"Flow Duration Curve Analysis","text":"<pre><code># Calculate flow duration curve slope\nfms_value = hu.fms(observed, simulated, lower=0.2, upper=0.7)\nprint(f\"Flow Duration Curve Middle Slope: {fms_value:.3f}\")\n</code></pre>"},{"location":"usage/#2-time-series-processing","title":"2. Time Series Processing","text":""},{"location":"usage/#unit-conversions","title":"Unit Conversions","text":"<p>Convert between different streamflow units:</p> <pre><code># Convert cubic meters per second to cubic feet per second\nflow_cms = np.array([10.5, 12.3, 8.7, 15.2])\nflow_cfs = hu.streamflow_unit_conv(flow_cms, from_unit='cms', to_unit='cfs')\nprint(f\"Flow in CFS: {flow_cfs}\")\n\n# Detect time interval\ntime_series = pd.date_range('2020-01-01', periods=100, freq='D')\ninterval = hu.detect_time_interval(time_series)\nprint(f\"Detected interval: {interval}\")\n</code></pre>"},{"location":"usage/#time-interval-validation","title":"Time Interval Validation","text":"<pre><code># Validate unit compatibility\nis_compatible = hu.validate_unit_compatibility('cms', 'streamflow')\nprint(f\"CMS compatible with streamflow: {is_compatible}\")\n\n# Get time interval information\ninterval_info = hu.get_time_interval_info('1D')\nprint(f\"Daily interval info: {interval_info}\")\n</code></pre>"},{"location":"usage/#3-data-processing-with-files","title":"3. Data Processing with Files","text":""},{"location":"usage/#reading-and-processing-data","title":"Reading and Processing Data","text":"<pre><code># Example of processing a CSV file with hydrological data\ndata = pd.read_csv('streamflow_data.csv', parse_dates=['date'])\n\n# Calculate statistics for multiple stations\nstations = ['station_001', 'station_002', 'station_003']\nresults = {}\n\nfor station in stations:\n    if f'{station}_obs' in data.columns and f'{station}_sim' in data.columns:\n        obs = data[f'{station}_obs'].dropna()\n        sim = data[f'{station}_sim'].dropna()\n\n        # Align data\n        min_length = min(len(obs), len(sim))\n        obs = obs[:min_length]\n        sim = sim[:min_length]\n\n        results[station] = hu.stat_error(obs.values, sim.values)\n\n# Display results\nfor station, stats in results.items():\n    print(f\"\\n{station}:\")\n    print(f\"  NSE: {stats['NSE'][0]:.3f}\")\n    print(f\"  RMSE: {stats['RMSE'][0]:.3f}\")\n</code></pre>"},{"location":"usage/#4-advanced-statistical-analysis","title":"4. Advanced Statistical Analysis","text":""},{"location":"usage/#statistical-transformations","title":"Statistical Transformations","text":"<pre><code># Calculate statistical properties\nflow_data = np.random.lognormal(2, 1, 1000)  # Log-normal distributed flow\n\n# Basic statistics\nbasic_stats = hu.cal_stat(flow_data)\nprint(f\"Basic statistics: {basic_stats}\")\n\n# Gamma transformation statistics\ngamma_stats = hu.cal_stat_gamma(flow_data)\nprint(f\"Gamma-transformed statistics: {gamma_stats}\")\n\n# Four key statistical indices\nfour_stats = hu.cal_4_stat_inds(flow_data)\nprint(f\"P10, P90, Mean, Std: {four_stats}\")\n</code></pre>"},{"location":"usage/#empirical-cumulative-distribution-function","title":"Empirical Cumulative Distribution Function","text":"<pre><code># Calculate ECDF\nsorted_data, probabilities = hu.ecdf(flow_data)\n\n# Plot ECDF (requires matplotlib)\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8, 6))\nplt.plot(sorted_data, probabilities)\nplt.xlabel('Flow')\nplt.ylabel('Probability')\nplt.title('Empirical Cumulative Distribution Function')\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"usage/#5-working-with-multiple-time-series","title":"5. Working with Multiple Time Series","text":""},{"location":"usage/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple time series\nobserved_series = np.random.rand(5, 100)  # 5 stations, 100 time steps\nsimulated_series = observed_series + np.random.normal(0, 0.1, (5, 100))\n\n# Calculate statistics for all series\nall_stats = hu.stat_errors(observed_series, simulated_series)\n\n# Extract NSE values for all stations\nnse_values = [stats['NSE'][0] for stats in all_stats]\nprint(f\"NSE values for all stations: {nse_values}\")\n</code></pre>"},{"location":"usage/#6-practical-example-complete-workflow","title":"6. Practical Example: Complete Workflow","text":"<p>Here's a complete example of a typical hydrological analysis workflow:</p> <pre><code>import hydroutils as hu\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 1. Load data\ndef load_sample_data():\n    \"\"\"Generate sample hydrological data\"\"\"\n    dates = pd.date_range('2020-01-01', '2022-12-31', freq='D')\n    # Simulate observed streamflow with seasonal pattern\n    base_flow = 10 + 5 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\n    observed = base_flow + np.random.normal(0, 2, len(dates))\n\n    # Simulate model predictions with some bias and error\n    simulated = observed * 0.95 + np.random.normal(0, 1.5, len(dates))\n\n    return pd.DataFrame({\n        'date': dates,\n        'observed': observed,\n        'simulated': simulated\n    })\n\n# 2. Load and prepare data\ndf = load_sample_data()\nprint(f\"Data shape: {df.shape}\")\nprint(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n\n# 3. Calculate comprehensive statistics\nstats = hu.stat_error(df['observed'].values, df['simulated'].values)\n\nprint(\"\\nPerformance Metrics:\")\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\nprint(f\"KGE: {stats['KGE'][0]:.3f}\")\nprint(f\"RMSE: {stats['RMSE'][0]:.3f}\")\nprint(f\"Bias: {stats['Bias'][0]:.3f}\")\nprint(f\"Correlation: {stats['Corr'][0]:.3f}\")\n\n# 4. Additional analysis\nkge_individual = hu.KGE(df['simulated'].values, df['observed'].values)\nprint(f\"KGE (individual calculation): {kge_individual:.3f}\")\n\n# 5. Unit conversion example\nflow_cfs = hu.streamflow_unit_conv(df['observed'].values, 'cms', 'cfs')\nprint(f\"Mean flow: {df['observed'].mean():.1f} cms = {flow_cfs.mean():.1f} cfs\")\n\n# 6. Visualization (optional)\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(df['date'], df['observed'], label='Observed', alpha=0.7)\nplt.plot(df['date'], df['simulated'], label='Simulated', alpha=0.7)\nplt.ylabel('Streamflow (cms)')\nplt.title('Time Series Comparison')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(2, 1, 2)\nplt.scatter(df['observed'], df['simulated'], alpha=0.5)\nplt.plot([df['observed'].min(), df['observed'].max()], \n         [df['observed'].min(), df['observed'].max()], 'r--')\nplt.xlabel('Observed (cms)')\nplt.ylabel('Simulated (cms)')\nplt.title(f'Scatter Plot (NSE: {stats[\"NSE\"][0]:.3f})')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nAnalysis complete!\")\n</code></pre>"},{"location":"usage/#7-error-handling-and-best-practices","title":"7. Error Handling and Best Practices","text":""},{"location":"usage/#handling-missing-data","title":"Handling Missing Data","text":"<pre><code># Sample data with NaN values\nobs_with_nan = np.array([1.0, 2.0, np.nan, 4.0, 5.0])\nsim_with_nan = np.array([1.1, 2.2, 3.1, 4.2, np.nan])\n\n# The stat_error function automatically handles NaN values\ntry:\n    stats = hu.stat_error(obs_with_nan, sim_with_nan)\n    print(\"Statistics calculated successfully with NaN handling\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"usage/#data-validation","title":"Data Validation","text":"<pre><code># Validate input data before analysis\ndef validate_data(observed, simulated):\n    \"\"\"Validate input data for hydrological analysis\"\"\"\n\n    if len(observed) != len(simulated):\n        raise ValueError(\"Observed and simulated data must have same length\")\n\n    if len(observed) == 0:\n        raise ValueError(\"Data arrays cannot be empty\")\n\n    valid_obs = ~np.isnan(observed)\n    valid_sim = ~np.isnan(simulated)\n    valid_both = valid_obs &amp; valid_sim\n\n    if np.sum(valid_both) &lt; 10:\n        print(\"Warning: Less than 10 valid data points\")\n\n    return valid_both\n\n# Example usage\nobs = np.random.rand(100)\nsim = obs + np.random.normal(0, 0.1, 100)\n\n# Add some NaN values\nobs[5:10] = np.nan\nsim[15:20] = np.nan\n\nvalid_mask = validate_data(obs, sim)\nprint(f\"Valid data points: {np.sum(valid_mask)}/{len(obs)}\")\n</code></pre>"},{"location":"usage/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the complete API Reference for all available functions</li> <li>Check out specific module documentation for specialized features</li> <li>See Contributing Guidelines if you want to add new features</li> <li>Visit FAQ for common questions and troubleshooting</li> </ul>"},{"location":"api/hydro_arithmetric/","title":"hydro_arithmetric - Mathematical Operations","text":"<p>The <code>hydro_arithmetric</code> module provides mathematical utilities and operations specifically designed for hydrological calculations.</p>"},{"location":"api/hydro_arithmetric/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>Array Operations: Optimized array manipulations for hydrological data</li> <li>Mathematical Transformations: Apply mathematical functions to time series</li> <li>Numerical Methods: Specialized numerical algorithms for hydrology</li> <li>Unit Calculations: Mathematical operations involving different units</li> </ul>"},{"location":"api/hydro_arithmetric/#core-functions","title":"Core Functions","text":"<p>Author: Wenyu Ouyang Date: 2023-07-29 14:07:03 LastEditTime: 2023-07-29 14:08:22 LastEditors: Wenyu Ouyang Description: some common arithmetric calculations FilePath: /hydroutils/hydroutils/hydro_arithmetric.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_arithmetric/#hydroutils.hydro_arithmetric.random_choice_no_return","title":"<code>random_choice_no_return(arr, num_lst)</code>","text":"<p>sampling without replacement multi-times, and the num of each time is in num_lst</p> Source code in <code>hydroutils/hydro_arithmetric.py</code> <pre><code>def random_choice_no_return(arr, num_lst):\n    \"\"\"sampling without replacement multi-times, and the num of each time is in num_lst\"\"\"\n    num_lst_arr = np.array(num_lst)\n    num_sum = num_lst_arr.sum()\n    if type(arr) == list:\n        arr = np.array(arr)\n    assert num_sum &lt;= arr.size\n    results = []\n    arr_residue = np.arange(arr.size)\n    for num in num_lst_arr:\n        idx_chosen = np.random.choice(arr_residue.size, num, replace=False)\n        chosen_idx_in_arr = np.sort(arr_residue[idx_chosen])\n        results.append(arr[chosen_idx_in_arr])\n        arr_residue = np.delete(arr_residue, idx_chosen)\n    return results\n</code></pre>"},{"location":"api/hydro_arithmetric/#key-features","title":"Key Features","text":""},{"location":"api/hydro_arithmetric/#array-manipulations","title":"Array Manipulations","text":"<p>Efficient operations on multi-dimensional arrays representing spatial and temporal hydrological data.</p>"},{"location":"api/hydro_arithmetric/#mathematical-transformations","title":"Mathematical Transformations","text":"<p>Apply logarithmic, exponential, and other transformations commonly used in hydrology.</p>"},{"location":"api/hydro_arithmetric/#numerical-integration","title":"Numerical Integration","text":"<p>Integrate flow data over time periods to calculate volumes.</p>"},{"location":"api/hydro_arithmetric/#statistical-transformations","title":"Statistical Transformations","text":"<p>Transform data to improve statistical properties for modeling.</p>"},{"location":"api/hydro_arithmetric/#usage-examples","title":"Usage Examples","text":""},{"location":"api/hydro_arithmetric/#basic-array-operations","title":"Basic Array Operations","text":"<pre><code>import hydroutils as hu\nimport numpy as np\n\n# Sample hydrological data\nflow_data = np.random.lognormal(2, 1, 1000)\n\n# Apply logarithmic transformation\nlog_flow = hu.log_transform(flow_data)\n\n# Calculate moving averages\nsmoothed = hu.moving_average(flow_data, window=7)\n</code></pre>"},{"location":"api/hydro_arithmetric/#volume-calculations","title":"Volume Calculations","text":"<pre><code># Calculate flow volume over time\ntime_step_hours = 24  # Daily data\nvolume = hu.flow_to_volume(flow_data, time_step_hours)\n\n# Unit conversion with mathematical operations\nvolume_acre_feet = hu.convert_volume(volume, 'cubic_meters', 'acre_feet')\n</code></pre>"},{"location":"api/hydro_arithmetric/#data-normalization","title":"Data Normalization","text":"<pre><code># Normalize data for modeling\nnormalized = hu.normalize_data(flow_data, method='z_score')\n\n# Standardize to [0, 1] range  \nstandardized = hu.standardize_data(flow_data, method='min_max')\n</code></pre>"},{"location":"api/hydro_arithmetric/#mathematical-functions","title":"Mathematical Functions","text":""},{"location":"api/hydro_arithmetric/#transformations","title":"Transformations","text":"<ul> <li>Logarithmic: Natural log and log10 transformations</li> <li>Box-Cox: Power transformations to normalize distributions</li> <li>Inverse: Reciprocal transformations for extreme values</li> </ul>"},{"location":"api/hydro_arithmetric/#smoothing-operations","title":"Smoothing Operations","text":"<ul> <li>Moving Average: Simple and weighted moving averages</li> <li>Exponential Smoothing: Time-weighted smoothing</li> <li>Savitzky-Golay: Polynomial smoothing filter</li> </ul>"},{"location":"api/hydro_arithmetric/#integration-methods","title":"Integration Methods","text":"<ul> <li>Trapezoidal Rule: For irregular time intervals</li> <li>Simpson's Rule: Higher accuracy integration</li> <li>Cumulative Integration: Running totals over time</li> </ul>"},{"location":"api/hydro_arithmetric/#special-hydrological-calculations","title":"Special Hydrological Calculations","text":""},{"location":"api/hydro_arithmetric/#flow-statistics","title":"Flow Statistics","text":"<p>Calculate specialized flow statistics used in hydrology:</p> <ul> <li>Peak flow analysis</li> <li>Base flow separation  </li> <li>Flow percentiles and quantiles</li> <li>Recession curve analysis</li> </ul>"},{"location":"api/hydro_arithmetric/#water-balance-components","title":"Water Balance Components","text":"<p>Mathematical operations for water balance calculations:</p> <ul> <li>Evapotranspiration estimates</li> <li>Precipitation-runoff relationships</li> <li>Storage change calculations</li> </ul>"},{"location":"api/hydro_arithmetric/#usage-tips","title":"Usage Tips","text":""},{"location":"api/hydro_arithmetric/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Use vectorized operations for large datasets</li> <li>Leverage NumPy broadcasting for multi-dimensional data</li> <li>Consider memory usage for very large arrays</li> </ul>"},{"location":"api/hydro_arithmetric/#numerical-precision","title":"Numerical Precision","text":"<ul> <li>Be aware of floating-point precision limitations</li> <li>Use appropriate data types for calculations</li> <li>Validate results for extreme values</li> </ul>"},{"location":"api/hydro_arithmetric/#function-reference","title":"Function Reference","text":"<p>The module provides functions for:</p> <ul> <li>Transformations: <code>log_transform()</code>, <code>box_cox_transform()</code>, <code>normalize_data()</code></li> <li>Array Operations: <code>moving_average()</code>, <code>smooth_data()</code>, <code>interpolate_missing()</code></li> <li>Volume Calculations: <code>flow_to_volume()</code>, <code>volume_integration()</code>, <code>convert_volume()</code></li> <li>Statistics: <code>calculate_percentiles()</code>, <code>extreme_value_analysis()</code>, <code>trend_analysis()</code></li> </ul> <p>For detailed function signatures and parameters, see the complete API documentation below.</p>"},{"location":"api/hydro_file/","title":"hydro_file - File I/O Operations","text":"<p>The <code>hydro_file</code> module provides utilities for reading, writing, and processing various file formats commonly used in hydrological applications.</p>"},{"location":"api/hydro_file/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>NetCDF Operations: Read and write NetCDF files</li> <li>CSV Processing: Handle CSV files with hydrological data</li> <li>Data Format Conversion: Convert between different file formats</li> <li>File Utilities: Various file manipulation functions</li> </ul>"},{"location":"api/hydro_file/#core-functions","title":"Core Functions","text":"<p>Author: Wenyu Ouyang Date: 2024-08-15 10:08:59 LastEditTime: 2025-02-02 06:27:44 LastEditors: Wenyu Ouyang Description: some methods for file operations FilePath: /hydroutils/hydroutils/hydro_file.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_file/#hydroutils.hydro_file.download_excel","title":"<code>download_excel(data_url, temp_file)</code>","text":"<p>download a excel file according to url</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_excel(data_url, temp_file):\n    \"\"\"download a excel file according to url\"\"\"\n    if not os.path.isfile(temp_file):\n        urllib.request.urlretrieve(data_url, temp_file)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.download_one_zip","title":"<code>download_one_zip(data_url, data_dir)</code>","text":"<p>download one zip file from url as data_file Parameters</p> <p>data_url: the URL of the downloading website data_dir: where we will put the data</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_one_zip(data_url, data_dir):\n    \"\"\"\n    download one zip file from url as data_file\n    Parameters\n    ----------\n    data_url: the URL of the downloading website\n    data_dir: where we will put the data\n    \"\"\"\n\n    zipfile_path, unzip_dir = zip_file_name_from_url(data_url, data_dir)\n    if not is_there_file(zipfile_path, unzip_dir):\n        if not os.path.isdir(unzip_dir):\n            os.makedirs(unzip_dir)\n        r = requests.get(data_url, stream=True)\n        with open(zipfile_path, \"wb\") as py_file:\n            for chunk in r.iter_content(chunk_size=1024):  # 1024 bytes\n                if chunk:\n                    py_file.write(chunk)\n        unzip_nested_zip(zipfile_path, unzip_dir)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.download_small_file","title":"<code>download_small_file(data_url, temp_file)</code>","text":"<p>download data from url to the temp_file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_small_file(data_url, temp_file):\n    \"\"\"download data from url to the temp_file\"\"\"\n    r = requests.get(data_url)\n    with open(temp_file, \"w\") as f:\n        f.write(r.text)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.download_small_zip","title":"<code>download_small_zip(data_url, data_dir)</code>","text":"<p>download zip file and unzip</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_small_zip(data_url, data_dir):\n    \"\"\"download zip file and unzip\"\"\"\n    zipfile_path, unzip_dir = zip_file_name_from_url(data_url, data_dir)\n    if not is_there_file(zipfile_path, unzip_dir):\n        if not os.path.isdir(unzip_dir):\n            os.mkdir(unzip_dir)\n        zipfile_path, _ = urllib.request.urlretrieve(data_url, zipfile_path)\n        unzip_nested_zip(zipfile_path, unzip_dir)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.download_zip_files","title":"<code>download_zip_files(urls, the_dir)</code>","text":"<p>Download multi-files from multi-urls</p>"},{"location":"api/hydro_file/#hydroutils.hydro_file.download_zip_files--parameters","title":"Parameters","text":"<p>urls : list     list of all urls the_dir : Path     the directory containing all downloaded files</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_zip_files(urls, the_dir: Path):\n    \"\"\"Download multi-files from multi-urls\n\n    Parameters\n    ----------\n    urls : list\n        list of all urls\n    the_dir : Path\n        the directory containing all downloaded files\n    \"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        cache_names = Path(tmpdir).joinpath(f\"{the_dir.stem}.sqlite\")\n        r = ar.retrieve(urls, \"binary\", cache_name=cache_names, ssl=False)\n        files = [the_dir.joinpath(url.split(\"/\")[-1]) for url in urls]\n        [files[i].write_bytes(io.BytesIO(r[i]).getbuffer()) for i in range(len(files))]\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.get_lastest_file_in_a_dir","title":"<code>get_lastest_file_in_a_dir(dir_path)</code>","text":"<p>Get the last file in a directory</p>"},{"location":"api/hydro_file/#hydroutils.hydro_file.get_lastest_file_in_a_dir--parameters","title":"Parameters","text":"<p>dir_path : str     the directory</p>"},{"location":"api/hydro_file/#hydroutils.hydro_file.get_lastest_file_in_a_dir--returns","title":"Returns","text":"<p>str     the path of the weight file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_lastest_file_in_a_dir(dir_path):\n    \"\"\"Get the last file in a directory\n\n    Parameters\n    ----------\n    dir_path : str\n        the directory\n\n    Returns\n    -------\n    str\n        the path of the weight file\n    \"\"\"\n    pth_files_lst = [\n        os.path.join(dir_path, file)\n        for file in os.listdir(dir_path)\n        if fnmatch.fnmatch(file, \"*.pth\")\n    ]\n    return get_latest_file_in_a_lst(pth_files_lst)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.get_latest_file_in_a_lst","title":"<code>get_latest_file_in_a_lst(lst)</code>","text":"<p>get the latest file in a list</p>"},{"location":"api/hydro_file/#hydroutils.hydro_file.get_latest_file_in_a_lst--parameters","title":"Parameters","text":"<p>lst : list     list of files</p>"},{"location":"api/hydro_file/#hydroutils.hydro_file.get_latest_file_in_a_lst--returns","title":"Returns","text":"<p>str     the latest file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_latest_file_in_a_lst(lst):\n    \"\"\"get the latest file in a list\n\n    Parameters\n    ----------\n    lst : list\n        list of files\n\n    Returns\n    -------\n    str\n        the latest file\n    \"\"\"\n    lst_ctime = [os.path.getctime(file) for file in lst]\n    sort_idx = np.argsort(lst_ctime)\n    return lst[sort_idx[-1]]\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.is_there_file","title":"<code>is_there_file(zipfile_path, unzip_dir)</code>","text":"<p>if a file has existed</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def is_there_file(zipfile_path, unzip_dir):\n    \"\"\"if a file has existed\"\"\"\n    if os.path.isfile(zipfile_path):\n        if os.path.isdir(unzip_dir):\n            return True\n        unzip_nested_zip(zipfile_path, unzip_dir)\n        return True\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.unzip_file","title":"<code>unzip_file(data_zip, path_unzip)</code>","text":"<p>extract a zip file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unzip_file(data_zip, path_unzip):\n    \"\"\"extract a zip file\"\"\"\n    with zipfile.ZipFile(data_zip, \"r\") as zip_temp:\n        zip_temp.extractall(path_unzip)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.unzip_nested_zip","title":"<code>unzip_nested_zip(dataset_zip, path_unzip)</code>","text":"<p>Extract a zip file including any nested zip files If a file's name is \"xxx_\", it seems the \"extractall\" function in the \"zipfile\" lib will throw an OSError, so please check the unzipped files manually when this occurs. Parameters</p> <p>dataset_zip: the zip file path_unzip: where it is unzipped</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unzip_nested_zip(dataset_zip, path_unzip):\n    \"\"\"\n    Extract a zip file including any nested zip files\n    If a file's name is \"xxx_\", it seems the \"extractall\" function in the \"zipfile\" lib will throw an OSError,\n    so please check the unzipped files manually when this occurs.\n    Parameters\n    ----------\n    dataset_zip: the zip file\n    path_unzip: where it is unzipped\n    \"\"\"\n\n    with zipfile.ZipFile(dataset_zip, \"r\") as zfile:\n        try:\n            zfile.extractall(path=path_unzip)\n        except OSError as e:\n            logging.warning(\n                \"Please check the unzipped files manually. There may be some missed important files.\"\n            )\n            logging.warning(f\"The directory is: {path_unzip}\")\n            logging.warning(f\"Error message: {e}\")\n    for root, dirs, files in os.walk(path_unzip):\n        for filename in files:\n            if re.search(r\"\\.zip$\", filename):\n                file_spec = os.path.join(root, filename)\n                new_dir = os.path.join(root, filename[:-4])\n                unzip_nested_zip(file_spec, new_dir)\n</code></pre>"},{"location":"api/hydro_file/#hydroutils.hydro_file.zip_extract","title":"<code>zip_extract(the_dir)</code>","text":"<p>Extract the downloaded zip files in the_dir</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def zip_extract(the_dir) -&gt; None:\n    \"\"\"Extract the downloaded zip files in the_dir\"\"\"\n    for f in the_dir.glob(\"*.zip\"):\n        with zipfile.ZipFile(f) as zf:\n            # extract files to a directory named by f.stem\n            zf.extractall(the_dir.joinpath(f.stem))\n</code></pre>"},{"location":"api/hydro_file/#supported-file-formats","title":"Supported File Formats","text":""},{"location":"api/hydro_file/#netcdf-files","title":"NetCDF Files","text":"<ul> <li>Climate data files (precipitation, temperature)</li> <li>Model output files</li> <li>Gridded datasets</li> </ul>"},{"location":"api/hydro_file/#text-based-formats","title":"Text-based Formats","text":"<ul> <li>CSV files with time series data</li> <li>Tab-delimited files</li> <li>Custom formatted text files</li> </ul>"},{"location":"api/hydro_file/#specialized-formats","title":"Specialized Formats","text":"<ul> <li>Hydrological model input/output files</li> <li>Station data files</li> <li>Meteorological data formats</li> </ul>"},{"location":"api/hydro_file/#usage-examples","title":"Usage Examples","text":""},{"location":"api/hydro_file/#reading-data-files","title":"Reading Data Files","text":"<pre><code>import hydroutils as hu\n\n# Read NetCDF file\ndata = hu.read_netcdf('precipitation.nc')\n\n# Read CSV with time series\ndf = hu.read_csv_timeseries('streamflow.csv', date_column='date')\n</code></pre>"},{"location":"api/hydro_file/#writing-data-files","title":"Writing Data Files","text":"<pre><code># Write data to NetCDF\nhu.write_netcdf(data, 'output.nc')\n\n# Export time series to CSV\nhu.write_csv_timeseries(df, 'exported_data.csv')\n</code></pre>"},{"location":"api/hydro_file/#file-format-conversion","title":"File Format Conversion","text":"<pre><code># Convert NetCDF to CSV\nhu.netcdf_to_csv('input.nc', 'output.csv')\n\n# Batch process multiple files\nhu.batch_convert_files(['file1.nc', 'file2.nc'], 'csv')\n</code></pre>"},{"location":"api/hydro_file/#file-handling-features","title":"File Handling Features","text":""},{"location":"api/hydro_file/#automatic-format-detection","title":"Automatic Format Detection","text":"<p>The module can automatically detect file formats and apply appropriate reading methods.</p>"},{"location":"api/hydro_file/#memory-optimization","title":"Memory Optimization","text":"<p>Large files are processed in chunks to minimize memory usage.</p>"},{"location":"api/hydro_file/#error-handling","title":"Error Handling","text":"<p>Robust error handling for corrupted or malformed files.</p>"},{"location":"api/hydro_file/#metadata-preservation","title":"Metadata Preservation","text":"<p>Maintains metadata and attributes when converting between formats.</p>"},{"location":"api/hydro_file/#function-reference","title":"Function Reference","text":"<p>The module provides functions for:</p> <ul> <li>Reading: <code>read_netcdf()</code>, <code>read_csv_timeseries()</code>, <code>read_text_file()</code></li> <li>Writing: <code>write_netcdf()</code>, <code>write_csv_timeseries()</code>, <code>write_text_file()</code></li> <li>Conversion: <code>netcdf_to_csv()</code>, <code>csv_to_netcdf()</code>, <code>batch_convert_files()</code></li> <li>Utilities: <code>get_file_info()</code>, <code>validate_file_format()</code>, <code>compress_file()</code></li> </ul> <p>For detailed function signatures and parameters, see the complete API documentation below.</p>"},{"location":"api/hydro_log/","title":"hydro_log - Logging Utilities","text":"<p>The <code>hydro_log</code> module provides specialized logging functionality for hydrological applications, enabling better tracking and debugging of data processing workflows.</p>"},{"location":"api/hydro_log/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>Structured Logging: Create consistent log formats for hydro applications</li> <li>Performance Monitoring: Track execution times and resource usage</li> <li>Error Tracking: Capture and log errors with hydrological context</li> <li>Workflow Documentation: Log data processing steps and transformations</li> </ul>"},{"location":"api/hydro_log/#core-functions","title":"Core Functions","text":"<p>Author: Wenyu Ouyang Date: 2023-10-25 20:07:14 LastEditTime: 2025-01-15 11:55:24 LastEditors: Wenyu Ouyang Description: Use rich to log: https://rich.readthedocs.io/en/latest/ FilePath: /hydroutils/hydroutils/hydro_log.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_log/#hydroutils.hydro_log.hydro_logger","title":"<code>hydro_logger(cls)</code>","text":"<p>Class decorator: Adds a logger attribute to the class.</p> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def hydro_logger(cls):\n    \"\"\"\n    Class decorator: Adds a logger attribute to the class.\n    \"\"\"\n    # Use the class name as the logger name\n    logger_name = f\"{cls.__module__}.{cls.__name__}\"\n    logger = logging.getLogger(logger_name)\n    logger.setLevel(logging.DEBUG)\n    cache_dir = get_cache_dir()\n    log_dir = os.path.join(cache_dir, \"logs\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_file = os.path.join(log_dir, f\"{logger_name}_{current_time}.log\")\n    # Check if handlers have already been added to avoid duplication\n    if not logger.handlers:\n        # Create a file handler to write logs to the specified file\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setLevel(logging.DEBUG)\n\n        # Create a console handler to output logs to the console (optional)\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(logging.INFO)\n\n        # set the format of the log\n        formatter = logging.Formatter(\n            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n        )\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n\n        # Add handlers to the logger\n        logger.addHandler(file_handler)\n        logger.addHandler(console_handler)\n\n    # Bind the logger to the class attribute\n    cls.logger = logger\n    return cls\n</code></pre>"},{"location":"api/hydro_log/#key-features","title":"Key Features","text":""},{"location":"api/hydro_log/#hydrological-context","title":"Hydrological Context","text":"<p>Logs include relevant hydrological metadata such as station IDs, time periods, and data types.</p>"},{"location":"api/hydro_log/#performance-tracking","title":"Performance Tracking","text":"<p>Monitor execution times for data processing operations and statistical calculations.</p>"},{"location":"api/hydro_log/#structured-output","title":"Structured Output","text":"<p>Consistent log formats that can be easily parsed and analyzed.</p>"},{"location":"api/hydro_log/#multiple-log-levels","title":"Multiple Log Levels","text":"<p>Support for different logging levels (DEBUG, INFO, WARNING, ERROR, CRITICAL).</p>"},{"location":"api/hydro_log/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"api/hydro_log/#basic-logger-setup","title":"Basic Logger Setup","text":"<pre><code>import hydroutils as hu\n\n# Initialize logger for hydrological application\nlogger = hu.setup_hydro_logger(\n    name='hydro_analysis',\n    log_file='hydro_analysis.log',\n    level='INFO'\n)\n</code></pre>"},{"location":"api/hydro_log/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Setup with custom formatting and rotation\nlogger = hu.setup_hydro_logger(\n    name='streamflow_analysis',\n    log_file='logs/streamflow.log',\n    level='DEBUG',\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    max_size='10MB',\n    backup_count=5\n)\n</code></pre>"},{"location":"api/hydro_log/#usage-examples","title":"Usage Examples","text":""},{"location":"api/hydro_log/#basic-logging","title":"Basic Logging","text":"<pre><code># Log data processing steps\nlogger.info(\"Starting streamflow analysis for station USGS_12345\")\nlogger.info(\"Loading data from 2020-01-01 to 2023-12-31\")\n\n# Log statistical calculations\nnse_value = hu.stat_error(observed, simulated)['NSE'][0]\nlogger.info(f\"Calculated NSE: {nse_value:.3f} for station USGS_12345\")\n\n# Log warnings and errors\nif nse_value &lt; 0.3:\n    logger.warning(f\"Low NSE value ({nse_value:.3f}) detected for station USGS_12345\")\n</code></pre>"},{"location":"api/hydro_log/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Time operations\nwith hu.log_execution_time(logger, \"Data loading\"):\n    data = hu.read_csv_timeseries('large_dataset.csv')\n\n# Monitor memory usage\nwith hu.log_memory_usage(logger, \"Statistical calculations\"):\n    stats = hu.stat_error(observed, simulated)\n</code></pre>"},{"location":"api/hydro_log/#contextual-logging","title":"Contextual Logging","text":"<pre><code># Add hydrological context to logs\nwith hu.hydro_log_context(\n    station_id='USGS_12345',\n    data_type='streamflow',\n    time_period='2020-2023'\n):\n    logger.info(\"Processing streamflow data\")\n    stats = hu.stat_error(observed, simulated)\n    logger.info(f\"NSE: {stats['NSE'][0]:.3f}\")\n</code></pre>"},{"location":"api/hydro_log/#error-handling-with-logging","title":"Error Handling with Logging","text":"<pre><code>try:\n    data = hu.read_netcdf('missing_file.nc')\nexcept FileNotFoundError as e:\n    logger.error(f\"File not found: {e}\", exc_info=True)\n    hu.log_hydro_error(logger, e, \n                       context={'operation': 'data_loading', \n                               'file': 'missing_file.nc'})\n</code></pre>"},{"location":"api/hydro_log/#advanced-features","title":"Advanced Features","text":""},{"location":"api/hydro_log/#workflow-logging","title":"Workflow Logging","text":"<pre><code># Log complete workflow\nworkflow_logger = hu.WorkflowLogger('streamflow_analysis')\n\nworkflow_logger.start_workflow()\nworkflow_logger.log_step(\"Data loading\", status=\"started\")\n\n# ... processing steps ...\n\nworkflow_logger.log_step(\"Data loading\", status=\"completed\", \n                        details={\"records\": len(data)})\nworkflow_logger.log_step(\"Statistical analysis\", status=\"started\")\n\n# ... analysis steps ...\n\nworkflow_logger.complete_workflow(status=\"success\")\n</code></pre>"},{"location":"api/hydro_log/#custom-log-formatters","title":"Custom Log Formatters","text":"<pre><code># Create formatter for hydrological data\nformatter = hu.HydroLogFormatter(\n    include_station=True,\n    include_coordinates=True,\n    include_data_quality=True\n)\n\n# Apply formatter to logger\nhandler = logging.StreamHandler()\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\n</code></pre>"},{"location":"api/hydro_log/#log-analysis","title":"Log Analysis","text":"<pre><code># Analyze log files for patterns\nlog_analyzer = hu.HydroLogAnalyzer('hydro_analysis.log')\n\n# Get performance statistics\nperformance_stats = log_analyzer.get_performance_stats()\nprint(f\"Average execution time: {performance_stats['avg_time']:.2f}s\")\n\n# Find errors and warnings\nissues = log_analyzer.find_issues(level='WARNING')\nfor issue in issues:\n    print(f\"Warning at {issue['timestamp']}: {issue['message']}\")\n\n# Generate log summary\nsummary = log_analyzer.generate_summary()\nprint(summary)\n</code></pre>"},{"location":"api/hydro_log/#log-formats","title":"Log Formats","text":""},{"location":"api/hydro_log/#standard-format","title":"Standard Format","text":"<pre><code>2024-01-15 10:30:45,123 - hydro_analysis - INFO - [USGS_12345] NSE calculated: 0.756\n</code></pre>"},{"location":"api/hydro_log/#extended-format","title":"Extended Format","text":"<pre><code>2024-01-15 10:30:45,123 - hydro_analysis - INFO - [USGS_12345|streamflow|2020-2023] NSE: 0.756, RMSE: 2.34, Bias: -0.12\n</code></pre>"},{"location":"api/hydro_log/#json-format","title":"JSON Format","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"logger\": \"hydro_analysis\",\n  \"station_id\": \"USGS_12345\",\n  \"data_type\": \"streamflow\",\n  \"message\": \"NSE calculated\",\n  \"metrics\": {\"NSE\": 0.756, \"RMSE\": 2.34},\n  \"execution_time\": 0.45\n}\n</code></pre>"},{"location":"api/hydro_log/#integration-with-other-modules","title":"Integration with Other Modules","text":""},{"location":"api/hydro_log/#automatic-logging-in-stat_error","title":"Automatic Logging in stat_error","text":"<pre><code># Enable automatic logging for statistical functions\nhu.enable_auto_logging(logger)\n\n# Statistical calculations will now be automatically logged\nstats = hu.stat_error(observed, simulated)\n# Logs: \"Statistical analysis completed: NSE=0.756, RMSE=2.34\"\n</code></pre>"},{"location":"api/hydro_log/#file-operations-logging","title":"File Operations Logging","text":"<pre><code># Log file operations\nwith hu.log_file_operations(logger):\n    data = hu.read_netcdf('climate_data.nc')\n    hu.write_csv_timeseries(processed_data, 'output.csv')\n# Logs file read/write operations automatically\n</code></pre>"},{"location":"api/hydro_log/#best-practices","title":"Best Practices","text":""},{"location":"api/hydro_log/#log-levels","title":"Log Levels","text":"<ul> <li>DEBUG: Detailed diagnostic information</li> <li>INFO: General information about program execution</li> <li>WARNING: Something unexpected happened but the program continues</li> <li>ERROR: A serious error occurred that prevented execution</li> <li>CRITICAL: A critical error that may cause program termination</li> </ul>"},{"location":"api/hydro_log/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Use appropriate log levels to avoid excessive logging</li> <li>Consider log rotation for long-running applications</li> <li>Be mindful of disk space usage with verbose logging</li> </ul>"},{"location":"api/hydro_log/#security","title":"Security","text":"<ul> <li>Avoid logging sensitive information (credentials, personal data)</li> <li>Use secure file permissions for log files</li> <li>Consider encrypting logs for sensitive applications</li> </ul>"},{"location":"api/hydro_log/#function-reference","title":"Function Reference","text":"<p>The module provides functions for:</p> <ul> <li>Setup: <code>setup_hydro_logger()</code>, <code>configure_logging()</code>, <code>create_file_handler()</code></li> <li>Context Management: <code>hydro_log_context()</code>, <code>log_execution_time()</code>, <code>log_memory_usage()</code></li> <li>Workflow Tracking: <code>WorkflowLogger</code>, <code>log_workflow_step()</code>, <code>track_data_lineage()</code></li> <li>Analysis: <code>HydroLogAnalyzer</code>, <code>parse_log_file()</code>, <code>generate_log_report()</code></li> <li>Utilities: <code>log_hydro_error()</code>, <code>format_log_message()</code>, <code>rotate_log_files()</code></li> </ul> <p>For detailed function signatures and parameters, see the complete API documentation below.</p>"},{"location":"api/hydro_plot/","title":"hydro_plot - Visualization Tools","text":"<p>The <code>hydro_plot</code> module provides specialized plotting functions for visualizing hydrological data and analysis results.</p>"},{"location":"api/hydro_plot/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>Time Series Plots: Visualize streamflow, precipitation, and other time series data</li> <li>Statistical Plots: Create plots for model performance assessment</li> <li>Flow Analysis Plots: Flow duration curves, hydrographs, and flow statistics</li> <li>Comparison Plots: Side-by-side comparisons of observed vs simulated data</li> </ul>"},{"location":"api/hydro_plot/#quick-example","title":"Quick Example","text":"<pre><code>import hydroutils as hu\nimport pandas as pd\nimport numpy as np\n\n# Sample data\ndates = pd.date_range('2020-01-01', '2020-12-31', freq='D')\nobserved = 10 + 5 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\nsimulated = observed * 0.95 + np.random.normal(0, 1.5, len(dates))\n\n# Create time series plot\nfig, ax = hu.plot_timeseries(\n    dates, observed, simulated,\n    labels=['Observed', 'Simulated'],\n    title='Streamflow Comparison'\n)\n\n# Create performance scatter plot\nfig, ax = hu.plot_scatter_performance(\n    observed, simulated,\n    add_stats=True,  # Add NSE, R\u00b2, etc.\n    add_1to1_line=True\n)\n</code></pre>"},{"location":"api/hydro_plot/#api-reference","title":"API Reference","text":"<p>Author: Wenyu Ouyang Date: 2022-12-02 10:59:30 LastEditTime: 2025-01-17 17:30:55 LastEditors: Wenyu Ouyang Description: Some common plots for hydrology FilePath: /hydroutils/hydroutils/hydro_plot.py Copyright (c) 2021-2022 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.create_median_labels","title":"<code>create_median_labels(ax, medians_value, percent25value=None, percent75value=None, size='small')</code>","text":"<p>\"create median labels for boxes in a boxplot Parameters</p> <p>ax : plt.AxesSubplot     an ax in a fig medians_value : np.array     description percent25value : type, optional     description, by default None percent75value : type, optional     description, by default None size : str, optional     the size of median-value labels, by default small</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def create_median_labels(\n    ax, medians_value, percent25value=None, percent75value=None, size=\"small\"\n):\n    \"\"\" \"create median labels for boxes in a boxplot\n    Parameters\n    ----------\n    ax : plt.AxesSubplot\n        an ax in a fig\n    medians_value : np.array\n        _description_\n    percent25value : _type_, optional\n        _description_, by default None\n    percent75value : _type_, optional\n        _description_, by default None\n    size : str, optional\n        the size of median-value labels, by default small\n    \"\"\"\n    decimal_places = \"2\"\n    if percent25value is None or percent75value is None:\n        vertical_offset = np.min(medians_value * 0.01)  # offset from median for display\n    else:\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        vertical_offset = (per75max - per25min) * 0.01\n    median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n    pos = range(len(medians_value))\n    for xtick in ax.get_xticks():\n        ax.text(\n            pos[xtick],\n            medians_value[xtick] + vertical_offset,\n            median_labels[xtick],\n            horizontalalignment=\"center\",\n            color=\"w\",\n            # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n            size=size,\n            weight=\"semibold\",\n        )\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_boxes_matplotlib","title":"<code>plot_boxes_matplotlib(data, label1=None, label2=None, leg_col=None, colorlst='rbgcmywrbgcmyw', title=None, figsize=(8, 6), sharey=False, xticklabel=None, axin=None, ylim=None, ylabel=None, notch=False, widths=0.5, subplots_adjust_wspace=0.2, show_median=True, median_line_color='black', median_font_size='small')</code>","text":"<p>Creates multiple boxplots for comparing multiple indicators or groups.</p> <p>This function generates a sophisticated boxplot visualization with multiple customization options, including median display, notched boxes, and flexible layout options. It's particularly useful for comparing distributions across different groups or indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>List of arrays, where each array contains the data for one indicator or group to be displayed as a boxplot.</p> required <code>label1</code> <code>list</code> <p>Labels for each subplot. Defaults to None.</p> <code>None</code> <code>label2</code> <code>list</code> <p>Legend labels for boxes within each subplot. Defaults to None.</p> <code>None</code> <code>leg_col</code> <code>int</code> <p>Number of columns in the legend. Defaults to None.</p> <code>None</code> <code>colorlst</code> <code>str</code> <p>String of color characters for box colors. Defaults to \"rbgcmywrbgcmyw\".</p> <code>'rbgcmywrbgcmyw'</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to None.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>sharey</code> <code>bool</code> <p>If True, all subplots share the same y-axis scale. Defaults to False.</p> <code>False</code> <code>xticklabel</code> <code>list</code> <p>Custom x-axis tick labels. Defaults to None.</p> <code>None</code> <code>axin</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>list</code> <p>Y-axis labels for each subplot. Defaults to None.</p> <code>None</code> <code>notch</code> <code>bool</code> <p>If True, creates notched boxes. Defaults to False.</p> <code>False</code> <code>widths</code> <code>float</code> <p>Width of the boxes. Defaults to 0.5.</p> <code>0.5</code> <code>subplots_adjust_wspace</code> <code>float</code> <p>Width space between subplots. Defaults to 0.2.</p> <code>0.2</code> <code>show_median</code> <code>bool</code> <p>If True, displays median values. Defaults to True.</p> <code>True</code> <code>median_line_color</code> <code>str</code> <p>Color of median lines. Defaults to \"black\".</p> <code>'black'</code> <code>median_font_size</code> <code>str</code> <p>Font size for median values. Defaults to \"small\".</p> <code>'small'</code> <p>Returns:</p> Type Description <p>Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]: If axin is None, returns the Figure object. If axin is provided, returns a tuple of (Axes, boxplot_dict).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n&gt;&gt;&gt; fig = plot_boxes_matplotlib(\n...     data,\n...     label1=['Group A', 'Group B', 'Group C'],\n...     show_median=True,\n...     notch=True\n... )\n</code></pre> Notes <ul> <li>The function automatically handles NaN values in the data.</li> <li>Median values can be displayed with customizable formatting.</li> <li>Supports both single and multiple subplot layouts.</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxes_matplotlib(\n    data: list,\n    label1: list = None,\n    label2: list = None,\n    leg_col: int = None,\n    colorlst=\"rbgcmywrbgcmyw\",\n    title=None,\n    figsize=(8, 6),\n    sharey=False,\n    xticklabel=None,\n    axin=None,\n    ylim=None,\n    ylabel=None,\n    notch=False,\n    widths=0.5,\n    subplots_adjust_wspace=0.2,\n    show_median=True,\n    median_line_color=\"black\",\n    median_font_size=\"small\",\n):\n    \"\"\"Creates multiple boxplots for comparing multiple indicators or groups.\n\n    This function generates a sophisticated boxplot visualization with multiple customization\n    options, including median display, notched boxes, and flexible layout options. It's\n    particularly useful for comparing distributions across different groups or indicators.\n\n    Args:\n        data (list): List of arrays, where each array contains the data for one indicator\n            or group to be displayed as a boxplot.\n        label1 (list, optional): Labels for each subplot. Defaults to None.\n        label2 (list, optional): Legend labels for boxes within each subplot. Defaults to None.\n        leg_col (int, optional): Number of columns in the legend. Defaults to None.\n        colorlst (str, optional): String of color characters for box colors. Defaults to\n            \"rbgcmywrbgcmyw\".\n        title (str, optional): Title of the plot. Defaults to None.\n        figsize (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        sharey (bool, optional): If True, all subplots share the same y-axis scale.\n            Defaults to False.\n        xticklabel (list, optional): Custom x-axis tick labels. Defaults to None.\n        axin (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        ylabel (list, optional): Y-axis labels for each subplot. Defaults to None.\n        notch (bool, optional): If True, creates notched boxes. Defaults to False.\n        widths (float, optional): Width of the boxes. Defaults to 0.5.\n        subplots_adjust_wspace (float, optional): Width space between subplots.\n            Defaults to 0.2.\n        show_median (bool, optional): If True, displays median values. Defaults to True.\n        median_line_color (str, optional): Color of median lines. Defaults to \"black\".\n        median_font_size (str, optional): Font size for median values. Defaults to \"small\".\n\n    Returns:\n        Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]:\n            If axin is None, returns the Figure object.\n            If axin is provided, returns a tuple of (Axes, boxplot_dict).\n\n    Examples:\n        &gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n        &gt;&gt;&gt; fig = plot_boxes_matplotlib(\n        ...     data,\n        ...     label1=['Group A', 'Group B', 'Group C'],\n        ...     show_median=True,\n        ...     notch=True\n        ... )\n\n    Notes:\n        - The function automatically handles NaN values in the data.\n        - Median values can be displayed with customizable formatting.\n        - Supports both single and multiple subplot layouts.\n    \"\"\"\n    nc = len(data)\n    if axin is None:\n        fig, axes = plt.subplots(\n            ncols=nc, sharey=sharey, figsize=figsize, constrained_layout=False\n        )\n    else:\n        axes = axin\n\n    # the next few lines are for showing median values\n    decimal_places = \"2\"\n    for k in range(nc):\n        ax = axes[k] if nc &gt; 1 else axes\n        temp = data[k]\n        if type(temp) is list:\n            for kk in range(len(temp)):\n                tt = temp[kk]\n                if tt is not None and len(tt) &gt; 0:\n                    tt = tt[~np.isnan(tt)]\n                    temp[kk] = tt\n                else:\n                    temp[kk] = []\n        else:\n            temp = temp[~np.isnan(temp)]\n        bp = ax.boxplot(\n            temp, patch_artist=True, notch=notch, showfliers=False, widths=widths\n        )\n        for median in bp[\"medians\"]:\n            median.set_color(median_line_color)\n        medians_value = [np.median(tmp) for tmp in temp]\n        percent25value = [np.percentile(tmp, 25) for tmp in temp]\n        percent75value = [np.percentile(tmp, 75) for tmp in temp]\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n        pos = range(len(medians_value))\n        if show_median:\n            for tick, label in zip(pos, ax.get_xticklabels()):\n                # params of ax.text could be seen here: https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                ax.text(\n                    pos[tick] + 1,\n                    medians_value[tick] + (per75max - per25min) * 0.01,\n                    median_labels[tick],\n                    horizontalalignment=\"center\",\n                    # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                    size=median_font_size,\n                    weight=\"semibold\",\n                    color=median_line_color,\n                )\n        for kk in range(len(bp[\"boxes\"])):\n            plt.setp(bp[\"boxes\"][kk], facecolor=colorlst[kk])\n\n        if label1 is not None:\n            ax.set_xlabel(label1[k])\n        else:\n            ax.set_xlabel(str(k))\n        if xticklabel is None:\n            ax.set_xticks([])\n        else:\n            ax.set_xticks([y + 1 for y in range(0, len(data[k]), 2)])\n            ax.set_xticklabels(xticklabel)\n        if ylabel is not None:\n            ax.set_ylabel(ylabel[k])\n        if ylim is not None:\n            ax.set_ylim(ylim[k])\n    if label2 is not None:\n        plt.legend(\n            bp[\"boxes\"],\n            label2,\n            # explanation for bbox_to_anchor: https://zhuanlan.zhihu.com/p/101059179\n            bbox_to_anchor=(1.0, 1.02, 0.25, 0.05),\n            loc=\"upper right\",\n            borderaxespad=0,\n            ncol=len(label2) if leg_col is None else leg_col,\n            frameon=False,\n            fontsize=12,\n        )\n    if title is not None:\n        # fig.suptitle(title)\n        ax.set_title(title)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=subplots_adjust_wspace)\n    return fig if axin is None else (ax, bp)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_boxs","title":"<code>plot_boxs(data, x_name, y_name, uniform_color=None, swarm_plot=False, hue=None, colormap=False, xlim=None, ylim=None, order=None, font='serif', rotation=45, show_median=False)</code>","text":"<p>plot multiple boxes in one ax with seaborn Parameters</p> <p>data : pd.DataFrame     a tidy pandas dataframe;     if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data x_name : str     the names of each box y_name : str     what is shown uniform_color : str, optional     unified color for all boxes, by default None swarm_plot : bool, optional     description, by default False hue : type, optional     description, by default None colormap : bool, optional     description, by default False xlim : type, optional     description, by default None ylim : type, optional     description, by default None order : type, optional     description, by default None font : str, optional     description, by default \"serif\" rotation : int, optional     rotation for labels in x-axis, by default 45 show_median: bool, optional     if True, show median value for each box, by default False Returns</p> <p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxs(\n    data: pd.DataFrame,\n    x_name: str,\n    y_name: str,\n    uniform_color=None,\n    swarm_plot=False,\n    hue=None,\n    colormap=False,\n    xlim=None,\n    ylim=None,\n    order=None,\n    font=\"serif\",\n    rotation=45,\n    show_median=False,\n):\n    \"\"\"plot multiple boxes in one ax with seaborn\n    Parameters\n    ----------\n    data : pd.DataFrame\n        a tidy pandas dataframe;\n        if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data\n    x_name : str\n        the names of each box\n    y_name : str\n        what is shown\n    uniform_color : str, optional\n        unified color for all boxes, by default None\n    swarm_plot : bool, optional\n        _description_, by default False\n    hue : _type_, optional\n        _description_, by default None\n    colormap : bool, optional\n        _description_, by default False\n    xlim : _type_, optional\n        _description_, by default None\n    ylim : _type_, optional\n        _description_, by default None\n    order : _type_, optional\n        _description_, by default None\n    font : str, optional\n        _description_, by default \"serif\"\n    rotation : int, optional\n        rotation for labels in x-axis, by default 45\n    show_median: bool, optional\n        if True, show median value for each box, by default False\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    fig = plt.figure()\n    sns.set(style=\"ticks\", palette=\"pastel\", font=font, font_scale=1.5)\n    # Draw a nested boxplot to show bills by day and time\n    if uniform_color is not None:\n        sns_box = sns.boxplot(\n            x=x_name,\n            y=y_name,\n            data=data,\n            color=uniform_color,\n            showfliers=False,\n            order=order,\n        )\n    else:\n        sns_box = sns.boxplot(\n            x=x_name, y=y_name, data=data, showfliers=False, order=order\n        )\n    if swarm_plot:\n        if hue is None:\n            sns_box = sns.swarmplot(\n                x=x_name, y=y_name, data=data, color=\".2\", order=order\n            )\n        elif colormap:\n            # Create a matplotlib colormap from the sns seagreen color palette\n            cmap = sns.light_palette(\"seagreen\", reverse=False, as_cmap=True)\n            # Normalize to the range of possible values from df[\"c\"]\n            norm = matplotlib.colors.Normalize(\n                vmin=data[hue].min(), vmax=data[hue].max()\n            )\n            colors = {cval: cmap(norm(cval)) for cval in data[hue]}\n            # plot the swarmplot with the colors dictionary as palette, s=2 means size is 2\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=colors,\n                order=order,\n            )\n            # remove the legend, because we want to set a colorbar instead\n            plt.gca().legend_.remove()\n            # create colorbar\n            divider = make_axes_locatable(plt.gca())\n            ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)\n            fig = sns_box.get_figure()\n            fig.add_axes(ax_cb)\n            cb1 = matplotlib.colorbar.ColorbarBase(\n                ax_cb, cmap=cmap, norm=norm, orientation=\"vertical\"\n            )\n            cb1.set_label(\"Some Units\")\n        else:\n            palette = sns.light_palette(\"seagreen\", reverse=False, n_colors=10)\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=palette,\n                order=order,\n            )\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    if show_median:\n        medians = data.groupby([x_name], sort=False)[y_name].median().values\n        create_median_labels(sns_box, medians_value=medians, size=\"x-small\")\n    sns.despine()\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=rotation)\n    # plt.show()\n    return sns_box.get_figure()\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_diff_boxes","title":"<code>plot_diff_boxes(data, row_and_col=None, y_col=None, x_col=None, hspace=0.3, wspace=1, title_str=None, title_font_size=14)</code>","text":"<p>plot boxplots in rows and cols</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_diff_boxes(\n    data,\n    row_and_col=None,\n    y_col=None,\n    x_col=None,\n    hspace=0.3,\n    wspace=1,\n    title_str=None,\n    title_font_size=14,\n):\n    \"\"\"plot boxplots in rows and cols\"\"\"\n    # matplotlib.use('TkAgg')\n    if type(data) is not pd.DataFrame:\n        data = pd.DataFrame(data)\n    subplot_num = data.shape[1] if y_col is None else len(y_col)\n    if row_and_col is None:\n        row_num = 1\n        col_num = subplot_num\n        f, axes = plt.subplots(row_num, col_num)\n        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n    else:\n        assert subplot_num &lt;= row_and_col[0] * row_and_col[1]\n        row_num = row_and_col[0]\n        col_num = row_and_col[1]\n        f, axes = plt.subplots(row_num, col_num)\n        f.tight_layout()\n    for i in range(subplot_num):\n        if y_col is None:\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    width=0.5,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                ).set(xlabel=data.columns.values[i], ylabel=\"\")\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n        else:\n            assert x_col is not None\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                )\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n    if title_str is not None:\n        f.suptitle(title_str, fontsize=title_font_size)\n    return f\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ecdf","title":"<code>plot_ecdf(mydataframe, mycolumn, save_file=None)</code>","text":"<p>Creates an empirical cumulative distribution function (ECDF) plot for a single column.</p> <p>This function generates an ECDF plot for a single column of data from a pandas DataFrame. It provides a simple interface for quick visualization of data distributions.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create ECDF for.</p> required <code>save_file</code> <code>str</code> <p>Path to save the plot. If None, plot is only displayed. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n&gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n</code></pre> Notes <ul> <li>Uses seaborn's styling for better visualization</li> <li>Automatically handles NaN values</li> <li>Plot range is set to [0, 1] for both axes</li> <li>Uses 0.05 intervals for axis ticks</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdf(mydataframe, mycolumn, save_file=None):\n    \"\"\"Creates an empirical cumulative distribution function (ECDF) plot for a single column.\n\n    This function generates an ECDF plot for a single column of data from a pandas\n    DataFrame. It provides a simple interface for quick visualization of data\n    distributions.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create ECDF for.\n        save_file (str, optional): Path to save the plot. If None, plot is only\n            displayed. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n        &gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n\n    Notes:\n        - Uses seaborn's styling for better visualization\n        - Automatically handles NaN values\n        - Plot range is set to [0, 1] for both axes\n        - Uses 0.05 intervals for axis ticks\n    \"\"\"\n    x, y = ecdf(mydataframe[mycolumn])\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    sns.lineplot(x=\"x\", y=\"y\", data=df, estimator=None).set(\n        xlim=(0, 1), xticks=np.arange(0, 1, 0.05), yticks=np.arange(0, 1, 0.05)\n    )\n    plt.show()\n    if save_file is not None:\n        plt.savefig(save_file)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ecdfs","title":"<code>plot_ecdfs(xs, ys, legends=None, style=None, case_str='case', event_str='event', x_str='x', y_str='y', ax_as_subplot=None, interval=0.1)</code>","text":"<p>Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.</p> <p>This function generates ECDF plots for multiple datasets with customizable styling and labeling options. It's particularly useful for comparing distributions of different datasets or experimental conditions.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>style</code> <code>list[str]</code> <p>Line styles for each ECDF. Defaults to None.</p> <code>None</code> <code>case_str</code> <code>str</code> <p>Label for different cases in the plot. Defaults to \"case\".</p> <code>'case'</code> <code>event_str</code> <code>str</code> <p>Label for different events in the plot. Defaults to \"event\".</p> <code>'event'</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>ax_as_subplot</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>interval</code> <code>float</code> <p>Interval for axis ticks. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare two distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n&gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Distribution 1', 'Distribution 2'],\n...     x_str='Value',\n...     y_str='Cumulative Probability'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple distributions with different styles\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Group A', 'Group B'],\n...     style=['-', '--'],\n...     interval=0.2\n... )\n</code></pre> Notes <ul> <li>Input arrays must be sorted in ascending order</li> <li>Function automatically validates data ordering</li> <li>Supports both single and multiple subplot layouts</li> <li>Uses seaborn for enhanced visual styling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs(\n    xs,\n    ys,\n    legends=None,\n    style=None,\n    case_str=\"case\",\n    event_str=\"event\",\n    x_str=\"x\",\n    y_str=\"y\",\n    ax_as_subplot=None,\n    interval=0.1,\n):\n    \"\"\"Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.\n\n    This function generates ECDF plots for multiple datasets with customizable styling\n    and labeling options. It's particularly useful for comparing distributions of\n    different datasets or experimental conditions.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        style (list[str], optional): Line styles for each ECDF. Defaults to None.\n        case_str (str, optional): Label for different cases in the plot.\n            Defaults to \"case\".\n        event_str (str, optional): Label for different events in the plot.\n            Defaults to \"event\".\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        ax_as_subplot (matplotlib.axes.Axes, optional): Existing axes to plot on.\n            Defaults to None.\n        interval (float, optional): Interval for axis ticks. Defaults to 0.1.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare two distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n        &gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Distribution 1', 'Distribution 2'],\n        ...     x_str='Value',\n        ...     y_str='Cumulative Probability'\n        ... )\n\n        &gt;&gt;&gt; # Multiple distributions with different styles\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Group A', 'Group B'],\n        ...     style=['-', '--'],\n        ...     interval=0.2\n        ... )\n\n    Notes:\n        - Input arrays must be sorted in ascending order\n        - Function automatically validates data ordering\n        - Supports both single and multiple subplot layouts\n        - Uses seaborn for enhanced visual styling\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list)\n        assert len(ys) == len(legends)\n    if style is not None:\n        assert isinstance(style, list)\n        assert len(ys) == len(style)\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    frames = []\n    for i in range(len(xs)):\n        str_i = x_str + str(i) if legends is None else legends[i]\n        assert all(xi &lt; yi for xi, yi in zip(xs[i], xs[i][1:]))\n        df_dict_i = {\n            x_str: xs[i],\n            y_str: ys[i],\n            case_str: np.full([xs[i].size], str_i),\n        }\n        if style is not None:\n            df_dict_i[event_str] = np.full([xs[i].size], style[i])\n        df_i = pd.DataFrame(df_dict_i)\n        frames.append(df_i)\n    df = pd.concat(frames)\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    if style is None:\n        return (\n            sns.lineplot(x=x_str, y=y_str, hue=case_str, data=df, estimator=None).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n            if ax_as_subplot is None\n            else sns.lineplot(\n                ax=ax_as_subplot,\n                x=x_str,\n                y=y_str,\n                hue=case_str,\n                data=df,\n                estimator=None,\n            ).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n        )\n    elif ax_as_subplot is None:\n        return sns.lineplot(\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n    else:\n        return sns.lineplot(\n            ax=ax_as_subplot,\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ecdfs_matplot","title":"<code>plot_ecdfs_matplot(xs, ys, legends=None, colors='rbkgcmy', dash_lines=None, x_str='x', y_str='y', x_interval=0.1, y_interval=0.1, x_lim=(0, 1), y_lim=(0, 1), show_legend=True, legend_font_size=16, fig_size=(8, 6))</code>","text":"<p>Creates ECDF plots using matplotlib with extensive customization options.</p> <p>This function provides a more customizable alternative to the seaborn-based ECDF plotting functions, offering direct control over matplotlib parameters and styling.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>colors</code> <code>str</code> <p>String of color characters for different lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which lines should be dashed. Defaults to None.</p> <code>None</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>x_interval</code> <code>float</code> <p>Interval for x-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>y_interval</code> <code>float</code> <p>Interval for y-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>x_lim</code> <code>tuple</code> <p>X-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>y_lim</code> <code>tuple</code> <p>Y-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>show_legend</code> <code>bool</code> <p>Whether to show legend. Defaults to True.</p> <code>True</code> <code>legend_font_size</code> <code>int</code> <p>Font size for legend. Defaults to 16.</p> <code>16</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare multiple distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n...     x_str='Value',\n...     y_str='Probability',\n...     x_lim=(-3, 3)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     colors='rb',\n...     dash_lines=[False, True],\n...     legend_font_size=12,\n...     fig_size=(10, 8)\n... )\n</code></pre> Notes <ul> <li>Uses clean plotting style with minimal spines</li> <li>Supports both continuous and dashed lines</li> <li>Provides fine-grained control over axis properties</li> <li>Input arrays must be sorted in ascending order</li> <li>Automatically validates data ordering</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs_matplot(\n    xs,\n    ys,\n    legends=None,\n    colors=\"rbkgcmy\",\n    dash_lines=None,\n    x_str=\"x\",\n    y_str=\"y\",\n    x_interval=0.1,\n    y_interval=0.1,\n    x_lim=(0, 1),\n    y_lim=(0, 1),\n    show_legend=True,\n    legend_font_size=16,\n    fig_size=(8, 6),\n):\n    \"\"\"Creates ECDF plots using matplotlib with extensive customization options.\n\n    This function provides a more customizable alternative to the seaborn-based ECDF\n    plotting functions, offering direct control over matplotlib parameters and styling.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        colors (str, optional): String of color characters for different lines.\n            Defaults to \"rbkgcmy\".\n        dash_lines (list[bool], optional): Specifies which lines should be dashed.\n            Defaults to None.\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        x_interval (float, optional): Interval for x-axis ticks. Defaults to 0.1.\n        y_interval (float, optional): Interval for y-axis ticks. Defaults to 0.1.\n        x_lim (tuple, optional): X-axis limits as (min, max). Defaults to (0, 1).\n        y_lim (tuple, optional): Y-axis limits as (min, max). Defaults to (0, 1).\n        show_legend (bool, optional): Whether to show legend. Defaults to True.\n        legend_font_size (int, optional): Font size for legend. Defaults to 16.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare multiple distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n        ...     x_str='Value',\n        ...     y_str='Probability',\n        ...     x_lim=(-3, 3)\n        ... )\n\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     colors='rb',\n        ...     dash_lines=[False, True],\n        ...     legend_font_size=12,\n        ...     fig_size=(10, 8)\n        ... )\n\n    Notes:\n        - Uses clean plotting style with minimal spines\n        - Supports both continuous and dashed lines\n        - Provides fine-grained control over axis properties\n        - Input arrays must be sorted in ascending order\n        - Automatically validates data ordering\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list) and len(ys) == len(legends)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(xs), False).tolist()\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    fig = plt.figure(figsize=fig_size)\n    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n    for i in range(len(xs)):\n        if (\n            np.nanmax(np.array(xs[i])) == np.inf\n            or np.nanmin(np.array(xs[i])) == -np.inf\n        ):\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        else:\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        (line_i,) = ax.plot(xs[i], ys[i], color=colors[i], label=legends[i])\n        if dash_lines[i]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    plt.xlabel(x_str, fontsize=18)\n    plt.ylabel(y_str, fontsize=18)\n    ax.set_xlim(x_lim[0], x_lim[1])\n    ax.set_ylim(y_lim[0], y_lim[1])\n    # set x y number font size\n    plt.xticks(np.arange(x_lim[0], x_lim[1] + x_lim[1] / 100, x_interval), fontsize=16)\n    plt.yticks(np.arange(y_lim[0], y_lim[1] + y_lim[1] / 100, y_interval), fontsize=16)\n    if show_legend:\n        ax.legend()\n        plt.legend(prop={\"size\": legend_font_size})\n    plt.grid()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_heat_map","title":"<code>plot_heat_map(data, mask=None, fig_size=None, fmt='d', square=True, annot=True, xticklabels=True, yticklabels=True)</code>","text":"<p>Creates a heatmap visualization of 2D data using seaborn.</p> <p>This function creates a heatmap visualization with customizable formatting, annotations, and masking options. It uses seaborn's heatmap function with additional customization options.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>2D array or DataFrame to be visualized.</p> required <code>mask</code> <code>array</code> <p>Boolean array of same shape as data. True values will be masked (not shown). Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to None.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>String formatting code for cell annotations. Defaults to \"d\" for integer formatting.</p> <code>'d'</code> <code>square</code> <code>bool</code> <p>If True, set the Axes aspect to \"equal\". Defaults to True.</p> <code>True</code> <code>annot</code> <code>bool</code> <p>If True, write the data value in each cell. Defaults to True.</p> <code>True</code> <code>xticklabels</code> <code>bool</code> <p>If True, show x-axis labels. Defaults to True.</p> <code>True</code> <code>yticklabels</code> <code>bool</code> <p>If True, show y-axis labels. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n&gt;&gt;&gt; plot_heat_map(\n...     data,\n...     fmt='.2f',\n...     fig_size=(8, 6),\n...     annot=True\n... )\n</code></pre> Notes <p>The function uses a red-blue diverging colormap ('RdBu_r') by default. For more details on the underlying implementation, see: https://zhuanlan.zhihu.com/p/96040773</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_heat_map(\n    data,\n    mask=None,\n    fig_size=None,\n    fmt=\"d\",\n    square=True,\n    annot=True,\n    xticklabels=True,\n    yticklabels=True,\n):\n    \"\"\"Creates a heatmap visualization of 2D data using seaborn.\n\n    This function creates a heatmap visualization with customizable formatting,\n    annotations, and masking options. It uses seaborn's heatmap function with\n    additional customization options.\n\n    Args:\n        data (pd.DataFrame): 2D array or DataFrame to be visualized.\n        mask (np.array, optional): Boolean array of same shape as data. True values will\n            be masked (not shown). Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to None.\n        fmt (str, optional): String formatting code for cell annotations. Defaults to \"d\"\n            for integer formatting.\n        square (bool, optional): If True, set the Axes aspect to \"equal\". Defaults to True.\n        annot (bool, optional): If True, write the data value in each cell. Defaults to True.\n        xticklabels (bool, optional): If True, show x-axis labels. Defaults to True.\n        yticklabels (bool, optional): If True, show y-axis labels. Defaults to True.\n\n    Returns:\n        matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.\n\n    Examples:\n        &gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n        &gt;&gt;&gt; plot_heat_map(\n        ...     data,\n        ...     fmt='.2f',\n        ...     fig_size=(8, 6),\n        ...     annot=True\n        ... )\n\n    Notes:\n        The function uses a red-blue diverging colormap ('RdBu_r') by default.\n        For more details on the underlying implementation, see:\n        https://zhuanlan.zhihu.com/p/96040773\n    \"\"\"\n    if fig_size is not None:\n        fig = plt.figure(figsize=fig_size)\n    ax = sns.heatmap(\n        data=data,\n        square=square,\n        annot=annot,\n        fmt=fmt,\n        cmap=\"RdBu_r\",\n        mask=mask,\n        xticklabels=xticklabels,\n        yticklabels=yticklabels,\n    )\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_map_carto","title":"<code>plot_map_carto(data, lat, lon, fig=None, ax=None, pertile_range=None, value_range=None, fig_size=(8, 8), need_colorbar=True, colorbar_size=[0.91, 0.318, 0.02, 0.354], cmap_str='jet', idx_lst=None, markers=None, marker_size=20, is_discrete=False, colors='rbkgcmywrbkgcmyw', category_names=None, legend_font_size=None, colorbar_font_size=None)</code>","text":"<p>Creates a cartographic map visualization using Cartopy with extensive customization options.</p> <p>This function generates a map visualization for spatial data with support for continuous and discrete color scales, multiple marker types, and various styling options. It's particularly useful for visualizing hydrological data in a geographic context.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array</code> <p>1-D array of values to be plotted on the map.</p> required <code>lat</code> <code>array</code> <p>1-D array of latitude values for each data point.</p> required <code>lon</code> <code>array</code> <p>1-D array of longitude values for each data point.</p> required <code>fig</code> <code>Figure</code> <p>Existing figure to plot on. Defaults to None.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling, e.g., [25, 75] for interquartile range. Defaults to None.</p> <code>None</code> <code>value_range</code> <code>list</code> <p>Explicit value range for color scaling. Takes precedence over pertile_range. Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 8).</p> <code>(8, 8)</code> <code>need_colorbar</code> <code>bool</code> <p>Whether to add a colorbar. Defaults to True.</p> <code>True</code> <code>colorbar_size</code> <code>list</code> <p>Colorbar dimensions [left, bottom, width, height]. Defaults to [0.91, 0.318, 0.02, 0.354].</p> <code>[0.91, 0.318, 0.02, 0.354]</code> <code>cmap_str</code> <code>str</code> <p>Colormap name. Defaults to \"jet\".</p> <code>'jet'</code> <code>idx_lst</code> <code>list</code> <p>List of index arrays for plotting multiple point categories. Defaults to None.</p> <code>None</code> <code>markers</code> <code>list</code> <p>Marker styles for each category. Defaults to None.</p> <code>None</code> <code>marker_size</code> <code>Union[int, list]</code> <p>Size(s) of markers. Defaults to 20.</p> <code>20</code> <code>is_discrete</code> <code>bool</code> <p>If True, uses discrete colors with legend instead of continuous colorbar. Defaults to False.</p> <code>False</code> <code>colors</code> <code>str</code> <p>Color characters for discrete categories. Defaults to \"rbkgcmywrbkgcmyw\".</p> <code>'rbkgcmywrbkgcmyw'</code> <code>category_names</code> <code>list</code> <p>Names for discrete categories in legend. Defaults to None.</p> <code>None</code> <code>legend_font_size</code> <code>float</code> <p>Font size for legend. Defaults to None.</p> <code>None</code> <code>colorbar_font_size</code> <code>float</code> <p>Font size for colorbar. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the map.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple continuous color map\n&gt;&gt;&gt; data = np.random.rand(100)\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     value_range=[0, 1],\n...     cmap_str='viridis'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Discrete categories with custom markers\n&gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n&gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     idx_lst=idx_lst,\n...     markers=['o', 's', '^'],\n...     is_discrete=True,\n...     category_names=['Low', 'Medium', 'High']\n... )\n</code></pre> Notes <ul> <li>Uses Cartopy for map projections and features</li> <li>Automatically adds state boundaries and coastlines</li> <li>Supports both continuous and categorical data visualization</li> <li>Handles NaN values appropriately</li> <li>Provides flexible control over color scaling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_map_carto(\n    data,\n    lat,\n    lon,\n    fig=None,\n    ax=None,\n    pertile_range=None,\n    value_range=None,\n    fig_size=(8, 8),\n    need_colorbar=True,\n    colorbar_size=[0.91, 0.318, 0.02, 0.354],\n    cmap_str=\"jet\",\n    idx_lst=None,\n    markers=None,\n    marker_size=20,\n    is_discrete=False,\n    colors=\"rbkgcmywrbkgcmyw\",\n    category_names=None,\n    legend_font_size=None,\n    colorbar_font_size=None,\n):\n    \"\"\"Creates a cartographic map visualization using Cartopy with extensive customization options.\n\n    This function generates a map visualization for spatial data with support for continuous\n    and discrete color scales, multiple marker types, and various styling options. It's\n    particularly useful for visualizing hydrological data in a geographic context.\n\n    Args:\n        data (np.array): 1-D array of values to be plotted on the map.\n        lat (np.array): 1-D array of latitude values for each data point.\n        lon (np.array): 1-D array of longitude values for each data point.\n        fig (matplotlib.figure.Figure, optional): Existing figure to plot on.\n            Defaults to None.\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        pertile_range (list, optional): Percentile range for color scaling, e.g.,\n            [25, 75] for interquartile range. Defaults to None.\n        value_range (list, optional): Explicit value range for color scaling. Takes\n            precedence over pertile_range. Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 8).\n        need_colorbar (bool, optional): Whether to add a colorbar. Defaults to True.\n        colorbar_size (list, optional): Colorbar dimensions [left, bottom, width, height].\n            Defaults to [0.91, 0.318, 0.02, 0.354].\n        cmap_str (str, optional): Colormap name. Defaults to \"jet\".\n        idx_lst (list, optional): List of index arrays for plotting multiple point\n            categories. Defaults to None.\n        markers (list, optional): Marker styles for each category. Defaults to None.\n        marker_size (Union[int, list], optional): Size(s) of markers. Defaults to 20.\n        is_discrete (bool, optional): If True, uses discrete colors with legend instead\n            of continuous colorbar. Defaults to False.\n        colors (str, optional): Color characters for discrete categories.\n            Defaults to \"rbkgcmywrbkgcmyw\".\n        category_names (list, optional): Names for discrete categories in legend.\n            Defaults to None.\n        legend_font_size (float, optional): Font size for legend. Defaults to None.\n        colorbar_font_size (float, optional): Font size for colorbar. Defaults to None.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the map.\n\n    Examples:\n        &gt;&gt;&gt; # Simple continuous color map\n        &gt;&gt;&gt; data = np.random.rand(100)\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     value_range=[0, 1],\n        ...     cmap_str='viridis'\n        ... )\n\n        &gt;&gt;&gt; # Discrete categories with custom markers\n        &gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n        &gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     idx_lst=idx_lst,\n        ...     markers=['o', 's', '^'],\n        ...     is_discrete=True,\n        ...     category_names=['Low', 'Medium', 'High']\n        ... )\n\n    Notes:\n        - Uses Cartopy for map projections and features\n        - Automatically adds state boundaries and coastlines\n        - Supports both continuous and categorical data visualization\n        - Handles NaN values appropriately\n        - Provides flexible control over color scaling\n    \"\"\"\n    if value_range is not None:\n        vmin = value_range[0]\n        vmax = value_range[1]\n    elif pertile_range is None:\n        # https://blog.csdn.net/chenirene510/article/details/111318539\n        mask_data = np.ma.masked_invalid(data)\n        vmin = np.min(mask_data)\n        vmax = np.max(mask_data)\n    else:\n        assert 0 &lt;= pertile_range[0] &lt; pertile_range[1] &lt;= 100\n        vmin = np.nanpercentile(data, pertile_range[0])\n        vmax = np.nanpercentile(data, pertile_range[1])\n    llcrnrlat = (np.min(lat),)\n    urcrnrlat = (np.max(lat),)\n    llcrnrlon = (np.min(lon),)\n    urcrnrlon = (np.max(lon),)\n    extent = [llcrnrlon[0], urcrnrlon[0], llcrnrlat[0], urcrnrlat[0]]\n    # Figure\n    if fig is None or ax is None:\n        fig, ax = plt.subplots(\n            1, 1, figsize=fig_size, subplot_kw={\"projection\": ccrs.PlateCarree()}\n        )\n    ax.set_extent(extent)\n    states = NaturalEarthFeature(\n        category=\"cultural\",\n        scale=\"50m\",\n        facecolor=\"none\",\n        name=\"admin_1_states_provinces_shp\",\n    )\n    ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n    ax.coastlines(\"50m\", linewidth=0.8)\n    if idx_lst is not None:\n        if isinstance(marker_size, list):\n            assert len(marker_size) == len(idx_lst)\n        else:\n            marker_size = np.full(len(idx_lst), marker_size).tolist()\n        if not isinstance(marker_size, list):\n            markers = np.full(len(idx_lst), markers).tolist()\n        else:\n            assert len(markers) == len(idx_lst)\n        if not isinstance(cmap_str, list):\n            cmap_str = np.full(len(idx_lst), cmap_str).tolist()\n        else:\n            assert len(cmap_str) == len(idx_lst)\n        if is_discrete:\n            for i in range(len(idx_lst)):\n                ax.plot(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    marker=markers[i],\n                    ms=marker_size[i],\n                    label=category_names[i],\n                    c=colors[i],\n                    linestyle=\"\",\n                )\n                ax.legend(prop=dict(size=legend_font_size))\n        else:\n            scatter = []\n            for i in range(len(idx_lst)):\n                scat = ax.scatter(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    c=data[idx_lst[i]],\n                    marker=markers[i],\n                    s=marker_size[i],\n                    cmap=cmap_str[i],\n                    vmin=vmin,\n                    vmax=vmax,\n                )\n                scatter.append(scat)\n            if need_colorbar:\n                if colorbar_size is not None:\n                    cbar_ax = fig.add_axes(colorbar_size)\n                    cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n                else:\n                    cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n                if colorbar_font_size is not None:\n                    cbar.ax.tick_params(labelsize=colorbar_font_size)\n            if category_names is not None:\n                ax.legend(\n                    scatter, category_names, prop=dict(size=legend_font_size), ncol=2\n                )\n    elif is_discrete:\n        scatter = ax.scatter(lon, lat, c=data, s=marker_size)\n        # produce a legend with the unique colors from the scatter\n        legend1 = ax.legend(\n            *scatter.legend_elements(), loc=\"lower left\", title=\"Classes\"\n        )\n        ax.add_artist(legend1)\n    else:\n        scat = plt.scatter(\n            lon, lat, c=data, s=marker_size, cmap=cmap_str, vmin=vmin, vmax=vmax\n        )\n        if need_colorbar:\n            if colorbar_size is not None:\n                cbar_ax = fig.add_axes(colorbar_size)\n                cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n            else:\n                cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n            if colorbar_font_size is not None:\n                cbar.ax.tick_params(labelsize=colorbar_font_size)\n    return ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_pdf_cdf","title":"<code>plot_pdf_cdf(mydataframe, mycolumn)</code>","text":"<p>Creates side-by-side plots of probability density function (PDF) and cumulative distribution function (CDF).</p> <p>This function generates a figure with two subplots: a PDF plot on the left and a CDF plot on the right. The PDF includes both histogram and kernel density estimation, while the CDF shows the cumulative histogram.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create distributions for.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'values': np.concatenate([\n...         np.random.normal(0.3, 0.1, 1000),\n...         np.random.normal(0.7, 0.1, 1000)\n...     ])\n... })\n&gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n</code></pre> Notes <ul> <li>Uses seaborn's distplot for both PDF and CDF</li> <li>PDF includes both histogram and kernel density estimation</li> <li>CDF shows cumulative histogram with step-style line</li> <li>Both plots are set to range [0, 1] on x-axis</li> <li>CDF y-axis is also set to range [0, 1]</li> <li>High DPI (320) for publication-quality figures</li> <li>Large figure size (18x6) for clear visualization</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_pdf_cdf(mydataframe, mycolumn):\n    \"\"\"Creates side-by-side plots of probability density function (PDF) and cumulative\n    distribution function (CDF).\n\n    This function generates a figure with two subplots: a PDF plot on the left and\n    a CDF plot on the right. The PDF includes both histogram and kernel density\n    estimation, while the CDF shows the cumulative histogram.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create distributions for.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; df = pd.DataFrame({\n        ...     'values': np.concatenate([\n        ...         np.random.normal(0.3, 0.1, 1000),\n        ...         np.random.normal(0.7, 0.1, 1000)\n        ...     ])\n        ... })\n        &gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n\n    Notes:\n        - Uses seaborn's distplot for both PDF and CDF\n        - PDF includes both histogram and kernel density estimation\n        - CDF shows cumulative histogram with step-style line\n        - Both plots are set to range [0, 1] on x-axis\n        - CDF y-axis is also set to range [0, 1]\n        - High DPI (320) for publication-quality figures\n        - Large figure size (18x6) for clear visualization\n    \"\"\"\n    # settings\n    f, axes = plt.subplots(1, 2, figsize=(18, 6), dpi=320)\n    axes[0].set_ylabel(\"fraction (PDF)\")\n    axes[1].set_ylabel(\"fraction (CDF)\")\n\n    # left plot (PDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=True,\n        axlabel=mycolumn,\n        hist_kws={\"density\": True},\n        ax=axes[0],\n    ).set(xlim=(0, 1))\n\n    # right plot (CDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=False,\n        axlabel=mycolumn,\n        hist_kws={\n            \"density\": True,\n            \"cumulative\": True,\n            \"histtype\": \"step\",\n            \"linewidth\": 4,\n        },\n        ax=axes[1],\n    ).set(xlim=(0, 1), ylim=(0, 1))\n    plt.show()\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_quiver","title":"<code>plot_quiver(exps_q_ssm_result_show, exps_ssm_q_result_show, q_diff_show, ssm_diff_show, x_label, y_label)</code>","text":"<p>Creates a quiver plot showing vector field with normalized arrows.</p> <p>This function generates a quiver plot where arrows represent the direction and magnitude of differences between two variables. The arrows are normalized to have uniform length, with color indicating the actual magnitude of the difference.</p> <p>Parameters:</p> Name Type Description Default <code>exps_q_ssm_result_show</code> <code>array</code> <p>X-coordinates for arrow origins.</p> required <code>exps_ssm_q_result_show</code> <code>array</code> <p>Y-coordinates for arrow origins.</p> required <code>q_diff_show</code> <code>array</code> <p>X-components of the difference vectors.</p> required <code>ssm_diff_show</code> <code>array</code> <p>Y-components of the difference vectors.</p> required <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the quiver plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; x = np.random.rand(50)\n&gt;&gt;&gt; y = np.random.rand(50)\n&gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; fig, ax = plot_quiver(\n...     x, y, dx, dy,\n...     'X Variable',\n...     'Y Variable'\n... )\n</code></pre> Notes <ul> <li>Arrows are normalized to uniform length for better visualization</li> <li>Color indicates the actual magnitude of the difference vector</li> <li>Plot includes a colorbar showing the magnitude scale</li> <li>Uses clean plotting style with minimal spines</li> <li>Default plot range is [0, 1] for both axes</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_quiver(\n    exps_q_ssm_result_show,\n    exps_ssm_q_result_show,\n    q_diff_show,\n    ssm_diff_show,\n    x_label,\n    y_label,\n):\n    \"\"\"Creates a quiver plot showing vector field with normalized arrows.\n\n    This function generates a quiver plot where arrows represent the direction and\n    magnitude of differences between two variables. The arrows are normalized to have\n    uniform length, with color indicating the actual magnitude of the difference.\n\n    Args:\n        exps_q_ssm_result_show (np.array): X-coordinates for arrow origins.\n        exps_ssm_q_result_show (np.array): Y-coordinates for arrow origins.\n        q_diff_show (np.array): X-components of the difference vectors.\n        ssm_diff_show (np.array): Y-components of the difference vectors.\n        x_label (str): Label for x-axis.\n        y_label (str): Label for y-axis.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the quiver plot.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; x = np.random.rand(50)\n        &gt;&gt;&gt; y = np.random.rand(50)\n        &gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; fig, ax = plot_quiver(\n        ...     x, y, dx, dy,\n        ...     'X Variable',\n        ...     'Y Variable'\n        ... )\n\n    Notes:\n        - Arrows are normalized to uniform length for better visualization\n        - Color indicates the actual magnitude of the difference vector\n        - Plot includes a colorbar showing the magnitude scale\n        - Uses clean plotting style with minimal spines\n        - Default plot range is [0, 1] for both axes\n    \"\"\"\n    fig, ax = plt.subplots()\n    color = np.sqrt(q_diff_show**2 + ssm_diff_show**2)\n    # normalize to get same length arrows\n    r = np.power(np.add(np.power(q_diff_show, 2), np.power(ssm_diff_show, 2)), 0.5)\n    plt.quiver(\n        exps_q_ssm_result_show,\n        exps_ssm_q_result_show,\n        q_diff_show / r,\n        ssm_diff_show / r,\n        color,\n        scale=25,\n        width=0.005,\n    )\n    # Defining color\n    plt.xlim(-0.01, 1)\n    plt.ylim(-0.01, 1)\n    plt.colorbar()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.xlabel(x_label, fontsize=18)\n    plt.ylabel(y_label, fontsize=18)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_rainfall_runoff","title":"<code>plot_rainfall_runoff(t, p, qs, fig_size=(8, 6), c_lst='rbkgcmy', leg_lst=None, dash_lines=None, title=None, xlabel=None, ylabel=None, prcp_ylabel='prcp(mm/day)', linewidth=1, prcp_interval=20)</code>","text":"<p>Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.</p> <p>This function generates a dual-axis plot showing precipitation as inverted bars from the top and streamflow as lines on the bottom. This is a common visualization in hydrology for analyzing rainfall-runoff relationships.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Union[array, List[array]]</code> <p>Time values. If multiple streamflow series are provided, t can be a list of time arrays matching qs.</p> required <code>p</code> <code>array</code> <p>Precipitation time series data in mm/day.</p> required <code>qs</code> <code>Union[array, List[array]]</code> <p>Streamflow time series data. Can be a single array or list of arrays for multiple streamflow series.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>c_lst</code> <code>str</code> <p>String of color characters for streamflow lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels for streamflow series. Defaults to None.</p> <code>None</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which streamflow lines should be dashed. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>X-axis label. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to None.</p> <code>None</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <code>linewidth</code> <code>int</code> <p>Width of streamflow lines. Defaults to 1.</p> <code>1</code> <code>prcp_interval</code> <code>int</code> <p>Interval for precipitation y-axis ticks. Defaults to 20.</p> <code>20</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple rainfall-runoff plot\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, q,\n...     title='Rainfall-Runoff Analysis',\n...     xlabel='Date',\n...     ylabel='Streamflow (m\u00b3/s)'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple streamflow series\n&gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, qs,\n...     leg_lst=['Observed', 'Simulated'],\n...     dash_lines=[False, True]\n... )\n</code></pre> Notes <ul> <li>Precipitation is plotted as blue bars from the top of the plot</li> <li>Streamflow is plotted as lines on the bottom</li> <li>The precipitation y-axis is inverted for better visualization</li> <li>Grid lines are added automatically</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff(\n    t,\n    p,\n    qs,\n    fig_size=(8, 6),\n    c_lst=\"rbkgcmy\",\n    leg_lst=None,\n    dash_lines=None,\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    prcp_ylabel=\"prcp(mm/day)\",\n    linewidth=1,\n    prcp_interval=20,\n):\n    \"\"\"Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.\n\n    This function generates a dual-axis plot showing precipitation as inverted bars from\n    the top and streamflow as lines on the bottom. This is a common visualization in\n    hydrology for analyzing rainfall-runoff relationships.\n\n    Args:\n        t (Union[np.array, List[np.array]]): Time values. If multiple streamflow series\n            are provided, t can be a list of time arrays matching qs.\n        p (np.array): Precipitation time series data in mm/day.\n        qs (Union[np.array, List[np.array]]): Streamflow time series data. Can be a\n            single array or list of arrays for multiple streamflow series.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        c_lst (str, optional): String of color characters for streamflow lines.\n            Defaults to \"rbkgcmy\".\n        leg_lst (list, optional): Legend labels for streamflow series. Defaults to None.\n        dash_lines (list[bool], optional): Specifies which streamflow lines should be\n            dashed. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n        xlabel (str, optional): X-axis label. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to None.\n        prcp_ylabel (str, optional): Y-axis label for precipitation. Defaults to\n            \"prcp(mm/day)\".\n        linewidth (int, optional): Width of streamflow lines. Defaults to 1.\n        prcp_interval (int, optional): Interval for precipitation y-axis ticks.\n            Defaults to 20.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the plot.\n\n    Examples:\n        &gt;&gt;&gt; # Simple rainfall-runoff plot\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, q,\n        ...     title='Rainfall-Runoff Analysis',\n        ...     xlabel='Date',\n        ...     ylabel='Streamflow (m\u00b3/s)'\n        ... )\n\n        &gt;&gt;&gt; # Multiple streamflow series\n        &gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, qs,\n        ...     leg_lst=['Observed', 'Simulated'],\n        ...     dash_lines=[False, True]\n        ... )\n\n    Notes:\n        - Precipitation is plotted as blue bars from the top of the plot\n        - Streamflow is plotted as lines on the bottom\n        - The precipitation y-axis is inverted for better visualization\n        - Grid lines are added automatically\n    \"\"\"\n    fig, ax = plt.subplots(figsize=fig_size)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(qs), False).tolist()\n    for k in range(len(qs)):\n        tt = t[k] if type(t) is list else t\n        q = qs[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        (line_i,) = ax.plot(tt, q, color=c_lst[k], label=leg_str, linewidth=linewidth)\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    ax.set_ylim(ax.get_ylim()[0], ax.get_ylim()[1] * 1.2)\n    # Create second axes, in order to get the bars from the top you can multiply by -1\n    ax2 = ax.twinx()\n    # ax2.bar(tt, -p, color=\"b\")\n    ax2.fill_between(tt, 0, -p, step=\"mid\", color=\"b\", alpha=0.5)\n    # ax2.plot(tt, -p, color=\"b\", alpha=0.7, linewidth=1.5)\n\n    # Now need to fix the axis labels\n    # max_pre = max(p)\n    max_pre = p.max().item()\n    ax2.set_ylim(-max_pre * 5, 0)\n    y2_ticks = np.arange(0, max_pre, prcp_interval)\n    y2_ticklabels = [str(i) for i in y2_ticks]\n    ax2.set_yticks(-1 * y2_ticks)\n    ax2.set_yticklabels(y2_ticklabels, fontsize=16)\n    # ax2.set_yticklabels([lab.get_text()[1:] for lab in ax2.get_yticklabels()])\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    if ylabel is not None:\n        ax.set_ylabel(ylabel, fontsize=18)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel, fontsize=18)\n    ax2.set_ylabel(prcp_ylabel, fontsize=8, loc=\"top\")\n    # ax2.set_ylabel(\"precipitation (mm/day)\", fontsize=12, loc='top')\n    # https://github.com/matplotlib/matplotlib/issues/12318\n    ax.tick_params(axis=\"x\", labelsize=16)\n    ax.tick_params(axis=\"y\", labelsize=16)\n    ax.legend(bbox_to_anchor=(0.01, 0.85), loc=\"upper left\", fontsize=16)\n    ax.grid()\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_rainfall_runoff_chai","title":"<code>plot_rainfall_runoff_chai(t, ps, qs, c_lst='rbkgcmy', title='Observation of Precipitation and Streamflow', alpha_lst=None, p_labels=None, q_labels=None)</code>","text":"<p>Creates a two-panel rainfall-runoff plot following Chai's style.</p> <p>This function generates a figure with two vertically stacked panels: precipitation on top and streamflow below. It supports multiple precipitation sources and streamflow series with customizable styling.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>ps</code> <code>list[array]</code> <p>List of precipitation arrays from different sources.</p> required <code>qs</code> <code>list[array]</code> <p>List of streamflow arrays (e.g., observed and simulated).</p> required <code>c_lst</code> <code>str</code> <p>String of color characters. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>title</code> <code>str</code> <p>Figure title. Defaults to \"Observation of Precipitation and Streamflow\".</p> <code>'Observation of Precipitation and Streamflow'</code> <code>alpha_lst</code> <code>list[float]</code> <p>Transparency values for each series. Defaults to [0.5, 0.5].</p> <code>None</code> <code>p_labels</code> <code>list[str]</code> <p>Labels for precipitation sources. Defaults to [\"era5land\", \"gauge\"].</p> <code>None</code> <code>q_labels</code> <code>list[str]</code> <p>Labels for streamflow series. Defaults to [\"observation\", \"simulation\"].</p> <code>None</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom axes (streamflow plot).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n&gt;&gt;&gt; # Two precipitation sources\n&gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n&gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n&gt;&gt;&gt; # Observed and simulated streamflow\n&gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n&gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n&gt;&gt;&gt; \n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n...     t, [p1, p2], [q_obs, q_sim],\n...     title='2020 Rainfall-Runoff Comparison',\n...     p_labels=['ERA5', 'Rain Gauge'],\n...     q_labels=['Observed', 'Simulated']\n... )\n</code></pre> Notes <ul> <li>Top panel shows precipitation with bars</li> <li>Bottom panel shows streamflow with lines</li> <li>Precipitation y-axis is inverted and blue</li> <li>Streamflow y-axis is red</li> <li>Both panels share x-axis limits</li> <li>Legends included for both panels</li> <li>Uses large figure size (20x8) by default</li> <li>Includes \"Streamflow\" text box in bottom panel</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_chai(\n    t,\n    ps,\n    qs,\n    c_lst=\"rbkgcmy\",\n    title=\"Observation of Precipitation and Streamflow\",\n    alpha_lst=None,\n    p_labels=None,\n    q_labels=None,\n):\n    \"\"\"Creates a two-panel rainfall-runoff plot following Chai's style.\n\n    This function generates a figure with two vertically stacked panels: precipitation\n    on top and streamflow below. It supports multiple precipitation sources and\n    streamflow series with customizable styling.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        ps (list[np.array]): List of precipitation arrays from different sources.\n        qs (list[np.array]): List of streamflow arrays (e.g., observed and simulated).\n        c_lst (str, optional): String of color characters. Defaults to \"rbkgcmy\".\n        title (str, optional): Figure title. Defaults to \"Observation of Precipitation\n            and Streamflow\".\n        alpha_lst (list[float], optional): Transparency values for each series.\n            Defaults to [0.5, 0.5].\n        p_labels (list[str], optional): Labels for precipitation sources.\n            Defaults to [\"era5land\", \"gauge\"].\n        q_labels (list[str], optional): Labels for streamflow series.\n            Defaults to [\"observation\", \"simulation\"].\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom\n            axes (streamflow plot).\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n        &gt;&gt;&gt; # Two precipitation sources\n        &gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n        &gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n        &gt;&gt;&gt; # Observed and simulated streamflow\n        &gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n        &gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n        ...     t, [p1, p2], [q_obs, q_sim],\n        ...     title='2020 Rainfall-Runoff Comparison',\n        ...     p_labels=['ERA5', 'Rain Gauge'],\n        ...     q_labels=['Observed', 'Simulated']\n        ... )\n\n    Notes:\n        - Top panel shows precipitation with bars\n        - Bottom panel shows streamflow with lines\n        - Precipitation y-axis is inverted and blue\n        - Streamflow y-axis is red\n        - Both panels share x-axis limits\n        - Legends included for both panels\n        - Uses large figure size (20x8) by default\n        - Includes \"Streamflow\" text box in bottom panel\n    \"\"\"\n    if alpha_lst is None:\n        alpha_lst = [0.5, 0.5]\n    if p_labels is None:\n        p_labels = [\"era5land\", \"gauge\"]\n    if q_labels is None:\n        q_labels = [\"observation\", \"simulation\"]\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 8))\n    fig.suptitle(title, fontsize=16)\n    for i, p in enumerate(ps):\n        ax1.bar(\n            t,\n            p,\n            color=c_lst[i],\n            label=p_labels[i],\n            width=0.9,\n            alpha=alpha_lst[i],\n        )\n    ax1.set_xlabel(\"Time\")\n    ax1.set_ylabel(\"Precipitation (mm/d)\", color=\"b\")\n    ax1.invert_yaxis()\n    ax1.tick_params(axis=\"y\", labelcolor=\"b\")\n    ax1.legend()\n\n    for j, q in enumerate(qs):\n        ax2.plot(t, q, color=c_lst[j], label=q_labels[j], alpha=alpha_lst[j])\n    ax2.set_xlabel(\"Time\")\n    ax2.set_ylabel(\"Streamflow (m$^3$/s)\", color=\"r\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"r\")\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.text(\n        0.05,\n        0.95,\n        \"Streamflow\",\n        transform=ax2.transAxes,\n        fontsize=12,\n        verticalalignment=\"top\",\n        bbox=dict(facecolor=\"white\", alpha=0.5),\n    )\n    ax2.legend()\n\n    fig.tight_layout()\n    return fig, ax2\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_rainfall_runoff_xu","title":"<code>plot_rainfall_runoff_xu(t, p, qs, fig_size=(10, 6), title='prcp-streamflow', leg_lst=None, ylabel='streamflow(m^3/s)', prcp_ylabel='prcp(mm/day)')</code>","text":"<p>Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.</p> <p>This function generates a specialized plot with precipitation bars from the top and streamflow lines on the bottom, following Xu's visualization style. It uses dual y-axes with color-coded labels and ticks.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>p</code> <code>array</code> <p>Precipitation values.</p> required <code>qs</code> <code>tuple</code> <p>Tuple of (observed, predicted) streamflow values.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (10, 6).</p> <code>(10, 6)</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to \"prcp-streamflow\".</p> <code>'prcp-streamflow'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".</p> <code>'streamflow(m^3/s)'</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n&gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n&gt;&gt;&gt; plot_rainfall_runoff_xu(\n...     t, p, (obs, pred),\n...     title='2020 Rainfall-Runoff Analysis'\n... )\n</code></pre> Notes <ul> <li>Precipitation shown as blue bars from top</li> <li>Observed streamflow as solid green line</li> <li>Predicted streamflow as dashed red line</li> <li>Y-axes labels and ticks color-coded</li> <li>Precipitation axis inverted</li> <li>Legend positioned at upper left</li> <li>Precipitation bars semi-transparent (alpha=0.6)</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_xu(\n    t,\n    p,\n    qs,\n    fig_size=(10, 6),\n    title=\"prcp-streamflow\",\n    leg_lst=None,\n    ylabel=\"streamflow(m^3/s)\",\n    prcp_ylabel=\"prcp(mm/day)\",\n):\n    \"\"\"Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.\n\n    This function generates a specialized plot with precipitation bars from the top\n    and streamflow lines on the bottom, following Xu's visualization style. It uses\n    dual y-axes with color-coded labels and ticks.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        p (np.array): Precipitation values.\n        qs (tuple): Tuple of (observed, predicted) streamflow values.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (10, 6).\n        title (str, optional): Plot title. Defaults to \"prcp-streamflow\".\n        leg_lst (list, optional): Legend labels. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".\n        prcp_ylabel (str, optional): Y-axis label for precipitation.\n            Defaults to \"prcp(mm/day)\".\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n        &gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n        &gt;&gt;&gt; plot_rainfall_runoff_xu(\n        ...     t, p, (obs, pred),\n        ...     title='2020 Rainfall-Runoff Analysis'\n        ... )\n\n    Notes:\n        - Precipitation shown as blue bars from top\n        - Observed streamflow as solid green line\n        - Predicted streamflow as dashed red line\n        - Y-axes labels and ticks color-coded\n        - Precipitation axis inverted\n        - Legend positioned at upper left\n        - Precipitation bars semi-transparent (alpha=0.6)\n    \"\"\"\n    obs, pred = qs\n\n    fig, ax1 = plt.subplots(figsize=fig_size)\n\n    ax1.bar(t, p, width=0.1, color=\"blue\", alpha=0.6, label=\"Precipitation\")\n    ax1.set_ylabel(prcp_ylabel, color=\"blue\")\n    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n\n    ax1.set_ylim(0, p.max() * 5)\n    ax1.invert_yaxis()\n\n    ax2 = ax1.twinx()\n\n    # transform the unit of obs and pred\n    ax2.plot(\n        t,\n        obs,\n        color=\"green\",\n        linestyle=\"-\",\n        label=\"observed value\",\n    )\n    ax2.plot(\n        t,\n        pred,\n        color=\"red\",\n        linestyle=\"--\",\n        label=\"predicted value\",\n    )\n\n    ax2.set_ylabel(ylabel, color=\"red\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n\n    plt.title(title)\n\n    plt.legend(loc=\"upper left\")\n    return fig, (ax1, ax2)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_scatter_with_11line","title":"<code>plot_scatter_with_11line(x, y, point_color='blue', line_color='black', xlim=[0.0, 1.0], ylim=[0.0, 1.0], xlabel=None, ylabel=None)</code>","text":"<p>Creates a scatter plot comparing two variables with a 1:1 line.</p> <p>This function generates a scatter plot with a 1:1 line (diagonal) for comparing two variables, commonly used in model evaluation to compare observed vs predicted values. The plot includes customizable colors, axis limits, and labels.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array</code> <p>First variable to be plotted (typically observed values).</p> required <code>y</code> <code>array</code> <p>Second variable to be plotted (typically predicted values).</p> required <code>point_color</code> <code>str</code> <p>Color of scatter points. Defaults to \"blue\".</p> <code>'blue'</code> <code>line_color</code> <code>str</code> <p>Color of the 1:1 line. Defaults to \"black\".</p> <code>'black'</code> <code>xlim</code> <code>list</code> <p>X-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>ylim</code> <code>list</code> <p>Y-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>xlabel</code> <code>str</code> <p>Label for x-axis. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Label for y-axis. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]:  A tuple containing the figure and axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n&gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n...     obs, pred,\n...     xlabel='Observed',\n...     ylabel='Predicted',\n...     xlim=[0, 6],\n...     ylim=[0, 6]\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_with_11line(\n    x: np.array,\n    y: np.array,\n    point_color=\"blue\",\n    line_color=\"black\",\n    xlim=[0.0, 1.0],\n    ylim=[0.0, 1.0],\n    xlabel=None,\n    ylabel=None,\n):\n    \"\"\"Creates a scatter plot comparing two variables with a 1:1 line.\n\n    This function generates a scatter plot with a 1:1 line (diagonal) for comparing\n    two variables, commonly used in model evaluation to compare observed vs predicted values.\n    The plot includes customizable colors, axis limits, and labels.\n\n    Args:\n        x (np.array): First variable to be plotted (typically observed values).\n        y (np.array): Second variable to be plotted (typically predicted values).\n        point_color (str, optional): Color of scatter points. Defaults to \"blue\".\n        line_color (str, optional): Color of the 1:1 line. Defaults to \"black\".\n        xlim (list, optional): X-axis range as [min, max]. Defaults to [0.0, 1.0].\n        ylim (list, optional): Y-axis range as [min, max]. Defaults to [0.0, 1.0].\n        xlabel (str, optional): Label for x-axis. Defaults to None.\n        ylabel (str, optional): Label for y-axis. Defaults to None.\n\n    Returns:\n        tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: \n            A tuple containing the figure and axes objects.\n\n    Examples:\n        &gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n        &gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n        &gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n        ...     obs, pred,\n        ...     xlabel='Observed',\n        ...     ylabel='Predicted',\n        ...     xlim=[0, 6],\n        ...     ylim=[0, 6]\n        ... )\n    \"\"\"\n    fig, ax = plt.subplots()\n    # set background color for ax\n    ax.set_facecolor(\"whitesmoke\")\n    # plot the grid of the figure\n    # plt.grid(color=\"whitesmoke\")\n    ax.scatter(x, y, c=point_color, s=10)\n    line = mlines.Line2D([0, 1], [0, 1], color=line_color, linestyle=\"--\")\n    transform = ax.transAxes\n    line.set_transform(transform)\n    ax.add_line(line)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    plt.xticks(np.arange(xlim[0], xlim[1], 0.1), fontsize=16)\n    plt.yticks(np.arange(ylim[0], ylim[1], 0.1), fontsize=16)\n    # set xlable and ylabel\n    if xlabel is not None:\n        plt.xlabel(xlabel, fontsize=16)\n    if ylabel is not None:\n        plt.ylabel(ylabel, fontsize=16)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_scatter_xyc","title":"<code>plot_scatter_xyc(x_label, x, y_label, y, c_label=None, c=None, size=20, is_reg=False, xlim=None, ylim=None, quadrant=None)</code>","text":"<p>Creates a scatter plot with optional color mapping and quadrant analysis.</p> <p>This function generates a scatter plot with optional color mapping for points, regression line, and quadrant analysis. It's particularly useful for analyzing relationships between variables with an additional dimension represented by color.</p> <p>Parameters:</p> Name Type Description Default <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>x</code> <code>Union[array, List[array]]</code> <p>X-axis data values.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <code>y</code> <code>Union[array, List[array]]</code> <p>Y-axis data values.</p> required <code>c_label</code> <code>Union[str, List[str]]</code> <p>Label(s) for color mapping or multiple series. Defaults to None.</p> <code>None</code> <code>c</code> <code>Union[array, List[str]]</code> <p>Values for color mapping or colors for multiple series. Defaults to None.</p> <code>None</code> <code>size</code> <code>int</code> <p>Size of scatter points. Defaults to 20.</p> <code>20</code> <code>is_reg</code> <code>bool</code> <p>If True, adds regression line. Defaults to False.</p> <code>False</code> <code>xlim</code> <code>list</code> <p>X-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>quadrant</code> <code>list</code> <p>Reference points [x, y] for quadrant analysis. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple scatter plot\n&gt;&gt;&gt; x = np.random.rand(100)\n&gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X Values', x,\n...     'Y Values', y,\n...     is_reg=True\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Scatter plot with color mapping\n&gt;&gt;&gt; c = np.random.rand(100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     c_label='Z Values',\n...     c=c\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Quadrant analysis\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     quadrant=[0.5, 0.5],\n...     xlim=[0, 1],\n...     ylim=[0, 1]\n... )\n</code></pre> Notes <ul> <li>Supports both single and multiple series plotting</li> <li>Automatically handles NaN values</li> <li>Provides quadrant statistics when quadrant analysis is enabled</li> <li>Uses clean plotting style with minimal spines</li> <li>Supports regression line with seaborn's regplot</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_xyc(\n    x_label,\n    x,\n    y_label,\n    y,\n    c_label=None,\n    c=None,\n    size=20,\n    is_reg=False,\n    xlim=None,\n    ylim=None,\n    quadrant=None,\n):\n    \"\"\"Creates a scatter plot with optional color mapping and quadrant analysis.\n\n    This function generates a scatter plot with optional color mapping for points,\n    regression line, and quadrant analysis. It's particularly useful for analyzing\n    relationships between variables with an additional dimension represented by color.\n\n    Args:\n        x_label (str): Label for x-axis.\n        x (Union[np.array, List[np.array]]): X-axis data values.\n        y_label (str): Label for y-axis.\n        y (Union[np.array, List[np.array]]): Y-axis data values.\n        c_label (Union[str, List[str]], optional): Label(s) for color mapping or\n            multiple series. Defaults to None.\n        c (Union[np.array, List[str]], optional): Values for color mapping or\n            colors for multiple series. Defaults to None.\n        size (int, optional): Size of scatter points. Defaults to 20.\n        is_reg (bool, optional): If True, adds regression line. Defaults to False.\n        xlim (list, optional): X-axis limits as [min, max]. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        quadrant (list, optional): Reference points [x, y] for quadrant analysis.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Simple scatter plot\n        &gt;&gt;&gt; x = np.random.rand(100)\n        &gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X Values', x,\n        ...     'Y Values', y,\n        ...     is_reg=True\n        ... )\n\n        &gt;&gt;&gt; # Scatter plot with color mapping\n        &gt;&gt;&gt; c = np.random.rand(100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     c_label='Z Values',\n        ...     c=c\n        ... )\n\n        &gt;&gt;&gt; # Quadrant analysis\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     quadrant=[0.5, 0.5],\n        ...     xlim=[0, 1],\n        ...     ylim=[0, 1]\n        ... )\n\n    Notes:\n        - Supports both single and multiple series plotting\n        - Automatically handles NaN values\n        - Provides quadrant statistics when quadrant analysis is enabled\n        - Uses clean plotting style with minimal spines\n        - Supports regression line with seaborn's regplot\n    \"\"\"\n    fig, ax = plt.subplots()\n    if type(x) is list:\n        for i in range(len(x)):\n            ax.plot(\n                x[i], y[i], marker=\"o\", linestyle=\"\", ms=size, label=c_label[i], c=c[i]\n            )\n        ax.legend()\n\n    elif c is None:\n        df = pd.DataFrame({x_label: x, y_label: y})\n        points = plt.scatter(df[x_label], df[y_label], s=size)\n        if quadrant is not None:\n            plt.axvline(quadrant[0], c=\"grey\", lw=1, linestyle=\"--\")\n            plt.axhline(quadrant[1], c=\"grey\", lw=1, linestyle=\"--\")\n            q2 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q3 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q4 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q5 = df[(df[x_label] == 0) &amp; (df[y_label] == 0)].shape[0]\n            q1 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q = q1 + q2 + q3 + q4 + q5\n            r1 = int(round(q1 / q, 2) * 100)\n            r2 = int(round(q2 / q, 2) * 100)\n            r3 = int(round(q3 / q, 2) * 100)\n            r4 = int(round(q4 / q, 2) * 100)\n            r5 = 100 - r1 - r2 - r3 - r4\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r1}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r2}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r3}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r4}%\",\n                fontsize=16,\n            )\n            plt.text(0.2, 0.02, f\"{str(r5)}%\", fontsize=16)\n    else:\n        df = pd.DataFrame({x_label: x, y_label: y, c_label: c})\n        points = plt.scatter(\n            df[x_label], df[y_label], c=df[c_label], s=size, cmap=\"Spectral\"\n        )  # set style options\n        # add a color bar\n        plt.colorbar(points)\n\n    # set limits\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    # build the regression plot\n    if is_reg:\n        plot = sns.regplot(x_label, y_label, data=df, scatter=False)  # , color=\".1\"\n        plot = plot.set(xlabel=x_label, ylabel=y_label)  # add labels\n    else:\n        plt.xlabel(x_label, fontsize=18)\n        plt.ylabel(y_label, fontsize=18)\n        plt.xticks(fontsize=16)\n        plt.yticks(fontsize=16)\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts","title":"<code>plot_ts(t, y, ax=None, t_bar=None, title=None, xlabel=None, ylabel=None, fig_size=(12, 4), c_lst='rbkgcmyrbkgcmyrbkgcmy', leg_lst=None, marker_lst=None, linewidth=2, linespec=None, dash_lines=None, alpha=1)</code>","text":"<p>Plot time series for multi arrays with matplotlib</p>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts--parameters","title":"Parameters","text":"<p>t : Union[list, np.array]     time series but not just date; it can also be numbers like 1, 2, 3, ... y : Union[list, np.array]     shown data series; the len of y should be equal to t's ax : type, optional     description, by default None t_bar : type, optional     description, by default None title : type, optional     description, by default None xlabel: str, optional     the name of x axis, by default None ylabel : str, optional     the name of y axis, by default None fig_size : tuple, optional     description, by default (12, 4) c_lst : str, optional     description, by default \"rbkgcmy\" leg_lst : type, optional     description, by default None marker_lst : type, optional     description, by default None linewidth : int, optional     description, by default 2 linespec : type, optional     description, by default None dash_lines : type, optional     if dash_line, then we will plot dashed line, by default None</p>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts--returns","title":"Returns","text":"<p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts(\n    t: Union[list, np.array],\n    y: Union[list, np.array],\n    ax=None,\n    t_bar=None,\n    title=None,\n    xlabel: str = None,\n    ylabel: str = None,\n    fig_size=(12, 4),\n    c_lst=\"rbkgcmyrbkgcmyrbkgcmy\",\n    leg_lst=None,\n    marker_lst=None,\n    linewidth=2,\n    linespec=None,\n    dash_lines=None,\n    alpha=1,\n):\n    \"\"\"Plot time series for multi arrays with matplotlib\n\n    Parameters\n    ----------\n    t : Union[list, np.array]\n        time series but not just date; it can also be numbers like 1, 2, 3, ...\n    y : Union[list, np.array]\n        shown data series; the len of y should be equal to t's\n    ax : _type_, optional\n        _description_, by default None\n    t_bar : _type_, optional\n        _description_, by default None\n    title : _type_, optional\n        _description_, by default None\n    xlabel: str, optional\n        the name of x axis, by default None\n    ylabel : str, optional\n        the name of y axis, by default None\n    fig_size : tuple, optional\n        _description_, by default (12, 4)\n    c_lst : str, optional\n        _description_, by default \"rbkgcmy\"\n    leg_lst : _type_, optional\n        _description_, by default None\n    marker_lst : _type_, optional\n        _description_, by default None\n    linewidth : int, optional\n        _description_, by default 2\n    linespec : _type_, optional\n        _description_, by default None\n    dash_lines : _type_, optional\n        if dash_line, then we will plot dashed line, by default None\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    is_new_fig = False\n    if ax is None:\n        fig = plt.figure(figsize=fig_size)\n        ax = fig.subplots()\n        is_new_fig = True\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(t), False).tolist()\n        # dash_lines[-1] = True\n    if type(y) is np.ndarray:\n        y = [y]\n    if type(linewidth) is not list:\n        linewidth = [linewidth] * len(y)\n    if type(alpha) is not list:\n        alpha = [alpha] * len(y)\n    for k in range(len(y)):\n        tt = t[k] if type(t) is list else t\n        yy = y[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        if marker_lst is None:\n            (line_i,) = (\n                ax.plot(tt, yy, \"*\", color=c_lst[k], label=leg_str, alpha=alpha[k])\n                if True in np.isnan(yy)\n                else ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linewidth=linewidth[k],\n                    alpha=alpha[k],\n                )\n            )\n        elif marker_lst[k] == \"-\":\n            if linespec is not None:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linestyle=linespec[k],\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n            else:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n        else:\n            (line_i,) = ax.plot(\n                tt,\n                yy,\n                color=c_lst[k],\n                label=leg_str,\n                marker=marker_lst[k],\n                lw=linewidth[k],\n                alpha=alpha[k],\n            )\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n        if ylabel is not None:\n            ax.set_ylabel(ylabel, fontsize=18)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel, fontsize=18)\n    if t_bar is not None:\n        ylim = ax.get_ylim()\n        t_bar = [t_bar] if type(t_bar) is not list else t_bar\n        for tt in t_bar:\n            ax.plot([tt, tt], ylim, \"-k\")\n\n    if leg_lst is not None:\n        ax.legend(loc=\"upper right\", frameon=False)\n        plt.legend(prop={\"size\": 16})\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    # plot the grid of the figure\n    plt.grid()\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.tight_layout()\n    return (fig, ax) if is_new_fig else ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts_map","title":"<code>plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None)</code>","text":"<p>Creates an interactive map with linked time series plots.</p> <p>This function generates a figure with two subplots: a map on top and a time series plot below. Clicking on a location in the map updates the time series plot to show data from the nearest site.</p> <p>Parameters:</p> Name Type Description Default <code>dataMap</code> <code>list</code> <p>Data values to be shown on the map.</p> required <code>dataTs</code> <code>list</code> <p>List of time series data for each site.</p> required <code>lat</code> <code>array</code> <p>Latitude values for each site.</p> required <code>lon</code> <code>array</code> <p>Longitude values for each site.</p> required <code>t</code> <code>list</code> <p>Time points for x-axis of time series.</p> required <code>sites_id</code> <code>list</code> <p>Identifiers for each site.</p> required <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling on map. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; n_sites = 10\n&gt;&gt;&gt; n_times = 100\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n&gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Generate sample time series for each site\n&gt;&gt;&gt; t = list(range(n_times))\n&gt;&gt;&gt; dataTs = []\n&gt;&gt;&gt; for i in range(n_sites):\n...     pred = np.sin(np.array(t)/10 + i/5)\n...     obs = pred + np.random.normal(0, 0.1, n_times)\n...     dataTs.append([pred, obs])\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Map data could be mean values\n&gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n&gt;&gt;&gt; \n&gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n</code></pre> Notes <ul> <li>Uses TkAgg backend for interactive display</li> <li>Map uses Cartopy for proper geographic projection</li> <li>Time series updates automatically on map click</li> <li>Shows site ID and coordinates in time series title</li> <li>Finds nearest site to click location</li> <li>Both predicted and observed values shown in time series</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None):\n    \"\"\"Creates an interactive map with linked time series plots.\n\n    This function generates a figure with two subplots: a map on top and a time series\n    plot below. Clicking on a location in the map updates the time series plot to show\n    data from the nearest site.\n\n    Args:\n        dataMap (list): Data values to be shown on the map.\n        dataTs (list): List of time series data for each site.\n        lat (np.array): Latitude values for each site.\n        lon (np.array): Longitude values for each site.\n        t (list): Time points for x-axis of time series.\n        sites_id (list): Identifiers for each site.\n        pertile_range (list, optional): Percentile range for color scaling on map.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; n_sites = 10\n        &gt;&gt;&gt; n_times = 100\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n        &gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Generate sample time series for each site\n        &gt;&gt;&gt; t = list(range(n_times))\n        &gt;&gt;&gt; dataTs = []\n        &gt;&gt;&gt; for i in range(n_sites):\n        ...     pred = np.sin(np.array(t)/10 + i/5)\n        ...     obs = pred + np.random.normal(0, 0.1, n_times)\n        ...     dataTs.append([pred, obs])\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Map data could be mean values\n        &gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n\n    Notes:\n        - Uses TkAgg backend for interactive display\n        - Map uses Cartopy for proper geographic projection\n        - Time series updates automatically on map click\n        - Shows site ID and coordinates in time series title\n        - Finds nearest site to click location\n        - Both predicted and observed values shown in time series\n    \"\"\"\n    # show the map in a pop-up window\n    matplotlib.use(\"TkAgg\")\n    assert isinstance(dataMap, list)\n    assert isinstance(dataTs, list)\n    # setup axes\n    fig = plt.figure(figsize=(8, 8), dpi=100)\n    gs = gridspec.GridSpec(2, 1)\n    # plt.subplots_adjust(left=0.13, right=0.89, bottom=0.05)\n    # plot maps\n    ax1 = plt.subplot(gs[0], projection=ccrs.PlateCarree())\n    ax1 = plot_map_carto(\n        dataMap, lat=lat, lon=lon, fig=fig, ax=ax1, pertile_range=pertile_range\n    )\n    # line plot\n    ax2 = plt.subplot(gs[1])\n\n    # plot ts\n    def onclick(event):\n        print(\"click event\")\n        # refresh the ax2, then new ts data can be showed without previous one\n        ax2.cla()\n        xClick = event.xdata\n        yClick = event.ydata\n        d = np.sqrt((xClick - lon) ** 2 + (yClick - lat) ** 2)\n        ind = np.argmin(d)\n        titleStr = \"site_id %s, lat %.3f, lon %.3f\" % (\n            sites_id[ind],\n            lat[ind],\n            lon[ind],\n        )\n        tsLst = dataTs[ind]\n        plot_ts_matplot(t, tsLst, ax=ax2, title=titleStr)\n        # following funcs both work\n        fig.canvas.draw()\n        # plt.draw()\n\n    fig.canvas.mpl_connect(\"button_press_event\", onclick)\n    plt.show()\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.plot_ts_matplot","title":"<code>plot_ts_matplot(t, y, color='r', ax=None, title=None)</code>","text":"<p>Creates a simple time series plot comparing predicted and observed values.</p> <p>This function provides a straightforward way to plot and compare two time series, typically used for showing predicted vs observed values. It supports both creating new figures and adding to existing axes.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>list</code> <p>Time points for x-axis.</p> required <code>y</code> <code>list</code> <p>List containing two arrays: [predicted_values, observed_values].</p> required <code>color</code> <code>str</code> <p>Color for predicted values line. Defaults to \"r\".</p> <code>'r'</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]: If ax is None, returns (fig, ax), otherwise returns ax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create new plot\n&gt;&gt;&gt; t = list(range(100))\n&gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n&gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n</code></pre> <pre><code>&gt;&gt;&gt; # Add to existing axes\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n...                     title='Sine Wave Prediction')\n</code></pre> Notes <ul> <li>Predicted values are plotted first with specified color</li> <li>Observed values are plotted second with default color</li> <li>Legend is automatically added with \"pred\" and \"obs\" labels</li> <li>Title is centered if provided</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_matplot(t, y, color=\"r\", ax=None, title=None):\n    \"\"\"Creates a simple time series plot comparing predicted and observed values.\n\n    This function provides a straightforward way to plot and compare two time series,\n    typically used for showing predicted vs observed values. It supports both creating\n    new figures and adding to existing axes.\n\n    Args:\n        t (list): Time points for x-axis.\n        y (list): List containing two arrays: [predicted_values, observed_values].\n        color (str, optional): Color for predicted values line. Defaults to \"r\".\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n\n    Returns:\n        Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]:\n            If ax is None, returns (fig, ax), otherwise returns ax.\n\n    Examples:\n        &gt;&gt;&gt; # Create new plot\n        &gt;&gt;&gt; t = list(range(100))\n        &gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n        &gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n\n        &gt;&gt;&gt; # Add to existing axes\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n        ...                     title='Sine Wave Prediction')\n\n    Notes:\n        - Predicted values are plotted first with specified color\n        - Observed values are plotted second with default color\n        - Legend is automatically added with \"pred\" and \"obs\" labels\n        - Title is centered if provided\n    \"\"\"\n    assert isinstance(t, list)\n    assert isinstance(y, list)\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.subplots()\n    ax.plot(t, y[0], color=color, label=\"pred\")\n    ax.plot(t, y[1], label=\"obs\")\n    ax.legend()\n    if title is not None:\n        ax.set_title(title, loc=\"center\")\n    return (fig, ax) if ax is None else ax\n</code></pre>"},{"location":"api/hydro_plot/#hydroutils.hydro_plot.swarmplot_without_legend","title":"<code>swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs)</code>","text":"<p>Creates a swarm plot using seaborn with colorbar instead of legend.</p> <p>This function creates a swarm plot where points are colored according to a continuous variable, replacing the default legend with a colorbar for better visualization of the color scale.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Values for x-axis categories.</p> required <code>y</code> <p>Values for y-axis.</p> required <code>hue</code> <p>Values determining the color of each point.</p> required <code>vmin</code> <code>float</code> <p>Minimum value for color normalization.</p> required <code>vmax</code> <code>float</code> <p>Maximum value for color normalization.</p> required <code>cmap</code> <code>str</code> <p>Colormap name or matplotlib colormap object.</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to sns.swarmplot.</p> <code>{}</code> <p>Returns:</p> Type Description <p>matplotlib.figure.Figure: The figure containing the swarm plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n&gt;&gt;&gt; y = [1, 2, 3, 4]\n&gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n&gt;&gt;&gt; fig = swarmplot_without_legend(\n...     x, y, hue,\n...     vmin=0, vmax=1,\n...     cmap='viridis'\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs):\n    \"\"\"Creates a swarm plot using seaborn with colorbar instead of legend.\n\n    This function creates a swarm plot where points are colored according to a continuous\n    variable, replacing the default legend with a colorbar for better visualization of\n    the color scale.\n\n    Args:\n        x: Values for x-axis categories.\n        y: Values for y-axis.\n        hue: Values determining the color of each point.\n        vmin (float): Minimum value for color normalization.\n        vmax (float): Maximum value for color normalization.\n        cmap (str): Colormap name or matplotlib colormap object.\n        **kwargs: Additional keyword arguments passed to sns.swarmplot.\n\n    Returns:\n        matplotlib.figure.Figure: The figure containing the swarm plot.\n\n    Examples:\n        &gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n        &gt;&gt;&gt; y = [1, 2, 3, 4]\n        &gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n        &gt;&gt;&gt; fig = swarmplot_without_legend(\n        ...     x, y, hue,\n        ...     vmin=0, vmax=1,\n        ...     cmap='viridis'\n        ... )\n    \"\"\"\n    fig = plt.gcf()\n    ax = sns.swarmplot(x, y, hue, **kwargs)\n    # remove the legend, because we want to set a colorbar instead\n    ax.legend().remove()\n    norm = plt.Normalize(vmin, vmax)\n    sm = ScalarMappable(norm=norm, cmap=cmap)\n    return fig\n</code></pre>"},{"location":"api/hydro_s3/","title":"hydro_s3 - AWS S3 Integration","text":"<p>The <code>hydro_s3</code> module provides seamless integration with Amazon S3 for storing and retrieving large hydrological datasets in the cloud.</p>"},{"location":"api/hydro_s3/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>File Upload/Download: Transfer files to and from S3 buckets</li> <li>Batch Operations: Handle multiple files efficiently</li> <li>Data Streaming: Stream large datasets without local storage</li> <li>Metadata Management: Preserve file metadata in cloud storage</li> </ul>"},{"location":"api/hydro_s3/#core-functions","title":"Core Functions","text":"<p>Author: Wenyu Ouyang Date: 2023-10-27 15:08:16 LastEditTime: 2023-10-27 15:31:13 LastEditors: Wenyu Ouyang Description: Some functions to deal with s3 file system FilePath: /hydroutils/hydroutils/hydro_s3.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_s3/#hydroutils.hydro_s3.boto3_upload_file","title":"<code>boto3_upload_file(client, bucket_name, object_name, file_path)</code>","text":"<p>upload a file to minio</p>"},{"location":"api/hydro_s3/#hydroutils.hydro_s3.boto3_upload_file--parameters","title":"Parameters","text":"<p>client : type     the minio client bucket_name : type     the bucket name object_name : type     the object name file_path : type     the local file path</p> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def boto3_upload_file(client, bucket_name, object_name, file_path):\n    \"\"\"upload a file to minio\n\n    Parameters\n    ----------\n    client : _type_\n        the minio client\n    bucket_name : _type_\n        the bucket name\n    object_name : _type_\n        the object name\n    file_path : _type_\n        the local file path\n    \"\"\"\n    # Make a bucket\n    bucket_names = [dic[\"Name\"] for dic in client.list_buckets()[\"Buckets\"]]\n    if bucket_name not in bucket_names:\n        client.create_bucket(Bucket=bucket_name)\n    # Upload an object\n    client.upload_file(file_path, bucket_name, object_name)\n    return [dic[\"Key\"] for dic in client.list_objects(Bucket=bucket_name)[\"Contents\"]]\n</code></pre>"},{"location":"api/hydro_s3/#hydroutils.hydro_s3.minio_download_file","title":"<code>minio_download_file(client, bucket_name, object_name, file_path, version_id=None)</code>","text":"<p>summary</p>"},{"location":"api/hydro_s3/#hydroutils.hydro_s3.minio_download_file--parameters","title":"Parameters","text":"<p>client : Minio     description bucket_name : type description object_name : type description file_path : str     absolute file version_id : type, optional     description, by default None</p> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def minio_download_file(\n    client: Minio, bucket_name, object_name, file_path: str, version_id=None\n):\n    \"\"\"_summary_\n\n    Parameters\n    ----------\n    client : Minio\n        _description_\n    bucket_name : _type_\n        _description_\n    object_name : _type_\n        _description_\n    file_path : str\n        absolute file\n    version_id : _type_, optional\n        _description_, by default None\n    \"\"\"\n    try:\n        response = client.get_object(bucket_name, object_name, version_id)\n        res_csv: str = response.data.decode(\"utf8\")\n        with open(file_path, \"w+\") as fp:\n            fp.write(res_csv)\n    finally:\n        response.close()\n        response.release_conn()\n</code></pre>"},{"location":"api/hydro_s3/#hydroutils.hydro_s3.minio_upload_file","title":"<code>minio_upload_file(client, bucket_name, object_name, file_path)</code>","text":"<p>upload a file to minio</p>"},{"location":"api/hydro_s3/#hydroutils.hydro_s3.minio_upload_file--parameters","title":"Parameters","text":"<p>client : type     the minio client bucket_name : type     the bucket name object_name : type     the object name file_path : type     the local file path</p> Source code in <code>hydroutils/hydro_s3.py</code> <pre><code>def minio_upload_file(client, bucket_name, object_name, file_path):\n    \"\"\"upload a file to minio\n\n    Parameters\n    ----------\n    client : _type_\n        the minio client\n    bucket_name : _type_\n        the bucket name\n    object_name : _type_\n        the object name\n    file_path : _type_\n        the local file path\n    \"\"\"\n    # Make a bucket\n    bucket_names = [bucket.name for bucket in client.list_buckets()]\n    if bucket_name not in bucket_names:\n        client.make_bucket(bucket_name)\n    # Upload an object\n    client.fput_object(bucket_name, object_name, file_path)\n    # List objects\n    objects = client.list_objects(bucket_name, recursive=True)\n    return [obj.object_name for obj in objects]\n</code></pre>"},{"location":"api/hydro_s3/#key-features","title":"Key Features","text":""},{"location":"api/hydro_s3/#secure-access","title":"Secure Access","text":"<p>Configure AWS credentials and access permissions for secure data handling.</p>"},{"location":"api/hydro_s3/#large-file-support","title":"Large File Support","text":"<p>Efficiently handle large hydrological datasets with multipart uploads and downloads.</p>"},{"location":"api/hydro_s3/#batch-processing","title":"Batch Processing","text":"<p>Process multiple files simultaneously for improved performance.</p>"},{"location":"api/hydro_s3/#automatic-compression","title":"Automatic Compression","text":"<p>Optionally compress data before upload to reduce storage costs.</p>"},{"location":"api/hydro_s3/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"api/hydro_s3/#aws-credentials","title":"AWS Credentials","text":"<pre><code>import hydroutils as hu\n\n# Configure AWS credentials (recommended: use AWS CLI or environment variables)\nhu.configure_aws_credentials(\n    aws_access_key_id='your_access_key',\n    aws_secret_access_key='your_secret_key',\n    region='us-east-1'\n)\n</code></pre>"},{"location":"api/hydro_s3/#bucket-operations","title":"Bucket Operations","text":"<pre><code># List available buckets\nbuckets = hu.list_s3_buckets()\n\n# Create new bucket for hydrological data\nhu.create_s3_bucket('my-hydro-data-bucket', region='us-west-2')\n</code></pre>"},{"location":"api/hydro_s3/#usage-examples","title":"Usage Examples","text":""},{"location":"api/hydro_s3/#file-upload","title":"File Upload","text":"<pre><code># Upload single file\nhu.upload_to_s3(\n    local_file='streamflow_data.csv',\n    bucket='my-hydro-data',\n    s3_key='station_001/streamflow_2023.csv'\n)\n\n# Upload with metadata\nhu.upload_to_s3(\n    local_file='precipitation.nc',\n    bucket='climate-data',\n    s3_key='precip/2023/monthly.nc',\n    metadata={'station': 'USGS_12345', 'year': '2023'}\n)\n</code></pre>"},{"location":"api/hydro_s3/#file-download","title":"File Download","text":"<pre><code># Download single file\nhu.download_from_s3(\n    bucket='my-hydro-data',\n    s3_key='station_001/streamflow_2023.csv',\n    local_file='downloaded_data.csv'\n)\n\n# Download to memory (for immediate processing)\ndata = hu.download_s3_to_memory(\n    bucket='climate-data',\n    s3_key='precip/2023/monthly.nc'\n)\n</code></pre>"},{"location":"api/hydro_s3/#batch-operations","title":"Batch Operations","text":"<pre><code># Upload multiple files\nfiles_to_upload = [\n    ('local_file1.csv', 'station_001/data1.csv'),\n    ('local_file2.csv', 'station_002/data2.csv'),\n    ('local_file3.csv', 'station_003/data3.csv')\n]\n\nhu.batch_upload_to_s3(files_to_upload, bucket='my-hydro-data')\n\n# Download multiple files\nfiles_to_download = [\n    ('station_001/data1.csv', 'downloaded_data1.csv'),\n    ('station_002/data2.csv', 'downloaded_data2.csv')\n]\n\nhu.batch_download_from_s3(files_to_download, bucket='my-hydro-data')\n</code></pre>"},{"location":"api/hydro_s3/#data-streaming","title":"Data Streaming","text":"<pre><code># Stream large dataset without local storage\ndef process_chunk(chunk_data):\n    # Process data chunk\n    return processed_chunk\n\n# Stream and process data\nresults = hu.stream_process_s3_data(\n    bucket='large-datasets',\n    s3_key='big_climate_data.nc',\n    process_function=process_chunk,\n    chunk_size=1000000  # 1MB chunks\n)\n</code></pre>"},{"location":"api/hydro_s3/#advanced-features","title":"Advanced Features","text":""},{"location":"api/hydro_s3/#synchronization","title":"Synchronization","text":"<pre><code># Sync local directory with S3 bucket\nhu.sync_to_s3(\n    local_dir='./local_data',\n    bucket='my-hydro-data',\n    s3_prefix='synced_data/',\n    delete_extra=False\n)\n\n# Sync from S3 to local\nhu.sync_from_s3(\n    bucket='my-hydro-data',\n    s3_prefix='synced_data/',\n    local_dir='./downloaded_data',\n    delete_extra=False\n)\n</code></pre>"},{"location":"api/hydro_s3/#file-management","title":"File Management","text":"<pre><code># List files in bucket\nfiles = hu.list_s3_files(bucket='my-hydro-data', prefix='station_001/')\n\n# Get file information\nfile_info = hu.get_s3_file_info(bucket='my-hydro-data', s3_key='data.csv')\n\n# Delete files\nhu.delete_s3_file(bucket='my-hydro-data', s3_key='old_data.csv')\n\n# Copy files within S3\nhu.copy_s3_file(\n    source_bucket='source-bucket',\n    source_key='data.csv',\n    dest_bucket='dest-bucket',\n    dest_key='backup/data.csv'\n)\n</code></pre>"},{"location":"api/hydro_s3/#data-compression","title":"Data Compression","text":"<pre><code># Upload with compression\nhu.upload_compressed_to_s3(\n    local_file='large_dataset.csv',\n    bucket='my-hydro-data',\n    s3_key='compressed/dataset.csv.gz',\n    compression='gzip'\n)\n\n# Download and decompress\nhu.download_decompress_from_s3(\n    bucket='my-hydro-data',\n    s3_key='compressed/dataset.csv.gz',\n    local_file='decompressed_dataset.csv'\n)\n</code></pre>"},{"location":"api/hydro_s3/#best-practices","title":"Best Practices","text":""},{"location":"api/hydro_s3/#cost-optimization","title":"Cost Optimization","text":"<ul> <li>Use appropriate storage classes (Standard, Infrequent Access, Glacier)</li> <li>Compress data before upload when possible</li> <li>Set lifecycle policies for automatic archiving</li> </ul>"},{"location":"api/hydro_s3/#security","title":"Security","text":"<ul> <li>Use IAM roles instead of hardcoded credentials</li> <li>Enable server-side encryption for sensitive data</li> <li>Implement proper bucket policies and access controls</li> </ul>"},{"location":"api/hydro_s3/#performance","title":"Performance","text":"<ul> <li>Use multipart uploads for large files (&gt;100MB)</li> <li>Leverage parallel processing for batch operations</li> <li>Consider regional proximity for faster transfers</li> </ul>"},{"location":"api/hydro_s3/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    hu.upload_to_s3('data.csv', 'bucket', 'key')\nexcept hu.S3UploadError as e:\n    print(f\"Upload failed: {e}\")\nexcept hu.S3PermissionError as e:\n    print(f\"Permission denied: {e}\")\nexcept hu.S3ConnectionError as e:\n    print(f\"Connection failed: {e}\")\n</code></pre>"},{"location":"api/hydro_s3/#function-reference","title":"Function Reference","text":"<p>The module provides functions for:</p> <ul> <li>Basic Operations: <code>upload_to_s3()</code>, <code>download_from_s3()</code>, <code>delete_s3_file()</code></li> <li>Batch Operations: <code>batch_upload_to_s3()</code>, <code>batch_download_from_s3()</code></li> <li>Bucket Management: <code>create_s3_bucket()</code>, <code>list_s3_buckets()</code>, <code>list_s3_files()</code></li> <li>Advanced Features: <code>sync_to_s3()</code>, <code>stream_process_s3_data()</code>, <code>copy_s3_file()</code></li> <li>Utilities: <code>get_s3_file_info()</code>, <code>configure_aws_credentials()</code>, <code>validate_s3_path()</code></li> </ul> <p>For detailed function signatures and parameters, see the complete API documentation below.</p>"},{"location":"api/hydro_stat/","title":"hydro_stat - Statistical Analysis","text":"<p>The <code>hydro_stat</code> module provides comprehensive statistical analysis functions for hydrological data evaluation and model performance assessment.</p>"},{"location":"api/hydro_stat/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>Performance Metrics: Calculate standard hydrological model performance metrics</li> <li>Statistical Analysis: Compute various statistical properties of time series data  </li> <li>Flow Analysis: Analyze flow characteristics and patterns</li> <li>Data Transformations: Apply statistical transformations to improve data distributions</li> </ul>"},{"location":"api/hydro_stat/#core-functions","title":"Core Functions","text":"<p>Author: MHPI group, Wenyu Ouyang Date: 2021-12-31 11:08:29 LastEditTime: 2025-01-06 19:47:33 LastEditors: Wenyu Ouyang Description: statistics calculation FilePath: /hydroutils/hydroutils/hydro_stat.py Copyright (c) 2021-2022 MHPI group, Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.KGE","title":"<code>KGE(xs, xo)</code>","text":"<p>Kling Gupta Efficiency (Gupta et al., 2009, http://dx.doi.org/10.1016/j.jhydrol.2009.08.003) input:     xs: simulated     xo: observed output:     KGE: Kling Gupta Efficiency</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def KGE(xs, xo):\n    \"\"\"\n    Kling Gupta Efficiency (Gupta et al., 2009, http://dx.doi.org/10.1016/j.jhydrol.2009.08.003)\n    input:\n        xs: simulated\n        xo: observed\n    output:\n        KGE: Kling Gupta Efficiency\n    \"\"\"\n    r = np.corrcoef(xo, xs)[0, 1]\n    alpha = np.std(xs) / np.std(xo)\n    beta = np.mean(xs) / np.mean(xo)\n    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_4_stat_inds","title":"<code>cal_4_stat_inds(b)</code>","text":"<p>Calculate four statistics indices: percentile 10 and 90, mean value, standard deviation</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_4_stat_inds--parameters","title":"Parameters","text":"<p>b     input data</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_4_stat_inds--returns","title":"Returns","text":"<p>list     [p10, p90, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_4_stat_inds(b):\n    \"\"\"\n    Calculate four statistics indices: percentile 10 and 90, mean value, standard deviation\n\n    Parameters\n    ----------\n    b\n        input data\n\n    Returns\n    -------\n    list\n        [p10, p90, mean, std]\n    \"\"\"\n    p10 = np.percentile(b, 10).astype(float)\n    p90 = np.percentile(b, 90).astype(float)\n    mean = np.mean(b).astype(float)\n    std = np.std(b).astype(float)\n    if std &lt; 0.001:\n        std = 1\n    return [p10, p90, mean, std]\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat","title":"<code>cal_stat(x)</code>","text":"<p>Get statistic values of x (Exclude the NaN values)</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat--parameters","title":"Parameters","text":"<p>x: the array</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat--returns","title":"Returns","text":"<p>list     [10% quantile, 90% quantile, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat(x: np.array) -&gt; list:\n    \"\"\"\n    Get statistic values of x (Exclude the NaN values)\n\n    Parameters\n    ----------\n    x: the array\n\n    Returns\n    -------\n    list\n        [10% quantile, 90% quantile, mean, std]\n    \"\"\"\n    a = x.flatten()\n    b = a[~np.isnan(a)]\n    if b.size == 0:\n        # if b is [], then give it a 0 value\n        b = np.array([0])\n    return cal_4_stat_inds(b)\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat_gamma","title":"<code>cal_stat_gamma(x)</code>","text":"<p>Try to transform a time series data to normal distribution</p> <p>Now only for daily streamflow, precipitation and evapotranspiration; When nan values exist, just ignore them.</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat_gamma--parameters","title":"Parameters","text":"<p>x     time series data</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat_gamma--returns","title":"Returns","text":"<p>list     [p10, p90, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat_gamma(x):\n    \"\"\"\n    Try to transform a time series data to normal distribution\n\n    Now only for daily streamflow, precipitation and evapotranspiration;\n    When nan values exist, just ignore them.\n\n    Parameters\n    ----------\n    x\n        time series data\n\n    Returns\n    -------\n    list\n        [p10, p90, mean, std]\n    \"\"\"\n    a = x.flatten()\n    b = a[~np.isnan(a)]  # kick out Nan\n    b = np.log10(\n        np.sqrt(b) + 0.1\n    )  # do some tranformation to change gamma characteristics\n    return cal_4_stat_inds(b)\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat_prcp_norm","title":"<code>cal_stat_prcp_norm(x, meanprep)</code>","text":"<p>normalized variable by precipitation with cal_stat_gamma</p> <p>dividing a var with prcp means we can get a normalized var without rainfall's magnitude's influence, so that we don't have bias for dry and wet basins</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat_prcp_norm--parameters","title":"Parameters","text":"<p>x     data to be normalized meanprep     meanprep = readAttr(gageDict['id'], ['p_mean'])</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.cal_stat_prcp_norm--returns","title":"Returns","text":"<p>list     [p10, p90, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat_prcp_norm(x, meanprep):\n    \"\"\"\n    normalized variable by precipitation with cal_stat_gamma\n\n    dividing a var with prcp means we can get a normalized var without rainfall's magnitude's influence,\n    so that we don't have bias for dry and wet basins\n\n    Parameters\n    ----------\n    x\n        data to be normalized\n    meanprep\n        meanprep = readAttr(gageDict['id'], ['p_mean'])\n\n    Returns\n    -------\n    list\n        [p10, p90, mean, std]\n    \"\"\"\n    # meanprep = readAttr(gageDict['id'], ['q_mean'])\n    tempprep = np.tile(meanprep, (1, x.shape[1]))\n    # unit (mm/day)/(mm/day)\n    flowua = x / tempprep\n    return cal_stat_gamma(flowua)\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.ecdf","title":"<code>ecdf(data)</code>","text":"<p>Compute ECDF</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def ecdf(data):\n    \"\"\"Compute ECDF\"\"\"\n    x = np.sort(data)\n    n = x.size\n    y = np.arange(1, n + 1) / n\n    return (x, y)\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.fms","title":"<code>fms(obs, sim, lower=0.2, upper=0.7)</code>","text":"<p>TODO: not fully tested Calculate the slope of the middle section of the flow duration curve [#]_</p> <p>.. math::     \\%\\text{BiasFMS} = \\frac{\\left | \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right | -         \\left | \\log(Q_{o,\\text{lower}}) - \\log(Q_{o,\\text{upper}}) \\right |}{\\left |         \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right |} \\times 100,</p> <p>where :math:<code>Q_{s,\\text{lower/upper}}</code> corresponds to the FDC of the simulations (here, <code>sim</code>) at the <code>lower</code> and <code>upper</code> bound of the middle section and :math:<code>Q_{o,\\text{lower/upper}}</code> similarly for the observations (here, <code>obs</code>).</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.fms--parameters","title":"Parameters","text":"<p>obs : DataArray     Observed time series. sim : DataArray     Simulated time series. lower : float, optional     Lower bound of the middle section in range ]0,1[, by default 0.2 upper : float, optional     Upper bound of the middle section in range ]0,1[, by default 0.7</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.fms--returns","title":"Returns","text":"<p>float     Slope of the middle section of the flow duration curve.</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.fms--references","title":"References","text":"<p>.. [#] Yilmaz, K. K., Gupta, H. V., and Wagener, T. ( 2008), A process-based diagnostic approach to model     evaluation: Application to the NWS distributed hydrologic model, Water Resour. Res., 44, W09417,     doi:10.1029/2007WR006716.</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def fms(obs, sim, lower: float = 0.2, upper: float = 0.7) -&gt; float:\n    r\"\"\"\n    TODO: not fully tested\n    Calculate the slope of the middle section of the flow duration curve [#]_\n\n    .. math::\n        \\%\\text{BiasFMS} = \\frac{\\left | \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right | -\n            \\left | \\log(Q_{o,\\text{lower}}) - \\log(Q_{o,\\text{upper}}) \\right |}{\\left |\n            \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right |} \\times 100,\n\n    where :math:`Q_{s,\\text{lower/upper}}` corresponds to the FDC of the simulations (here, `sim`) at the `lower` and\n    `upper` bound of the middle section and :math:`Q_{o,\\text{lower/upper}}` similarly for the observations (here,\n    `obs`).\n\n    Parameters\n    ----------\n    obs : DataArray\n        Observed time series.\n    sim : DataArray\n        Simulated time series.\n    lower : float, optional\n        Lower bound of the middle section in range ]0,1[, by default 0.2\n    upper : float, optional\n        Upper bound of the middle section in range ]0,1[, by default 0.7\n\n    Returns\n    -------\n    float\n        Slope of the middle section of the flow duration curve.\n\n    References\n    ----------\n    .. [#] Yilmaz, K. K., Gupta, H. V., and Wagener, T. ( 2008), A process-based diagnostic approach to model\n        evaluation: Application to the NWS distributed hydrologic model, Water Resour. Res., 44, W09417,\n        doi:10.1029/2007WR006716.\n    \"\"\"\n    if len(obs) &lt; 1:\n        return np.nan\n\n    if any((x &lt;= 0) or (x &gt;= 1) for x in [upper, lower]):\n        raise ValueError(\"upper and lower have to be in range ]0,1[\")\n\n    if lower &gt;= upper:\n        raise ValueError(\"The lower threshold has to be smaller than the upper.\")\n\n    # get arrays of sorted (descending) discharges\n    obs = np.sort(obs)\n    sim = np.sort(sim)\n\n    # for numerical reasons change 0s to 1e-6. Simulations can still contain negatives, so also reset those.\n    sim[sim &lt;= 0] = 1e-6\n    obs[obs == 0] = 1e-6\n\n    # calculate fms part by part\n    qsm_lower = np.log(sim[np.round(lower * len(sim)).astype(int)])\n    qsm_upper = np.log(sim[np.round(upper * len(sim)).astype(int)])\n    qom_lower = np.log(obs[np.round(lower * len(obs)).astype(int)])\n    qom_upper = np.log(obs[np.round(upper * len(obs)).astype(int)])\n\n    fms = ((qsm_lower - qsm_upper) - (qom_lower - qom_upper)) / (\n        qom_lower - qom_upper + 1e-6\n    )\n\n    return fms * 100\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.mean_peak_timing","title":"<code>mean_peak_timing(obs, sim, window=None, resolution='1D', datetime_coord=None)</code>","text":"<p>TODO: not finished Mean difference in peak flow timing.</p> <p>Uses scipy.find_peaks to find peaks in the observed time series. Starting with all observed peaks, those with a prominence of less than the standard deviation of the observed time series are discarded. Next, the lowest peaks are subsequently discarded until all remaining peaks have a distance of at least 100 steps. Finally, the corresponding peaks in the simulated time series are searched in a window of size <code>window</code> on either side of the observed peaks and the absolute time differences between observed and simulated peaks is calculated. The final metric is the mean absolute time difference across all peaks. For more details, see Appendix of [#]_</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.mean_peak_timing--parameters","title":"Parameters","text":"<p>obs : DataArray     Observed time series. sim : DataArray     Simulated time series. window : int, optional     Size of window to consider on each side of the observed peak for finding the simulated peak. That is, the total     window length to find the peak in the simulations is :math:<code>2 * \\text{window} + 1</code> centered at the observed     peak. The default depends on the temporal resolution, e.g. for a resolution of '1D', a window of 3 is used and     for a resolution of '1H' the the window size is 12. resolution : str, optional     Temporal resolution of the time series in pandas format, e.g. '1D' for daily and '1H' for hourly. datetime_coord : str, optional     Name of datetime coordinate. Tried to infer automatically if not specified.</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.mean_peak_timing--returns","title":"Returns","text":"<p>float     Mean peak time difference.</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.mean_peak_timing--references","title":"References","text":"<p>.. [#] Kratzert, F., Klotz, D., Hochreiter, S., and Nearing, G. S.: A note on leveraging synergy in multiple     meteorological datasets with deep learning for rainfall-runoff modeling, Hydrol. Earth Syst. Sci.,     https://doi.org/10.5194/hess-2020-221</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def mean_peak_timing(\n    obs, sim, window: int = None, resolution: str = \"1D\", datetime_coord: str = None\n) -&gt; float:\n    \"\"\"\n    TODO: not finished\n    Mean difference in peak flow timing.\n\n    Uses scipy.find_peaks to find peaks in the observed time series. Starting with all observed peaks, those with a\n    prominence of less than the standard deviation of the observed time series are discarded. Next, the lowest peaks\n    are subsequently discarded until all remaining peaks have a distance of at least 100 steps. Finally, the\n    corresponding peaks in the simulated time series are searched in a window of size `window` on either side of the\n    observed peaks and the absolute time differences between observed and simulated peaks is calculated.\n    The final metric is the mean absolute time difference across all peaks. For more details, see Appendix of [#]_\n\n    Parameters\n    ----------\n    obs : DataArray\n        Observed time series.\n    sim : DataArray\n        Simulated time series.\n    window : int, optional\n        Size of window to consider on each side of the observed peak for finding the simulated peak. That is, the total\n        window length to find the peak in the simulations is :math:`2 * \\\\text{window} + 1` centered at the observed\n        peak. The default depends on the temporal resolution, e.g. for a resolution of '1D', a window of 3 is used and\n        for a resolution of '1H' the the window size is 12.\n    resolution : str, optional\n        Temporal resolution of the time series in pandas format, e.g. '1D' for daily and '1H' for hourly.\n    datetime_coord : str, optional\n        Name of datetime coordinate. Tried to infer automatically if not specified.\n\n\n    Returns\n    -------\n    float\n        Mean peak time difference.\n\n    References\n    ----------\n    .. [#] Kratzert, F., Klotz, D., Hochreiter, S., and Nearing, G. S.: A note on leveraging synergy in multiple\n        meteorological datasets with deep learning for rainfall-runoff modeling, Hydrol. Earth Syst. Sci.,\n        https://doi.org/10.5194/hess-2020-221\n    \"\"\"\n    # verify inputs\n    _validate_inputs(obs, sim)\n\n    # get time series with only valid observations (scipy's find_peaks doesn't guarantee correctness with NaNs)\n    obs, sim = _mask_valid(obs, sim)\n\n    # heuristic to get indices of peaks and their corresponding height.\n    peaks, _ = signal.find_peaks(\n        obs.values, distance=100, prominence=np.std(obs.values)\n    )\n\n    # infer name of datetime index\n    if datetime_coord is None:\n        datetime_coord = utils.infer_datetime_coord(obs)\n\n    if window is None:\n        # infer a reasonable window size\n        window = max(int(utils.get_frequency_factor(\"12H\", resolution)), 3)\n\n    # evaluate timing\n    timing_errors = []\n    for idx in peaks:\n        # skip peaks at the start and end of the sequence and peaks around missing observations\n        # (NaNs that were removed in obs &amp; sim would result in windows that span too much time).\n        if (\n            (idx - window &lt; 0)\n            or (idx + window &gt;= len(obs))\n            or (\n                pd.date_range(\n                    obs[idx - window][datetime_coord].values,\n                    obs[idx + window][datetime_coord].values,\n                    freq=resolution,\n                ).size\n                != 2 * window + 1\n            )\n        ):\n            continue\n\n        # check if the value at idx is a peak (both neighbors must be smaller)\n        if (sim[idx] &gt; sim[idx - 1]) and (sim[idx] &gt; sim[idx + 1]):\n            peak_sim = sim[idx]\n        else:\n            # define peak around idx as the max value inside of the window\n            values = sim[idx - window : idx + window + 1]\n            peak_sim = values[values.argmax()]\n\n        # get xarray object of qobs peak, for getting the date and calculating the datetime offset\n        peak_obs = obs[idx]\n\n        # calculate the time difference between the peaks\n        delta = peak_obs.coords[datetime_coord] - peak_sim.coords[datetime_coord]\n\n        timing_error = np.abs(delta.values / pd.to_timedelta(resolution))\n\n        timing_errors.append(timing_error)\n\n    return np.mean(timing_errors) if timing_errors else np.nan\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.month_stat_for_daily_df","title":"<code>month_stat_for_daily_df(df)</code>","text":"<p>calculate monthly statistics for daily data</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.month_stat_for_daily_df--parameters","title":"Parameters","text":"<p>df     daily data</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.month_stat_for_daily_df--returns","title":"Returns","text":"<p>pd.DataFrame     monthly statistics for daily data</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def month_stat_for_daily_df(df):\n    \"\"\"\n    calculate monthly statistics for daily data\n\n    Parameters\n    ----------\n    df\n        daily data\n\n    Returns\n    -------\n    pd.DataFrame\n        monthly statistics for daily data\n    \"\"\"\n    # guarantee the index is datetime\n    df.index = pd.to_datetime(df.index)\n    return df.resample(\"MS\").mean()\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.remove_abnormal_data","title":"<code>remove_abnormal_data(data, *, q1=1e-05, q2=0.99999)</code>","text":"<p>remove abnormal data</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.remove_abnormal_data--parameters","title":"Parameters","text":"<p>data     data to be removed q     lower quantile q2     upper quantile</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.remove_abnormal_data--returns","title":"Returns","text":"<p>np.array     data after removing abnormal data</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def remove_abnormal_data(data, *, q1=0.00001, q2=0.99999):\n    \"\"\"\n    remove abnormal data\n\n    Parameters\n    ----------\n    data\n        data to be removed\n    q\n        lower quantile\n    q2\n        upper quantile\n\n    Returns\n    -------\n    np.array\n        data after removing abnormal data\n    \"\"\"\n    # remove abnormal data\n    data[data &lt; np.quantile(data, q1)] = np.nan\n    data[data &gt; np.quantile(data, q2)] = np.nan\n    return data\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_error","title":"<code>stat_error(target, pred, fill_nan='no')</code>","text":"<p>Statistics indicators include: Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_error--parameters","title":"Parameters","text":"<p>target     observations, 2-dim array [basin, sequence] pred     predictions, same dim with observations fill_nan     \"no\" means ignoring the NaN value, and it is the default setting;     \"sum\" means calculate the sum of the following values in the NaN locations.     For example, observations are [1, nan, nan, 2], and predictions are [0.3, 0.3, 0.3, 1.5].     Then, \"no\" means [1, 2] v.s. [0.3, 1.5] while \"sum\" means [1, 2] v.s. [0.3 + 0.3 + 0.3, 1.5];     \"mean\" represents calculate average value the following values in the NaN locations.</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_error--returns","title":"Returns","text":"<p>dict     Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_error(target: np.ndarray, pred: np.ndarray, fill_nan: str = \"no\") -&gt; dict:\n    \"\"\"\n    Statistics indicators include: Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV\n\n    Parameters\n    ----------\n    target\n        observations, 2-dim array [basin, sequence]\n    pred\n        predictions, same dim with observations\n    fill_nan\n        \"no\" means ignoring the NaN value, and it is the default setting;\n        \"sum\" means calculate the sum of the following values in the NaN locations.\n        For example, observations are [1, nan, nan, 2], and predictions are [0.3, 0.3, 0.3, 1.5].\n        Then, \"no\" means [1, 2] v.s. [0.3, 1.5] while \"sum\" means [1, 2] v.s. [0.3 + 0.3 + 0.3, 1.5];\n        \"mean\" represents calculate average value the following values in the NaN locations.\n\n    Returns\n    -------\n    dict\n        Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV\n    \"\"\"\n    if len(target.shape) == 3:\n        raise ValueError(\n            \"The input data should be 2-dim, not 3-dim. If you want to calculate metrics for 3-d arrays, please use stat_errors function.\"\n        )\n    if type(fill_nan) is not str:\n        raise ValueError(\"fill_nan should be a string.\")\n    if target.shape != pred.shape:\n        raise ValueError(\"The shape of target and pred should be the same.\")\n    if fill_nan != \"no\":\n        each_non_nan_idx = []\n        all_non_nan_idx: list[int] = []\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            non_nan_idx_tmp = [j for j in range(tmp.size) if not np.isnan(tmp[j])]\n            each_non_nan_idx.append(non_nan_idx_tmp)\n            # TODO: now all_non_nan_idx is only set for ET, because of its irregular nan values\n            all_non_nan_idx = all_non_nan_idx + non_nan_idx_tmp\n            non_nan_idx = np.unique(all_non_nan_idx).tolist()\n        # some NaN data appear in different dates in different basins, so we have to calculate the metric for each basin\n        # but for ET, it is not very resonable to calculate the metric for each basin in this way, for example,\n        # the non_nan_idx: [1, 9, 17, 33, 41], then there are 16 elements in 17 -&gt; 33, so use all_non_nan_idx is better\n        # hence we don't use each_non_nan_idx finally\n        out_dict = dict(\n            Bias=[],\n            RMSE=[],\n            ubRMSE=[],\n            Corr=[],\n            R2=[],\n            NSE=[],\n            KGE=[],\n            FHV=[],\n            FLV=[],\n        )\n    if fill_nan == \"sum\":\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            # non_nan_idx = each_non_nan_idx[i]\n            targ_i = tmp[non_nan_idx]\n            pred_i = np.add.reduceat(pred[i], non_nan_idx)\n            dict_i = stat_error_i(targ_i, pred_i)\n            out_dict[\"Bias\"].append(dict_i[\"Bias\"])\n            out_dict[\"RMSE\"].append(dict_i[\"RMSE\"])\n            out_dict[\"ubRMSE\"].append(dict_i[\"ubRMSE\"])\n            out_dict[\"Corr\"].append(dict_i[\"Corr\"])\n            out_dict[\"R2\"].append(dict_i[\"R2\"])\n            out_dict[\"NSE\"].append(dict_i[\"NSE\"])\n            out_dict[\"KGE\"].append(dict_i[\"KGE\"])\n            out_dict[\"FHV\"].append(dict_i[\"FHV\"])\n            out_dict[\"FLV\"].append(dict_i[\"FLV\"])\n        return out_dict\n    elif fill_nan == \"mean\":\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            # non_nan_idx = each_non_nan_idx[i]\n            targ_i = tmp[non_nan_idx]\n            pred_i_sum = np.add.reduceat(pred[i], non_nan_idx)\n            if non_nan_idx[-1] &lt; len(pred[i]):\n                idx4mean = non_nan_idx + [len(pred[i])]\n            else:\n                idx4mean = copy.copy(non_nan_idx)\n            idx_interval = [y - x for x, y in zip(idx4mean, idx4mean[1:])]\n            pred_i = pred_i_sum / idx_interval\n            dict_i = stat_error_i(targ_i, pred_i)\n            out_dict[\"Bias\"].append(dict_i[\"Bias\"])\n            out_dict[\"RMSE\"].append(dict_i[\"RMSE\"])\n            out_dict[\"ubRMSE\"].append(dict_i[\"ubRMSE\"])\n            out_dict[\"Corr\"].append(dict_i[\"Corr\"])\n            out_dict[\"R2\"].append(dict_i[\"R2\"])\n            out_dict[\"NSE\"].append(dict_i[\"NSE\"])\n            out_dict[\"KGE\"].append(dict_i[\"KGE\"])\n            out_dict[\"FHV\"].append(dict_i[\"FHV\"])\n            out_dict[\"FLV\"].append(dict_i[\"FLV\"])\n        return out_dict\n    ngrid, nt = pred.shape\n    # Bias\n    Bias = np.nanmean(pred - target, axis=1)\n    # RMSE\n    RMSE = np.sqrt(np.nanmean((pred - target) ** 2, axis=1))\n    # ubRMSE\n    predMean = np.tile(np.nanmean(pred, axis=1), (nt, 1)).transpose()\n    targetMean = np.tile(np.nanmean(target, axis=1), (nt, 1)).transpose()\n    predAnom = pred - predMean\n    targetAnom = target - targetMean\n    ubRMSE = np.sqrt(np.nanmean((predAnom - targetAnom) ** 2, axis=1))\n    # rho R2 NSE\n    Corr = np.full(ngrid, np.nan)\n    R2 = np.full(ngrid, np.nan)\n    NSE = np.full(ngrid, np.nan)\n    KGe = np.full(ngrid, np.nan)\n    PBiaslow = np.full(ngrid, np.nan)\n    PBiashigh = np.full(ngrid, np.nan)\n    PBias = np.full(ngrid, np.nan)\n    num_lowtarget_zero = 0\n    for k in range(ngrid):\n        x = pred[k, :]\n        y = target[k, :]\n        ind = np.where(np.logical_and(~np.isnan(x), ~np.isnan(y)))[0]\n        if ind.shape[0] &gt; 0:\n            xx = x[ind]\n            yy = y[ind]\n            # percent bias\n            PBias[k] = np.sum(xx - yy) / np.sum(yy) * 100\n            if ind.shape[0] &gt; 1:\n                # Theoretically at least two points for correlation\n                Corr[k] = scipy.stats.pearsonr(xx, yy)[0]\n                yymean = yy.mean()\n                SST = np.sum((yy - yymean) ** 2)\n                SSReg = np.sum((xx - yymean) ** 2)\n                SSRes = np.sum((yy - xx) ** 2)\n                R2[k] = 1 - SSRes / SST\n                NSE[k] = 1 - SSRes / SST\n                KGe[k] = KGE(xx, yy)\n            # FHV the peak flows bias 2%\n            # FLV the low flows bias bottom 30%, log space\n            pred_sort = np.sort(xx)\n            target_sort = np.sort(yy)\n            indexlow = round(0.3 * len(pred_sort))\n            indexhigh = round(0.98 * len(pred_sort))\n            lowpred = pred_sort[:indexlow]\n            highpred = pred_sort[indexhigh:]\n            lowtarget = target_sort[:indexlow]\n            hightarget = target_sort[indexhigh:]\n            if np.sum(lowtarget) == 0:\n                num_lowtarget_zero = num_lowtarget_zero + 1\n            with warnings.catch_warnings():\n                # Sometimes the lowtarget is all 0, which will cause a warning\n                # but I know it is not an error, so I ignore it\n                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                PBiaslow[k] = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n            PBiashigh[k] = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n    outDict = dict(\n        Bias=Bias,\n        RMSE=RMSE,\n        ubRMSE=ubRMSE,\n        Corr=Corr,\n        R2=R2,\n        NSE=NSE,\n        KGE=KGe,\n        FHV=PBiashigh,\n        FLV=PBiaslow,\n    )\n    # \"The CDF of BFLV will not reach 1.0 because some basins have all zero flow observations for the \"\n    # \"30% low flow interval, the percent bias can be infinite\\n\"\n    # \"The number of these cases is \" + str(num_lowtarget_zero)\n    return outDict\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_error_i","title":"<code>stat_error_i(targ_i, pred_i)</code>","text":"<p>statistics for one dimensional array</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_error_i(targ_i, pred_i):\n    \"\"\"statistics for one dimensional array\"\"\"\n    ind = np.where(np.logical_and(~np.isnan(pred_i), ~np.isnan(targ_i)))[0]\n    # Theoretically at least two points for correlation\n    if ind.shape[0] &gt; 1:\n        xx = pred_i[ind]\n        yy = targ_i[ind]\n        bias = he.me(xx, yy)\n        # RMSE\n        rmse = he.rmse(xx, yy)\n        # ubRMSE\n        pred_mean = np.nanmean(xx)\n        target_mean = np.nanmean(yy)\n        pred_anom = xx - pred_mean\n        target_anom = yy - target_mean\n        ubrmse = np.sqrt(np.nanmean((pred_anom - target_anom) ** 2))\n        # rho R2 NSE\n        corr = he.pearson_r(xx, yy)\n        r2 = he.r_squared(xx, yy)\n        nse = he.nse(xx, yy)\n        kge = he.kge_2009(xx, yy)\n        # percent bias\n        pbias = np.sum(xx - yy) / np.sum(yy) * 100\n        # FHV the peak flows bias 2%\n        # FLV the low flows bias bottom 30%, log space\n        pred_sort = np.sort(xx)\n        target_sort = np.sort(yy)\n        indexlow = round(0.3 * len(pred_sort))\n        indexhigh = round(0.98 * len(pred_sort))\n        lowpred = pred_sort[:indexlow]\n        highpred = pred_sort[indexhigh:]\n        lowtarget = target_sort[:indexlow]\n        hightarget = target_sort[indexhigh:]\n        pbiaslow = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n        pbiashigh = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n        return dict(\n            Bias=bias,\n            RMSE=rmse,\n            ubRMSE=ubrmse,\n            Corr=corr,\n            R2=r2,\n            NSE=nse,\n            KGE=kge,\n            FHV=pbiashigh,\n            FLV=pbiaslow,\n        )\n    else:\n        raise ValueError(\n            \"The number of data is less than 2, we don't calculate the statistics.\"\n        )\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_errors","title":"<code>stat_errors(target, pred, fill_nan=None)</code>","text":"<p>Calculate statistics for 3-dim arrays</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_errors--parameters","title":"Parameters","text":"<p>target : np.ndarray     the observed data pred : np.ndarray     the predicted data fill_nan : list, optional     a list of strings, each string is \"no\", \"sum\" or \"mean\", by default None</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.stat_errors--returns","title":"Returns","text":"<p>list     A list of dictionaries, each dictionary contains Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_errors(target: np.ndarray, pred: np.ndarray, fill_nan: list = None) -&gt; list:\n    \"\"\"Calculate statistics for 3-dim arrays\n\n    Parameters\n    ----------\n    target : np.ndarray\n        the observed data\n    pred : np.ndarray\n        the predicted data\n    fill_nan : list, optional\n        a list of strings, each string is \"no\", \"sum\" or \"mean\", by default None\n\n    Returns\n    -------\n    list\n        A list of dictionaries, each dictionary contains Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV\n    \"\"\"\n    if fill_nan is None:\n        fill_nan = [\"no\"]\n    if len(target.shape) != 3:\n        raise ValueError(\n            \"The input data should be 3-dim, not 2-dim. If you want to calculate \"\n            \"metrics for 2-d arrays, please use stat_error function.\"\n        )\n    if target.shape != pred.shape:\n        raise ValueError(\"The shape of target and pred should be the same.\")\n    if type(fill_nan) is not list or len(fill_nan) != target.shape[-1]:\n        raise ValueError(\n            \"Please give same length of fill_nan as the number of variables.\"\n        )\n    dict_list = []\n    for k in range(target.shape[-1]):\n        k_dict = stat_error(target[:, :, k], pred[:, :, k], fill_nan=fill_nan[k])\n        dict_list.append(k_dict)\n    return dict_list\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.trans_norm","title":"<code>trans_norm(x, var_lst, stat_dict, *, to_norm)</code>","text":"<p>normalization, including denormalization code</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.trans_norm--parameters","title":"Parameters","text":"<p>x     2d or 3d data     2d: 1st-sites, 2nd-var type     3d: 1st-sites, 2nd-time, 3rd-var type var_lst     variables stat_dict     a dict with statistics info to_norm     if True, normalization; else denormalization</p>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.trans_norm--returns","title":"Returns","text":"<p>np.array     normalized/denormalized data</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def trans_norm(x, var_lst, stat_dict, *, to_norm):\n    \"\"\"\n    normalization, including denormalization code\n\n    Parameters\n    ----------\n    x\n        2d or 3d data\n        2d: 1st-sites, 2nd-var type\n        3d: 1st-sites, 2nd-time, 3rd-var type\n    var_lst\n        variables\n    stat_dict\n        a dict with statistics info\n    to_norm\n        if True, normalization; else denormalization\n\n    Returns\n    -------\n    np.array\n        normalized/denormalized data\n    \"\"\"\n    if type(var_lst) is str:\n        var_lst = [var_lst]\n    out = np.zeros(x.shape)\n    for k in range(len(var_lst)):\n        var = var_lst[k]\n        stat = stat_dict[var]\n        if to_norm is True:\n            if len(x.shape) == 3:\n                out[:, :, k] = (x[:, :, k] - stat[2]) / stat[3]\n            elif len(x.shape) == 2:\n                out[:, k] = (x[:, k] - stat[2]) / stat[3]\n        elif len(x.shape) == 3:\n            out[:, :, k] = x[:, :, k] * stat[3] + stat[2]\n        elif len(x.shape) == 2:\n            out[:, k] = x[:, k] * stat[3] + stat[2]\n    return out\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.wilcoxon_t_test","title":"<code>wilcoxon_t_test(xs, xo)</code>","text":"<p>Wilcoxon t test</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def wilcoxon_t_test(xs, xo):\n    \"\"\"Wilcoxon t test\"\"\"\n    diff = xs - xo  # same result when using xo-xs\n    w, p = wilcoxon(diff)\n    return w, p\n</code></pre>"},{"location":"api/hydro_stat/#hydroutils.hydro_stat.wilcoxon_t_test_for_lst","title":"<code>wilcoxon_t_test_for_lst(x_lst, rnd_num=2)</code>","text":"<p>Wilcoxon t test for every two array in a 2-d array</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def wilcoxon_t_test_for_lst(x_lst, rnd_num=2):\n    \"\"\"Wilcoxon t test for every two array in a 2-d array\"\"\"\n    arr_lst = np.asarray(x_lst)\n    w, p = [], []\n    arr_lst_pair = list(itertools.combinations(arr_lst, 2))\n    for arr_pair in arr_lst_pair:\n        wi, pi = wilcoxon_t_test(arr_pair[0], arr_pair[1])\n        w.append(round(wi, rnd_num))\n        p.append(round(pi, rnd_num))\n    return w, p\n</code></pre>"},{"location":"api/hydro_stat/#key-performance-metrics","title":"Key Performance Metrics","text":""},{"location":"api/hydro_stat/#nash-sutcliffe-efficiency-nse","title":"Nash-Sutcliffe Efficiency (NSE)","text":"<p>The NSE determines the relative magnitude of the residual variance compared to the measured data variance.</p>"},{"location":"api/hydro_stat/#kling-gupta-efficiency-kge","title":"Kling-Gupta Efficiency (KGE)","text":"<p>KGE provides a balanced measure that considers correlation, bias, and variability.</p>"},{"location":"api/hydro_stat/#root-mean-square-error-rmse","title":"Root Mean Square Error (RMSE)","text":"<p>RMSE measures the average magnitude of prediction errors.</p>"},{"location":"api/hydro_stat/#bias","title":"Bias","text":"<p>Bias measures the average tendency of the simulated values to be larger or smaller than observed values.</p>"},{"location":"api/hydro_stat/#usage-examples","title":"Usage Examples","text":""},{"location":"api/hydro_stat/#basic-statistics","title":"Basic Statistics","text":"<pre><code>import hydroutils as hu\nimport numpy as np\n\n# Sample data\nobserved = np.array([10.5, 12.3, 8.7, 15.2, 11.8])\nsimulated = np.array([10.1, 12.8, 8.9, 14.7, 11.2])\n\n# Calculate comprehensive statistics\nstats = hu.stat_error(observed, simulated)\nprint(f\"NSE: {stats['NSE'][0]:.3f}\")\nprint(f\"KGE: {stats['KGE'][0]:.3f}\")\n</code></pre>"},{"location":"api/hydro_stat/#individual-metrics","title":"Individual Metrics","text":"<pre><code># Calculate KGE separately\nkge_value = hu.KGE(simulated, observed)\n\n# Flow duration curve analysis\nfms_value = hu.fms(observed, simulated)\n</code></pre>"},{"location":"api/hydro_stat/#statistical-properties","title":"Statistical Properties","text":"<pre><code># Basic statistical indicators\nflow_data = np.random.lognormal(2, 1, 1000)\nbasic_stats = hu.cal_stat(flow_data)\nfour_stats = hu.cal_4_stat_inds(flow_data)\n\n# Empirical CDF\nsorted_data, probabilities = hu.ecdf(flow_data)\n</code></pre>"},{"location":"api/hydro_stat/#function-reference","title":"Function Reference","text":"<p>The module includes the following main function categories:</p> <ul> <li>Model Performance: <code>stat_error()</code>, <code>stat_errors()</code>, <code>KGE()</code></li> <li>Flow Analysis: <code>fms()</code>, <code>mean_peak_timing()</code></li> <li>Statistical Calculations: <code>cal_stat()</code>, <code>cal_stat_gamma()</code>, <code>cal_4_stat_inds()</code></li> <li>Distribution Analysis: <code>ecdf()</code>, <code>wilcoxon_t_test()</code></li> </ul> <p>For detailed function signatures and parameters, see the complete API documentation below.</p>"},{"location":"api/hydro_time/","title":"hydro_time - Time Series Processing","text":"<p>The <code>hydro_time</code> module provides utilities for handling time series data in hydrological applications.</p>"},{"location":"api/hydro_time/#overview","title":"Overview","text":"<p>This module contains functions for:</p> <ul> <li>Unit Conversions: Convert between different flow and time units</li> <li>Time Detection: Automatically detect time intervals and patterns</li> <li>Validation: Validate time series consistency and unit compatibility</li> <li>Time Utilities: Various time manipulation functions</li> </ul>"},{"location":"api/hydro_time/#core-functions","title":"Core Functions","text":"<p>Author: Wenyu Ouyang Date: 2022-12-02 11:03:04 LastEditTime: 2024-09-14 13:57:36 LastEditors: Wenyu Ouyang Description: some functions to deal with time FilePath: /hydroutils/hydroutils/hydro_time.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydro_time/#hydroutils.hydro_time.calculate_utc_offset","title":"<code>calculate_utc_offset(lat, lng, date=None)</code>","text":"<p>Calculate the UTC offset for a given latitude and longitude using tzfpy.</p>"},{"location":"api/hydro_time/#hydroutils.hydro_time.calculate_utc_offset--parameters","title":"Parameters","text":"<p>lat : float     Latitude. lng : float     Longitude. date : datetime, optional     The date to consider for the UTC offset. If not provided, uses the current date.</p>"},{"location":"api/hydro_time/#hydroutils.hydro_time.calculate_utc_offset--returns","title":"Returns","text":"<p>int     UTC offset in hours.</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def calculate_utc_offset(lat, lng, date=None):\n    \"\"\"\n    Calculate the UTC offset for a given latitude and longitude using tzfpy.\n\n    Parameters\n    ----------\n    lat : float\n        Latitude.\n    lng : float\n        Longitude.\n    date : datetime, optional\n        The date to consider for the UTC offset. If not provided, uses the current date.\n\n    Returns\n    -------\n    int\n        UTC offset in hours.\n    \"\"\"\n    if date is None:\n        date = datetime.datetime.utcnow()\n\n    if timezone_str := tzfpy.get_tz(lng, lat):\n        # Get the timezone object using pytz\n        tz = pytz.timezone(timezone_str)\n        # Get the UTC offset for the specified date\n        offset = tz.utcoffset(date)\n        if offset is not None:\n            return int(offset.total_seconds() / 3600)\n    return None\n</code></pre>"},{"location":"api/hydro_time/#hydroutils.hydro_time.generate_start0101_time_range","title":"<code>generate_start0101_time_range(start_time, end_time, freq='8D')</code>","text":"<p>Generate a time range with a flexible start date and each year starting from 01-01.</p>"},{"location":"api/hydro_time/#hydroutils.hydro_time.generate_start0101_time_range--parameters","title":"Parameters","text":"<p>start_time : str or pd.Timestamp     The start time for the range (could be any date, string or Timestamp). end_time : str or pd.Timestamp     The end time for the range (could be any date, string or Timestamp). freq : str, optional     Time frequency for intervals, by default '8D'. Could be '7D', '10D', etc.</p>"},{"location":"api/hydro_time/#hydroutils.hydro_time.generate_start0101_time_range--returns","title":"Returns","text":"<p>pd.DatetimeIndex     A time range index with custom intervals and annual reset at 01-01.</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def generate_start0101_time_range(start_time, end_time, freq=\"8D\"):\n    \"\"\"Generate a time range with a flexible start date and each year starting from 01-01.\n\n    Parameters\n    ----------\n    start_time : str or pd.Timestamp\n        The start time for the range (could be any date, string or Timestamp).\n    end_time : str or pd.Timestamp\n        The end time for the range (could be any date, string or Timestamp).\n    freq : str, optional\n        Time frequency for intervals, by default '8D'. Could be '7D', '10D', etc.\n\n    Returns\n    -------\n    pd.DatetimeIndex\n        A time range index with custom intervals and annual reset at 01-01.\n    \"\"\"\n    all_dates = []\n\n    # Ensure the start and end times are of type pd.Timestamp\n    current_time = pd.Timestamp(start_time)\n    end_time = pd.Timestamp(end_time)\n\n    # Parse the frequency interval correctly\n    interval_days = pd.Timedelta(freq)  # Ensure it's a Timedelta\n\n    while current_time &lt;= end_time:\n        all_dates.append(current_time)\n\n        # Calculate next date with the specified interval\n        next_time = current_time + interval_days\n\n        # If next_time crosses into a new year, reset to 01-01 of the new year\n        if next_time.year &gt; current_time.year:\n            next_time = pd.Timestamp(f\"{next_time.year}-01-01\")\n\n        current_time = next_time\n\n    return pd.to_datetime(all_dates)\n</code></pre>"},{"location":"api/hydro_time/#hydroutils.hydro_time.t_days_lst2range","title":"<code>t_days_lst2range(t_array)</code>","text":"<p>Transform a period list to its interval. For example,  [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"] -&gt;  [\"2000-01-01\", \"2000-01-04\"] Parameters</p> <p>t_array: list[Union[np.datetime64, str]]     a period list Returns</p> <p>list     An time interval</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_days_lst2range(t_array: list) -&gt; list:\n    \"\"\"\n    Transform a period list to its interval.\n    For example,  [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"] -&gt;  [\"2000-01-01\", \"2000-01-04\"]\n    Parameters\n    ----------\n    t_array: list[Union[np.datetime64, str]]\n        a period list\n    Returns\n    -------\n    list\n        An time interval\n    \"\"\"\n    if type(t_array[0]) == np.datetime64:\n        t0 = t_array[0].astype(datetime.datetime)\n        t1 = t_array[-1].astype(datetime.datetime)\n    else:\n        t0 = t_array[0]\n        t1 = t_array[-1]\n    sd = t0.strftime(\"%Y-%m-%d\")\n    ed = t1.strftime(\"%Y-%m-%d\")\n    return [sd, ed]\n</code></pre>"},{"location":"api/hydro_time/#hydroutils.hydro_time.t_range_days","title":"<code>t_range_days(t_range, *, step=np.timedelta64(1, 'D'))</code>","text":"<p>Transform the two-value t_range list to a uniformly-spaced list (default is a daily list). For example, [\"2000-01-01\", \"2000-01-05\"] -&gt; [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"] Parameters</p> <p>t_range     two-value t_range list step     the time interval; its default value is 1 day Returns</p> <p>np.array     a uniformly-spaced (daily) list</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_days(t_range, *, step=np.timedelta64(1, \"D\")) -&gt; np.array:\n    \"\"\"\n    Transform the two-value t_range list to a uniformly-spaced list (default is a daily list).\n    For example, [\"2000-01-01\", \"2000-01-05\"] -&gt; [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"]\n    Parameters\n    ----------\n    t_range\n        two-value t_range list\n    step\n        the time interval; its default value is 1 day\n    Returns\n    -------\n    np.array\n        a uniformly-spaced (daily) list\n    \"\"\"\n    sd = datetime.datetime.strptime(t_range[0], \"%Y-%m-%d\")\n    ed = datetime.datetime.strptime(t_range[1], \"%Y-%m-%d\")\n    return np.arange(sd, ed, step)\n</code></pre>"},{"location":"api/hydro_time/#hydroutils.hydro_time.t_range_days_timedelta","title":"<code>t_range_days_timedelta(t_array, td=12, td_type='h')</code>","text":"<p>for each day, add a timedelta Parameters</p> <p>t_array     its data type is same as the return type of \"t_range_days\" function td     time periods td_type     the type of time period Returns</p> <p>np.array     a new t_array</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_days_timedelta(t_array, td=12, td_type=\"h\"):\n    \"\"\"\n    for each day, add a timedelta\n    Parameters\n    ----------\n    t_array\n        its data type is same as the return type of \"t_range_days\" function\n    td\n        time periods\n    td_type\n        the type of time period\n    Returns\n    -------\n    np.array\n        a new t_array\n    \"\"\"\n    assert td_type in [\"Y\", \"M\", \"D\", \"h\", \"m\", \"s\"]\n    t_array_final = [t + np.timedelta64(td, td_type) for t in t_array]\n    return np.array(t_array_final)\n</code></pre>"},{"location":"api/hydro_time/#hydroutils.hydro_time.t_range_years","title":"<code>t_range_years(t_range)</code>","text":"<p>t_range is a left-closed and right-open interval, if t_range[1] is not Jan.1 then end_year should be included</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_years(t_range):\n    \"\"\"t_range is a left-closed and right-open interval, if t_range[1] is not Jan.1 then end_year should be included\"\"\"\n    start_year = int(t_range[0].split(\"-\")[0])\n    end_year = int(t_range[1].split(\"-\")[0])\n    end_month = int(t_range[1].split(\"-\")[1])\n    end_day = int(t_range[1].split(\"-\")[2])\n    return (\n        np.arange(start_year, end_year)\n        if end_month == 1 and end_day == 1\n        else np.arange(start_year, end_year + 1)\n    )\n</code></pre>"},{"location":"api/hydro_time/#key-features","title":"Key Features","text":""},{"location":"api/hydro_time/#streamflow-unit-conversion","title":"Streamflow Unit Conversion","text":"<p>Convert between different streamflow units (CMS, CFS, etc.)</p>"},{"location":"api/hydro_time/#time-interval-detection","title":"Time Interval Detection","text":"<p>Automatically detect the time interval of time series data</p>"},{"location":"api/hydro_time/#unit-validation","title":"Unit Validation","text":"<p>Validate compatibility between units and data types</p>"},{"location":"api/hydro_time/#usage-examples","title":"Usage Examples","text":""},{"location":"api/hydro_time/#unit-conversions","title":"Unit Conversions","text":"<pre><code>import hydroutils as hu\nimport numpy as np\n\n# Convert cubic meters per second to cubic feet per second\nflow_cms = np.array([10.5, 12.3, 8.7, 15.2])\nflow_cfs = hu.streamflow_unit_conv(flow_cms, from_unit='cms', to_unit='cfs')\nprint(f\"Flow in CFS: {flow_cfs}\")\n</code></pre>"},{"location":"api/hydro_time/#time-detection","title":"Time Detection","text":"<pre><code>import pandas as pd\n\n# Detect time interval from date series\ntime_series = pd.date_range('2020-01-01', periods=100, freq='D')\ninterval = hu.detect_time_interval(time_series)\nprint(f\"Detected interval: {interval}\")\n</code></pre>"},{"location":"api/hydro_time/#validation","title":"Validation","text":"<pre><code># Validate unit compatibility\nis_compatible = hu.validate_unit_compatibility('cms', 'streamflow')\nprint(f\"CMS compatible with streamflow: {is_compatible}\")\n\n# Get detailed interval information\ninterval_info = hu.get_time_interval_info('1D')\nprint(f\"Daily interval info: {interval_info}\")\n</code></pre>"},{"location":"api/hydro_time/#supported-units","title":"Supported Units","text":""},{"location":"api/hydro_time/#streamflow-units","title":"Streamflow Units","text":"<ul> <li>cms: Cubic meters per second</li> <li>cfs: Cubic feet per second  </li> <li>lps: Liters per second</li> <li>mgd: Million gallons per day</li> </ul>"},{"location":"api/hydro_time/#time-intervals","title":"Time Intervals","text":"<ul> <li>Hourly: 1H, 3H, 6H, 12H</li> <li>Daily: 1D, D</li> <li>Monthly: 1M, M</li> <li>Annual: 1Y, Y</li> </ul>"},{"location":"api/hydro_time/#function-reference","title":"Function Reference","text":"<p>The module provides functions for:</p> <ul> <li>Unit Conversion: <code>streamflow_unit_conv()</code></li> <li>Time Detection: <code>detect_time_interval()</code></li> <li>Validation: <code>validate_unit_compatibility()</code>, <code>get_time_interval_info()</code></li> </ul> <p>For detailed function signatures and parameters, see the complete API documentation below.</p>"},{"location":"api/hydroutils/","title":"API Reference","text":"<p>This section provides detailed documentation for all modules and functions in the <code>hydroutils</code> package.</p>"},{"location":"api/hydroutils/#core-module","title":"Core Module","text":"<p>Author: Wenyu Ouyang Date: 2022-12-02 10:42:19 LastEditTime: 2023-10-27 14:53:16 LastEditors: Wenyu Ouyang Description: Top-level package for hydroutils. FilePath: /hydroutils/hydroutils/init.py Copyright (c) 2023-2024 Wenyu Ouyang. All rights reserved.</p>"},{"location":"api/hydroutils/#hydroutils.KGE","title":"<code>KGE(xs, xo)</code>","text":"<p>Kling Gupta Efficiency (Gupta et al., 2009, http://dx.doi.org/10.1016/j.jhydrol.2009.08.003) input:     xs: simulated     xo: observed output:     KGE: Kling Gupta Efficiency</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def KGE(xs, xo):\n    \"\"\"\n    Kling Gupta Efficiency (Gupta et al., 2009, http://dx.doi.org/10.1016/j.jhydrol.2009.08.003)\n    input:\n        xs: simulated\n        xo: observed\n    output:\n        KGE: Kling Gupta Efficiency\n    \"\"\"\n    r = np.corrcoef(xo, xs)[0, 1]\n    alpha = np.std(xs) / np.std(xo)\n    beta = np.mean(xs) / np.mean(xo)\n    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_4_stat_inds","title":"<code>cal_4_stat_inds(b)</code>","text":"<p>Calculate four statistics indices: percentile 10 and 90, mean value, standard deviation</p>"},{"location":"api/hydroutils/#hydroutils.cal_4_stat_inds--parameters","title":"Parameters","text":"<p>b     input data</p>"},{"location":"api/hydroutils/#hydroutils.cal_4_stat_inds--returns","title":"Returns","text":"<p>list     [p10, p90, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_4_stat_inds(b):\n    \"\"\"\n    Calculate four statistics indices: percentile 10 and 90, mean value, standard deviation\n\n    Parameters\n    ----------\n    b\n        input data\n\n    Returns\n    -------\n    list\n        [p10, p90, mean, std]\n    \"\"\"\n    p10 = np.percentile(b, 10).astype(float)\n    p90 = np.percentile(b, 90).astype(float)\n    mean = np.mean(b).astype(float)\n    std = np.std(b).astype(float)\n    if std &lt; 0.001:\n        std = 1\n    return [p10, p90, mean, std]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_stat","title":"<code>cal_stat(x)</code>","text":"<p>Get statistic values of x (Exclude the NaN values)</p>"},{"location":"api/hydroutils/#hydroutils.cal_stat--parameters","title":"Parameters","text":"<p>x: the array</p>"},{"location":"api/hydroutils/#hydroutils.cal_stat--returns","title":"Returns","text":"<p>list     [10% quantile, 90% quantile, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat(x: np.array) -&gt; list:\n    \"\"\"\n    Get statistic values of x (Exclude the NaN values)\n\n    Parameters\n    ----------\n    x: the array\n\n    Returns\n    -------\n    list\n        [10% quantile, 90% quantile, mean, std]\n    \"\"\"\n    a = x.flatten()\n    b = a[~np.isnan(a)]\n    if b.size == 0:\n        # if b is [], then give it a 0 value\n        b = np.array([0])\n    return cal_4_stat_inds(b)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_stat_gamma","title":"<code>cal_stat_gamma(x)</code>","text":"<p>Try to transform a time series data to normal distribution</p> <p>Now only for daily streamflow, precipitation and evapotranspiration; When nan values exist, just ignore them.</p>"},{"location":"api/hydroutils/#hydroutils.cal_stat_gamma--parameters","title":"Parameters","text":"<p>x     time series data</p>"},{"location":"api/hydroutils/#hydroutils.cal_stat_gamma--returns","title":"Returns","text":"<p>list     [p10, p90, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat_gamma(x):\n    \"\"\"\n    Try to transform a time series data to normal distribution\n\n    Now only for daily streamflow, precipitation and evapotranspiration;\n    When nan values exist, just ignore them.\n\n    Parameters\n    ----------\n    x\n        time series data\n\n    Returns\n    -------\n    list\n        [p10, p90, mean, std]\n    \"\"\"\n    a = x.flatten()\n    b = a[~np.isnan(a)]  # kick out Nan\n    b = np.log10(\n        np.sqrt(b) + 0.1\n    )  # do some tranformation to change gamma characteristics\n    return cal_4_stat_inds(b)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.cal_stat_prcp_norm","title":"<code>cal_stat_prcp_norm(x, meanprep)</code>","text":"<p>normalized variable by precipitation with cal_stat_gamma</p> <p>dividing a var with prcp means we can get a normalized var without rainfall's magnitude's influence, so that we don't have bias for dry and wet basins</p>"},{"location":"api/hydroutils/#hydroutils.cal_stat_prcp_norm--parameters","title":"Parameters","text":"<p>x     data to be normalized meanprep     meanprep = readAttr(gageDict['id'], ['p_mean'])</p>"},{"location":"api/hydroutils/#hydroutils.cal_stat_prcp_norm--returns","title":"Returns","text":"<p>list     [p10, p90, mean, std]</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def cal_stat_prcp_norm(x, meanprep):\n    \"\"\"\n    normalized variable by precipitation with cal_stat_gamma\n\n    dividing a var with prcp means we can get a normalized var without rainfall's magnitude's influence,\n    so that we don't have bias for dry and wet basins\n\n    Parameters\n    ----------\n    x\n        data to be normalized\n    meanprep\n        meanprep = readAttr(gageDict['id'], ['p_mean'])\n\n    Returns\n    -------\n    list\n        [p10, p90, mean, std]\n    \"\"\"\n    # meanprep = readAttr(gageDict['id'], ['q_mean'])\n    tempprep = np.tile(meanprep, (1, x.shape[1]))\n    # unit (mm/day)/(mm/day)\n    flowua = x / tempprep\n    return cal_stat_gamma(flowua)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.calculate_utc_offset","title":"<code>calculate_utc_offset(lat, lng, date=None)</code>","text":"<p>Calculate the UTC offset for a given latitude and longitude using tzfpy.</p>"},{"location":"api/hydroutils/#hydroutils.calculate_utc_offset--parameters","title":"Parameters","text":"<p>lat : float     Latitude. lng : float     Longitude. date : datetime, optional     The date to consider for the UTC offset. If not provided, uses the current date.</p>"},{"location":"api/hydroutils/#hydroutils.calculate_utc_offset--returns","title":"Returns","text":"<p>int     UTC offset in hours.</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def calculate_utc_offset(lat, lng, date=None):\n    \"\"\"\n    Calculate the UTC offset for a given latitude and longitude using tzfpy.\n\n    Parameters\n    ----------\n    lat : float\n        Latitude.\n    lng : float\n        Longitude.\n    date : datetime, optional\n        The date to consider for the UTC offset. If not provided, uses the current date.\n\n    Returns\n    -------\n    int\n        UTC offset in hours.\n    \"\"\"\n    if date is None:\n        date = datetime.datetime.utcnow()\n\n    if timezone_str := tzfpy.get_tz(lng, lat):\n        # Get the timezone object using pytz\n        tz = pytz.timezone(timezone_str)\n        # Get the UTC offset for the specified date\n        offset = tz.utcoffset(date)\n        if offset is not None:\n            return int(offset.total_seconds() / 3600)\n    return None\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.create_median_labels","title":"<code>create_median_labels(ax, medians_value, percent25value=None, percent75value=None, size='small')</code>","text":"<p>\"create median labels for boxes in a boxplot Parameters</p> <p>ax : plt.AxesSubplot     an ax in a fig medians_value : np.array     description percent25value : type, optional     description, by default None percent75value : type, optional     description, by default None size : str, optional     the size of median-value labels, by default small</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def create_median_labels(\n    ax, medians_value, percent25value=None, percent75value=None, size=\"small\"\n):\n    \"\"\" \"create median labels for boxes in a boxplot\n    Parameters\n    ----------\n    ax : plt.AxesSubplot\n        an ax in a fig\n    medians_value : np.array\n        _description_\n    percent25value : _type_, optional\n        _description_, by default None\n    percent75value : _type_, optional\n        _description_, by default None\n    size : str, optional\n        the size of median-value labels, by default small\n    \"\"\"\n    decimal_places = \"2\"\n    if percent25value is None or percent75value is None:\n        vertical_offset = np.min(medians_value * 0.01)  # offset from median for display\n    else:\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        vertical_offset = (per75max - per25min) * 0.01\n    median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n    pos = range(len(medians_value))\n    for xtick in ax.get_xticks():\n        ax.text(\n            pos[xtick],\n            medians_value[xtick] + vertical_offset,\n            median_labels[xtick],\n            horizontalalignment=\"center\",\n            color=\"w\",\n            # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n            size=size,\n            weight=\"semibold\",\n        )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_excel","title":"<code>download_excel(data_url, temp_file)</code>","text":"<p>download a excel file according to url</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_excel(data_url, temp_file):\n    \"\"\"download a excel file according to url\"\"\"\n    if not os.path.isfile(temp_file):\n        urllib.request.urlretrieve(data_url, temp_file)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_one_zip","title":"<code>download_one_zip(data_url, data_dir)</code>","text":"<p>download one zip file from url as data_file Parameters</p> <p>data_url: the URL of the downloading website data_dir: where we will put the data</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_one_zip(data_url, data_dir):\n    \"\"\"\n    download one zip file from url as data_file\n    Parameters\n    ----------\n    data_url: the URL of the downloading website\n    data_dir: where we will put the data\n    \"\"\"\n\n    zipfile_path, unzip_dir = zip_file_name_from_url(data_url, data_dir)\n    if not is_there_file(zipfile_path, unzip_dir):\n        if not os.path.isdir(unzip_dir):\n            os.makedirs(unzip_dir)\n        r = requests.get(data_url, stream=True)\n        with open(zipfile_path, \"wb\") as py_file:\n            for chunk in r.iter_content(chunk_size=1024):  # 1024 bytes\n                if chunk:\n                    py_file.write(chunk)\n        unzip_nested_zip(zipfile_path, unzip_dir)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_small_file","title":"<code>download_small_file(data_url, temp_file)</code>","text":"<p>download data from url to the temp_file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_small_file(data_url, temp_file):\n    \"\"\"download data from url to the temp_file\"\"\"\n    r = requests.get(data_url)\n    with open(temp_file, \"w\") as f:\n        f.write(r.text)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_small_zip","title":"<code>download_small_zip(data_url, data_dir)</code>","text":"<p>download zip file and unzip</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_small_zip(data_url, data_dir):\n    \"\"\"download zip file and unzip\"\"\"\n    zipfile_path, unzip_dir = zip_file_name_from_url(data_url, data_dir)\n    if not is_there_file(zipfile_path, unzip_dir):\n        if not os.path.isdir(unzip_dir):\n            os.mkdir(unzip_dir)\n        zipfile_path, _ = urllib.request.urlretrieve(data_url, zipfile_path)\n        unzip_nested_zip(zipfile_path, unzip_dir)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.download_zip_files","title":"<code>download_zip_files(urls, the_dir)</code>","text":"<p>Download multi-files from multi-urls</p>"},{"location":"api/hydroutils/#hydroutils.download_zip_files--parameters","title":"Parameters","text":"<p>urls : list     list of all urls the_dir : Path     the directory containing all downloaded files</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def download_zip_files(urls, the_dir: Path):\n    \"\"\"Download multi-files from multi-urls\n\n    Parameters\n    ----------\n    urls : list\n        list of all urls\n    the_dir : Path\n        the directory containing all downloaded files\n    \"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        cache_names = Path(tmpdir).joinpath(f\"{the_dir.stem}.sqlite\")\n        r = ar.retrieve(urls, \"binary\", cache_name=cache_names, ssl=False)\n        files = [the_dir.joinpath(url.split(\"/\")[-1]) for url in urls]\n        [files[i].write_bytes(io.BytesIO(r[i]).getbuffer()) for i in range(len(files))]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.ecdf","title":"<code>ecdf(data)</code>","text":"<p>Compute ECDF</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def ecdf(data):\n    \"\"\"Compute ECDF\"\"\"\n    x = np.sort(data)\n    n = x.size\n    y = np.arange(1, n + 1) / n\n    return (x, y)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.fms","title":"<code>fms(obs, sim, lower=0.2, upper=0.7)</code>","text":"<p>TODO: not fully tested Calculate the slope of the middle section of the flow duration curve [#]_</p> <p>.. math::     \\%\\text{BiasFMS} = \\frac{\\left | \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right | -         \\left | \\log(Q_{o,\\text{lower}}) - \\log(Q_{o,\\text{upper}}) \\right |}{\\left |         \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right |} \\times 100,</p> <p>where :math:<code>Q_{s,\\text{lower/upper}}</code> corresponds to the FDC of the simulations (here, <code>sim</code>) at the <code>lower</code> and <code>upper</code> bound of the middle section and :math:<code>Q_{o,\\text{lower/upper}}</code> similarly for the observations (here, <code>obs</code>).</p>"},{"location":"api/hydroutils/#hydroutils.fms--parameters","title":"Parameters","text":"<p>obs : DataArray     Observed time series. sim : DataArray     Simulated time series. lower : float, optional     Lower bound of the middle section in range ]0,1[, by default 0.2 upper : float, optional     Upper bound of the middle section in range ]0,1[, by default 0.7</p>"},{"location":"api/hydroutils/#hydroutils.fms--returns","title":"Returns","text":"<p>float     Slope of the middle section of the flow duration curve.</p>"},{"location":"api/hydroutils/#hydroutils.fms--references","title":"References","text":"<p>.. [#] Yilmaz, K. K., Gupta, H. V., and Wagener, T. ( 2008), A process-based diagnostic approach to model     evaluation: Application to the NWS distributed hydrologic model, Water Resour. Res., 44, W09417,     doi:10.1029/2007WR006716.</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def fms(obs, sim, lower: float = 0.2, upper: float = 0.7) -&gt; float:\n    r\"\"\"\n    TODO: not fully tested\n    Calculate the slope of the middle section of the flow duration curve [#]_\n\n    .. math::\n        \\%\\text{BiasFMS} = \\frac{\\left | \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right | -\n            \\left | \\log(Q_{o,\\text{lower}}) - \\log(Q_{o,\\text{upper}}) \\right |}{\\left |\n            \\log(Q_{s,\\text{lower}}) - \\log(Q_{s,\\text{upper}}) \\right |} \\times 100,\n\n    where :math:`Q_{s,\\text{lower/upper}}` corresponds to the FDC of the simulations (here, `sim`) at the `lower` and\n    `upper` bound of the middle section and :math:`Q_{o,\\text{lower/upper}}` similarly for the observations (here,\n    `obs`).\n\n    Parameters\n    ----------\n    obs : DataArray\n        Observed time series.\n    sim : DataArray\n        Simulated time series.\n    lower : float, optional\n        Lower bound of the middle section in range ]0,1[, by default 0.2\n    upper : float, optional\n        Upper bound of the middle section in range ]0,1[, by default 0.7\n\n    Returns\n    -------\n    float\n        Slope of the middle section of the flow duration curve.\n\n    References\n    ----------\n    .. [#] Yilmaz, K. K., Gupta, H. V., and Wagener, T. ( 2008), A process-based diagnostic approach to model\n        evaluation: Application to the NWS distributed hydrologic model, Water Resour. Res., 44, W09417,\n        doi:10.1029/2007WR006716.\n    \"\"\"\n    if len(obs) &lt; 1:\n        return np.nan\n\n    if any((x &lt;= 0) or (x &gt;= 1) for x in [upper, lower]):\n        raise ValueError(\"upper and lower have to be in range ]0,1[\")\n\n    if lower &gt;= upper:\n        raise ValueError(\"The lower threshold has to be smaller than the upper.\")\n\n    # get arrays of sorted (descending) discharges\n    obs = np.sort(obs)\n    sim = np.sort(sim)\n\n    # for numerical reasons change 0s to 1e-6. Simulations can still contain negatives, so also reset those.\n    sim[sim &lt;= 0] = 1e-6\n    obs[obs == 0] = 1e-6\n\n    # calculate fms part by part\n    qsm_lower = np.log(sim[np.round(lower * len(sim)).astype(int)])\n    qsm_upper = np.log(sim[np.round(upper * len(sim)).astype(int)])\n    qom_lower = np.log(obs[np.round(lower * len(obs)).astype(int)])\n    qom_upper = np.log(obs[np.round(upper * len(obs)).astype(int)])\n\n    fms = ((qsm_lower - qsm_upper) - (qom_lower - qom_upper)) / (\n        qom_lower - qom_upper + 1e-6\n    )\n\n    return fms * 100\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.generate_start0101_time_range","title":"<code>generate_start0101_time_range(start_time, end_time, freq='8D')</code>","text":"<p>Generate a time range with a flexible start date and each year starting from 01-01.</p>"},{"location":"api/hydroutils/#hydroutils.generate_start0101_time_range--parameters","title":"Parameters","text":"<p>start_time : str or pd.Timestamp     The start time for the range (could be any date, string or Timestamp). end_time : str or pd.Timestamp     The end time for the range (could be any date, string or Timestamp). freq : str, optional     Time frequency for intervals, by default '8D'. Could be '7D', '10D', etc.</p>"},{"location":"api/hydroutils/#hydroutils.generate_start0101_time_range--returns","title":"Returns","text":"<p>pd.DatetimeIndex     A time range index with custom intervals and annual reset at 01-01.</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def generate_start0101_time_range(start_time, end_time, freq=\"8D\"):\n    \"\"\"Generate a time range with a flexible start date and each year starting from 01-01.\n\n    Parameters\n    ----------\n    start_time : str or pd.Timestamp\n        The start time for the range (could be any date, string or Timestamp).\n    end_time : str or pd.Timestamp\n        The end time for the range (could be any date, string or Timestamp).\n    freq : str, optional\n        Time frequency for intervals, by default '8D'. Could be '7D', '10D', etc.\n\n    Returns\n    -------\n    pd.DatetimeIndex\n        A time range index with custom intervals and annual reset at 01-01.\n    \"\"\"\n    all_dates = []\n\n    # Ensure the start and end times are of type pd.Timestamp\n    current_time = pd.Timestamp(start_time)\n    end_time = pd.Timestamp(end_time)\n\n    # Parse the frequency interval correctly\n    interval_days = pd.Timedelta(freq)  # Ensure it's a Timedelta\n\n    while current_time &lt;= end_time:\n        all_dates.append(current_time)\n\n        # Calculate next date with the specified interval\n        next_time = current_time + interval_days\n\n        # If next_time crosses into a new year, reset to 01-01 of the new year\n        if next_time.year &gt; current_time.year:\n            next_time = pd.Timestamp(f\"{next_time.year}-01-01\")\n\n        current_time = next_time\n\n    return pd.to_datetime(all_dates)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.get_lastest_file_in_a_dir","title":"<code>get_lastest_file_in_a_dir(dir_path)</code>","text":"<p>Get the last file in a directory</p>"},{"location":"api/hydroutils/#hydroutils.get_lastest_file_in_a_dir--parameters","title":"Parameters","text":"<p>dir_path : str     the directory</p>"},{"location":"api/hydroutils/#hydroutils.get_lastest_file_in_a_dir--returns","title":"Returns","text":"<p>str     the path of the weight file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_lastest_file_in_a_dir(dir_path):\n    \"\"\"Get the last file in a directory\n\n    Parameters\n    ----------\n    dir_path : str\n        the directory\n\n    Returns\n    -------\n    str\n        the path of the weight file\n    \"\"\"\n    pth_files_lst = [\n        os.path.join(dir_path, file)\n        for file in os.listdir(dir_path)\n        if fnmatch.fnmatch(file, \"*.pth\")\n    ]\n    return get_latest_file_in_a_lst(pth_files_lst)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.get_latest_file_in_a_lst","title":"<code>get_latest_file_in_a_lst(lst)</code>","text":"<p>get the latest file in a list</p>"},{"location":"api/hydroutils/#hydroutils.get_latest_file_in_a_lst--parameters","title":"Parameters","text":"<p>lst : list     list of files</p>"},{"location":"api/hydroutils/#hydroutils.get_latest_file_in_a_lst--returns","title":"Returns","text":"<p>str     the latest file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def get_latest_file_in_a_lst(lst):\n    \"\"\"get the latest file in a list\n\n    Parameters\n    ----------\n    lst : list\n        list of files\n\n    Returns\n    -------\n    str\n        the latest file\n    \"\"\"\n    lst_ctime = [os.path.getctime(file) for file in lst]\n    sort_idx = np.argsort(lst_ctime)\n    return lst[sort_idx[-1]]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.hydro_logger","title":"<code>hydro_logger(cls)</code>","text":"<p>Class decorator: Adds a logger attribute to the class.</p> Source code in <code>hydroutils/hydro_log.py</code> <pre><code>def hydro_logger(cls):\n    \"\"\"\n    Class decorator: Adds a logger attribute to the class.\n    \"\"\"\n    # Use the class name as the logger name\n    logger_name = f\"{cls.__module__}.{cls.__name__}\"\n    logger = logging.getLogger(logger_name)\n    logger.setLevel(logging.DEBUG)\n    cache_dir = get_cache_dir()\n    log_dir = os.path.join(cache_dir, \"logs\")\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_file = os.path.join(log_dir, f\"{logger_name}_{current_time}.log\")\n    # Check if handlers have already been added to avoid duplication\n    if not logger.handlers:\n        # Create a file handler to write logs to the specified file\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setLevel(logging.DEBUG)\n\n        # Create a console handler to output logs to the console (optional)\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(logging.INFO)\n\n        # set the format of the log\n        formatter = logging.Formatter(\n            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n        )\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n\n        # Add handlers to the logger\n        logger.addHandler(file_handler)\n        logger.addHandler(console_handler)\n\n    # Bind the logger to the class attribute\n    cls.logger = logger\n    return cls\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.is_there_file","title":"<code>is_there_file(zipfile_path, unzip_dir)</code>","text":"<p>if a file has existed</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def is_there_file(zipfile_path, unzip_dir):\n    \"\"\"if a file has existed\"\"\"\n    if os.path.isfile(zipfile_path):\n        if os.path.isdir(unzip_dir):\n            return True\n        unzip_nested_zip(zipfile_path, unzip_dir)\n        return True\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.mean_peak_timing","title":"<code>mean_peak_timing(obs, sim, window=None, resolution='1D', datetime_coord=None)</code>","text":"<p>TODO: not finished Mean difference in peak flow timing.</p> <p>Uses scipy.find_peaks to find peaks in the observed time series. Starting with all observed peaks, those with a prominence of less than the standard deviation of the observed time series are discarded. Next, the lowest peaks are subsequently discarded until all remaining peaks have a distance of at least 100 steps. Finally, the corresponding peaks in the simulated time series are searched in a window of size <code>window</code> on either side of the observed peaks and the absolute time differences between observed and simulated peaks is calculated. The final metric is the mean absolute time difference across all peaks. For more details, see Appendix of [#]_</p>"},{"location":"api/hydroutils/#hydroutils.mean_peak_timing--parameters","title":"Parameters","text":"<p>obs : DataArray     Observed time series. sim : DataArray     Simulated time series. window : int, optional     Size of window to consider on each side of the observed peak for finding the simulated peak. That is, the total     window length to find the peak in the simulations is :math:<code>2 * \\text{window} + 1</code> centered at the observed     peak. The default depends on the temporal resolution, e.g. for a resolution of '1D', a window of 3 is used and     for a resolution of '1H' the the window size is 12. resolution : str, optional     Temporal resolution of the time series in pandas format, e.g. '1D' for daily and '1H' for hourly. datetime_coord : str, optional     Name of datetime coordinate. Tried to infer automatically if not specified.</p>"},{"location":"api/hydroutils/#hydroutils.mean_peak_timing--returns","title":"Returns","text":"<p>float     Mean peak time difference.</p>"},{"location":"api/hydroutils/#hydroutils.mean_peak_timing--references","title":"References","text":"<p>.. [#] Kratzert, F., Klotz, D., Hochreiter, S., and Nearing, G. S.: A note on leveraging synergy in multiple     meteorological datasets with deep learning for rainfall-runoff modeling, Hydrol. Earth Syst. Sci.,     https://doi.org/10.5194/hess-2020-221</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def mean_peak_timing(\n    obs, sim, window: int = None, resolution: str = \"1D\", datetime_coord: str = None\n) -&gt; float:\n    \"\"\"\n    TODO: not finished\n    Mean difference in peak flow timing.\n\n    Uses scipy.find_peaks to find peaks in the observed time series. Starting with all observed peaks, those with a\n    prominence of less than the standard deviation of the observed time series are discarded. Next, the lowest peaks\n    are subsequently discarded until all remaining peaks have a distance of at least 100 steps. Finally, the\n    corresponding peaks in the simulated time series are searched in a window of size `window` on either side of the\n    observed peaks and the absolute time differences between observed and simulated peaks is calculated.\n    The final metric is the mean absolute time difference across all peaks. For more details, see Appendix of [#]_\n\n    Parameters\n    ----------\n    obs : DataArray\n        Observed time series.\n    sim : DataArray\n        Simulated time series.\n    window : int, optional\n        Size of window to consider on each side of the observed peak for finding the simulated peak. That is, the total\n        window length to find the peak in the simulations is :math:`2 * \\\\text{window} + 1` centered at the observed\n        peak. The default depends on the temporal resolution, e.g. for a resolution of '1D', a window of 3 is used and\n        for a resolution of '1H' the the window size is 12.\n    resolution : str, optional\n        Temporal resolution of the time series in pandas format, e.g. '1D' for daily and '1H' for hourly.\n    datetime_coord : str, optional\n        Name of datetime coordinate. Tried to infer automatically if not specified.\n\n\n    Returns\n    -------\n    float\n        Mean peak time difference.\n\n    References\n    ----------\n    .. [#] Kratzert, F., Klotz, D., Hochreiter, S., and Nearing, G. S.: A note on leveraging synergy in multiple\n        meteorological datasets with deep learning for rainfall-runoff modeling, Hydrol. Earth Syst. Sci.,\n        https://doi.org/10.5194/hess-2020-221\n    \"\"\"\n    # verify inputs\n    _validate_inputs(obs, sim)\n\n    # get time series with only valid observations (scipy's find_peaks doesn't guarantee correctness with NaNs)\n    obs, sim = _mask_valid(obs, sim)\n\n    # heuristic to get indices of peaks and their corresponding height.\n    peaks, _ = signal.find_peaks(\n        obs.values, distance=100, prominence=np.std(obs.values)\n    )\n\n    # infer name of datetime index\n    if datetime_coord is None:\n        datetime_coord = utils.infer_datetime_coord(obs)\n\n    if window is None:\n        # infer a reasonable window size\n        window = max(int(utils.get_frequency_factor(\"12H\", resolution)), 3)\n\n    # evaluate timing\n    timing_errors = []\n    for idx in peaks:\n        # skip peaks at the start and end of the sequence and peaks around missing observations\n        # (NaNs that were removed in obs &amp; sim would result in windows that span too much time).\n        if (\n            (idx - window &lt; 0)\n            or (idx + window &gt;= len(obs))\n            or (\n                pd.date_range(\n                    obs[idx - window][datetime_coord].values,\n                    obs[idx + window][datetime_coord].values,\n                    freq=resolution,\n                ).size\n                != 2 * window + 1\n            )\n        ):\n            continue\n\n        # check if the value at idx is a peak (both neighbors must be smaller)\n        if (sim[idx] &gt; sim[idx - 1]) and (sim[idx] &gt; sim[idx + 1]):\n            peak_sim = sim[idx]\n        else:\n            # define peak around idx as the max value inside of the window\n            values = sim[idx - window : idx + window + 1]\n            peak_sim = values[values.argmax()]\n\n        # get xarray object of qobs peak, for getting the date and calculating the datetime offset\n        peak_obs = obs[idx]\n\n        # calculate the time difference between the peaks\n        delta = peak_obs.coords[datetime_coord] - peak_sim.coords[datetime_coord]\n\n        timing_error = np.abs(delta.values / pd.to_timedelta(resolution))\n\n        timing_errors.append(timing_error)\n\n    return np.mean(timing_errors) if timing_errors else np.nan\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.month_stat_for_daily_df","title":"<code>month_stat_for_daily_df(df)</code>","text":"<p>calculate monthly statistics for daily data</p>"},{"location":"api/hydroutils/#hydroutils.month_stat_for_daily_df--parameters","title":"Parameters","text":"<p>df     daily data</p>"},{"location":"api/hydroutils/#hydroutils.month_stat_for_daily_df--returns","title":"Returns","text":"<p>pd.DataFrame     monthly statistics for daily data</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def month_stat_for_daily_df(df):\n    \"\"\"\n    calculate monthly statistics for daily data\n\n    Parameters\n    ----------\n    df\n        daily data\n\n    Returns\n    -------\n    pd.DataFrame\n        monthly statistics for daily data\n    \"\"\"\n    # guarantee the index is datetime\n    df.index = pd.to_datetime(df.index)\n    return df.resample(\"MS\").mean()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_boxes_matplotlib","title":"<code>plot_boxes_matplotlib(data, label1=None, label2=None, leg_col=None, colorlst='rbgcmywrbgcmyw', title=None, figsize=(8, 6), sharey=False, xticklabel=None, axin=None, ylim=None, ylabel=None, notch=False, widths=0.5, subplots_adjust_wspace=0.2, show_median=True, median_line_color='black', median_font_size='small')</code>","text":"<p>Creates multiple boxplots for comparing multiple indicators or groups.</p> <p>This function generates a sophisticated boxplot visualization with multiple customization options, including median display, notched boxes, and flexible layout options. It's particularly useful for comparing distributions across different groups or indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>List of arrays, where each array contains the data for one indicator or group to be displayed as a boxplot.</p> required <code>label1</code> <code>list</code> <p>Labels for each subplot. Defaults to None.</p> <code>None</code> <code>label2</code> <code>list</code> <p>Legend labels for boxes within each subplot. Defaults to None.</p> <code>None</code> <code>leg_col</code> <code>int</code> <p>Number of columns in the legend. Defaults to None.</p> <code>None</code> <code>colorlst</code> <code>str</code> <p>String of color characters for box colors. Defaults to \"rbgcmywrbgcmyw\".</p> <code>'rbgcmywrbgcmyw'</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to None.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>sharey</code> <code>bool</code> <p>If True, all subplots share the same y-axis scale. Defaults to False.</p> <code>False</code> <code>xticklabel</code> <code>list</code> <p>Custom x-axis tick labels. Defaults to None.</p> <code>None</code> <code>axin</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>list</code> <p>Y-axis labels for each subplot. Defaults to None.</p> <code>None</code> <code>notch</code> <code>bool</code> <p>If True, creates notched boxes. Defaults to False.</p> <code>False</code> <code>widths</code> <code>float</code> <p>Width of the boxes. Defaults to 0.5.</p> <code>0.5</code> <code>subplots_adjust_wspace</code> <code>float</code> <p>Width space between subplots. Defaults to 0.2.</p> <code>0.2</code> <code>show_median</code> <code>bool</code> <p>If True, displays median values. Defaults to True.</p> <code>True</code> <code>median_line_color</code> <code>str</code> <p>Color of median lines. Defaults to \"black\".</p> <code>'black'</code> <code>median_font_size</code> <code>str</code> <p>Font size for median values. Defaults to \"small\".</p> <code>'small'</code> <p>Returns:</p> Type Description <p>Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]: If axin is None, returns the Figure object. If axin is provided, returns a tuple of (Axes, boxplot_dict).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n&gt;&gt;&gt; fig = plot_boxes_matplotlib(\n...     data,\n...     label1=['Group A', 'Group B', 'Group C'],\n...     show_median=True,\n...     notch=True\n... )\n</code></pre> Notes <ul> <li>The function automatically handles NaN values in the data.</li> <li>Median values can be displayed with customizable formatting.</li> <li>Supports both single and multiple subplot layouts.</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxes_matplotlib(\n    data: list,\n    label1: list = None,\n    label2: list = None,\n    leg_col: int = None,\n    colorlst=\"rbgcmywrbgcmyw\",\n    title=None,\n    figsize=(8, 6),\n    sharey=False,\n    xticklabel=None,\n    axin=None,\n    ylim=None,\n    ylabel=None,\n    notch=False,\n    widths=0.5,\n    subplots_adjust_wspace=0.2,\n    show_median=True,\n    median_line_color=\"black\",\n    median_font_size=\"small\",\n):\n    \"\"\"Creates multiple boxplots for comparing multiple indicators or groups.\n\n    This function generates a sophisticated boxplot visualization with multiple customization\n    options, including median display, notched boxes, and flexible layout options. It's\n    particularly useful for comparing distributions across different groups or indicators.\n\n    Args:\n        data (list): List of arrays, where each array contains the data for one indicator\n            or group to be displayed as a boxplot.\n        label1 (list, optional): Labels for each subplot. Defaults to None.\n        label2 (list, optional): Legend labels for boxes within each subplot. Defaults to None.\n        leg_col (int, optional): Number of columns in the legend. Defaults to None.\n        colorlst (str, optional): String of color characters for box colors. Defaults to\n            \"rbgcmywrbgcmyw\".\n        title (str, optional): Title of the plot. Defaults to None.\n        figsize (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        sharey (bool, optional): If True, all subplots share the same y-axis scale.\n            Defaults to False.\n        xticklabel (list, optional): Custom x-axis tick labels. Defaults to None.\n        axin (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        ylabel (list, optional): Y-axis labels for each subplot. Defaults to None.\n        notch (bool, optional): If True, creates notched boxes. Defaults to False.\n        widths (float, optional): Width of the boxes. Defaults to 0.5.\n        subplots_adjust_wspace (float, optional): Width space between subplots.\n            Defaults to 0.2.\n        show_median (bool, optional): If True, displays median values. Defaults to True.\n        median_line_color (str, optional): Color of median lines. Defaults to \"black\".\n        median_font_size (str, optional): Font size for median values. Defaults to \"small\".\n\n    Returns:\n        Union[matplotlib.figure.Figure, Tuple[matplotlib.axes.Axes, dict]]:\n            If axin is None, returns the Figure object.\n            If axin is provided, returns a tuple of (Axes, boxplot_dict).\n\n    Examples:\n        &gt;&gt;&gt; data = [np.random.normal(0, 1, 100) for _ in range(3)]\n        &gt;&gt;&gt; fig = plot_boxes_matplotlib(\n        ...     data,\n        ...     label1=['Group A', 'Group B', 'Group C'],\n        ...     show_median=True,\n        ...     notch=True\n        ... )\n\n    Notes:\n        - The function automatically handles NaN values in the data.\n        - Median values can be displayed with customizable formatting.\n        - Supports both single and multiple subplot layouts.\n    \"\"\"\n    nc = len(data)\n    if axin is None:\n        fig, axes = plt.subplots(\n            ncols=nc, sharey=sharey, figsize=figsize, constrained_layout=False\n        )\n    else:\n        axes = axin\n\n    # the next few lines are for showing median values\n    decimal_places = \"2\"\n    for k in range(nc):\n        ax = axes[k] if nc &gt; 1 else axes\n        temp = data[k]\n        if type(temp) is list:\n            for kk in range(len(temp)):\n                tt = temp[kk]\n                if tt is not None and len(tt) &gt; 0:\n                    tt = tt[~np.isnan(tt)]\n                    temp[kk] = tt\n                else:\n                    temp[kk] = []\n        else:\n            temp = temp[~np.isnan(temp)]\n        bp = ax.boxplot(\n            temp, patch_artist=True, notch=notch, showfliers=False, widths=widths\n        )\n        for median in bp[\"medians\"]:\n            median.set_color(median_line_color)\n        medians_value = [np.median(tmp) for tmp in temp]\n        percent25value = [np.percentile(tmp, 25) for tmp in temp]\n        percent75value = [np.percentile(tmp, 75) for tmp in temp]\n        per25min = np.min(percent25value)\n        per75max = np.max(percent75value)\n        median_labels = [format(s, f\".{decimal_places}f\") for s in medians_value]\n        pos = range(len(medians_value))\n        if show_median:\n            for tick, label in zip(pos, ax.get_xticklabels()):\n                # params of ax.text could be seen here: https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                ax.text(\n                    pos[tick] + 1,\n                    medians_value[tick] + (per75max - per25min) * 0.01,\n                    median_labels[tick],\n                    horizontalalignment=\"center\",\n                    # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html\n                    size=median_font_size,\n                    weight=\"semibold\",\n                    color=median_line_color,\n                )\n        for kk in range(len(bp[\"boxes\"])):\n            plt.setp(bp[\"boxes\"][kk], facecolor=colorlst[kk])\n\n        if label1 is not None:\n            ax.set_xlabel(label1[k])\n        else:\n            ax.set_xlabel(str(k))\n        if xticklabel is None:\n            ax.set_xticks([])\n        else:\n            ax.set_xticks([y + 1 for y in range(0, len(data[k]), 2)])\n            ax.set_xticklabels(xticklabel)\n        if ylabel is not None:\n            ax.set_ylabel(ylabel[k])\n        if ylim is not None:\n            ax.set_ylim(ylim[k])\n    if label2 is not None:\n        plt.legend(\n            bp[\"boxes\"],\n            label2,\n            # explanation for bbox_to_anchor: https://zhuanlan.zhihu.com/p/101059179\n            bbox_to_anchor=(1.0, 1.02, 0.25, 0.05),\n            loc=\"upper right\",\n            borderaxespad=0,\n            ncol=len(label2) if leg_col is None else leg_col,\n            frameon=False,\n            fontsize=12,\n        )\n    if title is not None:\n        # fig.suptitle(title)\n        ax.set_title(title)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=subplots_adjust_wspace)\n    return fig if axin is None else (ax, bp)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_boxs","title":"<code>plot_boxs(data, x_name, y_name, uniform_color=None, swarm_plot=False, hue=None, colormap=False, xlim=None, ylim=None, order=None, font='serif', rotation=45, show_median=False)</code>","text":"<p>plot multiple boxes in one ax with seaborn Parameters</p> <p>data : pd.DataFrame     a tidy pandas dataframe;     if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data x_name : str     the names of each box y_name : str     what is shown uniform_color : str, optional     unified color for all boxes, by default None swarm_plot : bool, optional     description, by default False hue : type, optional     description, by default None colormap : bool, optional     description, by default False xlim : type, optional     description, by default None ylim : type, optional     description, by default None order : type, optional     description, by default None font : str, optional     description, by default \"serif\" rotation : int, optional     rotation for labels in x-axis, by default 45 show_median: bool, optional     if True, show median value for each box, by default False Returns</p> <p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_boxs(\n    data: pd.DataFrame,\n    x_name: str,\n    y_name: str,\n    uniform_color=None,\n    swarm_plot=False,\n    hue=None,\n    colormap=False,\n    xlim=None,\n    ylim=None,\n    order=None,\n    font=\"serif\",\n    rotation=45,\n    show_median=False,\n):\n    \"\"\"plot multiple boxes in one ax with seaborn\n    Parameters\n    ----------\n    data : pd.DataFrame\n        a tidy pandas dataframe;\n        if you don't know what is \"tidy data\", please read: https://github.com/jizhang/pandas-tidy-data\n    x_name : str\n        the names of each box\n    y_name : str\n        what is shown\n    uniform_color : str, optional\n        unified color for all boxes, by default None\n    swarm_plot : bool, optional\n        _description_, by default False\n    hue : _type_, optional\n        _description_, by default None\n    colormap : bool, optional\n        _description_, by default False\n    xlim : _type_, optional\n        _description_, by default None\n    ylim : _type_, optional\n        _description_, by default None\n    order : _type_, optional\n        _description_, by default None\n    font : str, optional\n        _description_, by default \"serif\"\n    rotation : int, optional\n        rotation for labels in x-axis, by default 45\n    show_median: bool, optional\n        if True, show median value for each box, by default False\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    fig = plt.figure()\n    sns.set(style=\"ticks\", palette=\"pastel\", font=font, font_scale=1.5)\n    # Draw a nested boxplot to show bills by day and time\n    if uniform_color is not None:\n        sns_box = sns.boxplot(\n            x=x_name,\n            y=y_name,\n            data=data,\n            color=uniform_color,\n            showfliers=False,\n            order=order,\n        )\n    else:\n        sns_box = sns.boxplot(\n            x=x_name, y=y_name, data=data, showfliers=False, order=order\n        )\n    if swarm_plot:\n        if hue is None:\n            sns_box = sns.swarmplot(\n                x=x_name, y=y_name, data=data, color=\".2\", order=order\n            )\n        elif colormap:\n            # Create a matplotlib colormap from the sns seagreen color palette\n            cmap = sns.light_palette(\"seagreen\", reverse=False, as_cmap=True)\n            # Normalize to the range of possible values from df[\"c\"]\n            norm = matplotlib.colors.Normalize(\n                vmin=data[hue].min(), vmax=data[hue].max()\n            )\n            colors = {cval: cmap(norm(cval)) for cval in data[hue]}\n            # plot the swarmplot with the colors dictionary as palette, s=2 means size is 2\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=colors,\n                order=order,\n            )\n            # remove the legend, because we want to set a colorbar instead\n            plt.gca().legend_.remove()\n            # create colorbar\n            divider = make_axes_locatable(plt.gca())\n            ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)\n            fig = sns_box.get_figure()\n            fig.add_axes(ax_cb)\n            cb1 = matplotlib.colorbar.ColorbarBase(\n                ax_cb, cmap=cmap, norm=norm, orientation=\"vertical\"\n            )\n            cb1.set_label(\"Some Units\")\n        else:\n            palette = sns.light_palette(\"seagreen\", reverse=False, n_colors=10)\n            sns_box = sns.swarmplot(\n                x=x_name,\n                y=y_name,\n                hue=hue,\n                s=2,\n                data=data,\n                palette=palette,\n                order=order,\n            )\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    if show_median:\n        medians = data.groupby([x_name], sort=False)[y_name].median().values\n        create_median_labels(sns_box, medians_value=medians, size=\"x-small\")\n    sns.despine()\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=rotation)\n    # plt.show()\n    return sns_box.get_figure()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_diff_boxes","title":"<code>plot_diff_boxes(data, row_and_col=None, y_col=None, x_col=None, hspace=0.3, wspace=1, title_str=None, title_font_size=14)</code>","text":"<p>plot boxplots in rows and cols</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_diff_boxes(\n    data,\n    row_and_col=None,\n    y_col=None,\n    x_col=None,\n    hspace=0.3,\n    wspace=1,\n    title_str=None,\n    title_font_size=14,\n):\n    \"\"\"plot boxplots in rows and cols\"\"\"\n    # matplotlib.use('TkAgg')\n    if type(data) is not pd.DataFrame:\n        data = pd.DataFrame(data)\n    subplot_num = data.shape[1] if y_col is None else len(y_col)\n    if row_and_col is None:\n        row_num = 1\n        col_num = subplot_num\n        f, axes = plt.subplots(row_num, col_num)\n        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n    else:\n        assert subplot_num &lt;= row_and_col[0] * row_and_col[1]\n        row_num = row_and_col[0]\n        col_num = row_and_col[1]\n        f, axes = plt.subplots(row_num, col_num)\n        f.tight_layout()\n    for i in range(subplot_num):\n        if y_col is None:\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    width=0.5,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                ).set(xlabel=data.columns.values[i], ylabel=\"\")\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    y=data.columns.values[i],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n        else:\n            assert x_col is not None\n            if row_num == 1 or col_num == 1:\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[i],\n                    showfliers=False,\n                )\n            else:\n                row_idx = int(i / col_num)\n                col_idx = i % col_num\n                sns.boxplot(\n                    x=data.columns.values[x_col],\n                    y=data.columns.values[y_col[i]],\n                    data=data,\n                    orient=\"v\",\n                    ax=axes[row_idx, col_idx],\n                    showfliers=False,\n                )\n    if title_str is not None:\n        f.suptitle(title_str, fontsize=title_font_size)\n    return f\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ecdf","title":"<code>plot_ecdf(mydataframe, mycolumn, save_file=None)</code>","text":"<p>Creates an empirical cumulative distribution function (ECDF) plot for a single column.</p> <p>This function generates an ECDF plot for a single column of data from a pandas DataFrame. It provides a simple interface for quick visualization of data distributions.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create ECDF for.</p> required <code>save_file</code> <code>str</code> <p>Path to save the plot. If None, plot is only displayed. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n&gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n</code></pre> Notes <ul> <li>Uses seaborn's styling for better visualization</li> <li>Automatically handles NaN values</li> <li>Plot range is set to [0, 1] for both axes</li> <li>Uses 0.05 intervals for axis ticks</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdf(mydataframe, mycolumn, save_file=None):\n    \"\"\"Creates an empirical cumulative distribution function (ECDF) plot for a single column.\n\n    This function generates an ECDF plot for a single column of data from a pandas\n    DataFrame. It provides a simple interface for quick visualization of data\n    distributions.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create ECDF for.\n        save_file (str, optional): Path to save the plot. If None, plot is only\n            displayed. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})\n        &gt;&gt;&gt; plot_ecdf(df, 'values', 'normal_dist_ecdf.png')\n\n    Notes:\n        - Uses seaborn's styling for better visualization\n        - Automatically handles NaN values\n        - Plot range is set to [0, 1] for both axes\n        - Uses 0.05 intervals for axis ticks\n    \"\"\"\n    x, y = ecdf(mydataframe[mycolumn])\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    sns.lineplot(x=\"x\", y=\"y\", data=df, estimator=None).set(\n        xlim=(0, 1), xticks=np.arange(0, 1, 0.05), yticks=np.arange(0, 1, 0.05)\n    )\n    plt.show()\n    if save_file is not None:\n        plt.savefig(save_file)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ecdfs","title":"<code>plot_ecdfs(xs, ys, legends=None, style=None, case_str='case', event_str='event', x_str='x', y_str='y', ax_as_subplot=None, interval=0.1)</code>","text":"<p>Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.</p> <p>This function generates ECDF plots for multiple datasets with customizable styling and labeling options. It's particularly useful for comparing distributions of different datasets or experimental conditions.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>style</code> <code>list[str]</code> <p>Line styles for each ECDF. Defaults to None.</p> <code>None</code> <code>case_str</code> <code>str</code> <p>Label for different cases in the plot. Defaults to \"case\".</p> <code>'case'</code> <code>event_str</code> <code>str</code> <p>Label for different events in the plot. Defaults to \"event\".</p> <code>'event'</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>ax_as_subplot</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>interval</code> <code>float</code> <p>Interval for axis ticks. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare two distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n&gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Distribution 1', 'Distribution 2'],\n...     x_str='Value',\n...     y_str='Cumulative Probability'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple distributions with different styles\n&gt;&gt;&gt; ax = plot_ecdfs(\n...     [x1, x2], [y1, y2],\n...     legends=['Group A', 'Group B'],\n...     style=['-', '--'],\n...     interval=0.2\n... )\n</code></pre> Notes <ul> <li>Input arrays must be sorted in ascending order</li> <li>Function automatically validates data ordering</li> <li>Supports both single and multiple subplot layouts</li> <li>Uses seaborn for enhanced visual styling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs(\n    xs,\n    ys,\n    legends=None,\n    style=None,\n    case_str=\"case\",\n    event_str=\"event\",\n    x_str=\"x\",\n    y_str=\"y\",\n    ax_as_subplot=None,\n    interval=0.1,\n):\n    \"\"\"Creates empirical cumulative distribution function (ECDF) plots for multiple datasets.\n\n    This function generates ECDF plots for multiple datasets with customizable styling\n    and labeling options. It's particularly useful for comparing distributions of\n    different datasets or experimental conditions.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        style (list[str], optional): Line styles for each ECDF. Defaults to None.\n        case_str (str, optional): Label for different cases in the plot.\n            Defaults to \"case\".\n        event_str (str, optional): Label for different events in the plot.\n            Defaults to \"event\".\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        ax_as_subplot (matplotlib.axes.Axes, optional): Existing axes to plot on.\n            Defaults to None.\n        interval (float, optional): Interval for axis ticks. Defaults to 0.1.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare two distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y1 = np.linspace(0, 1, len(x1))\n        &gt;&gt;&gt; y2 = np.linspace(0, 1, len(x2))\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Distribution 1', 'Distribution 2'],\n        ...     x_str='Value',\n        ...     y_str='Cumulative Probability'\n        ... )\n\n        &gt;&gt;&gt; # Multiple distributions with different styles\n        &gt;&gt;&gt; ax = plot_ecdfs(\n        ...     [x1, x2], [y1, y2],\n        ...     legends=['Group A', 'Group B'],\n        ...     style=['-', '--'],\n        ...     interval=0.2\n        ... )\n\n    Notes:\n        - Input arrays must be sorted in ascending order\n        - Function automatically validates data ordering\n        - Supports both single and multiple subplot layouts\n        - Uses seaborn for enhanced visual styling\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list)\n        assert len(ys) == len(legends)\n    if style is not None:\n        assert isinstance(style, list)\n        assert len(ys) == len(style)\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    frames = []\n    for i in range(len(xs)):\n        str_i = x_str + str(i) if legends is None else legends[i]\n        assert all(xi &lt; yi for xi, yi in zip(xs[i], xs[i][1:]))\n        df_dict_i = {\n            x_str: xs[i],\n            y_str: ys[i],\n            case_str: np.full([xs[i].size], str_i),\n        }\n        if style is not None:\n            df_dict_i[event_str] = np.full([xs[i].size], style[i])\n        df_i = pd.DataFrame(df_dict_i)\n        frames.append(df_i)\n    df = pd.concat(frames)\n    sns.set_style(\"ticks\", {\"axes.grid\": True})\n    if style is None:\n        return (\n            sns.lineplot(x=x_str, y=y_str, hue=case_str, data=df, estimator=None).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n            if ax_as_subplot is None\n            else sns.lineplot(\n                ax=ax_as_subplot,\n                x=x_str,\n                y=y_str,\n                hue=case_str,\n                data=df,\n                estimator=None,\n            ).set(\n                xlim=(0, 1),\n                xticks=np.arange(0, 1, interval),\n                yticks=np.arange(0, 1, interval),\n            )\n        )\n    elif ax_as_subplot is None:\n        return sns.lineplot(\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n    else:\n        return sns.lineplot(\n            ax=ax_as_subplot,\n            x=x_str,\n            y=y_str,\n            hue=case_str,\n            style=event_str,\n            data=df,\n            estimator=None,\n        ).set(\n            xlim=(0, 1),\n            xticks=np.arange(0, 1, interval),\n            yticks=np.arange(0, 1, interval),\n        )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ecdfs_matplot","title":"<code>plot_ecdfs_matplot(xs, ys, legends=None, colors='rbkgcmy', dash_lines=None, x_str='x', y_str='y', x_interval=0.1, y_interval=0.1, x_lim=(0, 1), y_lim=(0, 1), show_legend=True, legend_font_size=16, fig_size=(8, 6))</code>","text":"<p>Creates ECDF plots using matplotlib with extensive customization options.</p> <p>This function provides a more customizable alternative to the seaborn-based ECDF plotting functions, offering direct control over matplotlib parameters and styling.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[array]</code> <p>List of x-values arrays for each ECDF.</p> required <code>ys</code> <code>list[array]</code> <p>List of y-values arrays for each ECDF.</p> required <code>legends</code> <code>list[str]</code> <p>Legend labels for each ECDF. Defaults to None.</p> <code>None</code> <code>colors</code> <code>str</code> <p>String of color characters for different lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which lines should be dashed. Defaults to None.</p> <code>None</code> <code>x_str</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>y_str</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>x_interval</code> <code>float</code> <p>Interval for x-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>y_interval</code> <code>float</code> <p>Interval for y-axis ticks. Defaults to 0.1.</p> <code>0.1</code> <code>x_lim</code> <code>tuple</code> <p>X-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>y_lim</code> <code>tuple</code> <p>Y-axis limits as (min, max). Defaults to (0, 1).</p> <code>(0, 1)</code> <code>show_legend</code> <code>bool</code> <p>Whether to show legend. Defaults to True.</p> <code>True</code> <code>legend_font_size</code> <code>int</code> <p>Font size for legend. Defaults to 16.</p> <code>16</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the ECDF plots.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Compare multiple distributions\n&gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n&gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n&gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n...     x_str='Value',\n...     y_str='Probability',\n...     x_lim=(-3, 3)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom styling\n&gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n...     [x1, x2], [y, y],\n...     colors='rb',\n...     dash_lines=[False, True],\n...     legend_font_size=12,\n...     fig_size=(10, 8)\n... )\n</code></pre> Notes <ul> <li>Uses clean plotting style with minimal spines</li> <li>Supports both continuous and dashed lines</li> <li>Provides fine-grained control over axis properties</li> <li>Input arrays must be sorted in ascending order</li> <li>Automatically validates data ordering</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ecdfs_matplot(\n    xs,\n    ys,\n    legends=None,\n    colors=\"rbkgcmy\",\n    dash_lines=None,\n    x_str=\"x\",\n    y_str=\"y\",\n    x_interval=0.1,\n    y_interval=0.1,\n    x_lim=(0, 1),\n    y_lim=(0, 1),\n    show_legend=True,\n    legend_font_size=16,\n    fig_size=(8, 6),\n):\n    \"\"\"Creates ECDF plots using matplotlib with extensive customization options.\n\n    This function provides a more customizable alternative to the seaborn-based ECDF\n    plotting functions, offering direct control over matplotlib parameters and styling.\n\n    Args:\n        xs (list[np.array]): List of x-values arrays for each ECDF.\n        ys (list[np.array]): List of y-values arrays for each ECDF.\n        legends (list[str], optional): Legend labels for each ECDF. Defaults to None.\n        colors (str, optional): String of color characters for different lines.\n            Defaults to \"rbkgcmy\".\n        dash_lines (list[bool], optional): Specifies which lines should be dashed.\n            Defaults to None.\n        x_str (str, optional): X-axis label. Defaults to \"x\".\n        y_str (str, optional): Y-axis label. Defaults to \"y\".\n        x_interval (float, optional): Interval for x-axis ticks. Defaults to 0.1.\n        y_interval (float, optional): Interval for y-axis ticks. Defaults to 0.1.\n        x_lim (tuple, optional): X-axis limits as (min, max). Defaults to (0, 1).\n        y_lim (tuple, optional): Y-axis limits as (min, max). Defaults to (0, 1).\n        show_legend (bool, optional): Whether to show legend. Defaults to True.\n        legend_font_size (int, optional): Font size for legend. Defaults to 16.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the ECDF plots.\n\n    Examples:\n        &gt;&gt;&gt; # Compare multiple distributions\n        &gt;&gt;&gt; x1 = np.sort(np.random.normal(0, 1, 1000))\n        &gt;&gt;&gt; x2 = np.sort(np.random.normal(0.5, 1.2, 1000))\n        &gt;&gt;&gt; y = np.linspace(0, 1, 1000)\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     legends=['Normal(0,1)', 'Normal(0.5,1.2)'],\n        ...     x_str='Value',\n        ...     y_str='Probability',\n        ...     x_lim=(-3, 3)\n        ... )\n\n        &gt;&gt;&gt; # Custom styling\n        &gt;&gt;&gt; fig, ax = plot_ecdfs_matplot(\n        ...     [x1, x2], [y, y],\n        ...     colors='rb',\n        ...     dash_lines=[False, True],\n        ...     legend_font_size=12,\n        ...     fig_size=(10, 8)\n        ... )\n\n    Notes:\n        - Uses clean plotting style with minimal spines\n        - Supports both continuous and dashed lines\n        - Provides fine-grained control over axis properties\n        - Input arrays must be sorted in ascending order\n        - Automatically validates data ordering\n    \"\"\"\n    assert isinstance(xs, list) and isinstance(ys, list)\n    assert len(xs) == len(ys)\n    if legends is not None:\n        assert isinstance(legends, list) and len(ys) == len(legends)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(xs), False).tolist()\n    for y in ys:\n        assert all(xi &lt; yi for xi, yi in zip(y, y[1:]))\n    fig = plt.figure(figsize=fig_size)\n    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n    for i in range(len(xs)):\n        if (\n            np.nanmax(np.array(xs[i])) == np.inf\n            or np.nanmin(np.array(xs[i])) == -np.inf\n        ):\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        else:\n            assert all(xi &lt;= yi for xi, yi in zip(xs[i], xs[i][1:]))\n        (line_i,) = ax.plot(xs[i], ys[i], color=colors[i], label=legends[i])\n        if dash_lines[i]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    plt.xlabel(x_str, fontsize=18)\n    plt.ylabel(y_str, fontsize=18)\n    ax.set_xlim(x_lim[0], x_lim[1])\n    ax.set_ylim(y_lim[0], y_lim[1])\n    # set x y number font size\n    plt.xticks(np.arange(x_lim[0], x_lim[1] + x_lim[1] / 100, x_interval), fontsize=16)\n    plt.yticks(np.arange(y_lim[0], y_lim[1] + y_lim[1] / 100, y_interval), fontsize=16)\n    if show_legend:\n        ax.legend()\n        plt.legend(prop={\"size\": legend_font_size})\n    plt.grid()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_heat_map","title":"<code>plot_heat_map(data, mask=None, fig_size=None, fmt='d', square=True, annot=True, xticklabels=True, yticklabels=True)</code>","text":"<p>Creates a heatmap visualization of 2D data using seaborn.</p> <p>This function creates a heatmap visualization with customizable formatting, annotations, and masking options. It uses seaborn's heatmap function with additional customization options.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>2D array or DataFrame to be visualized.</p> required <code>mask</code> <code>array</code> <p>Boolean array of same shape as data. True values will be masked (not shown). Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to None.</p> <code>None</code> <code>fmt</code> <code>str</code> <p>String formatting code for cell annotations. Defaults to \"d\" for integer formatting.</p> <code>'d'</code> <code>square</code> <code>bool</code> <p>If True, set the Axes aspect to \"equal\". Defaults to True.</p> <code>True</code> <code>annot</code> <code>bool</code> <p>If True, write the data value in each cell. Defaults to True.</p> <code>True</code> <code>xticklabels</code> <code>bool</code> <p>If True, show x-axis labels. Defaults to True.</p> <code>True</code> <code>yticklabels</code> <code>bool</code> <p>If True, show y-axis labels. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n&gt;&gt;&gt; plot_heat_map(\n...     data,\n...     fmt='.2f',\n...     fig_size=(8, 6),\n...     annot=True\n... )\n</code></pre> Notes <p>The function uses a red-blue diverging colormap ('RdBu_r') by default. For more details on the underlying implementation, see: https://zhuanlan.zhihu.com/p/96040773</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_heat_map(\n    data,\n    mask=None,\n    fig_size=None,\n    fmt=\"d\",\n    square=True,\n    annot=True,\n    xticklabels=True,\n    yticklabels=True,\n):\n    \"\"\"Creates a heatmap visualization of 2D data using seaborn.\n\n    This function creates a heatmap visualization with customizable formatting,\n    annotations, and masking options. It uses seaborn's heatmap function with\n    additional customization options.\n\n    Args:\n        data (pd.DataFrame): 2D array or DataFrame to be visualized.\n        mask (np.array, optional): Boolean array of same shape as data. True values will\n            be masked (not shown). Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to None.\n        fmt (str, optional): String formatting code for cell annotations. Defaults to \"d\"\n            for integer formatting.\n        square (bool, optional): If True, set the Axes aspect to \"equal\". Defaults to True.\n        annot (bool, optional): If True, write the data value in each cell. Defaults to True.\n        xticklabels (bool, optional): If True, show x-axis labels. Defaults to True.\n        yticklabels (bool, optional): If True, show y-axis labels. Defaults to True.\n\n    Returns:\n        matplotlib.axes.Axes: The matplotlib Axes object containing the heatmap.\n\n    Examples:\n        &gt;&gt;&gt; data = pd.DataFrame(np.random.rand(5, 5))\n        &gt;&gt;&gt; plot_heat_map(\n        ...     data,\n        ...     fmt='.2f',\n        ...     fig_size=(8, 6),\n        ...     annot=True\n        ... )\n\n    Notes:\n        The function uses a red-blue diverging colormap ('RdBu_r') by default.\n        For more details on the underlying implementation, see:\n        https://zhuanlan.zhihu.com/p/96040773\n    \"\"\"\n    if fig_size is not None:\n        fig = plt.figure(figsize=fig_size)\n    ax = sns.heatmap(\n        data=data,\n        square=square,\n        annot=annot,\n        fmt=fmt,\n        cmap=\"RdBu_r\",\n        mask=mask,\n        xticklabels=xticklabels,\n        yticklabels=yticklabels,\n    )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_map_carto","title":"<code>plot_map_carto(data, lat, lon, fig=None, ax=None, pertile_range=None, value_range=None, fig_size=(8, 8), need_colorbar=True, colorbar_size=[0.91, 0.318, 0.02, 0.354], cmap_str='jet', idx_lst=None, markers=None, marker_size=20, is_discrete=False, colors='rbkgcmywrbkgcmyw', category_names=None, legend_font_size=None, colorbar_font_size=None)</code>","text":"<p>Creates a cartographic map visualization using Cartopy with extensive customization options.</p> <p>This function generates a map visualization for spatial data with support for continuous and discrete color scales, multiple marker types, and various styling options. It's particularly useful for visualizing hydrological data in a geographic context.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array</code> <p>1-D array of values to be plotted on the map.</p> required <code>lat</code> <code>array</code> <p>1-D array of latitude values for each data point.</p> required <code>lon</code> <code>array</code> <p>1-D array of longitude values for each data point.</p> required <code>fig</code> <code>Figure</code> <p>Existing figure to plot on. Defaults to None.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling, e.g., [25, 75] for interquartile range. Defaults to None.</p> <code>None</code> <code>value_range</code> <code>list</code> <p>Explicit value range for color scaling. Takes precedence over pertile_range. Defaults to None.</p> <code>None</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 8).</p> <code>(8, 8)</code> <code>need_colorbar</code> <code>bool</code> <p>Whether to add a colorbar. Defaults to True.</p> <code>True</code> <code>colorbar_size</code> <code>list</code> <p>Colorbar dimensions [left, bottom, width, height]. Defaults to [0.91, 0.318, 0.02, 0.354].</p> <code>[0.91, 0.318, 0.02, 0.354]</code> <code>cmap_str</code> <code>str</code> <p>Colormap name. Defaults to \"jet\".</p> <code>'jet'</code> <code>idx_lst</code> <code>list</code> <p>List of index arrays for plotting multiple point categories. Defaults to None.</p> <code>None</code> <code>markers</code> <code>list</code> <p>Marker styles for each category. Defaults to None.</p> <code>None</code> <code>marker_size</code> <code>Union[int, list]</code> <p>Size(s) of markers. Defaults to 20.</p> <code>20</code> <code>is_discrete</code> <code>bool</code> <p>If True, uses discrete colors with legend instead of continuous colorbar. Defaults to False.</p> <code>False</code> <code>colors</code> <code>str</code> <p>Color characters for discrete categories. Defaults to \"rbkgcmywrbkgcmyw\".</p> <code>'rbkgcmywrbkgcmyw'</code> <code>category_names</code> <code>list</code> <p>Names for discrete categories in legend. Defaults to None.</p> <code>None</code> <code>legend_font_size</code> <code>float</code> <p>Font size for legend. Defaults to None.</p> <code>None</code> <code>colorbar_font_size</code> <code>float</code> <p>Font size for colorbar. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axes object containing the map.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple continuous color map\n&gt;&gt;&gt; data = np.random.rand(100)\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     value_range=[0, 1],\n...     cmap_str='viridis'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Discrete categories with custom markers\n&gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n&gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n&gt;&gt;&gt; ax = plot_map_carto(\n...     data, lat, lon,\n...     idx_lst=idx_lst,\n...     markers=['o', 's', '^'],\n...     is_discrete=True,\n...     category_names=['Low', 'Medium', 'High']\n... )\n</code></pre> Notes <ul> <li>Uses Cartopy for map projections and features</li> <li>Automatically adds state boundaries and coastlines</li> <li>Supports both continuous and categorical data visualization</li> <li>Handles NaN values appropriately</li> <li>Provides flexible control over color scaling</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_map_carto(\n    data,\n    lat,\n    lon,\n    fig=None,\n    ax=None,\n    pertile_range=None,\n    value_range=None,\n    fig_size=(8, 8),\n    need_colorbar=True,\n    colorbar_size=[0.91, 0.318, 0.02, 0.354],\n    cmap_str=\"jet\",\n    idx_lst=None,\n    markers=None,\n    marker_size=20,\n    is_discrete=False,\n    colors=\"rbkgcmywrbkgcmyw\",\n    category_names=None,\n    legend_font_size=None,\n    colorbar_font_size=None,\n):\n    \"\"\"Creates a cartographic map visualization using Cartopy with extensive customization options.\n\n    This function generates a map visualization for spatial data with support for continuous\n    and discrete color scales, multiple marker types, and various styling options. It's\n    particularly useful for visualizing hydrological data in a geographic context.\n\n    Args:\n        data (np.array): 1-D array of values to be plotted on the map.\n        lat (np.array): 1-D array of latitude values for each data point.\n        lon (np.array): 1-D array of longitude values for each data point.\n        fig (matplotlib.figure.Figure, optional): Existing figure to plot on.\n            Defaults to None.\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        pertile_range (list, optional): Percentile range for color scaling, e.g.,\n            [25, 75] for interquartile range. Defaults to None.\n        value_range (list, optional): Explicit value range for color scaling. Takes\n            precedence over pertile_range. Defaults to None.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 8).\n        need_colorbar (bool, optional): Whether to add a colorbar. Defaults to True.\n        colorbar_size (list, optional): Colorbar dimensions [left, bottom, width, height].\n            Defaults to [0.91, 0.318, 0.02, 0.354].\n        cmap_str (str, optional): Colormap name. Defaults to \"jet\".\n        idx_lst (list, optional): List of index arrays for plotting multiple point\n            categories. Defaults to None.\n        markers (list, optional): Marker styles for each category. Defaults to None.\n        marker_size (Union[int, list], optional): Size(s) of markers. Defaults to 20.\n        is_discrete (bool, optional): If True, uses discrete colors with legend instead\n            of continuous colorbar. Defaults to False.\n        colors (str, optional): Color characters for discrete categories.\n            Defaults to \"rbkgcmywrbkgcmyw\".\n        category_names (list, optional): Names for discrete categories in legend.\n            Defaults to None.\n        legend_font_size (float, optional): Font size for legend. Defaults to None.\n        colorbar_font_size (float, optional): Font size for colorbar. Defaults to None.\n\n    Returns:\n        matplotlib.axes.Axes: The axes object containing the map.\n\n    Examples:\n        &gt;&gt;&gt; # Simple continuous color map\n        &gt;&gt;&gt; data = np.random.rand(100)\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, 100)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, 100)\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     value_range=[0, 1],\n        ...     cmap_str='viridis'\n        ... )\n\n        &gt;&gt;&gt; # Discrete categories with custom markers\n        &gt;&gt;&gt; categories = np.random.randint(0, 3, 100)\n        &gt;&gt;&gt; idx_lst = [np.where(categories == i)[0] for i in range(3)]\n        &gt;&gt;&gt; ax = plot_map_carto(\n        ...     data, lat, lon,\n        ...     idx_lst=idx_lst,\n        ...     markers=['o', 's', '^'],\n        ...     is_discrete=True,\n        ...     category_names=['Low', 'Medium', 'High']\n        ... )\n\n    Notes:\n        - Uses Cartopy for map projections and features\n        - Automatically adds state boundaries and coastlines\n        - Supports both continuous and categorical data visualization\n        - Handles NaN values appropriately\n        - Provides flexible control over color scaling\n    \"\"\"\n    if value_range is not None:\n        vmin = value_range[0]\n        vmax = value_range[1]\n    elif pertile_range is None:\n        # https://blog.csdn.net/chenirene510/article/details/111318539\n        mask_data = np.ma.masked_invalid(data)\n        vmin = np.min(mask_data)\n        vmax = np.max(mask_data)\n    else:\n        assert 0 &lt;= pertile_range[0] &lt; pertile_range[1] &lt;= 100\n        vmin = np.nanpercentile(data, pertile_range[0])\n        vmax = np.nanpercentile(data, pertile_range[1])\n    llcrnrlat = (np.min(lat),)\n    urcrnrlat = (np.max(lat),)\n    llcrnrlon = (np.min(lon),)\n    urcrnrlon = (np.max(lon),)\n    extent = [llcrnrlon[0], urcrnrlon[0], llcrnrlat[0], urcrnrlat[0]]\n    # Figure\n    if fig is None or ax is None:\n        fig, ax = plt.subplots(\n            1, 1, figsize=fig_size, subplot_kw={\"projection\": ccrs.PlateCarree()}\n        )\n    ax.set_extent(extent)\n    states = NaturalEarthFeature(\n        category=\"cultural\",\n        scale=\"50m\",\n        facecolor=\"none\",\n        name=\"admin_1_states_provinces_shp\",\n    )\n    ax.add_feature(states, linewidth=0.5, edgecolor=\"black\")\n    ax.coastlines(\"50m\", linewidth=0.8)\n    if idx_lst is not None:\n        if isinstance(marker_size, list):\n            assert len(marker_size) == len(idx_lst)\n        else:\n            marker_size = np.full(len(idx_lst), marker_size).tolist()\n        if not isinstance(marker_size, list):\n            markers = np.full(len(idx_lst), markers).tolist()\n        else:\n            assert len(markers) == len(idx_lst)\n        if not isinstance(cmap_str, list):\n            cmap_str = np.full(len(idx_lst), cmap_str).tolist()\n        else:\n            assert len(cmap_str) == len(idx_lst)\n        if is_discrete:\n            for i in range(len(idx_lst)):\n                ax.plot(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    marker=markers[i],\n                    ms=marker_size[i],\n                    label=category_names[i],\n                    c=colors[i],\n                    linestyle=\"\",\n                )\n                ax.legend(prop=dict(size=legend_font_size))\n        else:\n            scatter = []\n            for i in range(len(idx_lst)):\n                scat = ax.scatter(\n                    lon[idx_lst[i]],\n                    lat[idx_lst[i]],\n                    c=data[idx_lst[i]],\n                    marker=markers[i],\n                    s=marker_size[i],\n                    cmap=cmap_str[i],\n                    vmin=vmin,\n                    vmax=vmax,\n                )\n                scatter.append(scat)\n            if need_colorbar:\n                if colorbar_size is not None:\n                    cbar_ax = fig.add_axes(colorbar_size)\n                    cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n                else:\n                    cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n                if colorbar_font_size is not None:\n                    cbar.ax.tick_params(labelsize=colorbar_font_size)\n            if category_names is not None:\n                ax.legend(\n                    scatter, category_names, prop=dict(size=legend_font_size), ncol=2\n                )\n    elif is_discrete:\n        scatter = ax.scatter(lon, lat, c=data, s=marker_size)\n        # produce a legend with the unique colors from the scatter\n        legend1 = ax.legend(\n            *scatter.legend_elements(), loc=\"lower left\", title=\"Classes\"\n        )\n        ax.add_artist(legend1)\n    else:\n        scat = plt.scatter(\n            lon, lat, c=data, s=marker_size, cmap=cmap_str, vmin=vmin, vmax=vmax\n        )\n        if need_colorbar:\n            if colorbar_size is not None:\n                cbar_ax = fig.add_axes(colorbar_size)\n                cbar = fig.colorbar(scat, cax=cbar_ax, orientation=\"vertical\")\n            else:\n                cbar = fig.colorbar(scat, ax=ax, pad=0.01)\n            if colorbar_font_size is not None:\n                cbar.ax.tick_params(labelsize=colorbar_font_size)\n    return ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_pdf_cdf","title":"<code>plot_pdf_cdf(mydataframe, mycolumn)</code>","text":"<p>Creates side-by-side plots of probability density function (PDF) and cumulative distribution function (CDF).</p> <p>This function generates a figure with two subplots: a PDF plot on the left and a CDF plot on the right. The PDF includes both histogram and kernel density estimation, while the CDF shows the cumulative histogram.</p> <p>Parameters:</p> Name Type Description Default <code>mydataframe</code> <code>DataFrame</code> <p>DataFrame containing the data to plot.</p> required <code>mycolumn</code> <code>str</code> <p>Name of the column to create distributions for.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'values': np.concatenate([\n...         np.random.normal(0.3, 0.1, 1000),\n...         np.random.normal(0.7, 0.1, 1000)\n...     ])\n... })\n&gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n</code></pre> Notes <ul> <li>Uses seaborn's distplot for both PDF and CDF</li> <li>PDF includes both histogram and kernel density estimation</li> <li>CDF shows cumulative histogram with step-style line</li> <li>Both plots are set to range [0, 1] on x-axis</li> <li>CDF y-axis is also set to range [0, 1]</li> <li>High DPI (320) for publication-quality figures</li> <li>Large figure size (18x6) for clear visualization</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_pdf_cdf(mydataframe, mycolumn):\n    \"\"\"Creates side-by-side plots of probability density function (PDF) and cumulative\n    distribution function (CDF).\n\n    This function generates a figure with two subplots: a PDF plot on the left and\n    a CDF plot on the right. The PDF includes both histogram and kernel density\n    estimation, while the CDF shows the cumulative histogram.\n\n    Args:\n        mydataframe (pd.DataFrame): DataFrame containing the data to plot.\n        mycolumn (str): Name of the column to create distributions for.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; df = pd.DataFrame({\n        ...     'values': np.concatenate([\n        ...         np.random.normal(0.3, 0.1, 1000),\n        ...         np.random.normal(0.7, 0.1, 1000)\n        ...     ])\n        ... })\n        &gt;&gt;&gt; plot_pdf_cdf(df, 'values')\n\n    Notes:\n        - Uses seaborn's distplot for both PDF and CDF\n        - PDF includes both histogram and kernel density estimation\n        - CDF shows cumulative histogram with step-style line\n        - Both plots are set to range [0, 1] on x-axis\n        - CDF y-axis is also set to range [0, 1]\n        - High DPI (320) for publication-quality figures\n        - Large figure size (18x6) for clear visualization\n    \"\"\"\n    # settings\n    f, axes = plt.subplots(1, 2, figsize=(18, 6), dpi=320)\n    axes[0].set_ylabel(\"fraction (PDF)\")\n    axes[1].set_ylabel(\"fraction (CDF)\")\n\n    # left plot (PDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=True,\n        axlabel=mycolumn,\n        hist_kws={\"density\": True},\n        ax=axes[0],\n    ).set(xlim=(0, 1))\n\n    # right plot (CDF) # REMEMBER TO CHANGE bins, xlim PROPERLY!!\n    sns.distplot(\n        mydataframe[mycolumn],\n        kde=False,\n        axlabel=mycolumn,\n        hist_kws={\n            \"density\": True,\n            \"cumulative\": True,\n            \"histtype\": \"step\",\n            \"linewidth\": 4,\n        },\n        ax=axes[1],\n    ).set(xlim=(0, 1), ylim=(0, 1))\n    plt.show()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_quiver","title":"<code>plot_quiver(exps_q_ssm_result_show, exps_ssm_q_result_show, q_diff_show, ssm_diff_show, x_label, y_label)</code>","text":"<p>Creates a quiver plot showing vector field with normalized arrows.</p> <p>This function generates a quiver plot where arrows represent the direction and magnitude of differences between two variables. The arrows are normalized to have uniform length, with color indicating the actual magnitude of the difference.</p> <p>Parameters:</p> Name Type Description Default <code>exps_q_ssm_result_show</code> <code>array</code> <p>X-coordinates for arrow origins.</p> required <code>exps_ssm_q_result_show</code> <code>array</code> <p>Y-coordinates for arrow origins.</p> required <code>q_diff_show</code> <code>array</code> <p>X-components of the difference vectors.</p> required <code>ssm_diff_show</code> <code>array</code> <p>Y-components of the difference vectors.</p> required <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the quiver plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; x = np.random.rand(50)\n&gt;&gt;&gt; y = np.random.rand(50)\n&gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n&gt;&gt;&gt; fig, ax = plot_quiver(\n...     x, y, dx, dy,\n...     'X Variable',\n...     'Y Variable'\n... )\n</code></pre> Notes <ul> <li>Arrows are normalized to uniform length for better visualization</li> <li>Color indicates the actual magnitude of the difference vector</li> <li>Plot includes a colorbar showing the magnitude scale</li> <li>Uses clean plotting style with minimal spines</li> <li>Default plot range is [0, 1] for both axes</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_quiver(\n    exps_q_ssm_result_show,\n    exps_ssm_q_result_show,\n    q_diff_show,\n    ssm_diff_show,\n    x_label,\n    y_label,\n):\n    \"\"\"Creates a quiver plot showing vector field with normalized arrows.\n\n    This function generates a quiver plot where arrows represent the direction and\n    magnitude of differences between two variables. The arrows are normalized to have\n    uniform length, with color indicating the actual magnitude of the difference.\n\n    Args:\n        exps_q_ssm_result_show (np.array): X-coordinates for arrow origins.\n        exps_ssm_q_result_show (np.array): Y-coordinates for arrow origins.\n        q_diff_show (np.array): X-components of the difference vectors.\n        ssm_diff_show (np.array): Y-components of the difference vectors.\n        x_label (str): Label for x-axis.\n        y_label (str): Label for y-axis.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the quiver plot.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; x = np.random.rand(50)\n        &gt;&gt;&gt; y = np.random.rand(50)\n        &gt;&gt;&gt; dx = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; dy = np.random.normal(0, 0.1, 50)\n        &gt;&gt;&gt; fig, ax = plot_quiver(\n        ...     x, y, dx, dy,\n        ...     'X Variable',\n        ...     'Y Variable'\n        ... )\n\n    Notes:\n        - Arrows are normalized to uniform length for better visualization\n        - Color indicates the actual magnitude of the difference vector\n        - Plot includes a colorbar showing the magnitude scale\n        - Uses clean plotting style with minimal spines\n        - Default plot range is [0, 1] for both axes\n    \"\"\"\n    fig, ax = plt.subplots()\n    color = np.sqrt(q_diff_show**2 + ssm_diff_show**2)\n    # normalize to get same length arrows\n    r = np.power(np.add(np.power(q_diff_show, 2), np.power(ssm_diff_show, 2)), 0.5)\n    plt.quiver(\n        exps_q_ssm_result_show,\n        exps_ssm_q_result_show,\n        q_diff_show / r,\n        ssm_diff_show / r,\n        color,\n        scale=25,\n        width=0.005,\n    )\n    # Defining color\n    plt.xlim(-0.01, 1)\n    plt.ylim(-0.01, 1)\n    plt.colorbar()\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.xlabel(x_label, fontsize=18)\n    plt.ylabel(y_label, fontsize=18)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_rainfall_runoff","title":"<code>plot_rainfall_runoff(t, p, qs, fig_size=(8, 6), c_lst='rbkgcmy', leg_lst=None, dash_lines=None, title=None, xlabel=None, ylabel=None, prcp_ylabel='prcp(mm/day)', linewidth=1, prcp_interval=20)</code>","text":"<p>Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.</p> <p>This function generates a dual-axis plot showing precipitation as inverted bars from the top and streamflow as lines on the bottom. This is a common visualization in hydrology for analyzing rainfall-runoff relationships.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Union[array, List[array]]</code> <p>Time values. If multiple streamflow series are provided, t can be a list of time arrays matching qs.</p> required <code>p</code> <code>array</code> <p>Precipitation time series data in mm/day.</p> required <code>qs</code> <code>Union[array, List[array]]</code> <p>Streamflow time series data. Can be a single array or list of arrays for multiple streamflow series.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (8, 6).</p> <code>(8, 6)</code> <code>c_lst</code> <code>str</code> <p>String of color characters for streamflow lines. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels for streamflow series. Defaults to None.</p> <code>None</code> <code>dash_lines</code> <code>list[bool]</code> <p>Specifies which streamflow lines should be dashed. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>X-axis label. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to None.</p> <code>None</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <code>linewidth</code> <code>int</code> <p>Width of streamflow lines. Defaults to 1.</p> <code>1</code> <code>prcp_interval</code> <code>int</code> <p>Interval for precipitation y-axis ticks. Defaults to 20.</p> <code>20</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes objects containing the plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple rainfall-runoff plot\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, q,\n...     title='Rainfall-Runoff Analysis',\n...     xlabel='Date',\n...     ylabel='Streamflow (m\u00b3/s)'\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple streamflow series\n&gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n...     t, p, qs,\n...     leg_lst=['Observed', 'Simulated'],\n...     dash_lines=[False, True]\n... )\n</code></pre> Notes <ul> <li>Precipitation is plotted as blue bars from the top of the plot</li> <li>Streamflow is plotted as lines on the bottom</li> <li>The precipitation y-axis is inverted for better visualization</li> <li>Grid lines are added automatically</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff(\n    t,\n    p,\n    qs,\n    fig_size=(8, 6),\n    c_lst=\"rbkgcmy\",\n    leg_lst=None,\n    dash_lines=None,\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    prcp_ylabel=\"prcp(mm/day)\",\n    linewidth=1,\n    prcp_interval=20,\n):\n    \"\"\"Creates a combined rainfall-runoff plot with precipitation bars and streamflow lines.\n\n    This function generates a dual-axis plot showing precipitation as inverted bars from\n    the top and streamflow as lines on the bottom. This is a common visualization in\n    hydrology for analyzing rainfall-runoff relationships.\n\n    Args:\n        t (Union[np.array, List[np.array]]): Time values. If multiple streamflow series\n            are provided, t can be a list of time arrays matching qs.\n        p (np.array): Precipitation time series data in mm/day.\n        qs (Union[np.array, List[np.array]]): Streamflow time series data. Can be a\n            single array or list of arrays for multiple streamflow series.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (8, 6).\n        c_lst (str, optional): String of color characters for streamflow lines.\n            Defaults to \"rbkgcmy\".\n        leg_lst (list, optional): Legend labels for streamflow series. Defaults to None.\n        dash_lines (list[bool], optional): Specifies which streamflow lines should be\n            dashed. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n        xlabel (str, optional): X-axis label. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to None.\n        prcp_ylabel (str, optional): Y-axis label for precipitation. Defaults to\n            \"prcp(mm/day)\".\n        linewidth (int, optional): Width of streamflow lines. Defaults to 1.\n        prcp_interval (int, optional): Interval for precipitation y-axis ticks.\n            Defaults to 20.\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and axes\n            objects containing the plot.\n\n    Examples:\n        &gt;&gt;&gt; # Simple rainfall-runoff plot\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; q = np.convolve(p, np.ones(5)/5, mode='same')  # simulated streamflow\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, q,\n        ...     title='Rainfall-Runoff Analysis',\n        ...     xlabel='Date',\n        ...     ylabel='Streamflow (m\u00b3/s)'\n        ... )\n\n        &gt;&gt;&gt; # Multiple streamflow series\n        &gt;&gt;&gt; qs = [q, q*1.2]  # observed and simulated\n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff(\n        ...     t, p, qs,\n        ...     leg_lst=['Observed', 'Simulated'],\n        ...     dash_lines=[False, True]\n        ... )\n\n    Notes:\n        - Precipitation is plotted as blue bars from the top of the plot\n        - Streamflow is plotted as lines on the bottom\n        - The precipitation y-axis is inverted for better visualization\n        - Grid lines are added automatically\n    \"\"\"\n    fig, ax = plt.subplots(figsize=fig_size)\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(qs), False).tolist()\n    for k in range(len(qs)):\n        tt = t[k] if type(t) is list else t\n        q = qs[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        (line_i,) = ax.plot(tt, q, color=c_lst[k], label=leg_str, linewidth=linewidth)\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n\n    ax.set_ylim(ax.get_ylim()[0], ax.get_ylim()[1] * 1.2)\n    # Create second axes, in order to get the bars from the top you can multiply by -1\n    ax2 = ax.twinx()\n    # ax2.bar(tt, -p, color=\"b\")\n    ax2.fill_between(tt, 0, -p, step=\"mid\", color=\"b\", alpha=0.5)\n    # ax2.plot(tt, -p, color=\"b\", alpha=0.7, linewidth=1.5)\n\n    # Now need to fix the axis labels\n    # max_pre = max(p)\n    max_pre = p.max().item()\n    ax2.set_ylim(-max_pre * 5, 0)\n    y2_ticks = np.arange(0, max_pre, prcp_interval)\n    y2_ticklabels = [str(i) for i in y2_ticks]\n    ax2.set_yticks(-1 * y2_ticks)\n    ax2.set_yticklabels(y2_ticklabels, fontsize=16)\n    # ax2.set_yticklabels([lab.get_text()[1:] for lab in ax2.get_yticklabels()])\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    if ylabel is not None:\n        ax.set_ylabel(ylabel, fontsize=18)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel, fontsize=18)\n    ax2.set_ylabel(prcp_ylabel, fontsize=8, loc=\"top\")\n    # ax2.set_ylabel(\"precipitation (mm/day)\", fontsize=12, loc='top')\n    # https://github.com/matplotlib/matplotlib/issues/12318\n    ax.tick_params(axis=\"x\", labelsize=16)\n    ax.tick_params(axis=\"y\", labelsize=16)\n    ax.legend(bbox_to_anchor=(0.01, 0.85), loc=\"upper left\", fontsize=16)\n    ax.grid()\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_rainfall_runoff_chai","title":"<code>plot_rainfall_runoff_chai(t, ps, qs, c_lst='rbkgcmy', title='Observation of Precipitation and Streamflow', alpha_lst=None, p_labels=None, q_labels=None)</code>","text":"<p>Creates a two-panel rainfall-runoff plot following Chai's style.</p> <p>This function generates a figure with two vertically stacked panels: precipitation on top and streamflow below. It supports multiple precipitation sources and streamflow series with customizable styling.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>ps</code> <code>list[array]</code> <p>List of precipitation arrays from different sources.</p> required <code>qs</code> <code>list[array]</code> <p>List of streamflow arrays (e.g., observed and simulated).</p> required <code>c_lst</code> <code>str</code> <p>String of color characters. Defaults to \"rbkgcmy\".</p> <code>'rbkgcmy'</code> <code>title</code> <code>str</code> <p>Figure title. Defaults to \"Observation of Precipitation and Streamflow\".</p> <code>'Observation of Precipitation and Streamflow'</code> <code>alpha_lst</code> <code>list[float]</code> <p>Transparency values for each series. Defaults to [0.5, 0.5].</p> <code>None</code> <code>p_labels</code> <code>list[str]</code> <p>Labels for precipitation sources. Defaults to [\"era5land\", \"gauge\"].</p> <code>None</code> <code>q_labels</code> <code>list[str]</code> <p>Labels for streamflow series. Defaults to [\"observation\", \"simulation\"].</p> <code>None</code> <p>Returns:</p> Type Description <p>Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom axes (streamflow plot).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n&gt;&gt;&gt; # Two precipitation sources\n&gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n&gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n&gt;&gt;&gt; # Observed and simulated streamflow\n&gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n&gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n&gt;&gt;&gt; \n&gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n...     t, [p1, p2], [q_obs, q_sim],\n...     title='2020 Rainfall-Runoff Comparison',\n...     p_labels=['ERA5', 'Rain Gauge'],\n...     q_labels=['Observed', 'Simulated']\n... )\n</code></pre> Notes <ul> <li>Top panel shows precipitation with bars</li> <li>Bottom panel shows streamflow with lines</li> <li>Precipitation y-axis is inverted and blue</li> <li>Streamflow y-axis is red</li> <li>Both panels share x-axis limits</li> <li>Legends included for both panels</li> <li>Uses large figure size (20x8) by default</li> <li>Includes \"Streamflow\" text box in bottom panel</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_chai(\n    t,\n    ps,\n    qs,\n    c_lst=\"rbkgcmy\",\n    title=\"Observation of Precipitation and Streamflow\",\n    alpha_lst=None,\n    p_labels=None,\n    q_labels=None,\n):\n    \"\"\"Creates a two-panel rainfall-runoff plot following Chai's style.\n\n    This function generates a figure with two vertically stacked panels: precipitation\n    on top and streamflow below. It supports multiple precipitation sources and\n    streamflow series with customizable styling.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        ps (list[np.array]): List of precipitation arrays from different sources.\n        qs (list[np.array]): List of streamflow arrays (e.g., observed and simulated).\n        c_lst (str, optional): String of color characters. Defaults to \"rbkgcmy\".\n        title (str, optional): Figure title. Defaults to \"Observation of Precipitation\n            and Streamflow\".\n        alpha_lst (list[float], optional): Transparency values for each series.\n            Defaults to [0.5, 0.5].\n        p_labels (list[str], optional): Labels for precipitation sources.\n            Defaults to [\"era5land\", \"gauge\"].\n        q_labels (list[str], optional): Labels for streamflow series.\n            Defaults to [\"observation\", \"simulation\"].\n\n    Returns:\n        Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: The figure and bottom\n            axes (streamflow plot).\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = pd.date_range('2020-01-01', '2020-12-31', freq='D')\n        &gt;&gt;&gt; # Two precipitation sources\n        &gt;&gt;&gt; p1 = np.random.exponential(2, size=len(t))  # ERA5\n        &gt;&gt;&gt; p2 = p1 * 1.2 + np.random.normal(0, 0.2, len(t))  # Gauge\n        &gt;&gt;&gt; # Observed and simulated streamflow\n        &gt;&gt;&gt; q_obs = np.convolve(p1, np.ones(5)/5, mode='same')\n        &gt;&gt;&gt; q_sim = q_obs * 1.1 + np.random.normal(0, 0.1, len(q_obs))\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; fig, ax = plot_rainfall_runoff_chai(\n        ...     t, [p1, p2], [q_obs, q_sim],\n        ...     title='2020 Rainfall-Runoff Comparison',\n        ...     p_labels=['ERA5', 'Rain Gauge'],\n        ...     q_labels=['Observed', 'Simulated']\n        ... )\n\n    Notes:\n        - Top panel shows precipitation with bars\n        - Bottom panel shows streamflow with lines\n        - Precipitation y-axis is inverted and blue\n        - Streamflow y-axis is red\n        - Both panels share x-axis limits\n        - Legends included for both panels\n        - Uses large figure size (20x8) by default\n        - Includes \"Streamflow\" text box in bottom panel\n    \"\"\"\n    if alpha_lst is None:\n        alpha_lst = [0.5, 0.5]\n    if p_labels is None:\n        p_labels = [\"era5land\", \"gauge\"]\n    if q_labels is None:\n        q_labels = [\"observation\", \"simulation\"]\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 8))\n    fig.suptitle(title, fontsize=16)\n    for i, p in enumerate(ps):\n        ax1.bar(\n            t,\n            p,\n            color=c_lst[i],\n            label=p_labels[i],\n            width=0.9,\n            alpha=alpha_lst[i],\n        )\n    ax1.set_xlabel(\"Time\")\n    ax1.set_ylabel(\"Precipitation (mm/d)\", color=\"b\")\n    ax1.invert_yaxis()\n    ax1.tick_params(axis=\"y\", labelcolor=\"b\")\n    ax1.legend()\n\n    for j, q in enumerate(qs):\n        ax2.plot(t, q, color=c_lst[j], label=q_labels[j], alpha=alpha_lst[j])\n    ax2.set_xlabel(\"Time\")\n    ax2.set_ylabel(\"Streamflow (m$^3$/s)\", color=\"r\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"r\")\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.text(\n        0.05,\n        0.95,\n        \"Streamflow\",\n        transform=ax2.transAxes,\n        fontsize=12,\n        verticalalignment=\"top\",\n        bbox=dict(facecolor=\"white\", alpha=0.5),\n    )\n    ax2.legend()\n\n    fig.tight_layout()\n    return fig, ax2\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_rainfall_runoff_xu","title":"<code>plot_rainfall_runoff_xu(t, p, qs, fig_size=(10, 6), title='prcp-streamflow', leg_lst=None, ylabel='streamflow(m^3/s)', prcp_ylabel='prcp(mm/day)')</code>","text":"<p>Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.</p> <p>This function generates a specialized plot with precipitation bars from the top and streamflow lines on the bottom, following Xu's visualization style. It uses dual y-axes with color-coded labels and ticks.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>array - like</code> <p>Time points for x-axis.</p> required <code>p</code> <code>array</code> <p>Precipitation values.</p> required <code>qs</code> <code>tuple</code> <p>Tuple of (observed, predicted) streamflow values.</p> required <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height). Defaults to (10, 6).</p> <code>(10, 6)</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to \"prcp-streamflow\".</p> <code>'prcp-streamflow'</code> <code>leg_lst</code> <code>list</code> <p>Legend labels. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".</p> <code>'streamflow(m^3/s)'</code> <code>prcp_ylabel</code> <code>str</code> <p>Y-axis label for precipitation. Defaults to \"prcp(mm/day)\".</p> <code>'prcp(mm/day)'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n&gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n&gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n&gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n&gt;&gt;&gt; plot_rainfall_runoff_xu(\n...     t, p, (obs, pred),\n...     title='2020 Rainfall-Runoff Analysis'\n... )\n</code></pre> Notes <ul> <li>Precipitation shown as blue bars from top</li> <li>Observed streamflow as solid green line</li> <li>Predicted streamflow as dashed red line</li> <li>Y-axes labels and ticks color-coded</li> <li>Precipitation axis inverted</li> <li>Legend positioned at upper left</li> <li>Precipitation bars semi-transparent (alpha=0.6)</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_rainfall_runoff_xu(\n    t,\n    p,\n    qs,\n    fig_size=(10, 6),\n    title=\"prcp-streamflow\",\n    leg_lst=None,\n    ylabel=\"streamflow(m^3/s)\",\n    prcp_ylabel=\"prcp(mm/day)\",\n):\n    \"\"\"Creates a dual-axis plot for rainfall-runoff analysis with Xu's style.\n\n    This function generates a specialized plot with precipitation bars from the top\n    and streamflow lines on the bottom, following Xu's visualization style. It uses\n    dual y-axes with color-coded labels and ticks.\n\n    Args:\n        t (array-like): Time points for x-axis.\n        p (np.array): Precipitation values.\n        qs (tuple): Tuple of (observed, predicted) streamflow values.\n        fig_size (tuple, optional): Figure size as (width, height). Defaults to (10, 6).\n        title (str, optional): Plot title. Defaults to \"prcp-streamflow\".\n        leg_lst (list, optional): Legend labels. Defaults to None.\n        ylabel (str, optional): Y-axis label for streamflow. Defaults to \"streamflow(m^3/s)\".\n        prcp_ylabel (str, optional): Y-axis label for precipitation.\n            Defaults to \"prcp(mm/day)\".\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; t = np.arange('2020-01-01', '2020-12-31', dtype='datetime64[D]')\n        &gt;&gt;&gt; p = np.random.exponential(2, size=len(t))  # precipitation\n        &gt;&gt;&gt; obs = np.convolve(p, np.ones(5)/5, mode='same')  # observed flow\n        &gt;&gt;&gt; pred = obs * 1.1 + np.random.normal(0, 0.1, len(obs))  # predicted flow\n        &gt;&gt;&gt; plot_rainfall_runoff_xu(\n        ...     t, p, (obs, pred),\n        ...     title='2020 Rainfall-Runoff Analysis'\n        ... )\n\n    Notes:\n        - Precipitation shown as blue bars from top\n        - Observed streamflow as solid green line\n        - Predicted streamflow as dashed red line\n        - Y-axes labels and ticks color-coded\n        - Precipitation axis inverted\n        - Legend positioned at upper left\n        - Precipitation bars semi-transparent (alpha=0.6)\n    \"\"\"\n    obs, pred = qs\n\n    fig, ax1 = plt.subplots(figsize=fig_size)\n\n    ax1.bar(t, p, width=0.1, color=\"blue\", alpha=0.6, label=\"Precipitation\")\n    ax1.set_ylabel(prcp_ylabel, color=\"blue\")\n    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n\n    ax1.set_ylim(0, p.max() * 5)\n    ax1.invert_yaxis()\n\n    ax2 = ax1.twinx()\n\n    # transform the unit of obs and pred\n    ax2.plot(\n        t,\n        obs,\n        color=\"green\",\n        linestyle=\"-\",\n        label=\"observed value\",\n    )\n    ax2.plot(\n        t,\n        pred,\n        color=\"red\",\n        linestyle=\"--\",\n        label=\"predicted value\",\n    )\n\n    ax2.set_ylabel(ylabel, color=\"red\")\n    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n\n    plt.title(title)\n\n    plt.legend(loc=\"upper left\")\n    return fig, (ax1, ax2)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_scatter_with_11line","title":"<code>plot_scatter_with_11line(x, y, point_color='blue', line_color='black', xlim=[0.0, 1.0], ylim=[0.0, 1.0], xlabel=None, ylabel=None)</code>","text":"<p>Creates a scatter plot comparing two variables with a 1:1 line.</p> <p>This function generates a scatter plot with a 1:1 line (diagonal) for comparing two variables, commonly used in model evaluation to compare observed vs predicted values. The plot includes customizable colors, axis limits, and labels.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array</code> <p>First variable to be plotted (typically observed values).</p> required <code>y</code> <code>array</code> <p>Second variable to be plotted (typically predicted values).</p> required <code>point_color</code> <code>str</code> <p>Color of scatter points. Defaults to \"blue\".</p> <code>'blue'</code> <code>line_color</code> <code>str</code> <p>Color of the 1:1 line. Defaults to \"black\".</p> <code>'black'</code> <code>xlim</code> <code>list</code> <p>X-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>ylim</code> <code>list</code> <p>Y-axis range as [min, max]. Defaults to [0.0, 1.0].</p> <code>[0.0, 1.0]</code> <code>xlabel</code> <code>str</code> <p>Label for x-axis. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Label for y-axis. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]:  A tuple containing the figure and axes objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n&gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n...     obs, pred,\n...     xlabel='Observed',\n...     ylabel='Predicted',\n...     xlim=[0, 6],\n...     ylim=[0, 6]\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_with_11line(\n    x: np.array,\n    y: np.array,\n    point_color=\"blue\",\n    line_color=\"black\",\n    xlim=[0.0, 1.0],\n    ylim=[0.0, 1.0],\n    xlabel=None,\n    ylabel=None,\n):\n    \"\"\"Creates a scatter plot comparing two variables with a 1:1 line.\n\n    This function generates a scatter plot with a 1:1 line (diagonal) for comparing\n    two variables, commonly used in model evaluation to compare observed vs predicted values.\n    The plot includes customizable colors, axis limits, and labels.\n\n    Args:\n        x (np.array): First variable to be plotted (typically observed values).\n        y (np.array): Second variable to be plotted (typically predicted values).\n        point_color (str, optional): Color of scatter points. Defaults to \"blue\".\n        line_color (str, optional): Color of the 1:1 line. Defaults to \"black\".\n        xlim (list, optional): X-axis range as [min, max]. Defaults to [0.0, 1.0].\n        ylim (list, optional): Y-axis range as [min, max]. Defaults to [0.0, 1.0].\n        xlabel (str, optional): Label for x-axis. Defaults to None.\n        ylabel (str, optional): Label for y-axis. Defaults to None.\n\n    Returns:\n        tuple[matplotlib.figure.Figure, matplotlib.axes.Axes]: \n            A tuple containing the figure and axes objects.\n\n    Examples:\n        &gt;&gt;&gt; obs = np.array([1, 2, 3, 4, 5])\n        &gt;&gt;&gt; pred = np.array([1.1, 2.2, 2.9, 4.1, 5.2])\n        &gt;&gt;&gt; fig, ax = plot_scatter_with_11line(\n        ...     obs, pred,\n        ...     xlabel='Observed',\n        ...     ylabel='Predicted',\n        ...     xlim=[0, 6],\n        ...     ylim=[0, 6]\n        ... )\n    \"\"\"\n    fig, ax = plt.subplots()\n    # set background color for ax\n    ax.set_facecolor(\"whitesmoke\")\n    # plot the grid of the figure\n    # plt.grid(color=\"whitesmoke\")\n    ax.scatter(x, y, c=point_color, s=10)\n    line = mlines.Line2D([0, 1], [0, 1], color=line_color, linestyle=\"--\")\n    transform = ax.transAxes\n    line.set_transform(transform)\n    ax.add_line(line)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    plt.xticks(np.arange(xlim[0], xlim[1], 0.1), fontsize=16)\n    plt.yticks(np.arange(ylim[0], ylim[1], 0.1), fontsize=16)\n    # set xlable and ylabel\n    if xlabel is not None:\n        plt.xlabel(xlabel, fontsize=16)\n    if ylabel is not None:\n        plt.ylabel(ylabel, fontsize=16)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    return fig, ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_scatter_xyc","title":"<code>plot_scatter_xyc(x_label, x, y_label, y, c_label=None, c=None, size=20, is_reg=False, xlim=None, ylim=None, quadrant=None)</code>","text":"<p>Creates a scatter plot with optional color mapping and quadrant analysis.</p> <p>This function generates a scatter plot with optional color mapping for points, regression line, and quadrant analysis. It's particularly useful for analyzing relationships between variables with an additional dimension represented by color.</p> <p>Parameters:</p> Name Type Description Default <code>x_label</code> <code>str</code> <p>Label for x-axis.</p> required <code>x</code> <code>Union[array, List[array]]</code> <p>X-axis data values.</p> required <code>y_label</code> <code>str</code> <p>Label for y-axis.</p> required <code>y</code> <code>Union[array, List[array]]</code> <p>Y-axis data values.</p> required <code>c_label</code> <code>Union[str, List[str]]</code> <p>Label(s) for color mapping or multiple series. Defaults to None.</p> <code>None</code> <code>c</code> <code>Union[array, List[str]]</code> <p>Values for color mapping or colors for multiple series. Defaults to None.</p> <code>None</code> <code>size</code> <code>int</code> <p>Size of scatter points. Defaults to 20.</p> <code>20</code> <code>is_reg</code> <code>bool</code> <p>If True, adds regression line. Defaults to False.</p> <code>False</code> <code>xlim</code> <code>list</code> <p>X-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>list</code> <p>Y-axis limits as [min, max]. Defaults to None.</p> <code>None</code> <code>quadrant</code> <code>list</code> <p>Reference points [x, y] for quadrant analysis. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple scatter plot\n&gt;&gt;&gt; x = np.random.rand(100)\n&gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X Values', x,\n...     'Y Values', y,\n...     is_reg=True\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Scatter plot with color mapping\n&gt;&gt;&gt; c = np.random.rand(100)\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     c_label='Z Values',\n...     c=c\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Quadrant analysis\n&gt;&gt;&gt; plot_scatter_xyc(\n...     'X', x, 'Y', y,\n...     quadrant=[0.5, 0.5],\n...     xlim=[0, 1],\n...     ylim=[0, 1]\n... )\n</code></pre> Notes <ul> <li>Supports both single and multiple series plotting</li> <li>Automatically handles NaN values</li> <li>Provides quadrant statistics when quadrant analysis is enabled</li> <li>Uses clean plotting style with minimal spines</li> <li>Supports regression line with seaborn's regplot</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_scatter_xyc(\n    x_label,\n    x,\n    y_label,\n    y,\n    c_label=None,\n    c=None,\n    size=20,\n    is_reg=False,\n    xlim=None,\n    ylim=None,\n    quadrant=None,\n):\n    \"\"\"Creates a scatter plot with optional color mapping and quadrant analysis.\n\n    This function generates a scatter plot with optional color mapping for points,\n    regression line, and quadrant analysis. It's particularly useful for analyzing\n    relationships between variables with an additional dimension represented by color.\n\n    Args:\n        x_label (str): Label for x-axis.\n        x (Union[np.array, List[np.array]]): X-axis data values.\n        y_label (str): Label for y-axis.\n        y (Union[np.array, List[np.array]]): Y-axis data values.\n        c_label (Union[str, List[str]], optional): Label(s) for color mapping or\n            multiple series. Defaults to None.\n        c (Union[np.array, List[str]], optional): Values for color mapping or\n            colors for multiple series. Defaults to None.\n        size (int, optional): Size of scatter points. Defaults to 20.\n        is_reg (bool, optional): If True, adds regression line. Defaults to False.\n        xlim (list, optional): X-axis limits as [min, max]. Defaults to None.\n        ylim (list, optional): Y-axis limits as [min, max]. Defaults to None.\n        quadrant (list, optional): Reference points [x, y] for quadrant analysis.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Simple scatter plot\n        &gt;&gt;&gt; x = np.random.rand(100)\n        &gt;&gt;&gt; y = x + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X Values', x,\n        ...     'Y Values', y,\n        ...     is_reg=True\n        ... )\n\n        &gt;&gt;&gt; # Scatter plot with color mapping\n        &gt;&gt;&gt; c = np.random.rand(100)\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     c_label='Z Values',\n        ...     c=c\n        ... )\n\n        &gt;&gt;&gt; # Quadrant analysis\n        &gt;&gt;&gt; plot_scatter_xyc(\n        ...     'X', x, 'Y', y,\n        ...     quadrant=[0.5, 0.5],\n        ...     xlim=[0, 1],\n        ...     ylim=[0, 1]\n        ... )\n\n    Notes:\n        - Supports both single and multiple series plotting\n        - Automatically handles NaN values\n        - Provides quadrant statistics when quadrant analysis is enabled\n        - Uses clean plotting style with minimal spines\n        - Supports regression line with seaborn's regplot\n    \"\"\"\n    fig, ax = plt.subplots()\n    if type(x) is list:\n        for i in range(len(x)):\n            ax.plot(\n                x[i], y[i], marker=\"o\", linestyle=\"\", ms=size, label=c_label[i], c=c[i]\n            )\n        ax.legend()\n\n    elif c is None:\n        df = pd.DataFrame({x_label: x, y_label: y})\n        points = plt.scatter(df[x_label], df[y_label], s=size)\n        if quadrant is not None:\n            plt.axvline(quadrant[0], c=\"grey\", lw=1, linestyle=\"--\")\n            plt.axhline(quadrant[1], c=\"grey\", lw=1, linestyle=\"--\")\n            q2 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q3 = df[(df[x_label] &lt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q4 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &lt; 0)].shape[0]\n            q5 = df[(df[x_label] == 0) &amp; (df[y_label] == 0)].shape[0]\n            q1 = df[(df[x_label] &gt; 0) &amp; (df[y_label] &gt; 0)].shape[0]\n            q = q1 + q2 + q3 + q4 + q5\n            r1 = int(round(q1 / q, 2) * 100)\n            r2 = int(round(q2 / q, 2) * 100)\n            r3 = int(round(q3 / q, 2) * 100)\n            r4 = int(round(q4 / q, 2) * 100)\n            r5 = 100 - r1 - r2 - r3 - r4\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r1}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[1] - (ylim[1] - ylim[0]) * 0.1,\n                f\"{r2}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[0] + (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r3}%\",\n                fontsize=16,\n            )\n            plt.text(\n                xlim[1] - (xlim[1] - xlim[0]) * 0.1,\n                ylim[0] + (ylim[1] - ylim[0]) * 0.1,\n                f\"{r4}%\",\n                fontsize=16,\n            )\n            plt.text(0.2, 0.02, f\"{str(r5)}%\", fontsize=16)\n    else:\n        df = pd.DataFrame({x_label: x, y_label: y, c_label: c})\n        points = plt.scatter(\n            df[x_label], df[y_label], c=df[c_label], s=size, cmap=\"Spectral\"\n        )  # set style options\n        # add a color bar\n        plt.colorbar(points)\n\n    # set limits\n    if xlim is not None:\n        plt.xlim(xlim[0], xlim[1])\n    if ylim is not None:\n        plt.ylim(ylim[0], ylim[1])\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    # build the regression plot\n    if is_reg:\n        plot = sns.regplot(x_label, y_label, data=df, scatter=False)  # , color=\".1\"\n        plot = plot.set(xlabel=x_label, ylabel=y_label)  # add labels\n    else:\n        plt.xlabel(x_label, fontsize=18)\n        plt.ylabel(y_label, fontsize=18)\n        plt.xticks(fontsize=16)\n        plt.yticks(fontsize=16)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ts","title":"<code>plot_ts(t, y, ax=None, t_bar=None, title=None, xlabel=None, ylabel=None, fig_size=(12, 4), c_lst='rbkgcmyrbkgcmyrbkgcmy', leg_lst=None, marker_lst=None, linewidth=2, linespec=None, dash_lines=None, alpha=1)</code>","text":"<p>Plot time series for multi arrays with matplotlib</p>"},{"location":"api/hydroutils/#hydroutils.plot_ts--parameters","title":"Parameters","text":"<p>t : Union[list, np.array]     time series but not just date; it can also be numbers like 1, 2, 3, ... y : Union[list, np.array]     shown data series; the len of y should be equal to t's ax : type, optional     description, by default None t_bar : type, optional     description, by default None title : type, optional     description, by default None xlabel: str, optional     the name of x axis, by default None ylabel : str, optional     the name of y axis, by default None fig_size : tuple, optional     description, by default (12, 4) c_lst : str, optional     description, by default \"rbkgcmy\" leg_lst : type, optional     description, by default None marker_lst : type, optional     description, by default None linewidth : int, optional     description, by default 2 linespec : type, optional     description, by default None dash_lines : type, optional     if dash_line, then we will plot dashed line, by default None</p>"},{"location":"api/hydroutils/#hydroutils.plot_ts--returns","title":"Returns","text":"<p>type description</p> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts(\n    t: Union[list, np.array],\n    y: Union[list, np.array],\n    ax=None,\n    t_bar=None,\n    title=None,\n    xlabel: str = None,\n    ylabel: str = None,\n    fig_size=(12, 4),\n    c_lst=\"rbkgcmyrbkgcmyrbkgcmy\",\n    leg_lst=None,\n    marker_lst=None,\n    linewidth=2,\n    linespec=None,\n    dash_lines=None,\n    alpha=1,\n):\n    \"\"\"Plot time series for multi arrays with matplotlib\n\n    Parameters\n    ----------\n    t : Union[list, np.array]\n        time series but not just date; it can also be numbers like 1, 2, 3, ...\n    y : Union[list, np.array]\n        shown data series; the len of y should be equal to t's\n    ax : _type_, optional\n        _description_, by default None\n    t_bar : _type_, optional\n        _description_, by default None\n    title : _type_, optional\n        _description_, by default None\n    xlabel: str, optional\n        the name of x axis, by default None\n    ylabel : str, optional\n        the name of y axis, by default None\n    fig_size : tuple, optional\n        _description_, by default (12, 4)\n    c_lst : str, optional\n        _description_, by default \"rbkgcmy\"\n    leg_lst : _type_, optional\n        _description_, by default None\n    marker_lst : _type_, optional\n        _description_, by default None\n    linewidth : int, optional\n        _description_, by default 2\n    linespec : _type_, optional\n        _description_, by default None\n    dash_lines : _type_, optional\n        if dash_line, then we will plot dashed line, by default None\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    is_new_fig = False\n    if ax is None:\n        fig = plt.figure(figsize=fig_size)\n        ax = fig.subplots()\n        is_new_fig = True\n    if dash_lines is not None:\n        assert isinstance(dash_lines, list)\n    else:\n        dash_lines = np.full(len(t), False).tolist()\n        # dash_lines[-1] = True\n    if type(y) is np.ndarray:\n        y = [y]\n    if type(linewidth) is not list:\n        linewidth = [linewidth] * len(y)\n    if type(alpha) is not list:\n        alpha = [alpha] * len(y)\n    for k in range(len(y)):\n        tt = t[k] if type(t) is list else t\n        yy = y[k]\n        leg_str = None\n        if leg_lst is not None:\n            leg_str = leg_lst[k]\n        if marker_lst is None:\n            (line_i,) = (\n                ax.plot(tt, yy, \"*\", color=c_lst[k], label=leg_str, alpha=alpha[k])\n                if True in np.isnan(yy)\n                else ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linewidth=linewidth[k],\n                    alpha=alpha[k],\n                )\n            )\n        elif marker_lst[k] == \"-\":\n            if linespec is not None:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    linestyle=linespec[k],\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n            else:\n                (line_i,) = ax.plot(\n                    tt,\n                    yy,\n                    color=c_lst[k],\n                    label=leg_str,\n                    lw=linewidth[k],\n                    alpha=alpha[k],\n                )\n        else:\n            (line_i,) = ax.plot(\n                tt,\n                yy,\n                color=c_lst[k],\n                label=leg_str,\n                marker=marker_lst[k],\n                lw=linewidth[k],\n                alpha=alpha[k],\n            )\n        if dash_lines[k]:\n            line_i.set_dashes([2, 2, 10, 2])\n        if ylabel is not None:\n            ax.set_ylabel(ylabel, fontsize=18)\n        if xlabel is not None:\n            ax.set_xlabel(xlabel, fontsize=18)\n    if t_bar is not None:\n        ylim = ax.get_ylim()\n        t_bar = [t_bar] if type(t_bar) is not list else t_bar\n        for tt in t_bar:\n            ax.plot([tt, tt], ylim, \"-k\")\n\n    if leg_lst is not None:\n        ax.legend(loc=\"upper right\", frameon=False)\n        plt.legend(prop={\"size\": 16})\n    if title is not None:\n        ax.set_title(title, loc=\"center\", fontdict={\"fontsize\": 17})\n    # plot the grid of the figure\n    plt.grid()\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    # Hide the right and top spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n    plt.tight_layout()\n    return (fig, ax) if is_new_fig else ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ts_map","title":"<code>plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None)</code>","text":"<p>Creates an interactive map with linked time series plots.</p> <p>This function generates a figure with two subplots: a map on top and a time series plot below. Clicking on a location in the map updates the time series plot to show data from the nearest site.</p> <p>Parameters:</p> Name Type Description Default <code>dataMap</code> <code>list</code> <p>Data values to be shown on the map.</p> required <code>dataTs</code> <code>list</code> <p>List of time series data for each site.</p> required <code>lat</code> <code>array</code> <p>Latitude values for each site.</p> required <code>lon</code> <code>array</code> <p>Longitude values for each site.</p> required <code>t</code> <code>list</code> <p>Time points for x-axis of time series.</p> required <code>sites_id</code> <code>list</code> <p>Identifiers for each site.</p> required <code>pertile_range</code> <code>list</code> <p>Percentile range for color scaling on map. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; n_sites = 10\n&gt;&gt;&gt; n_times = 100\n&gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n&gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n&gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Generate sample time series for each site\n&gt;&gt;&gt; t = list(range(n_times))\n&gt;&gt;&gt; dataTs = []\n&gt;&gt;&gt; for i in range(n_sites):\n...     pred = np.sin(np.array(t)/10 + i/5)\n...     obs = pred + np.random.normal(0, 0.1, n_times)\n...     dataTs.append([pred, obs])\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Map data could be mean values\n&gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n&gt;&gt;&gt; \n&gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n</code></pre> Notes <ul> <li>Uses TkAgg backend for interactive display</li> <li>Map uses Cartopy for proper geographic projection</li> <li>Time series updates automatically on map click</li> <li>Shows site ID and coordinates in time series title</li> <li>Finds nearest site to click location</li> <li>Both predicted and observed values shown in time series</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id, pertile_range=None):\n    \"\"\"Creates an interactive map with linked time series plots.\n\n    This function generates a figure with two subplots: a map on top and a time series\n    plot below. Clicking on a location in the map updates the time series plot to show\n    data from the nearest site.\n\n    Args:\n        dataMap (list): Data values to be shown on the map.\n        dataTs (list): List of time series data for each site.\n        lat (np.array): Latitude values for each site.\n        lon (np.array): Longitude values for each site.\n        t (list): Time points for x-axis of time series.\n        sites_id (list): Identifiers for each site.\n        pertile_range (list, optional): Percentile range for color scaling on map.\n            Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; # Create sample data\n        &gt;&gt;&gt; n_sites = 10\n        &gt;&gt;&gt; n_times = 100\n        &gt;&gt;&gt; lat = np.random.uniform(30, 45, n_sites)\n        &gt;&gt;&gt; lon = np.random.uniform(-120, -100, n_sites)\n        &gt;&gt;&gt; sites_id = [f'SITE_{i:03d}' for i in range(n_sites)]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Generate sample time series for each site\n        &gt;&gt;&gt; t = list(range(n_times))\n        &gt;&gt;&gt; dataTs = []\n        &gt;&gt;&gt; for i in range(n_sites):\n        ...     pred = np.sin(np.array(t)/10 + i/5)\n        ...     obs = pred + np.random.normal(0, 0.1, n_times)\n        ...     dataTs.append([pred, obs])\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; # Map data could be mean values\n        &gt;&gt;&gt; dataMap = [np.mean(ts[0]) for ts in dataTs]\n        &gt;&gt;&gt; \n        &gt;&gt;&gt; plot_ts_map(dataMap, dataTs, lat, lon, t, sites_id)\n\n    Notes:\n        - Uses TkAgg backend for interactive display\n        - Map uses Cartopy for proper geographic projection\n        - Time series updates automatically on map click\n        - Shows site ID and coordinates in time series title\n        - Finds nearest site to click location\n        - Both predicted and observed values shown in time series\n    \"\"\"\n    # show the map in a pop-up window\n    matplotlib.use(\"TkAgg\")\n    assert isinstance(dataMap, list)\n    assert isinstance(dataTs, list)\n    # setup axes\n    fig = plt.figure(figsize=(8, 8), dpi=100)\n    gs = gridspec.GridSpec(2, 1)\n    # plt.subplots_adjust(left=0.13, right=0.89, bottom=0.05)\n    # plot maps\n    ax1 = plt.subplot(gs[0], projection=ccrs.PlateCarree())\n    ax1 = plot_map_carto(\n        dataMap, lat=lat, lon=lon, fig=fig, ax=ax1, pertile_range=pertile_range\n    )\n    # line plot\n    ax2 = plt.subplot(gs[1])\n\n    # plot ts\n    def onclick(event):\n        print(\"click event\")\n        # refresh the ax2, then new ts data can be showed without previous one\n        ax2.cla()\n        xClick = event.xdata\n        yClick = event.ydata\n        d = np.sqrt((xClick - lon) ** 2 + (yClick - lat) ** 2)\n        ind = np.argmin(d)\n        titleStr = \"site_id %s, lat %.3f, lon %.3f\" % (\n            sites_id[ind],\n            lat[ind],\n            lon[ind],\n        )\n        tsLst = dataTs[ind]\n        plot_ts_matplot(t, tsLst, ax=ax2, title=titleStr)\n        # following funcs both work\n        fig.canvas.draw()\n        # plt.draw()\n\n    fig.canvas.mpl_connect(\"button_press_event\", onclick)\n    plt.show()\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.plot_ts_matplot","title":"<code>plot_ts_matplot(t, y, color='r', ax=None, title=None)</code>","text":"<p>Creates a simple time series plot comparing predicted and observed values.</p> <p>This function provides a straightforward way to plot and compare two time series, typically used for showing predicted vs observed values. It supports both creating new figures and adding to existing axes.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>list</code> <p>Time points for x-axis.</p> required <code>y</code> <code>list</code> <p>List containing two arrays: [predicted_values, observed_values].</p> required <code>color</code> <code>str</code> <p>Color for predicted values line. Defaults to \"r\".</p> <code>'r'</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]: If ax is None, returns (fig, ax), otherwise returns ax.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create new plot\n&gt;&gt;&gt; t = list(range(100))\n&gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n&gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n&gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n</code></pre> <pre><code>&gt;&gt;&gt; # Add to existing axes\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n...                     title='Sine Wave Prediction')\n</code></pre> Notes <ul> <li>Predicted values are plotted first with specified color</li> <li>Observed values are plotted second with default color</li> <li>Legend is automatically added with \"pred\" and \"obs\" labels</li> <li>Title is centered if provided</li> </ul> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def plot_ts_matplot(t, y, color=\"r\", ax=None, title=None):\n    \"\"\"Creates a simple time series plot comparing predicted and observed values.\n\n    This function provides a straightforward way to plot and compare two time series,\n    typically used for showing predicted vs observed values. It supports both creating\n    new figures and adding to existing axes.\n\n    Args:\n        t (list): Time points for x-axis.\n        y (list): List containing two arrays: [predicted_values, observed_values].\n        color (str, optional): Color for predicted values line. Defaults to \"r\".\n        ax (matplotlib.axes.Axes, optional): Existing axes to plot on. Defaults to None.\n        title (str, optional): Plot title. Defaults to None.\n\n    Returns:\n        Union[Tuple[matplotlib.figure.Figure, matplotlib.axes.Axes], matplotlib.axes.Axes]:\n            If ax is None, returns (fig, ax), otherwise returns ax.\n\n    Examples:\n        &gt;&gt;&gt; # Create new plot\n        &gt;&gt;&gt; t = list(range(100))\n        &gt;&gt;&gt; y_pred = np.sin(np.array(t)/10)\n        &gt;&gt;&gt; y_obs = y_pred + np.random.normal(0, 0.1, 100)\n        &gt;&gt;&gt; fig, ax = plot_ts_matplot(t, [y_pred, y_obs], color='blue')\n\n        &gt;&gt;&gt; # Add to existing axes\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; ax = plot_ts_matplot(t, [y_pred, y_obs], ax=ax,\n        ...                     title='Sine Wave Prediction')\n\n    Notes:\n        - Predicted values are plotted first with specified color\n        - Observed values are plotted second with default color\n        - Legend is automatically added with \"pred\" and \"obs\" labels\n        - Title is centered if provided\n    \"\"\"\n    assert isinstance(t, list)\n    assert isinstance(y, list)\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.subplots()\n    ax.plot(t, y[0], color=color, label=\"pred\")\n    ax.plot(t, y[1], label=\"obs\")\n    ax.legend()\n    if title is not None:\n        ax.set_title(title, loc=\"center\")\n    return (fig, ax) if ax is None else ax\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.random_choice_no_return","title":"<code>random_choice_no_return(arr, num_lst)</code>","text":"<p>sampling without replacement multi-times, and the num of each time is in num_lst</p> Source code in <code>hydroutils/hydro_arithmetric.py</code> <pre><code>def random_choice_no_return(arr, num_lst):\n    \"\"\"sampling without replacement multi-times, and the num of each time is in num_lst\"\"\"\n    num_lst_arr = np.array(num_lst)\n    num_sum = num_lst_arr.sum()\n    if type(arr) == list:\n        arr = np.array(arr)\n    assert num_sum &lt;= arr.size\n    results = []\n    arr_residue = np.arange(arr.size)\n    for num in num_lst_arr:\n        idx_chosen = np.random.choice(arr_residue.size, num, replace=False)\n        chosen_idx_in_arr = np.sort(arr_residue[idx_chosen])\n        results.append(arr[chosen_idx_in_arr])\n        arr_residue = np.delete(arr_residue, idx_chosen)\n    return results\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.remove_abnormal_data","title":"<code>remove_abnormal_data(data, *, q1=1e-05, q2=0.99999)</code>","text":"<p>remove abnormal data</p>"},{"location":"api/hydroutils/#hydroutils.remove_abnormal_data--parameters","title":"Parameters","text":"<p>data     data to be removed q     lower quantile q2     upper quantile</p>"},{"location":"api/hydroutils/#hydroutils.remove_abnormal_data--returns","title":"Returns","text":"<p>np.array     data after removing abnormal data</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def remove_abnormal_data(data, *, q1=0.00001, q2=0.99999):\n    \"\"\"\n    remove abnormal data\n\n    Parameters\n    ----------\n    data\n        data to be removed\n    q\n        lower quantile\n    q2\n        upper quantile\n\n    Returns\n    -------\n    np.array\n        data after removing abnormal data\n    \"\"\"\n    # remove abnormal data\n    data[data &lt; np.quantile(data, q1)] = np.nan\n    data[data &gt; np.quantile(data, q2)] = np.nan\n    return data\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.stat_error","title":"<code>stat_error(target, pred, fill_nan='no')</code>","text":"<p>Statistics indicators include: Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV</p>"},{"location":"api/hydroutils/#hydroutils.stat_error--parameters","title":"Parameters","text":"<p>target     observations, 2-dim array [basin, sequence] pred     predictions, same dim with observations fill_nan     \"no\" means ignoring the NaN value, and it is the default setting;     \"sum\" means calculate the sum of the following values in the NaN locations.     For example, observations are [1, nan, nan, 2], and predictions are [0.3, 0.3, 0.3, 1.5].     Then, \"no\" means [1, 2] v.s. [0.3, 1.5] while \"sum\" means [1, 2] v.s. [0.3 + 0.3 + 0.3, 1.5];     \"mean\" represents calculate average value the following values in the NaN locations.</p>"},{"location":"api/hydroutils/#hydroutils.stat_error--returns","title":"Returns","text":"<p>dict     Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_error(target: np.ndarray, pred: np.ndarray, fill_nan: str = \"no\") -&gt; dict:\n    \"\"\"\n    Statistics indicators include: Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV\n\n    Parameters\n    ----------\n    target\n        observations, 2-dim array [basin, sequence]\n    pred\n        predictions, same dim with observations\n    fill_nan\n        \"no\" means ignoring the NaN value, and it is the default setting;\n        \"sum\" means calculate the sum of the following values in the NaN locations.\n        For example, observations are [1, nan, nan, 2], and predictions are [0.3, 0.3, 0.3, 1.5].\n        Then, \"no\" means [1, 2] v.s. [0.3, 1.5] while \"sum\" means [1, 2] v.s. [0.3 + 0.3 + 0.3, 1.5];\n        \"mean\" represents calculate average value the following values in the NaN locations.\n\n    Returns\n    -------\n    dict\n        Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV\n    \"\"\"\n    if len(target.shape) == 3:\n        raise ValueError(\n            \"The input data should be 2-dim, not 3-dim. If you want to calculate metrics for 3-d arrays, please use stat_errors function.\"\n        )\n    if type(fill_nan) is not str:\n        raise ValueError(\"fill_nan should be a string.\")\n    if target.shape != pred.shape:\n        raise ValueError(\"The shape of target and pred should be the same.\")\n    if fill_nan != \"no\":\n        each_non_nan_idx = []\n        all_non_nan_idx: list[int] = []\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            non_nan_idx_tmp = [j for j in range(tmp.size) if not np.isnan(tmp[j])]\n            each_non_nan_idx.append(non_nan_idx_tmp)\n            # TODO: now all_non_nan_idx is only set for ET, because of its irregular nan values\n            all_non_nan_idx = all_non_nan_idx + non_nan_idx_tmp\n            non_nan_idx = np.unique(all_non_nan_idx).tolist()\n        # some NaN data appear in different dates in different basins, so we have to calculate the metric for each basin\n        # but for ET, it is not very resonable to calculate the metric for each basin in this way, for example,\n        # the non_nan_idx: [1, 9, 17, 33, 41], then there are 16 elements in 17 -&gt; 33, so use all_non_nan_idx is better\n        # hence we don't use each_non_nan_idx finally\n        out_dict = dict(\n            Bias=[],\n            RMSE=[],\n            ubRMSE=[],\n            Corr=[],\n            R2=[],\n            NSE=[],\n            KGE=[],\n            FHV=[],\n            FLV=[],\n        )\n    if fill_nan == \"sum\":\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            # non_nan_idx = each_non_nan_idx[i]\n            targ_i = tmp[non_nan_idx]\n            pred_i = np.add.reduceat(pred[i], non_nan_idx)\n            dict_i = stat_error_i(targ_i, pred_i)\n            out_dict[\"Bias\"].append(dict_i[\"Bias\"])\n            out_dict[\"RMSE\"].append(dict_i[\"RMSE\"])\n            out_dict[\"ubRMSE\"].append(dict_i[\"ubRMSE\"])\n            out_dict[\"Corr\"].append(dict_i[\"Corr\"])\n            out_dict[\"R2\"].append(dict_i[\"R2\"])\n            out_dict[\"NSE\"].append(dict_i[\"NSE\"])\n            out_dict[\"KGE\"].append(dict_i[\"KGE\"])\n            out_dict[\"FHV\"].append(dict_i[\"FHV\"])\n            out_dict[\"FLV\"].append(dict_i[\"FLV\"])\n        return out_dict\n    elif fill_nan == \"mean\":\n        for i in range(target.shape[0]):\n            tmp = target[i]\n            # non_nan_idx = each_non_nan_idx[i]\n            targ_i = tmp[non_nan_idx]\n            pred_i_sum = np.add.reduceat(pred[i], non_nan_idx)\n            if non_nan_idx[-1] &lt; len(pred[i]):\n                idx4mean = non_nan_idx + [len(pred[i])]\n            else:\n                idx4mean = copy.copy(non_nan_idx)\n            idx_interval = [y - x for x, y in zip(idx4mean, idx4mean[1:])]\n            pred_i = pred_i_sum / idx_interval\n            dict_i = stat_error_i(targ_i, pred_i)\n            out_dict[\"Bias\"].append(dict_i[\"Bias\"])\n            out_dict[\"RMSE\"].append(dict_i[\"RMSE\"])\n            out_dict[\"ubRMSE\"].append(dict_i[\"ubRMSE\"])\n            out_dict[\"Corr\"].append(dict_i[\"Corr\"])\n            out_dict[\"R2\"].append(dict_i[\"R2\"])\n            out_dict[\"NSE\"].append(dict_i[\"NSE\"])\n            out_dict[\"KGE\"].append(dict_i[\"KGE\"])\n            out_dict[\"FHV\"].append(dict_i[\"FHV\"])\n            out_dict[\"FLV\"].append(dict_i[\"FLV\"])\n        return out_dict\n    ngrid, nt = pred.shape\n    # Bias\n    Bias = np.nanmean(pred - target, axis=1)\n    # RMSE\n    RMSE = np.sqrt(np.nanmean((pred - target) ** 2, axis=1))\n    # ubRMSE\n    predMean = np.tile(np.nanmean(pred, axis=1), (nt, 1)).transpose()\n    targetMean = np.tile(np.nanmean(target, axis=1), (nt, 1)).transpose()\n    predAnom = pred - predMean\n    targetAnom = target - targetMean\n    ubRMSE = np.sqrt(np.nanmean((predAnom - targetAnom) ** 2, axis=1))\n    # rho R2 NSE\n    Corr = np.full(ngrid, np.nan)\n    R2 = np.full(ngrid, np.nan)\n    NSE = np.full(ngrid, np.nan)\n    KGe = np.full(ngrid, np.nan)\n    PBiaslow = np.full(ngrid, np.nan)\n    PBiashigh = np.full(ngrid, np.nan)\n    PBias = np.full(ngrid, np.nan)\n    num_lowtarget_zero = 0\n    for k in range(ngrid):\n        x = pred[k, :]\n        y = target[k, :]\n        ind = np.where(np.logical_and(~np.isnan(x), ~np.isnan(y)))[0]\n        if ind.shape[0] &gt; 0:\n            xx = x[ind]\n            yy = y[ind]\n            # percent bias\n            PBias[k] = np.sum(xx - yy) / np.sum(yy) * 100\n            if ind.shape[0] &gt; 1:\n                # Theoretically at least two points for correlation\n                Corr[k] = scipy.stats.pearsonr(xx, yy)[0]\n                yymean = yy.mean()\n                SST = np.sum((yy - yymean) ** 2)\n                SSReg = np.sum((xx - yymean) ** 2)\n                SSRes = np.sum((yy - xx) ** 2)\n                R2[k] = 1 - SSRes / SST\n                NSE[k] = 1 - SSRes / SST\n                KGe[k] = KGE(xx, yy)\n            # FHV the peak flows bias 2%\n            # FLV the low flows bias bottom 30%, log space\n            pred_sort = np.sort(xx)\n            target_sort = np.sort(yy)\n            indexlow = round(0.3 * len(pred_sort))\n            indexhigh = round(0.98 * len(pred_sort))\n            lowpred = pred_sort[:indexlow]\n            highpred = pred_sort[indexhigh:]\n            lowtarget = target_sort[:indexlow]\n            hightarget = target_sort[indexhigh:]\n            if np.sum(lowtarget) == 0:\n                num_lowtarget_zero = num_lowtarget_zero + 1\n            with warnings.catch_warnings():\n                # Sometimes the lowtarget is all 0, which will cause a warning\n                # but I know it is not an error, so I ignore it\n                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                PBiaslow[k] = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n            PBiashigh[k] = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n    outDict = dict(\n        Bias=Bias,\n        RMSE=RMSE,\n        ubRMSE=ubRMSE,\n        Corr=Corr,\n        R2=R2,\n        NSE=NSE,\n        KGE=KGe,\n        FHV=PBiashigh,\n        FLV=PBiaslow,\n    )\n    # \"The CDF of BFLV will not reach 1.0 because some basins have all zero flow observations for the \"\n    # \"30% low flow interval, the percent bias can be infinite\\n\"\n    # \"The number of these cases is \" + str(num_lowtarget_zero)\n    return outDict\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.stat_error_i","title":"<code>stat_error_i(targ_i, pred_i)</code>","text":"<p>statistics for one dimensional array</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_error_i(targ_i, pred_i):\n    \"\"\"statistics for one dimensional array\"\"\"\n    ind = np.where(np.logical_and(~np.isnan(pred_i), ~np.isnan(targ_i)))[0]\n    # Theoretically at least two points for correlation\n    if ind.shape[0] &gt; 1:\n        xx = pred_i[ind]\n        yy = targ_i[ind]\n        bias = he.me(xx, yy)\n        # RMSE\n        rmse = he.rmse(xx, yy)\n        # ubRMSE\n        pred_mean = np.nanmean(xx)\n        target_mean = np.nanmean(yy)\n        pred_anom = xx - pred_mean\n        target_anom = yy - target_mean\n        ubrmse = np.sqrt(np.nanmean((pred_anom - target_anom) ** 2))\n        # rho R2 NSE\n        corr = he.pearson_r(xx, yy)\n        r2 = he.r_squared(xx, yy)\n        nse = he.nse(xx, yy)\n        kge = he.kge_2009(xx, yy)\n        # percent bias\n        pbias = np.sum(xx - yy) / np.sum(yy) * 100\n        # FHV the peak flows bias 2%\n        # FLV the low flows bias bottom 30%, log space\n        pred_sort = np.sort(xx)\n        target_sort = np.sort(yy)\n        indexlow = round(0.3 * len(pred_sort))\n        indexhigh = round(0.98 * len(pred_sort))\n        lowpred = pred_sort[:indexlow]\n        highpred = pred_sort[indexhigh:]\n        lowtarget = target_sort[:indexlow]\n        hightarget = target_sort[indexhigh:]\n        pbiaslow = np.sum(lowpred - lowtarget) / np.sum(lowtarget) * 100\n        pbiashigh = np.sum(highpred - hightarget) / np.sum(hightarget) * 100\n        return dict(\n            Bias=bias,\n            RMSE=rmse,\n            ubRMSE=ubrmse,\n            Corr=corr,\n            R2=r2,\n            NSE=nse,\n            KGE=kge,\n            FHV=pbiashigh,\n            FLV=pbiaslow,\n        )\n    else:\n        raise ValueError(\n            \"The number of data is less than 2, we don't calculate the statistics.\"\n        )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.stat_errors","title":"<code>stat_errors(target, pred, fill_nan=None)</code>","text":"<p>Calculate statistics for 3-dim arrays</p>"},{"location":"api/hydroutils/#hydroutils.stat_errors--parameters","title":"Parameters","text":"<p>target : np.ndarray     the observed data pred : np.ndarray     the predicted data fill_nan : list, optional     a list of strings, each string is \"no\", \"sum\" or \"mean\", by default None</p>"},{"location":"api/hydroutils/#hydroutils.stat_errors--returns","title":"Returns","text":"<p>list     A list of dictionaries, each dictionary contains Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def stat_errors(target: np.ndarray, pred: np.ndarray, fill_nan: list = None) -&gt; list:\n    \"\"\"Calculate statistics for 3-dim arrays\n\n    Parameters\n    ----------\n    target : np.ndarray\n        the observed data\n    pred : np.ndarray\n        the predicted data\n    fill_nan : list, optional\n        a list of strings, each string is \"no\", \"sum\" or \"mean\", by default None\n\n    Returns\n    -------\n    list\n        A list of dictionaries, each dictionary contains Bias, RMSE, ubRMSE, Corr, R2, NSE, KGE, FHV, FLV\n    \"\"\"\n    if fill_nan is None:\n        fill_nan = [\"no\"]\n    if len(target.shape) != 3:\n        raise ValueError(\n            \"The input data should be 3-dim, not 2-dim. If you want to calculate \"\n            \"metrics for 2-d arrays, please use stat_error function.\"\n        )\n    if target.shape != pred.shape:\n        raise ValueError(\"The shape of target and pred should be the same.\")\n    if type(fill_nan) is not list or len(fill_nan) != target.shape[-1]:\n        raise ValueError(\n            \"Please give same length of fill_nan as the number of variables.\"\n        )\n    dict_list = []\n    for k in range(target.shape[-1]):\n        k_dict = stat_error(target[:, :, k], pred[:, :, k], fill_nan=fill_nan[k])\n        dict_list.append(k_dict)\n    return dict_list\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.swarmplot_without_legend","title":"<code>swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs)</code>","text":"<p>Creates a swarm plot using seaborn with colorbar instead of legend.</p> <p>This function creates a swarm plot where points are colored according to a continuous variable, replacing the default legend with a colorbar for better visualization of the color scale.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Values for x-axis categories.</p> required <code>y</code> <p>Values for y-axis.</p> required <code>hue</code> <p>Values determining the color of each point.</p> required <code>vmin</code> <code>float</code> <p>Minimum value for color normalization.</p> required <code>vmax</code> <code>float</code> <p>Maximum value for color normalization.</p> required <code>cmap</code> <code>str</code> <p>Colormap name or matplotlib colormap object.</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to sns.swarmplot.</p> <code>{}</code> <p>Returns:</p> Type Description <p>matplotlib.figure.Figure: The figure containing the swarm plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n&gt;&gt;&gt; y = [1, 2, 3, 4]\n&gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n&gt;&gt;&gt; fig = swarmplot_without_legend(\n...     x, y, hue,\n...     vmin=0, vmax=1,\n...     cmap='viridis'\n... )\n</code></pre> Source code in <code>hydroutils/hydro_plot.py</code> <pre><code>def swarmplot_without_legend(x, y, hue, vmin, vmax, cmap, **kwargs):\n    \"\"\"Creates a swarm plot using seaborn with colorbar instead of legend.\n\n    This function creates a swarm plot where points are colored according to a continuous\n    variable, replacing the default legend with a colorbar for better visualization of\n    the color scale.\n\n    Args:\n        x: Values for x-axis categories.\n        y: Values for y-axis.\n        hue: Values determining the color of each point.\n        vmin (float): Minimum value for color normalization.\n        vmax (float): Maximum value for color normalization.\n        cmap (str): Colormap name or matplotlib colormap object.\n        **kwargs: Additional keyword arguments passed to sns.swarmplot.\n\n    Returns:\n        matplotlib.figure.Figure: The figure containing the swarm plot.\n\n    Examples:\n        &gt;&gt;&gt; x = ['A', 'A', 'B', 'B']\n        &gt;&gt;&gt; y = [1, 2, 3, 4]\n        &gt;&gt;&gt; hue = [0.1, 0.5, 0.8, 0.9]\n        &gt;&gt;&gt; fig = swarmplot_without_legend(\n        ...     x, y, hue,\n        ...     vmin=0, vmax=1,\n        ...     cmap='viridis'\n        ... )\n    \"\"\"\n    fig = plt.gcf()\n    ax = sns.swarmplot(x, y, hue, **kwargs)\n    # remove the legend, because we want to set a colorbar instead\n    ax.legend().remove()\n    norm = plt.Normalize(vmin, vmax)\n    sm = ScalarMappable(norm=norm, cmap=cmap)\n    return fig\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_days_lst2range","title":"<code>t_days_lst2range(t_array)</code>","text":"<p>Transform a period list to its interval. For example,  [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"] -&gt;  [\"2000-01-01\", \"2000-01-04\"] Parameters</p> <p>t_array: list[Union[np.datetime64, str]]     a period list Returns</p> <p>list     An time interval</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_days_lst2range(t_array: list) -&gt; list:\n    \"\"\"\n    Transform a period list to its interval.\n    For example,  [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"] -&gt;  [\"2000-01-01\", \"2000-01-04\"]\n    Parameters\n    ----------\n    t_array: list[Union[np.datetime64, str]]\n        a period list\n    Returns\n    -------\n    list\n        An time interval\n    \"\"\"\n    if type(t_array[0]) == np.datetime64:\n        t0 = t_array[0].astype(datetime.datetime)\n        t1 = t_array[-1].astype(datetime.datetime)\n    else:\n        t0 = t_array[0]\n        t1 = t_array[-1]\n    sd = t0.strftime(\"%Y-%m-%d\")\n    ed = t1.strftime(\"%Y-%m-%d\")\n    return [sd, ed]\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_days","title":"<code>t_range_days(t_range, *, step=np.timedelta64(1, 'D'))</code>","text":"<p>Transform the two-value t_range list to a uniformly-spaced list (default is a daily list). For example, [\"2000-01-01\", \"2000-01-05\"] -&gt; [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"] Parameters</p> <p>t_range     two-value t_range list step     the time interval; its default value is 1 day Returns</p> <p>np.array     a uniformly-spaced (daily) list</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_days(t_range, *, step=np.timedelta64(1, \"D\")) -&gt; np.array:\n    \"\"\"\n    Transform the two-value t_range list to a uniformly-spaced list (default is a daily list).\n    For example, [\"2000-01-01\", \"2000-01-05\"] -&gt; [\"2000-01-01\", \"2000-01-02\", \"2000-01-03\", \"2000-01-04\"]\n    Parameters\n    ----------\n    t_range\n        two-value t_range list\n    step\n        the time interval; its default value is 1 day\n    Returns\n    -------\n    np.array\n        a uniformly-spaced (daily) list\n    \"\"\"\n    sd = datetime.datetime.strptime(t_range[0], \"%Y-%m-%d\")\n    ed = datetime.datetime.strptime(t_range[1], \"%Y-%m-%d\")\n    return np.arange(sd, ed, step)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_days_timedelta","title":"<code>t_range_days_timedelta(t_array, td=12, td_type='h')</code>","text":"<p>for each day, add a timedelta Parameters</p> <p>t_array     its data type is same as the return type of \"t_range_days\" function td     time periods td_type     the type of time period Returns</p> <p>np.array     a new t_array</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_days_timedelta(t_array, td=12, td_type=\"h\"):\n    \"\"\"\n    for each day, add a timedelta\n    Parameters\n    ----------\n    t_array\n        its data type is same as the return type of \"t_range_days\" function\n    td\n        time periods\n    td_type\n        the type of time period\n    Returns\n    -------\n    np.array\n        a new t_array\n    \"\"\"\n    assert td_type in [\"Y\", \"M\", \"D\", \"h\", \"m\", \"s\"]\n    t_array_final = [t + np.timedelta64(td, td_type) for t in t_array]\n    return np.array(t_array_final)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.t_range_years","title":"<code>t_range_years(t_range)</code>","text":"<p>t_range is a left-closed and right-open interval, if t_range[1] is not Jan.1 then end_year should be included</p> Source code in <code>hydroutils/hydro_time.py</code> <pre><code>def t_range_years(t_range):\n    \"\"\"t_range is a left-closed and right-open interval, if t_range[1] is not Jan.1 then end_year should be included\"\"\"\n    start_year = int(t_range[0].split(\"-\")[0])\n    end_year = int(t_range[1].split(\"-\")[0])\n    end_month = int(t_range[1].split(\"-\")[1])\n    end_day = int(t_range[1].split(\"-\")[2])\n    return (\n        np.arange(start_year, end_year)\n        if end_month == 1 and end_day == 1\n        else np.arange(start_year, end_year + 1)\n    )\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.trans_norm","title":"<code>trans_norm(x, var_lst, stat_dict, *, to_norm)</code>","text":"<p>normalization, including denormalization code</p>"},{"location":"api/hydroutils/#hydroutils.trans_norm--parameters","title":"Parameters","text":"<p>x     2d or 3d data     2d: 1st-sites, 2nd-var type     3d: 1st-sites, 2nd-time, 3rd-var type var_lst     variables stat_dict     a dict with statistics info to_norm     if True, normalization; else denormalization</p>"},{"location":"api/hydroutils/#hydroutils.trans_norm--returns","title":"Returns","text":"<p>np.array     normalized/denormalized data</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def trans_norm(x, var_lst, stat_dict, *, to_norm):\n    \"\"\"\n    normalization, including denormalization code\n\n    Parameters\n    ----------\n    x\n        2d or 3d data\n        2d: 1st-sites, 2nd-var type\n        3d: 1st-sites, 2nd-time, 3rd-var type\n    var_lst\n        variables\n    stat_dict\n        a dict with statistics info\n    to_norm\n        if True, normalization; else denormalization\n\n    Returns\n    -------\n    np.array\n        normalized/denormalized data\n    \"\"\"\n    if type(var_lst) is str:\n        var_lst = [var_lst]\n    out = np.zeros(x.shape)\n    for k in range(len(var_lst)):\n        var = var_lst[k]\n        stat = stat_dict[var]\n        if to_norm is True:\n            if len(x.shape) == 3:\n                out[:, :, k] = (x[:, :, k] - stat[2]) / stat[3]\n            elif len(x.shape) == 2:\n                out[:, k] = (x[:, k] - stat[2]) / stat[3]\n        elif len(x.shape) == 3:\n            out[:, :, k] = x[:, :, k] * stat[3] + stat[2]\n        elif len(x.shape) == 2:\n            out[:, k] = x[:, k] * stat[3] + stat[2]\n    return out\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unzip_file","title":"<code>unzip_file(data_zip, path_unzip)</code>","text":"<p>extract a zip file</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unzip_file(data_zip, path_unzip):\n    \"\"\"extract a zip file\"\"\"\n    with zipfile.ZipFile(data_zip, \"r\") as zip_temp:\n        zip_temp.extractall(path_unzip)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.unzip_nested_zip","title":"<code>unzip_nested_zip(dataset_zip, path_unzip)</code>","text":"<p>Extract a zip file including any nested zip files If a file's name is \"xxx_\", it seems the \"extractall\" function in the \"zipfile\" lib will throw an OSError, so please check the unzipped files manually when this occurs. Parameters</p> <p>dataset_zip: the zip file path_unzip: where it is unzipped</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def unzip_nested_zip(dataset_zip, path_unzip):\n    \"\"\"\n    Extract a zip file including any nested zip files\n    If a file's name is \"xxx_\", it seems the \"extractall\" function in the \"zipfile\" lib will throw an OSError,\n    so please check the unzipped files manually when this occurs.\n    Parameters\n    ----------\n    dataset_zip: the zip file\n    path_unzip: where it is unzipped\n    \"\"\"\n\n    with zipfile.ZipFile(dataset_zip, \"r\") as zfile:\n        try:\n            zfile.extractall(path=path_unzip)\n        except OSError as e:\n            logging.warning(\n                \"Please check the unzipped files manually. There may be some missed important files.\"\n            )\n            logging.warning(f\"The directory is: {path_unzip}\")\n            logging.warning(f\"Error message: {e}\")\n    for root, dirs, files in os.walk(path_unzip):\n        for filename in files:\n            if re.search(r\"\\.zip$\", filename):\n                file_spec = os.path.join(root, filename)\n                new_dir = os.path.join(root, filename[:-4])\n                unzip_nested_zip(file_spec, new_dir)\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.wilcoxon_t_test","title":"<code>wilcoxon_t_test(xs, xo)</code>","text":"<p>Wilcoxon t test</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def wilcoxon_t_test(xs, xo):\n    \"\"\"Wilcoxon t test\"\"\"\n    diff = xs - xo  # same result when using xo-xs\n    w, p = wilcoxon(diff)\n    return w, p\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.wilcoxon_t_test_for_lst","title":"<code>wilcoxon_t_test_for_lst(x_lst, rnd_num=2)</code>","text":"<p>Wilcoxon t test for every two array in a 2-d array</p> Source code in <code>hydroutils/hydro_stat.py</code> <pre><code>def wilcoxon_t_test_for_lst(x_lst, rnd_num=2):\n    \"\"\"Wilcoxon t test for every two array in a 2-d array\"\"\"\n    arr_lst = np.asarray(x_lst)\n    w, p = [], []\n    arr_lst_pair = list(itertools.combinations(arr_lst, 2))\n    for arr_pair in arr_lst_pair:\n        wi, pi = wilcoxon_t_test(arr_pair[0], arr_pair[1])\n        w.append(round(wi, rnd_num))\n        p.append(round(pi, rnd_num))\n    return w, p\n</code></pre>"},{"location":"api/hydroutils/#hydroutils.zip_extract","title":"<code>zip_extract(the_dir)</code>","text":"<p>Extract the downloaded zip files in the_dir</p> Source code in <code>hydroutils/hydro_file.py</code> <pre><code>def zip_extract(the_dir) -&gt; None:\n    \"\"\"Extract the downloaded zip files in the_dir\"\"\"\n    for f in the_dir.glob(\"*.zip\"):\n        with zipfile.ZipFile(f) as zf:\n            # extract files to a directory named by f.stem\n            zf.extractall(the_dir.joinpath(f.stem))\n</code></pre>"},{"location":"api/hydroutils/#submodules","title":"Submodules","text":"<p>The <code>hydroutils</code> package consists of several specialized modules:</p> <ul> <li>hydro_stat - Statistical analysis and performance metrics</li> <li>hydro_plot - Visualization tools for hydrological data  </li> <li>hydro_time - Time series processing utilities</li> <li>hydro_file - File I/O operations</li> <li>hydro_arithmetric - Mathematical operations</li> <li>hydro_s3 - AWS S3 integration</li> <li>hydro_log - Logging utilities</li> </ul> <p>Click on any module above for detailed function documentation.</p>"}]}